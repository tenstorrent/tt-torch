module {
  func.func @main(%arg0: tensor<1x3x480x640xbf16>, %arg1: tensor<64x3x7x7xbf16>, %arg2: tensor<64xbf16>, %arg3: tensor<64xbf16>, %arg4: tensor<64xbf16>, %arg5: tensor<64xbf16>, %arg6: tensor<64xbf16>, %arg7: tensor<64x64x8x8xbf16>, %arg8: tensor<64xbf16>, %arg9: tensor<64xbf16>, %arg10: tensor<64xbf16>, %arg11: tensor<64xbf16>, %arg12: tensor<64xbf16>, %arg13: tensor<256x1x3x3xbf16>, %arg14: tensor<256xbf16>, %arg15: tensor<64xbf16>, %arg16: tensor<64xbf16>, %arg17: tensor<64xbf16>, %arg18: tensor<64x64x8x8xbf16>, %arg19: tensor<64xbf16>, %arg20: tensor<64xbf16>, %arg21: tensor<64xbf16>, %arg22: tensor<64xbf16>, %arg23: tensor<64xbf16>, %arg24: tensor<256x1x3x3xbf16>, %arg25: tensor<256xbf16>, %arg26: tensor<64xbf16>, %arg27: tensor<64xbf16>, %arg28: tensor<64xbf16>, %arg29: tensor<64x64x8x8xbf16>, %arg30: tensor<64xbf16>, %arg31: tensor<64xbf16>, %arg32: tensor<64xbf16>, %arg33: tensor<64xbf16>, %arg34: tensor<64xbf16>, %arg35: tensor<256x1x3x3xbf16>, %arg36: tensor<256xbf16>, %arg37: tensor<64xbf16>, %arg38: tensor<64xbf16>, %arg39: tensor<64xbf16>, %arg40: tensor<128x64x3x3xbf16>, %arg41: tensor<128xbf16>, %arg42: tensor<128xbf16>, %arg43: tensor<128xbf16>, %arg44: tensor<128xbf16>, %arg45: tensor<128xbf16>, %arg46: tensor<128x128x4x4xbf16>, %arg47: tensor<128xbf16>, %arg48: tensor<128xbf16>, %arg49: tensor<128xbf16>, %arg50: tensor<128xbf16>, %arg51: tensor<128xbf16>, %arg52: tensor<512x1x3x3xbf16>, %arg53: tensor<512xbf16>, %arg54: tensor<128xbf16>, %arg55: tensor<128xbf16>, %arg56: tensor<128xbf16>, %arg57: tensor<128x128x4x4xbf16>, %arg58: tensor<128xbf16>, %arg59: tensor<128xbf16>, %arg60: tensor<128xbf16>, %arg61: tensor<128xbf16>, %arg62: tensor<128xbf16>, %arg63: tensor<512x1x3x3xbf16>, %arg64: tensor<512xbf16>, %arg65: tensor<128xbf16>, %arg66: tensor<128xbf16>, %arg67: tensor<128xbf16>, %arg68: tensor<128x128x4x4xbf16>, %arg69: tensor<128xbf16>, %arg70: tensor<128xbf16>, %arg71: tensor<128xbf16>, %arg72: tensor<128xbf16>, %arg73: tensor<128xbf16>, %arg74: tensor<512x1x3x3xbf16>, %arg75: tensor<512xbf16>, %arg76: tensor<128xbf16>, %arg77: tensor<128xbf16>, %arg78: tensor<128xbf16>, %arg79: tensor<128x128x4x4xbf16>, %arg80: tensor<128xbf16>, %arg81: tensor<128xbf16>, %arg82: tensor<128xbf16>, %arg83: tensor<128xbf16>, %arg84: tensor<128xbf16>, %arg85: tensor<512x1x3x3xbf16>, %arg86: tensor<512xbf16>, %arg87: tensor<128xbf16>, %arg88: tensor<128xbf16>, %arg89: tensor<128xbf16>, %arg90: tensor<128x128x4x4xbf16>, %arg91: tensor<128xbf16>, %arg92: tensor<128xbf16>, %arg93: tensor<128xbf16>, %arg94: tensor<128xbf16>, %arg95: tensor<128xbf16>, %arg96: tensor<512x1x3x3xbf16>, %arg97: tensor<512xbf16>, %arg98: tensor<128xbf16>, %arg99: tensor<128xbf16>, %arg100: tensor<128xbf16>, %arg101: tensor<128x128x4x4xbf16>, %arg102: tensor<128xbf16>, %arg103: tensor<128xbf16>, %arg104: tensor<128xbf16>, %arg105: tensor<128xbf16>, %arg106: tensor<128xbf16>, %arg107: tensor<512x1x3x3xbf16>, %arg108: tensor<512xbf16>, %arg109: tensor<128xbf16>, %arg110: tensor<128xbf16>, %arg111: tensor<128xbf16>, %arg112: tensor<128x128x4x4xbf16>, %arg113: tensor<128xbf16>, %arg114: tensor<128xbf16>, %arg115: tensor<128xbf16>, %arg116: tensor<128xbf16>, %arg117: tensor<128xbf16>, %arg118: tensor<512x1x3x3xbf16>, %arg119: tensor<512xbf16>, %arg120: tensor<128xbf16>, %arg121: tensor<128xbf16>, %arg122: tensor<128xbf16>, %arg123: tensor<128x128x4x4xbf16>, %arg124: tensor<128xbf16>, %arg125: tensor<128xbf16>, %arg126: tensor<128xbf16>, %arg127: tensor<128xbf16>, %arg128: tensor<128xbf16>, %arg129: tensor<512x1x3x3xbf16>, %arg130: tensor<512xbf16>, %arg131: tensor<128xbf16>, %arg132: tensor<128xbf16>, %arg133: tensor<128xbf16>, %arg134: tensor<320x128x3x3xbf16>, %arg135: tensor<320xbf16>, %arg136: tensor<320xbf16>, %arg137: tensor<320xbf16>, %arg138: tensor<320xbf16>, %arg139: tensor<320xbf16>, %arg140: tensor<320x320x2x2xbf16>, %arg141: tensor<320xbf16>, %arg142: tensor<320xbf16>, %arg143: tensor<320xbf16>, %arg144: tensor<320xbf16>, %arg145: tensor<320xbf16>, %arg146: tensor<1280x1x3x3xbf16>, %arg147: tensor<1280xbf16>, %arg148: tensor<320xbf16>, %arg149: tensor<320xbf16>, %arg150: tensor<320xbf16>, %arg151: tensor<320x320x2x2xbf16>, %arg152: tensor<320xbf16>, %arg153: tensor<320xbf16>, %arg154: tensor<320xbf16>, %arg155: tensor<320xbf16>, %arg156: tensor<320xbf16>, %arg157: tensor<1280x1x3x3xbf16>, %arg158: tensor<1280xbf16>, %arg159: tensor<320xbf16>, %arg160: tensor<320xbf16>, %arg161: tensor<320xbf16>, %arg162: tensor<320x320x2x2xbf16>, %arg163: tensor<320xbf16>, %arg164: tensor<320xbf16>, %arg165: tensor<320xbf16>, %arg166: tensor<320xbf16>, %arg167: tensor<320xbf16>, %arg168: tensor<1280x1x3x3xbf16>, %arg169: tensor<1280xbf16>, %arg170: tensor<320xbf16>, %arg171: tensor<320xbf16>, %arg172: tensor<320xbf16>, %arg173: tensor<320x320x2x2xbf16>, %arg174: tensor<320xbf16>, %arg175: tensor<320xbf16>, %arg176: tensor<320xbf16>, %arg177: tensor<320xbf16>, %arg178: tensor<320xbf16>, %arg179: tensor<1280x1x3x3xbf16>, %arg180: tensor<1280xbf16>, %arg181: tensor<320xbf16>, %arg182: tensor<320xbf16>, %arg183: tensor<320xbf16>, %arg184: tensor<320x320x2x2xbf16>, %arg185: tensor<320xbf16>, %arg186: tensor<320xbf16>, %arg187: tensor<320xbf16>, %arg188: tensor<320xbf16>, %arg189: tensor<320xbf16>, %arg190: tensor<1280x1x3x3xbf16>, %arg191: tensor<1280xbf16>, %arg192: tensor<320xbf16>, %arg193: tensor<320xbf16>, %arg194: tensor<320xbf16>, %arg195: tensor<320x320x2x2xbf16>, %arg196: tensor<320xbf16>, %arg197: tensor<320xbf16>, %arg198: tensor<320xbf16>, %arg199: tensor<320xbf16>, %arg200: tensor<320xbf16>, %arg201: tensor<1280x1x3x3xbf16>, %arg202: tensor<1280xbf16>, %arg203: tensor<320xbf16>, %arg204: tensor<320xbf16>, %arg205: tensor<320xbf16>, %arg206: tensor<320x320x2x2xbf16>, %arg207: tensor<320xbf16>, %arg208: tensor<320xbf16>, %arg209: tensor<320xbf16>, %arg210: tensor<320xbf16>, %arg211: tensor<320xbf16>, %arg212: tensor<1280x1x3x3xbf16>, %arg213: tensor<1280xbf16>, %arg214: tensor<320xbf16>, %arg215: tensor<320xbf16>, %arg216: tensor<320xbf16>, %arg217: tensor<320x320x2x2xbf16>, %arg218: tensor<320xbf16>, %arg219: tensor<320xbf16>, %arg220: tensor<320xbf16>, %arg221: tensor<320xbf16>, %arg222: tensor<320xbf16>, %arg223: tensor<1280x1x3x3xbf16>, %arg224: tensor<1280xbf16>, %arg225: tensor<320xbf16>, %arg226: tensor<320xbf16>, %arg227: tensor<320xbf16>, %arg228: tensor<320x320x2x2xbf16>, %arg229: tensor<320xbf16>, %arg230: tensor<320xbf16>, %arg231: tensor<320xbf16>, %arg232: tensor<320xbf16>, %arg233: tensor<320xbf16>, %arg234: tensor<1280x1x3x3xbf16>, %arg235: tensor<1280xbf16>, %arg236: tensor<320xbf16>, %arg237: tensor<320xbf16>, %arg238: tensor<320xbf16>, %arg239: tensor<320x320x2x2xbf16>, %arg240: tensor<320xbf16>, %arg241: tensor<320xbf16>, %arg242: tensor<320xbf16>, %arg243: tensor<320xbf16>, %arg244: tensor<320xbf16>, %arg245: tensor<1280x1x3x3xbf16>, %arg246: tensor<1280xbf16>, %arg247: tensor<320xbf16>, %arg248: tensor<320xbf16>, %arg249: tensor<320xbf16>, %arg250: tensor<320x320x2x2xbf16>, %arg251: tensor<320xbf16>, %arg252: tensor<320xbf16>, %arg253: tensor<320xbf16>, %arg254: tensor<320xbf16>, %arg255: tensor<320xbf16>, %arg256: tensor<1280x1x3x3xbf16>, %arg257: tensor<1280xbf16>, %arg258: tensor<320xbf16>, %arg259: tensor<320xbf16>, %arg260: tensor<320xbf16>, %arg261: tensor<320x320x2x2xbf16>, %arg262: tensor<320xbf16>, %arg263: tensor<320xbf16>, %arg264: tensor<320xbf16>, %arg265: tensor<320xbf16>, %arg266: tensor<320xbf16>, %arg267: tensor<1280x1x3x3xbf16>, %arg268: tensor<1280xbf16>, %arg269: tensor<320xbf16>, %arg270: tensor<320xbf16>, %arg271: tensor<320xbf16>, %arg272: tensor<320x320x2x2xbf16>, %arg273: tensor<320xbf16>, %arg274: tensor<320xbf16>, %arg275: tensor<320xbf16>, %arg276: tensor<320xbf16>, %arg277: tensor<320xbf16>, %arg278: tensor<1280x1x3x3xbf16>, %arg279: tensor<1280xbf16>, %arg280: tensor<320xbf16>, %arg281: tensor<320xbf16>, %arg282: tensor<320xbf16>, %arg283: tensor<320x320x2x2xbf16>, %arg284: tensor<320xbf16>, %arg285: tensor<320xbf16>, %arg286: tensor<320xbf16>, %arg287: tensor<320xbf16>, %arg288: tensor<320xbf16>, %arg289: tensor<1280x1x3x3xbf16>, %arg290: tensor<1280xbf16>, %arg291: tensor<320xbf16>, %arg292: tensor<320xbf16>, %arg293: tensor<320xbf16>, %arg294: tensor<320x320x2x2xbf16>, %arg295: tensor<320xbf16>, %arg296: tensor<320xbf16>, %arg297: tensor<320xbf16>, %arg298: tensor<320xbf16>, %arg299: tensor<320xbf16>, %arg300: tensor<1280x1x3x3xbf16>, %arg301: tensor<1280xbf16>, %arg302: tensor<320xbf16>, %arg303: tensor<320xbf16>, %arg304: tensor<320xbf16>, %arg305: tensor<320x320x2x2xbf16>, %arg306: tensor<320xbf16>, %arg307: tensor<320xbf16>, %arg308: tensor<320xbf16>, %arg309: tensor<320xbf16>, %arg310: tensor<320xbf16>, %arg311: tensor<1280x1x3x3xbf16>, %arg312: tensor<1280xbf16>, %arg313: tensor<320xbf16>, %arg314: tensor<320xbf16>, %arg315: tensor<320xbf16>, %arg316: tensor<320x320x2x2xbf16>, %arg317: tensor<320xbf16>, %arg318: tensor<320xbf16>, %arg319: tensor<320xbf16>, %arg320: tensor<320xbf16>, %arg321: tensor<320xbf16>, %arg322: tensor<1280x1x3x3xbf16>, %arg323: tensor<1280xbf16>, %arg324: tensor<320xbf16>, %arg325: tensor<320xbf16>, %arg326: tensor<320xbf16>, %arg327: tensor<320x320x2x2xbf16>, %arg328: tensor<320xbf16>, %arg329: tensor<320xbf16>, %arg330: tensor<320xbf16>, %arg331: tensor<320xbf16>, %arg332: tensor<320xbf16>, %arg333: tensor<1280x1x3x3xbf16>, %arg334: tensor<1280xbf16>, %arg335: tensor<320xbf16>, %arg336: tensor<320xbf16>, %arg337: tensor<320xbf16>, %arg338: tensor<320x320x2x2xbf16>, %arg339: tensor<320xbf16>, %arg340: tensor<320xbf16>, %arg341: tensor<320xbf16>, %arg342: tensor<320xbf16>, %arg343: tensor<320xbf16>, %arg344: tensor<1280x1x3x3xbf16>, %arg345: tensor<1280xbf16>, %arg346: tensor<320xbf16>, %arg347: tensor<320xbf16>, %arg348: tensor<320xbf16>, %arg349: tensor<320x320x2x2xbf16>, %arg350: tensor<320xbf16>, %arg351: tensor<320xbf16>, %arg352: tensor<320xbf16>, %arg353: tensor<320xbf16>, %arg354: tensor<320xbf16>, %arg355: tensor<1280x1x3x3xbf16>, %arg356: tensor<1280xbf16>, %arg357: tensor<320xbf16>, %arg358: tensor<320xbf16>, %arg359: tensor<320xbf16>, %arg360: tensor<320x320x2x2xbf16>, %arg361: tensor<320xbf16>, %arg362: tensor<320xbf16>, %arg363: tensor<320xbf16>, %arg364: tensor<320xbf16>, %arg365: tensor<320xbf16>, %arg366: tensor<1280x1x3x3xbf16>, %arg367: tensor<1280xbf16>, %arg368: tensor<320xbf16>, %arg369: tensor<320xbf16>, %arg370: tensor<320xbf16>, %arg371: tensor<320x320x2x2xbf16>, %arg372: tensor<320xbf16>, %arg373: tensor<320xbf16>, %arg374: tensor<320xbf16>, %arg375: tensor<320xbf16>, %arg376: tensor<320xbf16>, %arg377: tensor<1280x1x3x3xbf16>, %arg378: tensor<1280xbf16>, %arg379: tensor<320xbf16>, %arg380: tensor<320xbf16>, %arg381: tensor<320xbf16>, %arg382: tensor<320x320x2x2xbf16>, %arg383: tensor<320xbf16>, %arg384: tensor<320xbf16>, %arg385: tensor<320xbf16>, %arg386: tensor<320xbf16>, %arg387: tensor<320xbf16>, %arg388: tensor<1280x1x3x3xbf16>, %arg389: tensor<1280xbf16>, %arg390: tensor<320xbf16>, %arg391: tensor<320xbf16>, %arg392: tensor<320xbf16>, %arg393: tensor<320x320x2x2xbf16>, %arg394: tensor<320xbf16>, %arg395: tensor<320xbf16>, %arg396: tensor<320xbf16>, %arg397: tensor<320xbf16>, %arg398: tensor<320xbf16>, %arg399: tensor<1280x1x3x3xbf16>, %arg400: tensor<1280xbf16>, %arg401: tensor<320xbf16>, %arg402: tensor<320xbf16>, %arg403: tensor<320xbf16>, %arg404: tensor<320x320x2x2xbf16>, %arg405: tensor<320xbf16>, %arg406: tensor<320xbf16>, %arg407: tensor<320xbf16>, %arg408: tensor<320xbf16>, %arg409: tensor<320xbf16>, %arg410: tensor<1280x1x3x3xbf16>, %arg411: tensor<1280xbf16>, %arg412: tensor<320xbf16>, %arg413: tensor<320xbf16>, %arg414: tensor<320xbf16>, %arg415: tensor<320x320x2x2xbf16>, %arg416: tensor<320xbf16>, %arg417: tensor<320xbf16>, %arg418: tensor<320xbf16>, %arg419: tensor<320xbf16>, %arg420: tensor<320xbf16>, %arg421: tensor<1280x1x3x3xbf16>, %arg422: tensor<1280xbf16>, %arg423: tensor<320xbf16>, %arg424: tensor<320xbf16>, %arg425: tensor<320xbf16>, %arg426: tensor<320x320x2x2xbf16>, %arg427: tensor<320xbf16>, %arg428: tensor<320xbf16>, %arg429: tensor<320xbf16>, %arg430: tensor<320xbf16>, %arg431: tensor<320xbf16>, %arg432: tensor<1280x1x3x3xbf16>, %arg433: tensor<1280xbf16>, %arg434: tensor<320xbf16>, %arg435: tensor<320xbf16>, %arg436: tensor<320xbf16>, %arg437: tensor<512x320x3x3xbf16>, %arg438: tensor<512xbf16>, %arg439: tensor<512xbf16>, %arg440: tensor<512xbf16>, %arg441: tensor<512xbf16>, %arg442: tensor<512xbf16>, %arg443: tensor<512xbf16>, %arg444: tensor<512xbf16>, %arg445: tensor<2048x1x3x3xbf16>, %arg446: tensor<2048xbf16>, %arg447: tensor<512xbf16>, %arg448: tensor<512xbf16>, %arg449: tensor<512xbf16>, %arg450: tensor<512xbf16>, %arg451: tensor<512xbf16>, %arg452: tensor<2048x1x3x3xbf16>, %arg453: tensor<2048xbf16>, %arg454: tensor<512xbf16>, %arg455: tensor<512xbf16>, %arg456: tensor<512xbf16>, %arg457: tensor<512xbf16>, %arg458: tensor<512xbf16>, %arg459: tensor<2048x1x3x3xbf16>, %arg460: tensor<2048xbf16>, %arg461: tensor<512xbf16>, %arg462: tensor<512xbf16>, %arg463: tensor<512xbf16>, %arg464: tensor<64x512x1x1xbf16>, %arg465: tensor<64xbf16>, %arg466: tensor<64x320x1x1xbf16>, %arg467: tensor<64xbf16>, %arg468: tensor<64x128x3x3xbf16>, %arg469: tensor<64xbf16>, %arg470: tensor<32x64x3x3xbf16>, %arg471: tensor<32xbf16>, %arg472: tensor<2x32x3x3xbf16>, %arg473: tensor<2xbf16>, %arg474: tensor<64x128x1x1xbf16>, %arg475: tensor<64xbf16>, %arg476: tensor<64x128x3x3xbf16>, %arg477: tensor<64xbf16>, %arg478: tensor<32x64x3x3xbf16>, %arg479: tensor<32xbf16>, %arg480: tensor<2x32x3x3xbf16>, %arg481: tensor<2xbf16>, %arg482: tensor<64x128x3x3xbf16>, %arg483: tensor<64xbf16>, %arg484: tensor<32x64x3x3xbf16>, %arg485: tensor<32xbf16>, %arg486: tensor<2x32x3x3xbf16>, %arg487: tensor<2xbf16>, %arg488: tensor<64x64x3x3xbf16>, %arg489: tensor<64xbf16>, %arg490: tensor<1x64x3x3xbf16>, %arg491: tensor<1xbf16>, %arg492: tensor<64x64xf32>, %arg493: tensor<64xf32>, %arg494: tensor<64x64xf32>, %arg495: tensor<64xf32>, %arg496: tensor<64x64xf32>, %arg497: tensor<64xf32>, %arg498: tensor<64x64xf32>, %arg499: tensor<64xf32>, %arg500: tensor<64x256xf32>, %arg501: tensor<256xf32>, %arg502: tensor<256x64xbf16>, %arg503: tensor<64x64xf32>, %arg504: tensor<64xf32>, %arg505: tensor<64x64xf32>, %arg506: tensor<64xf32>, %arg507: tensor<64x64xf32>, %arg508: tensor<64xf32>, %arg509: tensor<64x64xf32>, %arg510: tensor<64xf32>, %arg511: tensor<64x256xf32>, %arg512: tensor<256xf32>, %arg513: tensor<256x64xbf16>, %arg514: tensor<64x64xf32>, %arg515: tensor<64xf32>, %arg516: tensor<64x64xf32>, %arg517: tensor<64xf32>, %arg518: tensor<64x64xf32>, %arg519: tensor<64xf32>, %arg520: tensor<64x64xf32>, %arg521: tensor<64xf32>, %arg522: tensor<64x256xf32>, %arg523: tensor<256xf32>, %arg524: tensor<256x64xbf16>, %arg525: tensor<128x128xf32>, %arg526: tensor<128xf32>, %arg527: tensor<128x128xf32>, %arg528: tensor<128xf32>, %arg529: tensor<128x128xf32>, %arg530: tensor<128xf32>, %arg531: tensor<128x128xf32>, %arg532: tensor<128xf32>, %arg533: tensor<128x512xf32>, %arg534: tensor<512xf32>, %arg535: tensor<512x128xbf16>, %arg536: tensor<128x128xf32>, %arg537: tensor<128xf32>, %arg538: tensor<128x128xf32>, %arg539: tensor<128xf32>, %arg540: tensor<128x128xf32>, %arg541: tensor<128xf32>, %arg542: tensor<128x128xf32>, %arg543: tensor<128xf32>, %arg544: tensor<128x512xf32>, %arg545: tensor<512xf32>, %arg546: tensor<512x128xbf16>, %arg547: tensor<128x128xf32>, %arg548: tensor<128xf32>, %arg549: tensor<128x128xf32>, %arg550: tensor<128xf32>, %arg551: tensor<128x128xf32>, %arg552: tensor<128xf32>, %arg553: tensor<128x128xf32>, %arg554: tensor<128xf32>, %arg555: tensor<128x512xf32>, %arg556: tensor<512xf32>, %arg557: tensor<512x128xbf16>, %arg558: tensor<128x128xf32>, %arg559: tensor<128xf32>, %arg560: tensor<128x128xf32>, %arg561: tensor<128xf32>, %arg562: tensor<128x128xf32>, %arg563: tensor<128xf32>, %arg564: tensor<128x128xf32>, %arg565: tensor<128xf32>, %arg566: tensor<128x512xf32>, %arg567: tensor<512xf32>, %arg568: tensor<512x128xbf16>, %arg569: tensor<128x128xf32>, %arg570: tensor<128xf32>, %arg571: tensor<128x128xf32>, %arg572: tensor<128xf32>, %arg573: tensor<128x128xf32>, %arg574: tensor<128xf32>, %arg575: tensor<128x128xf32>, %arg576: tensor<128xf32>, %arg577: tensor<128x512xf32>, %arg578: tensor<512xf32>, %arg579: tensor<512x128xbf16>, %arg580: tensor<128x128xf32>, %arg581: tensor<128xf32>, %arg582: tensor<128x128xf32>, %arg583: tensor<128xf32>, %arg584: tensor<128x128xf32>, %arg585: tensor<128xf32>, %arg586: tensor<128x128xf32>, %arg587: tensor<128xf32>, %arg588: tensor<128x512xf32>, %arg589: tensor<512xf32>, %arg590: tensor<512x128xbf16>, %arg591: tensor<128x128xf32>, %arg592: tensor<128xf32>, %arg593: tensor<128x128xf32>, %arg594: tensor<128xf32>, %arg595: tensor<128x128xf32>, %arg596: tensor<128xf32>, %arg597: tensor<128x128xf32>, %arg598: tensor<128xf32>, %arg599: tensor<128x512xf32>, %arg600: tensor<512xf32>, %arg601: tensor<512x128xbf16>, %arg602: tensor<128x128xf32>, %arg603: tensor<128xf32>, %arg604: tensor<128x128xf32>, %arg605: tensor<128xf32>, %arg606: tensor<128x128xf32>, %arg607: tensor<128xf32>, %arg608: tensor<128x128xf32>, %arg609: tensor<128xf32>, %arg610: tensor<128x512xf32>, %arg611: tensor<512xf32>, %arg612: tensor<512x128xbf16>, %arg613: tensor<320x320xf32>, %arg614: tensor<320xf32>, %arg615: tensor<320x320xf32>, %arg616: tensor<320xf32>, %arg617: tensor<320x320xf32>, %arg618: tensor<320xf32>, %arg619: tensor<320x320xf32>, %arg620: tensor<320xf32>, %arg621: tensor<320x1280xf32>, %arg622: tensor<1280xf32>, %arg623: tensor<1280x320xbf16>, %arg624: tensor<320x320xf32>, %arg625: tensor<320xf32>, %arg626: tensor<320x320xf32>, %arg627: tensor<320xf32>, %arg628: tensor<320x320xf32>, %arg629: tensor<320xf32>, %arg630: tensor<320x320xf32>, %arg631: tensor<320xf32>, %arg632: tensor<320x1280xf32>, %arg633: tensor<1280xf32>, %arg634: tensor<1280x320xbf16>, %arg635: tensor<320x320xf32>, %arg636: tensor<320xf32>, %arg637: tensor<320x320xf32>, %arg638: tensor<320xf32>, %arg639: tensor<320x320xf32>, %arg640: tensor<320xf32>, %arg641: tensor<320x320xf32>, %arg642: tensor<320xf32>, %arg643: tensor<320x1280xf32>, %arg644: tensor<1280xf32>, %arg645: tensor<1280x320xbf16>, %arg646: tensor<320x320xf32>, %arg647: tensor<320xf32>, %arg648: tensor<320x320xf32>, %arg649: tensor<320xf32>, %arg650: tensor<320x320xf32>, %arg651: tensor<320xf32>, %arg652: tensor<320x320xf32>, %arg653: tensor<320xf32>, %arg654: tensor<320x1280xf32>, %arg655: tensor<1280xf32>, %arg656: tensor<1280x320xbf16>, %arg657: tensor<320x320xf32>, %arg658: tensor<320xf32>, %arg659: tensor<320x320xf32>, %arg660: tensor<320xf32>, %arg661: tensor<320x320xf32>, %arg662: tensor<320xf32>, %arg663: tensor<320x320xf32>, %arg664: tensor<320xf32>, %arg665: tensor<320x1280xf32>, %arg666: tensor<1280xf32>, %arg667: tensor<1280x320xbf16>, %arg668: tensor<320x320xf32>, %arg669: tensor<320xf32>, %arg670: tensor<320x320xf32>, %arg671: tensor<320xf32>, %arg672: tensor<320x320xf32>, %arg673: tensor<320xf32>, %arg674: tensor<320x320xf32>, %arg675: tensor<320xf32>, %arg676: tensor<320x1280xf32>, %arg677: tensor<1280xf32>, %arg678: tensor<1280x320xbf16>, %arg679: tensor<320x320xf32>, %arg680: tensor<320xf32>, %arg681: tensor<320x320xf32>, %arg682: tensor<320xf32>, %arg683: tensor<320x320xf32>, %arg684: tensor<320xf32>, %arg685: tensor<320x320xf32>, %arg686: tensor<320xf32>, %arg687: tensor<320x1280xf32>, %arg688: tensor<1280xf32>, %arg689: tensor<1280x320xbf16>, %arg690: tensor<320x320xf32>, %arg691: tensor<320xf32>, %arg692: tensor<320x320xf32>, %arg693: tensor<320xf32>, %arg694: tensor<320x320xf32>, %arg695: tensor<320xf32>, %arg696: tensor<320x320xf32>, %arg697: tensor<320xf32>, %arg698: tensor<320x1280xf32>, %arg699: tensor<1280xf32>, %arg700: tensor<1280x320xbf16>, %arg701: tensor<320x320xf32>, %arg702: tensor<320xf32>, %arg703: tensor<320x320xf32>, %arg704: tensor<320xf32>, %arg705: tensor<320x320xf32>, %arg706: tensor<320xf32>, %arg707: tensor<320x320xf32>, %arg708: tensor<320xf32>, %arg709: tensor<320x1280xf32>, %arg710: tensor<1280xf32>, %arg711: tensor<1280x320xbf16>, %arg712: tensor<320x320xf32>, %arg713: tensor<320xf32>, %arg714: tensor<320x320xf32>, %arg715: tensor<320xf32>, %arg716: tensor<320x320xf32>, %arg717: tensor<320xf32>, %arg718: tensor<320x320xf32>, %arg719: tensor<320xf32>, %arg720: tensor<320x1280xf32>, %arg721: tensor<1280xf32>, %arg722: tensor<1280x320xbf16>, %arg723: tensor<320x320xf32>, %arg724: tensor<320xf32>, %arg725: tensor<320x320xf32>, %arg726: tensor<320xf32>, %arg727: tensor<320x320xf32>, %arg728: tensor<320xf32>, %arg729: tensor<320x320xf32>, %arg730: tensor<320xf32>, %arg731: tensor<320x1280xf32>, %arg732: tensor<1280xf32>, %arg733: tensor<1280x320xbf16>, %arg734: tensor<320x320xf32>, %arg735: tensor<320xf32>, %arg736: tensor<320x320xf32>, %arg737: tensor<320xf32>, %arg738: tensor<320x320xf32>, %arg739: tensor<320xf32>, %arg740: tensor<320x320xf32>, %arg741: tensor<320xf32>, %arg742: tensor<320x1280xf32>, %arg743: tensor<1280xf32>, %arg744: tensor<1280x320xbf16>, %arg745: tensor<320x320xf32>, %arg746: tensor<320xf32>, %arg747: tensor<320x320xf32>, %arg748: tensor<320xf32>, %arg749: tensor<320x320xf32>, %arg750: tensor<320xf32>, %arg751: tensor<320x320xf32>, %arg752: tensor<320xf32>, %arg753: tensor<320x1280xf32>, %arg754: tensor<1280xf32>, %arg755: tensor<1280x320xbf16>, %arg756: tensor<320x320xf32>, %arg757: tensor<320xf32>, %arg758: tensor<320x320xf32>, %arg759: tensor<320xf32>, %arg760: tensor<320x320xf32>, %arg761: tensor<320xf32>, %arg762: tensor<320x320xf32>, %arg763: tensor<320xf32>, %arg764: tensor<320x1280xf32>, %arg765: tensor<1280xf32>, %arg766: tensor<1280x320xbf16>, %arg767: tensor<320x320xf32>, %arg768: tensor<320xf32>, %arg769: tensor<320x320xf32>, %arg770: tensor<320xf32>, %arg771: tensor<320x320xf32>, %arg772: tensor<320xf32>, %arg773: tensor<320x320xf32>, %arg774: tensor<320xf32>, %arg775: tensor<320x1280xf32>, %arg776: tensor<1280xf32>, %arg777: tensor<1280x320xbf16>, %arg778: tensor<320x320xf32>, %arg779: tensor<320xf32>, %arg780: tensor<320x320xf32>, %arg781: tensor<320xf32>, %arg782: tensor<320x320xf32>, %arg783: tensor<320xf32>, %arg784: tensor<320x320xf32>, %arg785: tensor<320xf32>, %arg786: tensor<320x1280xf32>, %arg787: tensor<1280xf32>, %arg788: tensor<1280x320xbf16>, %arg789: tensor<320x320xf32>, %arg790: tensor<320xf32>, %arg791: tensor<320x320xf32>, %arg792: tensor<320xf32>, %arg793: tensor<320x320xf32>, %arg794: tensor<320xf32>, %arg795: tensor<320x320xf32>, %arg796: tensor<320xf32>, %arg797: tensor<320x1280xf32>, %arg798: tensor<1280xf32>, %arg799: tensor<1280x320xbf16>, %arg800: tensor<320x320xf32>, %arg801: tensor<320xf32>, %arg802: tensor<320x320xf32>, %arg803: tensor<320xf32>, %arg804: tensor<320x320xf32>, %arg805: tensor<320xf32>, %arg806: tensor<320x320xf32>, %arg807: tensor<320xf32>, %arg808: tensor<320x1280xf32>, %arg809: tensor<1280xf32>, %arg810: tensor<1280x320xbf16>, %arg811: tensor<320x320xf32>, %arg812: tensor<320xf32>, %arg813: tensor<320x320xf32>, %arg814: tensor<320xf32>, %arg815: tensor<320x320xf32>, %arg816: tensor<320xf32>, %arg817: tensor<320x320xf32>, %arg818: tensor<320xf32>, %arg819: tensor<320x1280xf32>, %arg820: tensor<1280xf32>, %arg821: tensor<1280x320xbf16>, %arg822: tensor<320x320xf32>, %arg823: tensor<320xf32>, %arg824: tensor<320x320xf32>, %arg825: tensor<320xf32>, %arg826: tensor<320x320xf32>, %arg827: tensor<320xf32>, %arg828: tensor<320x320xf32>, %arg829: tensor<320xf32>, %arg830: tensor<320x1280xf32>, %arg831: tensor<1280xf32>, %arg832: tensor<1280x320xbf16>, %arg833: tensor<320x320xf32>, %arg834: tensor<320xf32>, %arg835: tensor<320x320xf32>, %arg836: tensor<320xf32>, %arg837: tensor<320x320xf32>, %arg838: tensor<320xf32>, %arg839: tensor<320x320xf32>, %arg840: tensor<320xf32>, %arg841: tensor<320x1280xf32>, %arg842: tensor<1280xf32>, %arg843: tensor<1280x320xbf16>, %arg844: tensor<320x320xf32>, %arg845: tensor<320xf32>, %arg846: tensor<320x320xf32>, %arg847: tensor<320xf32>, %arg848: tensor<320x320xf32>, %arg849: tensor<320xf32>, %arg850: tensor<320x320xf32>, %arg851: tensor<320xf32>, %arg852: tensor<320x1280xf32>, %arg853: tensor<1280xf32>, %arg854: tensor<1280x320xbf16>, %arg855: tensor<320x320xf32>, %arg856: tensor<320xf32>, %arg857: tensor<320x320xf32>, %arg858: tensor<320xf32>, %arg859: tensor<320x320xf32>, %arg860: tensor<320xf32>, %arg861: tensor<320x320xf32>, %arg862: tensor<320xf32>, %arg863: tensor<320x1280xf32>, %arg864: tensor<1280xf32>, %arg865: tensor<1280x320xbf16>, %arg866: tensor<320x320xf32>, %arg867: tensor<320xf32>, %arg868: tensor<320x320xf32>, %arg869: tensor<320xf32>, %arg870: tensor<320x320xf32>, %arg871: tensor<320xf32>, %arg872: tensor<320x320xf32>, %arg873: tensor<320xf32>, %arg874: tensor<320x1280xf32>, %arg875: tensor<1280xf32>, %arg876: tensor<1280x320xbf16>, %arg877: tensor<320x320xf32>, %arg878: tensor<320xf32>, %arg879: tensor<320x320xf32>, %arg880: tensor<320xf32>, %arg881: tensor<320x320xf32>, %arg882: tensor<320xf32>, %arg883: tensor<320x320xf32>, %arg884: tensor<320xf32>, %arg885: tensor<320x1280xf32>, %arg886: tensor<1280xf32>, %arg887: tensor<1280x320xbf16>, %arg888: tensor<320x320xf32>, %arg889: tensor<320xf32>, %arg890: tensor<320x320xf32>, %arg891: tensor<320xf32>, %arg892: tensor<320x320xf32>, %arg893: tensor<320xf32>, %arg894: tensor<320x320xf32>, %arg895: tensor<320xf32>, %arg896: tensor<320x1280xf32>, %arg897: tensor<1280xf32>, %arg898: tensor<1280x320xbf16>, %arg899: tensor<320x320xf32>, %arg900: tensor<320xf32>, %arg901: tensor<320x320xf32>, %arg902: tensor<320xf32>, %arg903: tensor<320x320xf32>, %arg904: tensor<320xf32>, %arg905: tensor<320x320xf32>, %arg906: tensor<320xf32>, %arg907: tensor<320x1280xf32>, %arg908: tensor<1280xf32>, %arg909: tensor<1280x320xbf16>, %arg910: tensor<512x512xf32>, %arg911: tensor<512xf32>, %arg912: tensor<512x512xf32>, %arg913: tensor<512xf32>, %arg914: tensor<512x512xf32>, %arg915: tensor<512xf32>, %arg916: tensor<512x512xf32>, %arg917: tensor<512xf32>, %arg918: tensor<512x2048xf32>, %arg919: tensor<2048xf32>, %arg920: tensor<2048x512xbf16>, %arg921: tensor<512x512xf32>, %arg922: tensor<512xf32>, %arg923: tensor<512x512xf32>, %arg924: tensor<512xf32>, %arg925: tensor<512x512xf32>, %arg926: tensor<512xf32>, %arg927: tensor<512x512xf32>, %arg928: tensor<512xf32>, %arg929: tensor<512x2048xf32>, %arg930: tensor<2048xf32>, %arg931: tensor<2048x512xbf16>, %arg932: tensor<512x512xf32>, %arg933: tensor<512xf32>, %arg934: tensor<512x512xf32>, %arg935: tensor<512xf32>, %arg936: tensor<512x512xf32>, %arg937: tensor<512xf32>, %arg938: tensor<512x512xf32>, %arg939: tensor<512xf32>, %arg940: tensor<512x2048xf32>, %arg941: tensor<2048xf32>, %arg942: tensor<2048x512xbf16>, %arg943: tensor<64x15x30xbf16>, %arg944: tensor<64x20x40xbf16>, %arg945: tensor<64x1x1xf32>, %arg946: tensor<64x1x1xf32>, %arg947: tensor<64x1x1xbf16>, %arg948: tensor<64x1x1xbf16>, %arg949: tensor<32x1x1xf32>, %arg950: tensor<32x1x1xf32>, %arg951: tensor<32x1x1xbf16>, %arg952: tensor<32x1x1xbf16>, %arg953: tensor<64x30x60xbf16>, %arg954: tensor<64x40x80xbf16>, %arg955: tensor<64x1x1xf32>, %arg956: tensor<64x1x1xf32>, %arg957: tensor<64x1x1xbf16>, %arg958: tensor<64x1x1xbf16>, %arg959: tensor<32x1x1xf32>, %arg960: tensor<32x1x1xf32>, %arg961: tensor<32x1x1xbf16>, %arg962: tensor<32x1x1xbf16>, %arg963: tensor<64x60x120xbf16>, %arg964: tensor<64x80x160xbf16>, %arg965: tensor<64x1x1xf32>, %arg966: tensor<64x1x1xf32>, %arg967: tensor<64x1x1xbf16>, %arg968: tensor<64x1x1xbf16>, %arg969: tensor<32x1x1xf32>, %arg970: tensor<32x1x1xf32>, %arg971: tensor<32x1x1xbf16>, %arg972: tensor<32x1x1xbf16>, %arg973: tensor<64x120x240xbf16>, %arg974: tensor<64x160x320xbf16>, %arg975: tensor<64x240x480xbf16>, %arg976: tensor<64x320x640xbf16>) -> tensor<1x480x640xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f64>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.000000e+00> : tensor<1x19200x256xbf16>
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<1x19200x256xbf16>
    %cst_4 = stablehlo.constant dense<5.000000e-01> : tensor<1x19200x256xbf16>
    %cst_5 = stablehlo.constant dense<-4.000000e+00> : tensor<1x19200x256xf32>
    %cst_6 = stablehlo.constant dense<4.000000e+00> : tensor<1x19200x256xf32>
    %cst_7 = stablehlo.constant dense<-2.72614237E-10> : tensor<1x19200x256xf32>
    %cst_8 = stablehlo.constant dense<2.77068146E-8> : tensor<1x19200x256xf32>
    %cst_9 = stablehlo.constant dense<-2.10102394E-6> : tensor<1x19200x256xf32>
    %cst_10 = stablehlo.constant dense<-5.69250624E-5> : tensor<1x19200x256xf32>
    %cst_11 = stablehlo.constant dense<-7.34990637E-4> : tensor<1x19200x256xf32>
    %cst_12 = stablehlo.constant dense<-2.954600e-03> : tensor<1x19200x256xf32>
    %cst_13 = stablehlo.constant dense<-0.0160960332> : tensor<1x19200x256xf32>
    %cst_14 = stablehlo.constant dense<-1.45660715E-5> : tensor<1x19200x256xf32>
    %cst_15 = stablehlo.constant dense<-2.13374049E-4> : tensor<1x19200x256xf32>
    %cst_16 = stablehlo.constant dense<-0.00168282702> : tensor<1x19200x256xf32>
    %cst_17 = stablehlo.constant dense<-0.00737332925> : tensor<1x19200x256xf32>
    %cst_18 = stablehlo.constant dense<-0.0142647391> : tensor<1x19200x256xf32>
    %cst_19 = stablehlo.constant dense<-1.000000e+00> : tensor<1x19200x256xf32>
    %cst_20 = stablehlo.constant dense<1.000000e+00> : tensor<1x19200x256xf32>
    %cst_21 = stablehlo.constant dense<1.000000e+00> : tensor<1x4800x512xbf16>
    %cst_22 = stablehlo.constant dense<2.000000e+00> : tensor<1x4800x512xbf16>
    %cst_23 = stablehlo.constant dense<5.000000e-01> : tensor<1x4800x512xbf16>
    %cst_24 = stablehlo.constant dense<-4.000000e+00> : tensor<1x4800x512xf32>
    %cst_25 = stablehlo.constant dense<4.000000e+00> : tensor<1x4800x512xf32>
    %cst_26 = stablehlo.constant dense<-2.72614237E-10> : tensor<1x4800x512xf32>
    %cst_27 = stablehlo.constant dense<2.77068146E-8> : tensor<1x4800x512xf32>
    %cst_28 = stablehlo.constant dense<-2.10102394E-6> : tensor<1x4800x512xf32>
    %cst_29 = stablehlo.constant dense<-5.69250624E-5> : tensor<1x4800x512xf32>
    %cst_30 = stablehlo.constant dense<-7.34990637E-4> : tensor<1x4800x512xf32>
    %cst_31 = stablehlo.constant dense<-2.954600e-03> : tensor<1x4800x512xf32>
    %cst_32 = stablehlo.constant dense<-0.0160960332> : tensor<1x4800x512xf32>
    %cst_33 = stablehlo.constant dense<-1.45660715E-5> : tensor<1x4800x512xf32>
    %cst_34 = stablehlo.constant dense<-2.13374049E-4> : tensor<1x4800x512xf32>
    %cst_35 = stablehlo.constant dense<-0.00168282702> : tensor<1x4800x512xf32>
    %cst_36 = stablehlo.constant dense<-0.00737332925> : tensor<1x4800x512xf32>
    %cst_37 = stablehlo.constant dense<-0.0142647391> : tensor<1x4800x512xf32>
    %cst_38 = stablehlo.constant dense<-1.000000e+00> : tensor<1x4800x512xf32>
    %cst_39 = stablehlo.constant dense<1.000000e+00> : tensor<1x4800x512xf32>
    %cst_40 = stablehlo.constant dense<1.000000e+00> : tensor<1x1200x1280xbf16>
    %cst_41 = stablehlo.constant dense<2.000000e+00> : tensor<1x1200x1280xbf16>
    %cst_42 = stablehlo.constant dense<5.000000e-01> : tensor<1x1200x1280xbf16>
    %cst_43 = stablehlo.constant dense<-4.000000e+00> : tensor<1x1200x1280xf32>
    %cst_44 = stablehlo.constant dense<4.000000e+00> : tensor<1x1200x1280xf32>
    %cst_45 = stablehlo.constant dense<-2.72614237E-10> : tensor<1x1200x1280xf32>
    %cst_46 = stablehlo.constant dense<2.77068146E-8> : tensor<1x1200x1280xf32>
    %cst_47 = stablehlo.constant dense<-2.10102394E-6> : tensor<1x1200x1280xf32>
    %cst_48 = stablehlo.constant dense<-5.69250624E-5> : tensor<1x1200x1280xf32>
    %cst_49 = stablehlo.constant dense<-7.34990637E-4> : tensor<1x1200x1280xf32>
    %cst_50 = stablehlo.constant dense<-2.954600e-03> : tensor<1x1200x1280xf32>
    %cst_51 = stablehlo.constant dense<-0.0160960332> : tensor<1x1200x1280xf32>
    %cst_52 = stablehlo.constant dense<-1.45660715E-5> : tensor<1x1200x1280xf32>
    %cst_53 = stablehlo.constant dense<-2.13374049E-4> : tensor<1x1200x1280xf32>
    %cst_54 = stablehlo.constant dense<-0.00168282702> : tensor<1x1200x1280xf32>
    %cst_55 = stablehlo.constant dense<-0.00737332925> : tensor<1x1200x1280xf32>
    %cst_56 = stablehlo.constant dense<-0.0142647391> : tensor<1x1200x1280xf32>
    %cst_57 = stablehlo.constant dense<-1.000000e+00> : tensor<1x1200x1280xf32>
    %cst_58 = stablehlo.constant dense<1.000000e+00> : tensor<1x1200x1280xf32>
    %cst_59 = stablehlo.constant dense<1.000000e+00> : tensor<1x300x2048xbf16>
    %cst_60 = stablehlo.constant dense<2.000000e+00> : tensor<1x300x2048xbf16>
    %cst_61 = stablehlo.constant dense<5.000000e-01> : tensor<1x300x2048xbf16>
    %cst_62 = stablehlo.constant dense<-4.000000e+00> : tensor<1x300x2048xf32>
    %cst_63 = stablehlo.constant dense<4.000000e+00> : tensor<1x300x2048xf32>
    %cst_64 = stablehlo.constant dense<-2.72614237E-10> : tensor<1x300x2048xf32>
    %cst_65 = stablehlo.constant dense<2.77068146E-8> : tensor<1x300x2048xf32>
    %cst_66 = stablehlo.constant dense<-2.10102394E-6> : tensor<1x300x2048xf32>
    %cst_67 = stablehlo.constant dense<-5.69250624E-5> : tensor<1x300x2048xf32>
    %cst_68 = stablehlo.constant dense<-7.34990637E-4> : tensor<1x300x2048xf32>
    %cst_69 = stablehlo.constant dense<-2.954600e-03> : tensor<1x300x2048xf32>
    %cst_70 = stablehlo.constant dense<-0.0160960332> : tensor<1x300x2048xf32>
    %cst_71 = stablehlo.constant dense<-1.45660715E-5> : tensor<1x300x2048xf32>
    %cst_72 = stablehlo.constant dense<-2.13374049E-4> : tensor<1x300x2048xf32>
    %cst_73 = stablehlo.constant dense<-0.00168282702> : tensor<1x300x2048xf32>
    %cst_74 = stablehlo.constant dense<-0.00737332925> : tensor<1x300x2048xf32>
    %cst_75 = stablehlo.constant dense<-0.0142647391> : tensor<1x300x2048xf32>
    %cst_76 = stablehlo.constant dense<-1.000000e+00> : tensor<1x300x2048xf32>
    %cst_77 = stablehlo.constant dense<1.000000e+00> : tensor<1x300x2048xf32>
    %cst_78 = stablehlo.constant dense<0.000000e+00> : tensor<1x64x30x40xbf16>
    %cst_79 = stablehlo.constant dense<0.000000e+00> : tensor<1x32x30x40xbf16>
    %cst_80 = stablehlo.constant dense<0.000000e+00> : tensor<1x64x60x80xbf16>
    %cst_81 = stablehlo.constant dense<0.000000e+00> : tensor<1x32x60x80xbf16>
    %cst_82 = stablehlo.constant dense<0.000000e+00> : tensor<1x64x120x160xbf16>
    %cst_83 = stablehlo.constant dense<0.000000e+00> : tensor<1x32x120x160xbf16>
    %cst_84 = stablehlo.constant dense<0.000000e+00> : tensor<1x64x480x640xbf16>
    %cst_85 = arith.constant dense<64> : tensor<1xi64>
    %cst_86 = arith.constant dense<1.000000e-05> : tensor<1xf64>
    %cst_87 = arith.constant dense<1> : tensor<1xi64>
    %cst_88 = arith.constant dense<8.000000e+00> : tensor<1xf64>
    %cst_89 = arith.constant dense<128> : tensor<1xi64>
    %cst_90 = arith.constant dense<320> : tensor<1xi64>
    %cst_91 = arith.constant dense<512> : tensor<1xi64>
    %cst_92 = arith.constant dense<10> : tensor<1xi64>
    %0 = stablehlo.convolution(%arg0, %arg1) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[3, 3], [3, 3]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x3x480x640xbf16>, tensor<64x3x7x7xbf16>) -> tensor<1x64x120x160xbf16>
    %1 = stablehlo.reshape %arg2 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %2 = stablehlo.broadcast_in_dim %0, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %3 = stablehlo.broadcast_in_dim %1, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x120x160xbf16>
    %4 = stablehlo.add %2, %3 : tensor<1x64x120x160xbf16>
    %5 = stablehlo.reshape %4 : (tensor<1x64x120x160xbf16>) -> tensor<1x64x19200xbf16>
    %6 = stablehlo.transpose %5, dims = [0, 2, 1] : (tensor<1x64x19200xbf16>) -> tensor<1x19200x64xbf16>
    %7 = stablehlo.convert %6 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %8 = stablehlo.convert %7 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %9 = stablehlo.reduce(%8 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %10 = stablehlo.reshape %9 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %11 = stablehlo.convert %cst_85 : (tensor<1xi64>) -> tensor<1xf64>
    %12 = stablehlo.reshape %11 : (tensor<1xf64>) -> tensor<f64>
    %13 = stablehlo.broadcast_in_dim %10, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %14 = stablehlo.broadcast_in_dim %12, dims = [] : (tensor<f64>) -> tensor<1x19200x1xf64>
    %15 = stablehlo.divide %13, %14 : tensor<1x19200x1xf64>
    %16 = stablehlo.broadcast_in_dim %8, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %17 = stablehlo.broadcast_in_dim %15, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %18 = stablehlo.subtract %16, %17 : tensor<1x19200x64xf64>
    %19 = stablehlo.multiply %18, %18 : tensor<1x19200x64xf64>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %21 = stablehlo.reshape %20 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %22 = stablehlo.broadcast_in_dim %21, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %23 = stablehlo.divide %22, %14 : tensor<1x19200x1xf64>
    %24 = stablehlo.convert %23 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %25 = stablehlo.reduce(%7 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %27 = stablehlo.convert %cst_85 : (tensor<1xi64>) -> tensor<1xf32>
    %28 = stablehlo.reshape %27 : (tensor<1xf32>) -> tensor<f32>
    %29 = stablehlo.broadcast_in_dim %26, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %30 = stablehlo.broadcast_in_dim %28, dims = [] : (tensor<f32>) -> tensor<1x19200x1xf32>
    %31 = stablehlo.divide %29, %30 : tensor<1x19200x1xf32>
    %32 = stablehlo.convert %cst_86 : (tensor<1xf64>) -> tensor<1xf32>
    %33 = stablehlo.reshape %32 : (tensor<1xf32>) -> tensor<f32>
    %34 = stablehlo.broadcast_in_dim %24, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %35 = stablehlo.broadcast_in_dim %33, dims = [] : (tensor<f32>) -> tensor<1x19200x1xf32>
    %36 = stablehlo.add %34, %35 : tensor<1x19200x1xf32>
    %37 = stablehlo.rsqrt %36 : tensor<1x19200x1xf32>
    %38 = stablehlo.broadcast_in_dim %7, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %39 = stablehlo.broadcast_in_dim %31, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %40 = stablehlo.subtract %38, %39 : tensor<1x19200x64xf32>
    %41 = stablehlo.broadcast_in_dim %40, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %42 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %43 = stablehlo.multiply %41, %42 : tensor<1x19200x64xf32>
    %44 = stablehlo.convert %arg3 : (tensor<64xbf16>) -> tensor<64xf32>
    %45 = stablehlo.broadcast_in_dim %43, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %46 = stablehlo.broadcast_in_dim %44, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %47 = stablehlo.multiply %45, %46 : tensor<1x19200x64xf32>
    %48 = stablehlo.convert %arg4 : (tensor<64xbf16>) -> tensor<64xf32>
    %49 = stablehlo.broadcast_in_dim %47, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %50 = stablehlo.broadcast_in_dim %48, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %51 = stablehlo.add %49, %50 : tensor<1x19200x64xf32>
    %52 = stablehlo.convert %51 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %53 = stablehlo.convert %52 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %54 = stablehlo.convert %53 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %55 = stablehlo.reduce(%54 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %56 = stablehlo.reshape %55 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %57 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %58 = stablehlo.divide %57, %14 : tensor<1x19200x1xf64>
    %59 = stablehlo.broadcast_in_dim %54, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %60 = stablehlo.broadcast_in_dim %58, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %61 = stablehlo.subtract %59, %60 : tensor<1x19200x64xf64>
    %62 = stablehlo.multiply %61, %61 : tensor<1x19200x64xf64>
    %63 = stablehlo.reduce(%62 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %64 = stablehlo.reshape %63 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %65 = stablehlo.broadcast_in_dim %64, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %66 = stablehlo.divide %65, %14 : tensor<1x19200x1xf64>
    %67 = stablehlo.convert %66 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %68 = stablehlo.reduce(%53 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %69 = stablehlo.reshape %68 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %70 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %71 = stablehlo.divide %70, %30 : tensor<1x19200x1xf32>
    %72 = stablehlo.broadcast_in_dim %67, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %73 = stablehlo.add %72, %35 : tensor<1x19200x1xf32>
    %74 = stablehlo.rsqrt %73 : tensor<1x19200x1xf32>
    %75 = stablehlo.broadcast_in_dim %53, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %76 = stablehlo.broadcast_in_dim %71, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %77 = stablehlo.subtract %75, %76 : tensor<1x19200x64xf32>
    %78 = stablehlo.broadcast_in_dim %77, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %79 = stablehlo.broadcast_in_dim %74, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %80 = stablehlo.multiply %78, %79 : tensor<1x19200x64xf32>
    %81 = stablehlo.convert %arg5 : (tensor<64xbf16>) -> tensor<64xf32>
    %82 = stablehlo.broadcast_in_dim %80, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %83 = stablehlo.broadcast_in_dim %81, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %84 = stablehlo.multiply %82, %83 : tensor<1x19200x64xf32>
    %85 = stablehlo.convert %arg6 : (tensor<64xbf16>) -> tensor<64xf32>
    %86 = stablehlo.broadcast_in_dim %84, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %87 = stablehlo.broadcast_in_dim %85, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %88 = stablehlo.add %86, %87 : tensor<1x19200x64xf32>
    %89 = stablehlo.convert %88 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %90 = stablehlo.reshape %89 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %91 = stablehlo.convert %90 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %92 = stablehlo.dot_general %91, %arg492, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x64xf32>) -> tensor<19200x64xf32>
    %93 = stablehlo.convert %cst_87 : (tensor<1xi64>) -> tensor<1xf32>
    %94 = stablehlo.reshape %93 : (tensor<1xf32>) -> tensor<f32>
    %95 = stablehlo.broadcast_in_dim %92, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %96 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<19200x64xf32>
    %97 = stablehlo.multiply %95, %96 : tensor<19200x64xf32>
    %98 = stablehlo.broadcast_in_dim %97, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %99 = stablehlo.broadcast_in_dim %arg493, dims = [1] : (tensor<64xf32>) -> tensor<19200x64xf32>
    %100 = stablehlo.add %98, %99 : tensor<19200x64xf32>
    %101 = stablehlo.convert %100 : (tensor<19200x64xf32>) -> tensor<19200x64xbf16>
    %102 = stablehlo.reshape %101 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %103 = stablehlo.reshape %102 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x1x64xbf16>
    %104 = stablehlo.transpose %103, dims = [0, 2, 1, 3] : (tensor<1x19200x1x64xbf16>) -> tensor<1x1x19200x64xbf16>
    %105 = stablehlo.transpose %89, dims = [0, 2, 1] : (tensor<1x19200x64xbf16>) -> tensor<1x64x19200xbf16>
    %106 = stablehlo.reshape %105 : (tensor<1x64x19200xbf16>) -> tensor<1x64x120x160xbf16>
    %107 = stablehlo.convolution(%106, %arg7) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [8, 8], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x120x160xbf16>, tensor<64x64x8x8xbf16>) -> tensor<1x64x15x20xbf16>
    %108 = stablehlo.reshape %arg8 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %109 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2, 3] : (tensor<1x64x15x20xbf16>) -> tensor<1x64x15x20xbf16>
    %110 = stablehlo.broadcast_in_dim %108, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x15x20xbf16>
    %111 = stablehlo.add %109, %110 : tensor<1x64x15x20xbf16>
    %112 = stablehlo.reshape %111 : (tensor<1x64x15x20xbf16>) -> tensor<1x64x300xbf16>
    %113 = stablehlo.transpose %112, dims = [0, 2, 1] : (tensor<1x64x300xbf16>) -> tensor<1x300x64xbf16>
    %114 = stablehlo.convert %113 : (tensor<1x300x64xbf16>) -> tensor<1x300x64xf32>
    %115 = stablehlo.convert %114 : (tensor<1x300x64xf32>) -> tensor<1x300x64xf64>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf64>, tensor<f64>) -> tensor<1x300xf64>
    %117 = stablehlo.reshape %116 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %118 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %119 = stablehlo.broadcast_in_dim %12, dims = [] : (tensor<f64>) -> tensor<1x300x1xf64>
    %120 = stablehlo.divide %118, %119 : tensor<1x300x1xf64>
    %121 = stablehlo.broadcast_in_dim %115, dims = [0, 1, 2] : (tensor<1x300x64xf64>) -> tensor<1x300x64xf64>
    %122 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x64xf64>
    %123 = stablehlo.subtract %121, %122 : tensor<1x300x64xf64>
    %124 = stablehlo.multiply %123, %123 : tensor<1x300x64xf64>
    %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf64>, tensor<f64>) -> tensor<1x300xf64>
    %126 = stablehlo.reshape %125 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %128 = stablehlo.divide %127, %119 : tensor<1x300x1xf64>
    %129 = stablehlo.convert %128 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %130 = stablehlo.reduce(%114 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf32>, tensor<f32>) -> tensor<1x300xf32>
    %131 = stablehlo.reshape %130 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %133 = stablehlo.broadcast_in_dim %28, dims = [] : (tensor<f32>) -> tensor<1x300x1xf32>
    %134 = stablehlo.divide %132, %133 : tensor<1x300x1xf32>
    %135 = stablehlo.broadcast_in_dim %129, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %136 = stablehlo.broadcast_in_dim %33, dims = [] : (tensor<f32>) -> tensor<1x300x1xf32>
    %137 = stablehlo.add %135, %136 : tensor<1x300x1xf32>
    %138 = stablehlo.rsqrt %137 : tensor<1x300x1xf32>
    %139 = stablehlo.broadcast_in_dim %114, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %140 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x64xf32>
    %141 = stablehlo.subtract %139, %140 : tensor<1x300x64xf32>
    %142 = stablehlo.broadcast_in_dim %141, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %143 = stablehlo.broadcast_in_dim %138, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x64xf32>
    %144 = stablehlo.multiply %142, %143 : tensor<1x300x64xf32>
    %145 = stablehlo.convert %arg9 : (tensor<64xbf16>) -> tensor<64xf32>
    %146 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %147 = stablehlo.broadcast_in_dim %145, dims = [2] : (tensor<64xf32>) -> tensor<1x300x64xf32>
    %148 = stablehlo.multiply %146, %147 : tensor<1x300x64xf32>
    %149 = stablehlo.convert %arg10 : (tensor<64xbf16>) -> tensor<64xf32>
    %150 = stablehlo.broadcast_in_dim %148, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %151 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<64xf32>) -> tensor<1x300x64xf32>
    %152 = stablehlo.add %150, %151 : tensor<1x300x64xf32>
    %153 = stablehlo.convert %152 : (tensor<1x300x64xf32>) -> tensor<1x300x64xbf16>
    %154 = stablehlo.reshape %153 : (tensor<1x300x64xbf16>) -> tensor<300x64xbf16>
    %155 = stablehlo.convert %154 : (tensor<300x64xbf16>) -> tensor<300x64xf32>
    %156 = stablehlo.dot_general %155, %arg494, contracting_dims = [1] x [0] : (tensor<300x64xf32>, tensor<64x64xf32>) -> tensor<300x64xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %158 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<300x64xf32>
    %159 = stablehlo.multiply %157, %158 : tensor<300x64xf32>
    %160 = stablehlo.broadcast_in_dim %159, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %161 = stablehlo.broadcast_in_dim %arg495, dims = [1] : (tensor<64xf32>) -> tensor<300x64xf32>
    %162 = stablehlo.add %160, %161 : tensor<300x64xf32>
    %163 = stablehlo.convert %162 : (tensor<300x64xf32>) -> tensor<300x64xbf16>
    %164 = stablehlo.reshape %163 : (tensor<300x64xbf16>) -> tensor<1x300x64xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x300x64xbf16>) -> tensor<1x300x1x64xbf16>
    %166 = stablehlo.transpose %165, dims = [0, 2, 1, 3] : (tensor<1x300x1x64xbf16>) -> tensor<1x1x300x64xbf16>
    %167 = stablehlo.dot_general %155, %arg496, contracting_dims = [1] x [0] : (tensor<300x64xf32>, tensor<64x64xf32>) -> tensor<300x64xf32>
    %168 = stablehlo.broadcast_in_dim %167, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %169 = stablehlo.multiply %168, %158 : tensor<300x64xf32>
    %170 = stablehlo.broadcast_in_dim %169, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %171 = stablehlo.broadcast_in_dim %arg497, dims = [1] : (tensor<64xf32>) -> tensor<300x64xf32>
    %172 = stablehlo.add %170, %171 : tensor<300x64xf32>
    %173 = stablehlo.convert %172 : (tensor<300x64xf32>) -> tensor<300x64xbf16>
    %174 = stablehlo.reshape %173 : (tensor<300x64xbf16>) -> tensor<1x300x64xbf16>
    %175 = stablehlo.reshape %174 : (tensor<1x300x64xbf16>) -> tensor<1x300x1x64xbf16>
    %176 = stablehlo.transpose %175, dims = [0, 2, 1, 3] : (tensor<1x300x1x64xbf16>) -> tensor<1x1x300x64xbf16>
    %177 = stablehlo.transpose %166, dims = [0, 1, 3, 2] : (tensor<1x1x300x64xbf16>) -> tensor<1x1x64x300xbf16>
    %178 = stablehlo.reshape %104 : (tensor<1x1x19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %179 = stablehlo.reshape %177 : (tensor<1x1x64x300xbf16>) -> tensor<1x64x300xbf16>
    %180 = stablehlo.broadcast_in_dim %179, dims = [0, 1, 2] : (tensor<1x64x300xbf16>) -> tensor<1x64x300xbf16>
    %181 = stablehlo.dot_general %178, %180, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x19200x64xbf16>, tensor<1x64x300xbf16>) -> tensor<1x19200x300xbf16>
    %182 = stablehlo.reshape %181 : (tensor<1x19200x300xbf16>) -> tensor<1x1x19200x300xbf16>
    %183 = stablehlo.convert %cst_88 : (tensor<1xf64>) -> tensor<1xbf16>
    %184 = stablehlo.reshape %183 : (tensor<1xbf16>) -> tensor<bf16>
    %185 = stablehlo.broadcast_in_dim %182, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xbf16>) -> tensor<1x1x19200x300xbf16>
    %186 = stablehlo.broadcast_in_dim %184, dims = [] : (tensor<bf16>) -> tensor<1x1x19200x300xbf16>
    %187 = stablehlo.divide %185, %186 : tensor<1x1x19200x300xbf16>
    %188 = stablehlo.convert %187 : (tensor<1x1x19200x300xbf16>) -> tensor<1x1x19200x300xf32>
    %189 = stablehlo.reduce(%188 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x1x19200x300xf32>, tensor<f32>) -> tensor<1x1x19200xf32>
    %190 = stablehlo.reshape %189 : (tensor<1x1x19200xf32>) -> tensor<1x1x19200x1xf32>
    %191 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xf32>
    %192 = stablehlo.broadcast_in_dim %190, dims = [0, 1, 2, 3] : (tensor<1x1x19200x1xf32>) -> tensor<1x1x19200x300xf32>
    %193 = stablehlo.subtract %191, %192 : tensor<1x1x19200x300xf32>
    %194 = stablehlo.exponential %193 : tensor<1x1x19200x300xf32>
    %195 = stablehlo.reduce(%194 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x1x19200x300xf32>, tensor<f32>) -> tensor<1x1x19200xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x1x19200xf32>) -> tensor<1x1x19200x1xf32>
    %197 = stablehlo.broadcast_in_dim %194, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xf32>
    %198 = stablehlo.broadcast_in_dim %196, dims = [0, 1, 2, 3] : (tensor<1x1x19200x1xf32>) -> tensor<1x1x19200x300xf32>
    %199 = stablehlo.divide %197, %198 : tensor<1x1x19200x300xf32>
    %200 = stablehlo.convert %199 : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xbf16>
    %201 = stablehlo.reshape %200 : (tensor<1x1x19200x300xbf16>) -> tensor<1x19200x300xbf16>
    %202 = stablehlo.reshape %176 : (tensor<1x1x300x64xbf16>) -> tensor<1x300x64xbf16>
    %203 = stablehlo.broadcast_in_dim %202, dims = [0, 1, 2] : (tensor<1x300x64xbf16>) -> tensor<1x300x64xbf16>
    %204 = stablehlo.dot_general %201, %203, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x19200x300xbf16>, tensor<1x300x64xbf16>) -> tensor<1x19200x64xbf16>
    %205 = stablehlo.reshape %204 : (tensor<1x19200x64xbf16>) -> tensor<1x1x19200x64xbf16>
    %206 = stablehlo.transpose %205, dims = [0, 2, 1, 3] : (tensor<1x1x19200x64xbf16>) -> tensor<1x19200x1x64xbf16>
    %207 = stablehlo.reshape %206 : (tensor<1x19200x1x64xbf16>) -> tensor<1x19200x64xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %209 = stablehlo.convert %208 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %210 = stablehlo.dot_general %209, %arg498, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x64xf32>) -> tensor<19200x64xf32>
    %211 = stablehlo.broadcast_in_dim %210, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %212 = stablehlo.multiply %211, %96 : tensor<19200x64xf32>
    %213 = stablehlo.broadcast_in_dim %212, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %214 = stablehlo.broadcast_in_dim %arg499, dims = [1] : (tensor<64xf32>) -> tensor<19200x64xf32>
    %215 = stablehlo.add %213, %214 : tensor<19200x64xf32>
    %216 = stablehlo.convert %215 : (tensor<19200x64xf32>) -> tensor<19200x64xbf16>
    %217 = stablehlo.reshape %216 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %218 = stablehlo.add %217, %52 : tensor<1x19200x64xbf16>
    %219 = stablehlo.convert %218 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %220 = stablehlo.convert %219 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %221 = stablehlo.reduce(%220 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %222 = stablehlo.reshape %221 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %223 = stablehlo.broadcast_in_dim %222, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %224 = stablehlo.divide %223, %14 : tensor<1x19200x1xf64>
    %225 = stablehlo.broadcast_in_dim %220, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %226 = stablehlo.broadcast_in_dim %224, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %227 = stablehlo.subtract %225, %226 : tensor<1x19200x64xf64>
    %228 = stablehlo.multiply %227, %227 : tensor<1x19200x64xf64>
    %229 = stablehlo.reduce(%228 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %230 = stablehlo.reshape %229 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %231 = stablehlo.broadcast_in_dim %230, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %232 = stablehlo.divide %231, %14 : tensor<1x19200x1xf64>
    %233 = stablehlo.convert %232 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %234 = stablehlo.reduce(%219 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %235 = stablehlo.reshape %234 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %236 = stablehlo.broadcast_in_dim %235, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %237 = stablehlo.divide %236, %30 : tensor<1x19200x1xf32>
    %238 = stablehlo.broadcast_in_dim %233, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %239 = stablehlo.add %238, %35 : tensor<1x19200x1xf32>
    %240 = stablehlo.rsqrt %239 : tensor<1x19200x1xf32>
    %241 = stablehlo.broadcast_in_dim %219, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %242 = stablehlo.broadcast_in_dim %237, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %243 = stablehlo.subtract %241, %242 : tensor<1x19200x64xf32>
    %244 = stablehlo.broadcast_in_dim %243, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %245 = stablehlo.broadcast_in_dim %240, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %246 = stablehlo.multiply %244, %245 : tensor<1x19200x64xf32>
    %247 = stablehlo.convert %arg11 : (tensor<64xbf16>) -> tensor<64xf32>
    %248 = stablehlo.broadcast_in_dim %246, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %249 = stablehlo.broadcast_in_dim %247, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %250 = stablehlo.multiply %248, %249 : tensor<1x19200x64xf32>
    %251 = stablehlo.convert %arg12 : (tensor<64xbf16>) -> tensor<64xf32>
    %252 = stablehlo.broadcast_in_dim %250, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %253 = stablehlo.broadcast_in_dim %251, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %254 = stablehlo.add %252, %253 : tensor<1x19200x64xf32>
    %255 = stablehlo.convert %254 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %256 = stablehlo.reshape %255 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %257 = stablehlo.convert %256 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %258 = stablehlo.dot_general %257, %arg500, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x256xf32>) -> tensor<19200x256xf32>
    %259 = stablehlo.broadcast_in_dim %258, dims = [0, 1] : (tensor<19200x256xf32>) -> tensor<19200x256xf32>
    %260 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<19200x256xf32>
    %261 = stablehlo.multiply %259, %260 : tensor<19200x256xf32>
    %262 = stablehlo.broadcast_in_dim %261, dims = [0, 1] : (tensor<19200x256xf32>) -> tensor<19200x256xf32>
    %263 = stablehlo.broadcast_in_dim %arg501, dims = [1] : (tensor<256xf32>) -> tensor<19200x256xf32>
    %264 = stablehlo.add %262, %263 : tensor<19200x256xf32>
    %265 = stablehlo.convert %264 : (tensor<19200x256xf32>) -> tensor<19200x256xbf16>
    %266 = stablehlo.reshape %265 : (tensor<19200x256xbf16>) -> tensor<1x19200x256xbf16>
    %267 = stablehlo.transpose %266, dims = [0, 2, 1] : (tensor<1x19200x256xbf16>) -> tensor<1x256x19200xbf16>
    %268 = stablehlo.reshape %267 : (tensor<1x256x19200xbf16>) -> tensor<1x256x120x160xbf16>
    %269 = stablehlo.convolution(%268, %arg13) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 256 : i64} : (tensor<1x256x120x160xbf16>, tensor<256x1x3x3xbf16>) -> tensor<1x256x120x160xbf16>
    %270 = stablehlo.reshape %arg14 : (tensor<256xbf16>) -> tensor<256x1x1xbf16>
    %271 = stablehlo.broadcast_in_dim %269, dims = [0, 1, 2, 3] : (tensor<1x256x120x160xbf16>) -> tensor<1x256x120x160xbf16>
    %272 = stablehlo.broadcast_in_dim %270, dims = [1, 2, 3] : (tensor<256x1x1xbf16>) -> tensor<1x256x120x160xbf16>
    %273 = stablehlo.add %271, %272 : tensor<1x256x120x160xbf16>
    %274 = stablehlo.reshape %273 : (tensor<1x256x120x160xbf16>) -> tensor<1x256x19200xbf16>
    %275 = stablehlo.transpose %274, dims = [0, 2, 1] : (tensor<1x256x19200xbf16>) -> tensor<1x19200x256xbf16>
    %276 = stablehlo.multiply %275, %cst_4 : tensor<1x19200x256xbf16>
    %277 = stablehlo.rsqrt %cst_3 : tensor<1x19200x256xbf16>
    %278 = stablehlo.multiply %275, %277 : tensor<1x19200x256xbf16>
    %279 = stablehlo.convert %278 : (tensor<1x19200x256xbf16>) -> tensor<1x19200x256xf32>
    %280 = stablehlo.clamp %cst_5, %279, %cst_6 : tensor<1x19200x256xf32>
    %281 = stablehlo.multiply %280, %280 : tensor<1x19200x256xf32>
    %282 = stablehlo.multiply %cst_7, %281 : tensor<1x19200x256xf32>
    %283 = stablehlo.add %282, %cst_8 : tensor<1x19200x256xf32>
    %284 = stablehlo.multiply %283, %281 : tensor<1x19200x256xf32>
    %285 = stablehlo.add %284, %cst_9 : tensor<1x19200x256xf32>
    %286 = stablehlo.multiply %285, %281 : tensor<1x19200x256xf32>
    %287 = stablehlo.add %286, %cst_10 : tensor<1x19200x256xf32>
    %288 = stablehlo.multiply %287, %281 : tensor<1x19200x256xf32>
    %289 = stablehlo.add %288, %cst_11 : tensor<1x19200x256xf32>
    %290 = stablehlo.multiply %289, %281 : tensor<1x19200x256xf32>
    %291 = stablehlo.add %290, %cst_12 : tensor<1x19200x256xf32>
    %292 = stablehlo.multiply %291, %281 : tensor<1x19200x256xf32>
    %293 = stablehlo.add %292, %cst_13 : tensor<1x19200x256xf32>
    %294 = stablehlo.multiply %cst_14, %281 : tensor<1x19200x256xf32>
    %295 = stablehlo.add %294, %cst_15 : tensor<1x19200x256xf32>
    %296 = stablehlo.multiply %295, %281 : tensor<1x19200x256xf32>
    %297 = stablehlo.add %296, %cst_16 : tensor<1x19200x256xf32>
    %298 = stablehlo.multiply %297, %281 : tensor<1x19200x256xf32>
    %299 = stablehlo.add %298, %cst_17 : tensor<1x19200x256xf32>
    %300 = stablehlo.multiply %299, %281 : tensor<1x19200x256xf32>
    %301 = stablehlo.add %300, %cst_18 : tensor<1x19200x256xf32>
    %302 = stablehlo.multiply %280, %293 : tensor<1x19200x256xf32>
    %303 = stablehlo.divide %302, %301 : tensor<1x19200x256xf32>
    %304 = stablehlo.clamp %cst_19, %303, %cst_20 : tensor<1x19200x256xf32>
    %305 = stablehlo.convert %304 : (tensor<1x19200x256xf32>) -> tensor<1x19200x256xbf16>
    %306 = stablehlo.add %305, %cst_2 : tensor<1x19200x256xbf16>
    %307 = stablehlo.multiply %306, %276 : tensor<1x19200x256xbf16>
    %308 = stablehlo.reshape %307 : (tensor<1x19200x256xbf16>) -> tensor<19200x256xbf16>
    %309 = stablehlo.dot_general %308, %arg502, contracting_dims = [1] x [0] : (tensor<19200x256xbf16>, tensor<256x64xbf16>) -> tensor<19200x64xbf16>
    %310 = stablehlo.reshape %309 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %311 = stablehlo.broadcast_in_dim %310, dims = [0, 1, 2] : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %312 = stablehlo.broadcast_in_dim %arg15, dims = [2] : (tensor<64xbf16>) -> tensor<1x19200x64xbf16>
    %313 = stablehlo.add %311, %312 : tensor<1x19200x64xbf16>
    %314 = stablehlo.reshape %313 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %315 = stablehlo.reshape %314 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %316 = stablehlo.add %315, %218 : tensor<1x19200x64xbf16>
    %317 = stablehlo.convert %316 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %318 = stablehlo.convert %317 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %319 = stablehlo.reduce(%318 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %320 = stablehlo.reshape %319 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %321 = stablehlo.broadcast_in_dim %320, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %322 = stablehlo.divide %321, %14 : tensor<1x19200x1xf64>
    %323 = stablehlo.broadcast_in_dim %318, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %324 = stablehlo.broadcast_in_dim %322, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %325 = stablehlo.subtract %323, %324 : tensor<1x19200x64xf64>
    %326 = stablehlo.multiply %325, %325 : tensor<1x19200x64xf64>
    %327 = stablehlo.reduce(%326 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %328 = stablehlo.reshape %327 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %329 = stablehlo.broadcast_in_dim %328, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %330 = stablehlo.divide %329, %14 : tensor<1x19200x1xf64>
    %331 = stablehlo.convert %330 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %332 = stablehlo.reduce(%317 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %333 = stablehlo.reshape %332 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %334 = stablehlo.broadcast_in_dim %333, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %335 = stablehlo.divide %334, %30 : tensor<1x19200x1xf32>
    %336 = stablehlo.broadcast_in_dim %331, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %337 = stablehlo.add %336, %35 : tensor<1x19200x1xf32>
    %338 = stablehlo.rsqrt %337 : tensor<1x19200x1xf32>
    %339 = stablehlo.broadcast_in_dim %317, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %340 = stablehlo.broadcast_in_dim %335, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %341 = stablehlo.subtract %339, %340 : tensor<1x19200x64xf32>
    %342 = stablehlo.broadcast_in_dim %341, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %343 = stablehlo.broadcast_in_dim %338, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %344 = stablehlo.multiply %342, %343 : tensor<1x19200x64xf32>
    %345 = stablehlo.convert %arg16 : (tensor<64xbf16>) -> tensor<64xf32>
    %346 = stablehlo.broadcast_in_dim %344, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %347 = stablehlo.broadcast_in_dim %345, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %348 = stablehlo.multiply %346, %347 : tensor<1x19200x64xf32>
    %349 = stablehlo.convert %arg17 : (tensor<64xbf16>) -> tensor<64xf32>
    %350 = stablehlo.broadcast_in_dim %348, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %351 = stablehlo.broadcast_in_dim %349, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %352 = stablehlo.add %350, %351 : tensor<1x19200x64xf32>
    %353 = stablehlo.convert %352 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %354 = stablehlo.reshape %353 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %355 = stablehlo.convert %354 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %356 = stablehlo.dot_general %355, %arg503, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x64xf32>) -> tensor<19200x64xf32>
    %357 = stablehlo.broadcast_in_dim %356, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %358 = stablehlo.multiply %357, %96 : tensor<19200x64xf32>
    %359 = stablehlo.broadcast_in_dim %358, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %360 = stablehlo.broadcast_in_dim %arg504, dims = [1] : (tensor<64xf32>) -> tensor<19200x64xf32>
    %361 = stablehlo.add %359, %360 : tensor<19200x64xf32>
    %362 = stablehlo.convert %361 : (tensor<19200x64xf32>) -> tensor<19200x64xbf16>
    %363 = stablehlo.reshape %362 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %364 = stablehlo.reshape %363 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x1x64xbf16>
    %365 = stablehlo.transpose %364, dims = [0, 2, 1, 3] : (tensor<1x19200x1x64xbf16>) -> tensor<1x1x19200x64xbf16>
    %366 = stablehlo.transpose %353, dims = [0, 2, 1] : (tensor<1x19200x64xbf16>) -> tensor<1x64x19200xbf16>
    %367 = stablehlo.reshape %366 : (tensor<1x64x19200xbf16>) -> tensor<1x64x120x160xbf16>
    %368 = stablehlo.convolution(%367, %arg18) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [8, 8], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x120x160xbf16>, tensor<64x64x8x8xbf16>) -> tensor<1x64x15x20xbf16>
    %369 = stablehlo.reshape %arg19 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %370 = stablehlo.broadcast_in_dim %368, dims = [0, 1, 2, 3] : (tensor<1x64x15x20xbf16>) -> tensor<1x64x15x20xbf16>
    %371 = stablehlo.broadcast_in_dim %369, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x15x20xbf16>
    %372 = stablehlo.add %370, %371 : tensor<1x64x15x20xbf16>
    %373 = stablehlo.reshape %372 : (tensor<1x64x15x20xbf16>) -> tensor<1x64x300xbf16>
    %374 = stablehlo.transpose %373, dims = [0, 2, 1] : (tensor<1x64x300xbf16>) -> tensor<1x300x64xbf16>
    %375 = stablehlo.convert %374 : (tensor<1x300x64xbf16>) -> tensor<1x300x64xf32>
    %376 = stablehlo.convert %375 : (tensor<1x300x64xf32>) -> tensor<1x300x64xf64>
    %377 = stablehlo.reduce(%376 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf64>, tensor<f64>) -> tensor<1x300xf64>
    %378 = stablehlo.reshape %377 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %379 = stablehlo.broadcast_in_dim %378, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %380 = stablehlo.divide %379, %119 : tensor<1x300x1xf64>
    %381 = stablehlo.broadcast_in_dim %376, dims = [0, 1, 2] : (tensor<1x300x64xf64>) -> tensor<1x300x64xf64>
    %382 = stablehlo.broadcast_in_dim %380, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x64xf64>
    %383 = stablehlo.subtract %381, %382 : tensor<1x300x64xf64>
    %384 = stablehlo.multiply %383, %383 : tensor<1x300x64xf64>
    %385 = stablehlo.reduce(%384 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf64>, tensor<f64>) -> tensor<1x300xf64>
    %386 = stablehlo.reshape %385 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %387 = stablehlo.broadcast_in_dim %386, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %388 = stablehlo.divide %387, %119 : tensor<1x300x1xf64>
    %389 = stablehlo.convert %388 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %390 = stablehlo.reduce(%375 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf32>, tensor<f32>) -> tensor<1x300xf32>
    %391 = stablehlo.reshape %390 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %392 = stablehlo.broadcast_in_dim %391, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %393 = stablehlo.divide %392, %133 : tensor<1x300x1xf32>
    %394 = stablehlo.broadcast_in_dim %389, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %395 = stablehlo.add %394, %136 : tensor<1x300x1xf32>
    %396 = stablehlo.rsqrt %395 : tensor<1x300x1xf32>
    %397 = stablehlo.broadcast_in_dim %375, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %398 = stablehlo.broadcast_in_dim %393, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x64xf32>
    %399 = stablehlo.subtract %397, %398 : tensor<1x300x64xf32>
    %400 = stablehlo.broadcast_in_dim %399, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %401 = stablehlo.broadcast_in_dim %396, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x64xf32>
    %402 = stablehlo.multiply %400, %401 : tensor<1x300x64xf32>
    %403 = stablehlo.convert %arg20 : (tensor<64xbf16>) -> tensor<64xf32>
    %404 = stablehlo.broadcast_in_dim %402, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %405 = stablehlo.broadcast_in_dim %403, dims = [2] : (tensor<64xf32>) -> tensor<1x300x64xf32>
    %406 = stablehlo.multiply %404, %405 : tensor<1x300x64xf32>
    %407 = stablehlo.convert %arg21 : (tensor<64xbf16>) -> tensor<64xf32>
    %408 = stablehlo.broadcast_in_dim %406, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %409 = stablehlo.broadcast_in_dim %407, dims = [2] : (tensor<64xf32>) -> tensor<1x300x64xf32>
    %410 = stablehlo.add %408, %409 : tensor<1x300x64xf32>
    %411 = stablehlo.convert %410 : (tensor<1x300x64xf32>) -> tensor<1x300x64xbf16>
    %412 = stablehlo.reshape %411 : (tensor<1x300x64xbf16>) -> tensor<300x64xbf16>
    %413 = stablehlo.convert %412 : (tensor<300x64xbf16>) -> tensor<300x64xf32>
    %414 = stablehlo.dot_general %413, %arg505, contracting_dims = [1] x [0] : (tensor<300x64xf32>, tensor<64x64xf32>) -> tensor<300x64xf32>
    %415 = stablehlo.broadcast_in_dim %414, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %416 = stablehlo.multiply %415, %158 : tensor<300x64xf32>
    %417 = stablehlo.broadcast_in_dim %416, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %418 = stablehlo.broadcast_in_dim %arg506, dims = [1] : (tensor<64xf32>) -> tensor<300x64xf32>
    %419 = stablehlo.add %417, %418 : tensor<300x64xf32>
    %420 = stablehlo.convert %419 : (tensor<300x64xf32>) -> tensor<300x64xbf16>
    %421 = stablehlo.reshape %420 : (tensor<300x64xbf16>) -> tensor<1x300x64xbf16>
    %422 = stablehlo.reshape %421 : (tensor<1x300x64xbf16>) -> tensor<1x300x1x64xbf16>
    %423 = stablehlo.transpose %422, dims = [0, 2, 1, 3] : (tensor<1x300x1x64xbf16>) -> tensor<1x1x300x64xbf16>
    %424 = stablehlo.dot_general %413, %arg507, contracting_dims = [1] x [0] : (tensor<300x64xf32>, tensor<64x64xf32>) -> tensor<300x64xf32>
    %425 = stablehlo.broadcast_in_dim %424, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %426 = stablehlo.multiply %425, %158 : tensor<300x64xf32>
    %427 = stablehlo.broadcast_in_dim %426, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %428 = stablehlo.broadcast_in_dim %arg508, dims = [1] : (tensor<64xf32>) -> tensor<300x64xf32>
    %429 = stablehlo.add %427, %428 : tensor<300x64xf32>
    %430 = stablehlo.convert %429 : (tensor<300x64xf32>) -> tensor<300x64xbf16>
    %431 = stablehlo.reshape %430 : (tensor<300x64xbf16>) -> tensor<1x300x64xbf16>
    %432 = stablehlo.reshape %431 : (tensor<1x300x64xbf16>) -> tensor<1x300x1x64xbf16>
    %433 = stablehlo.transpose %432, dims = [0, 2, 1, 3] : (tensor<1x300x1x64xbf16>) -> tensor<1x1x300x64xbf16>
    %434 = stablehlo.transpose %423, dims = [0, 1, 3, 2] : (tensor<1x1x300x64xbf16>) -> tensor<1x1x64x300xbf16>
    %435 = stablehlo.reshape %365 : (tensor<1x1x19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %436 = stablehlo.reshape %434 : (tensor<1x1x64x300xbf16>) -> tensor<1x64x300xbf16>
    %437 = stablehlo.broadcast_in_dim %436, dims = [0, 1, 2] : (tensor<1x64x300xbf16>) -> tensor<1x64x300xbf16>
    %438 = stablehlo.dot_general %435, %437, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x19200x64xbf16>, tensor<1x64x300xbf16>) -> tensor<1x19200x300xbf16>
    %439 = stablehlo.reshape %438 : (tensor<1x19200x300xbf16>) -> tensor<1x1x19200x300xbf16>
    %440 = stablehlo.broadcast_in_dim %439, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xbf16>) -> tensor<1x1x19200x300xbf16>
    %441 = stablehlo.divide %440, %186 : tensor<1x1x19200x300xbf16>
    %442 = stablehlo.convert %441 : (tensor<1x1x19200x300xbf16>) -> tensor<1x1x19200x300xf32>
    %443 = stablehlo.reduce(%442 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x1x19200x300xf32>, tensor<f32>) -> tensor<1x1x19200xf32>
    %444 = stablehlo.reshape %443 : (tensor<1x1x19200xf32>) -> tensor<1x1x19200x1xf32>
    %445 = stablehlo.broadcast_in_dim %442, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xf32>
    %446 = stablehlo.broadcast_in_dim %444, dims = [0, 1, 2, 3] : (tensor<1x1x19200x1xf32>) -> tensor<1x1x19200x300xf32>
    %447 = stablehlo.subtract %445, %446 : tensor<1x1x19200x300xf32>
    %448 = stablehlo.exponential %447 : tensor<1x1x19200x300xf32>
    %449 = stablehlo.reduce(%448 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x1x19200x300xf32>, tensor<f32>) -> tensor<1x1x19200xf32>
    %450 = stablehlo.reshape %449 : (tensor<1x1x19200xf32>) -> tensor<1x1x19200x1xf32>
    %451 = stablehlo.broadcast_in_dim %448, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xf32>
    %452 = stablehlo.broadcast_in_dim %450, dims = [0, 1, 2, 3] : (tensor<1x1x19200x1xf32>) -> tensor<1x1x19200x300xf32>
    %453 = stablehlo.divide %451, %452 : tensor<1x1x19200x300xf32>
    %454 = stablehlo.convert %453 : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xbf16>
    %455 = stablehlo.reshape %454 : (tensor<1x1x19200x300xbf16>) -> tensor<1x19200x300xbf16>
    %456 = stablehlo.reshape %433 : (tensor<1x1x300x64xbf16>) -> tensor<1x300x64xbf16>
    %457 = stablehlo.broadcast_in_dim %456, dims = [0, 1, 2] : (tensor<1x300x64xbf16>) -> tensor<1x300x64xbf16>
    %458 = stablehlo.dot_general %455, %457, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x19200x300xbf16>, tensor<1x300x64xbf16>) -> tensor<1x19200x64xbf16>
    %459 = stablehlo.reshape %458 : (tensor<1x19200x64xbf16>) -> tensor<1x1x19200x64xbf16>
    %460 = stablehlo.transpose %459, dims = [0, 2, 1, 3] : (tensor<1x1x19200x64xbf16>) -> tensor<1x19200x1x64xbf16>
    %461 = stablehlo.reshape %460 : (tensor<1x19200x1x64xbf16>) -> tensor<1x19200x64xbf16>
    %462 = stablehlo.reshape %461 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %463 = stablehlo.convert %462 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %464 = stablehlo.dot_general %463, %arg509, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x64xf32>) -> tensor<19200x64xf32>
    %465 = stablehlo.broadcast_in_dim %464, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %466 = stablehlo.multiply %465, %96 : tensor<19200x64xf32>
    %467 = stablehlo.broadcast_in_dim %466, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %468 = stablehlo.broadcast_in_dim %arg510, dims = [1] : (tensor<64xf32>) -> tensor<19200x64xf32>
    %469 = stablehlo.add %467, %468 : tensor<19200x64xf32>
    %470 = stablehlo.convert %469 : (tensor<19200x64xf32>) -> tensor<19200x64xbf16>
    %471 = stablehlo.reshape %470 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %472 = stablehlo.add %471, %316 : tensor<1x19200x64xbf16>
    %473 = stablehlo.convert %472 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %474 = stablehlo.convert %473 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %475 = stablehlo.reduce(%474 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %476 = stablehlo.reshape %475 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %477 = stablehlo.broadcast_in_dim %476, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %478 = stablehlo.divide %477, %14 : tensor<1x19200x1xf64>
    %479 = stablehlo.broadcast_in_dim %474, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %480 = stablehlo.broadcast_in_dim %478, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %481 = stablehlo.subtract %479, %480 : tensor<1x19200x64xf64>
    %482 = stablehlo.multiply %481, %481 : tensor<1x19200x64xf64>
    %483 = stablehlo.reduce(%482 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %484 = stablehlo.reshape %483 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %485 = stablehlo.broadcast_in_dim %484, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %486 = stablehlo.divide %485, %14 : tensor<1x19200x1xf64>
    %487 = stablehlo.convert %486 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %488 = stablehlo.reduce(%473 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %489 = stablehlo.reshape %488 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %490 = stablehlo.broadcast_in_dim %489, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %491 = stablehlo.divide %490, %30 : tensor<1x19200x1xf32>
    %492 = stablehlo.broadcast_in_dim %487, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %493 = stablehlo.add %492, %35 : tensor<1x19200x1xf32>
    %494 = stablehlo.rsqrt %493 : tensor<1x19200x1xf32>
    %495 = stablehlo.broadcast_in_dim %473, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %496 = stablehlo.broadcast_in_dim %491, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %497 = stablehlo.subtract %495, %496 : tensor<1x19200x64xf32>
    %498 = stablehlo.broadcast_in_dim %497, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %499 = stablehlo.broadcast_in_dim %494, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %500 = stablehlo.multiply %498, %499 : tensor<1x19200x64xf32>
    %501 = stablehlo.convert %arg22 : (tensor<64xbf16>) -> tensor<64xf32>
    %502 = stablehlo.broadcast_in_dim %500, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %503 = stablehlo.broadcast_in_dim %501, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %504 = stablehlo.multiply %502, %503 : tensor<1x19200x64xf32>
    %505 = stablehlo.convert %arg23 : (tensor<64xbf16>) -> tensor<64xf32>
    %506 = stablehlo.broadcast_in_dim %504, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %507 = stablehlo.broadcast_in_dim %505, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %508 = stablehlo.add %506, %507 : tensor<1x19200x64xf32>
    %509 = stablehlo.convert %508 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %510 = stablehlo.reshape %509 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %511 = stablehlo.convert %510 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %512 = stablehlo.dot_general %511, %arg511, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x256xf32>) -> tensor<19200x256xf32>
    %513 = stablehlo.broadcast_in_dim %512, dims = [0, 1] : (tensor<19200x256xf32>) -> tensor<19200x256xf32>
    %514 = stablehlo.multiply %513, %260 : tensor<19200x256xf32>
    %515 = stablehlo.broadcast_in_dim %514, dims = [0, 1] : (tensor<19200x256xf32>) -> tensor<19200x256xf32>
    %516 = stablehlo.broadcast_in_dim %arg512, dims = [1] : (tensor<256xf32>) -> tensor<19200x256xf32>
    %517 = stablehlo.add %515, %516 : tensor<19200x256xf32>
    %518 = stablehlo.convert %517 : (tensor<19200x256xf32>) -> tensor<19200x256xbf16>
    %519 = stablehlo.reshape %518 : (tensor<19200x256xbf16>) -> tensor<1x19200x256xbf16>
    %520 = stablehlo.transpose %519, dims = [0, 2, 1] : (tensor<1x19200x256xbf16>) -> tensor<1x256x19200xbf16>
    %521 = stablehlo.reshape %520 : (tensor<1x256x19200xbf16>) -> tensor<1x256x120x160xbf16>
    %522 = stablehlo.convolution(%521, %arg24) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 256 : i64} : (tensor<1x256x120x160xbf16>, tensor<256x1x3x3xbf16>) -> tensor<1x256x120x160xbf16>
    %523 = stablehlo.reshape %arg25 : (tensor<256xbf16>) -> tensor<256x1x1xbf16>
    %524 = stablehlo.broadcast_in_dim %522, dims = [0, 1, 2, 3] : (tensor<1x256x120x160xbf16>) -> tensor<1x256x120x160xbf16>
    %525 = stablehlo.broadcast_in_dim %523, dims = [1, 2, 3] : (tensor<256x1x1xbf16>) -> tensor<1x256x120x160xbf16>
    %526 = stablehlo.add %524, %525 : tensor<1x256x120x160xbf16>
    %527 = stablehlo.reshape %526 : (tensor<1x256x120x160xbf16>) -> tensor<1x256x19200xbf16>
    %528 = stablehlo.transpose %527, dims = [0, 2, 1] : (tensor<1x256x19200xbf16>) -> tensor<1x19200x256xbf16>
    %529 = stablehlo.multiply %528, %cst_4 : tensor<1x19200x256xbf16>
    %530 = stablehlo.multiply %528, %277 : tensor<1x19200x256xbf16>
    %531 = stablehlo.convert %530 : (tensor<1x19200x256xbf16>) -> tensor<1x19200x256xf32>
    %532 = stablehlo.clamp %cst_5, %531, %cst_6 : tensor<1x19200x256xf32>
    %533 = stablehlo.multiply %532, %532 : tensor<1x19200x256xf32>
    %534 = stablehlo.multiply %cst_7, %533 : tensor<1x19200x256xf32>
    %535 = stablehlo.add %534, %cst_8 : tensor<1x19200x256xf32>
    %536 = stablehlo.multiply %535, %533 : tensor<1x19200x256xf32>
    %537 = stablehlo.add %536, %cst_9 : tensor<1x19200x256xf32>
    %538 = stablehlo.multiply %537, %533 : tensor<1x19200x256xf32>
    %539 = stablehlo.add %538, %cst_10 : tensor<1x19200x256xf32>
    %540 = stablehlo.multiply %539, %533 : tensor<1x19200x256xf32>
    %541 = stablehlo.add %540, %cst_11 : tensor<1x19200x256xf32>
    %542 = stablehlo.multiply %541, %533 : tensor<1x19200x256xf32>
    %543 = stablehlo.add %542, %cst_12 : tensor<1x19200x256xf32>
    %544 = stablehlo.multiply %543, %533 : tensor<1x19200x256xf32>
    %545 = stablehlo.add %544, %cst_13 : tensor<1x19200x256xf32>
    %546 = stablehlo.multiply %cst_14, %533 : tensor<1x19200x256xf32>
    %547 = stablehlo.add %546, %cst_15 : tensor<1x19200x256xf32>
    %548 = stablehlo.multiply %547, %533 : tensor<1x19200x256xf32>
    %549 = stablehlo.add %548, %cst_16 : tensor<1x19200x256xf32>
    %550 = stablehlo.multiply %549, %533 : tensor<1x19200x256xf32>
    %551 = stablehlo.add %550, %cst_17 : tensor<1x19200x256xf32>
    %552 = stablehlo.multiply %551, %533 : tensor<1x19200x256xf32>
    %553 = stablehlo.add %552, %cst_18 : tensor<1x19200x256xf32>
    %554 = stablehlo.multiply %532, %545 : tensor<1x19200x256xf32>
    %555 = stablehlo.divide %554, %553 : tensor<1x19200x256xf32>
    %556 = stablehlo.clamp %cst_19, %555, %cst_20 : tensor<1x19200x256xf32>
    %557 = stablehlo.convert %556 : (tensor<1x19200x256xf32>) -> tensor<1x19200x256xbf16>
    %558 = stablehlo.add %557, %cst_2 : tensor<1x19200x256xbf16>
    %559 = stablehlo.multiply %558, %529 : tensor<1x19200x256xbf16>
    %560 = stablehlo.reshape %559 : (tensor<1x19200x256xbf16>) -> tensor<19200x256xbf16>
    %561 = stablehlo.dot_general %560, %arg513, contracting_dims = [1] x [0] : (tensor<19200x256xbf16>, tensor<256x64xbf16>) -> tensor<19200x64xbf16>
    %562 = stablehlo.reshape %561 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %563 = stablehlo.broadcast_in_dim %562, dims = [0, 1, 2] : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %564 = stablehlo.broadcast_in_dim %arg26, dims = [2] : (tensor<64xbf16>) -> tensor<1x19200x64xbf16>
    %565 = stablehlo.add %563, %564 : tensor<1x19200x64xbf16>
    %566 = stablehlo.reshape %565 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %567 = stablehlo.reshape %566 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %568 = stablehlo.add %567, %472 : tensor<1x19200x64xbf16>
    %569 = stablehlo.convert %568 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %570 = stablehlo.convert %569 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %571 = stablehlo.reduce(%570 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %572 = stablehlo.reshape %571 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %573 = stablehlo.broadcast_in_dim %572, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %574 = stablehlo.divide %573, %14 : tensor<1x19200x1xf64>
    %575 = stablehlo.broadcast_in_dim %570, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %576 = stablehlo.broadcast_in_dim %574, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %577 = stablehlo.subtract %575, %576 : tensor<1x19200x64xf64>
    %578 = stablehlo.multiply %577, %577 : tensor<1x19200x64xf64>
    %579 = stablehlo.reduce(%578 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %580 = stablehlo.reshape %579 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %581 = stablehlo.broadcast_in_dim %580, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %582 = stablehlo.divide %581, %14 : tensor<1x19200x1xf64>
    %583 = stablehlo.convert %582 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %584 = stablehlo.reduce(%569 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %585 = stablehlo.reshape %584 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %586 = stablehlo.broadcast_in_dim %585, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %587 = stablehlo.divide %586, %30 : tensor<1x19200x1xf32>
    %588 = stablehlo.broadcast_in_dim %583, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %589 = stablehlo.add %588, %35 : tensor<1x19200x1xf32>
    %590 = stablehlo.rsqrt %589 : tensor<1x19200x1xf32>
    %591 = stablehlo.broadcast_in_dim %569, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %592 = stablehlo.broadcast_in_dim %587, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %593 = stablehlo.subtract %591, %592 : tensor<1x19200x64xf32>
    %594 = stablehlo.broadcast_in_dim %593, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %595 = stablehlo.broadcast_in_dim %590, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %596 = stablehlo.multiply %594, %595 : tensor<1x19200x64xf32>
    %597 = stablehlo.convert %arg27 : (tensor<64xbf16>) -> tensor<64xf32>
    %598 = stablehlo.broadcast_in_dim %596, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %599 = stablehlo.broadcast_in_dim %597, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %600 = stablehlo.multiply %598, %599 : tensor<1x19200x64xf32>
    %601 = stablehlo.convert %arg28 : (tensor<64xbf16>) -> tensor<64xf32>
    %602 = stablehlo.broadcast_in_dim %600, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %603 = stablehlo.broadcast_in_dim %601, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %604 = stablehlo.add %602, %603 : tensor<1x19200x64xf32>
    %605 = stablehlo.convert %604 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %606 = stablehlo.reshape %605 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %607 = stablehlo.convert %606 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %608 = stablehlo.dot_general %607, %arg514, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x64xf32>) -> tensor<19200x64xf32>
    %609 = stablehlo.broadcast_in_dim %608, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %610 = stablehlo.multiply %609, %96 : tensor<19200x64xf32>
    %611 = stablehlo.broadcast_in_dim %610, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %612 = stablehlo.broadcast_in_dim %arg515, dims = [1] : (tensor<64xf32>) -> tensor<19200x64xf32>
    %613 = stablehlo.add %611, %612 : tensor<19200x64xf32>
    %614 = stablehlo.convert %613 : (tensor<19200x64xf32>) -> tensor<19200x64xbf16>
    %615 = stablehlo.reshape %614 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %616 = stablehlo.reshape %615 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x1x64xbf16>
    %617 = stablehlo.transpose %616, dims = [0, 2, 1, 3] : (tensor<1x19200x1x64xbf16>) -> tensor<1x1x19200x64xbf16>
    %618 = stablehlo.transpose %605, dims = [0, 2, 1] : (tensor<1x19200x64xbf16>) -> tensor<1x64x19200xbf16>
    %619 = stablehlo.reshape %618 : (tensor<1x64x19200xbf16>) -> tensor<1x64x120x160xbf16>
    %620 = stablehlo.convolution(%619, %arg29) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [8, 8], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x120x160xbf16>, tensor<64x64x8x8xbf16>) -> tensor<1x64x15x20xbf16>
    %621 = stablehlo.reshape %arg30 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %622 = stablehlo.broadcast_in_dim %620, dims = [0, 1, 2, 3] : (tensor<1x64x15x20xbf16>) -> tensor<1x64x15x20xbf16>
    %623 = stablehlo.broadcast_in_dim %621, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x15x20xbf16>
    %624 = stablehlo.add %622, %623 : tensor<1x64x15x20xbf16>
    %625 = stablehlo.reshape %624 : (tensor<1x64x15x20xbf16>) -> tensor<1x64x300xbf16>
    %626 = stablehlo.transpose %625, dims = [0, 2, 1] : (tensor<1x64x300xbf16>) -> tensor<1x300x64xbf16>
    %627 = stablehlo.convert %626 : (tensor<1x300x64xbf16>) -> tensor<1x300x64xf32>
    %628 = stablehlo.convert %627 : (tensor<1x300x64xf32>) -> tensor<1x300x64xf64>
    %629 = stablehlo.reduce(%628 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf64>, tensor<f64>) -> tensor<1x300xf64>
    %630 = stablehlo.reshape %629 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %631 = stablehlo.broadcast_in_dim %630, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %632 = stablehlo.divide %631, %119 : tensor<1x300x1xf64>
    %633 = stablehlo.broadcast_in_dim %628, dims = [0, 1, 2] : (tensor<1x300x64xf64>) -> tensor<1x300x64xf64>
    %634 = stablehlo.broadcast_in_dim %632, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x64xf64>
    %635 = stablehlo.subtract %633, %634 : tensor<1x300x64xf64>
    %636 = stablehlo.multiply %635, %635 : tensor<1x300x64xf64>
    %637 = stablehlo.reduce(%636 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf64>, tensor<f64>) -> tensor<1x300xf64>
    %638 = stablehlo.reshape %637 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %639 = stablehlo.broadcast_in_dim %638, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %640 = stablehlo.divide %639, %119 : tensor<1x300x1xf64>
    %641 = stablehlo.convert %640 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %642 = stablehlo.reduce(%627 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x64xf32>, tensor<f32>) -> tensor<1x300xf32>
    %643 = stablehlo.reshape %642 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %644 = stablehlo.broadcast_in_dim %643, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %645 = stablehlo.divide %644, %133 : tensor<1x300x1xf32>
    %646 = stablehlo.broadcast_in_dim %641, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %647 = stablehlo.add %646, %136 : tensor<1x300x1xf32>
    %648 = stablehlo.rsqrt %647 : tensor<1x300x1xf32>
    %649 = stablehlo.broadcast_in_dim %627, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %650 = stablehlo.broadcast_in_dim %645, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x64xf32>
    %651 = stablehlo.subtract %649, %650 : tensor<1x300x64xf32>
    %652 = stablehlo.broadcast_in_dim %651, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %653 = stablehlo.broadcast_in_dim %648, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x64xf32>
    %654 = stablehlo.multiply %652, %653 : tensor<1x300x64xf32>
    %655 = stablehlo.convert %arg31 : (tensor<64xbf16>) -> tensor<64xf32>
    %656 = stablehlo.broadcast_in_dim %654, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %657 = stablehlo.broadcast_in_dim %655, dims = [2] : (tensor<64xf32>) -> tensor<1x300x64xf32>
    %658 = stablehlo.multiply %656, %657 : tensor<1x300x64xf32>
    %659 = stablehlo.convert %arg32 : (tensor<64xbf16>) -> tensor<64xf32>
    %660 = stablehlo.broadcast_in_dim %658, dims = [0, 1, 2] : (tensor<1x300x64xf32>) -> tensor<1x300x64xf32>
    %661 = stablehlo.broadcast_in_dim %659, dims = [2] : (tensor<64xf32>) -> tensor<1x300x64xf32>
    %662 = stablehlo.add %660, %661 : tensor<1x300x64xf32>
    %663 = stablehlo.convert %662 : (tensor<1x300x64xf32>) -> tensor<1x300x64xbf16>
    %664 = stablehlo.reshape %663 : (tensor<1x300x64xbf16>) -> tensor<300x64xbf16>
    %665 = stablehlo.convert %664 : (tensor<300x64xbf16>) -> tensor<300x64xf32>
    %666 = stablehlo.dot_general %665, %arg516, contracting_dims = [1] x [0] : (tensor<300x64xf32>, tensor<64x64xf32>) -> tensor<300x64xf32>
    %667 = stablehlo.broadcast_in_dim %666, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %668 = stablehlo.multiply %667, %158 : tensor<300x64xf32>
    %669 = stablehlo.broadcast_in_dim %668, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %670 = stablehlo.broadcast_in_dim %arg517, dims = [1] : (tensor<64xf32>) -> tensor<300x64xf32>
    %671 = stablehlo.add %669, %670 : tensor<300x64xf32>
    %672 = stablehlo.convert %671 : (tensor<300x64xf32>) -> tensor<300x64xbf16>
    %673 = stablehlo.reshape %672 : (tensor<300x64xbf16>) -> tensor<1x300x64xbf16>
    %674 = stablehlo.reshape %673 : (tensor<1x300x64xbf16>) -> tensor<1x300x1x64xbf16>
    %675 = stablehlo.transpose %674, dims = [0, 2, 1, 3] : (tensor<1x300x1x64xbf16>) -> tensor<1x1x300x64xbf16>
    %676 = stablehlo.dot_general %665, %arg518, contracting_dims = [1] x [0] : (tensor<300x64xf32>, tensor<64x64xf32>) -> tensor<300x64xf32>
    %677 = stablehlo.broadcast_in_dim %676, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %678 = stablehlo.multiply %677, %158 : tensor<300x64xf32>
    %679 = stablehlo.broadcast_in_dim %678, dims = [0, 1] : (tensor<300x64xf32>) -> tensor<300x64xf32>
    %680 = stablehlo.broadcast_in_dim %arg519, dims = [1] : (tensor<64xf32>) -> tensor<300x64xf32>
    %681 = stablehlo.add %679, %680 : tensor<300x64xf32>
    %682 = stablehlo.convert %681 : (tensor<300x64xf32>) -> tensor<300x64xbf16>
    %683 = stablehlo.reshape %682 : (tensor<300x64xbf16>) -> tensor<1x300x64xbf16>
    %684 = stablehlo.reshape %683 : (tensor<1x300x64xbf16>) -> tensor<1x300x1x64xbf16>
    %685 = stablehlo.transpose %684, dims = [0, 2, 1, 3] : (tensor<1x300x1x64xbf16>) -> tensor<1x1x300x64xbf16>
    %686 = stablehlo.transpose %675, dims = [0, 1, 3, 2] : (tensor<1x1x300x64xbf16>) -> tensor<1x1x64x300xbf16>
    %687 = stablehlo.reshape %617 : (tensor<1x1x19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %688 = stablehlo.reshape %686 : (tensor<1x1x64x300xbf16>) -> tensor<1x64x300xbf16>
    %689 = stablehlo.broadcast_in_dim %688, dims = [0, 1, 2] : (tensor<1x64x300xbf16>) -> tensor<1x64x300xbf16>
    %690 = stablehlo.dot_general %687, %689, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x19200x64xbf16>, tensor<1x64x300xbf16>) -> tensor<1x19200x300xbf16>
    %691 = stablehlo.reshape %690 : (tensor<1x19200x300xbf16>) -> tensor<1x1x19200x300xbf16>
    %692 = stablehlo.broadcast_in_dim %691, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xbf16>) -> tensor<1x1x19200x300xbf16>
    %693 = stablehlo.divide %692, %186 : tensor<1x1x19200x300xbf16>
    %694 = stablehlo.convert %693 : (tensor<1x1x19200x300xbf16>) -> tensor<1x1x19200x300xf32>
    %695 = stablehlo.reduce(%694 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x1x19200x300xf32>, tensor<f32>) -> tensor<1x1x19200xf32>
    %696 = stablehlo.reshape %695 : (tensor<1x1x19200xf32>) -> tensor<1x1x19200x1xf32>
    %697 = stablehlo.broadcast_in_dim %694, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xf32>
    %698 = stablehlo.broadcast_in_dim %696, dims = [0, 1, 2, 3] : (tensor<1x1x19200x1xf32>) -> tensor<1x1x19200x300xf32>
    %699 = stablehlo.subtract %697, %698 : tensor<1x1x19200x300xf32>
    %700 = stablehlo.exponential %699 : tensor<1x1x19200x300xf32>
    %701 = stablehlo.reduce(%700 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x1x19200x300xf32>, tensor<f32>) -> tensor<1x1x19200xf32>
    %702 = stablehlo.reshape %701 : (tensor<1x1x19200xf32>) -> tensor<1x1x19200x1xf32>
    %703 = stablehlo.broadcast_in_dim %700, dims = [0, 1, 2, 3] : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xf32>
    %704 = stablehlo.broadcast_in_dim %702, dims = [0, 1, 2, 3] : (tensor<1x1x19200x1xf32>) -> tensor<1x1x19200x300xf32>
    %705 = stablehlo.divide %703, %704 : tensor<1x1x19200x300xf32>
    %706 = stablehlo.convert %705 : (tensor<1x1x19200x300xf32>) -> tensor<1x1x19200x300xbf16>
    %707 = stablehlo.reshape %706 : (tensor<1x1x19200x300xbf16>) -> tensor<1x19200x300xbf16>
    %708 = stablehlo.reshape %685 : (tensor<1x1x300x64xbf16>) -> tensor<1x300x64xbf16>
    %709 = stablehlo.broadcast_in_dim %708, dims = [0, 1, 2] : (tensor<1x300x64xbf16>) -> tensor<1x300x64xbf16>
    %710 = stablehlo.dot_general %707, %709, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x19200x300xbf16>, tensor<1x300x64xbf16>) -> tensor<1x19200x64xbf16>
    %711 = stablehlo.reshape %710 : (tensor<1x19200x64xbf16>) -> tensor<1x1x19200x64xbf16>
    %712 = stablehlo.transpose %711, dims = [0, 2, 1, 3] : (tensor<1x1x19200x64xbf16>) -> tensor<1x19200x1x64xbf16>
    %713 = stablehlo.reshape %712 : (tensor<1x19200x1x64xbf16>) -> tensor<1x19200x64xbf16>
    %714 = stablehlo.reshape %713 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %715 = stablehlo.convert %714 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %716 = stablehlo.dot_general %715, %arg520, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x64xf32>) -> tensor<19200x64xf32>
    %717 = stablehlo.broadcast_in_dim %716, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %718 = stablehlo.multiply %717, %96 : tensor<19200x64xf32>
    %719 = stablehlo.broadcast_in_dim %718, dims = [0, 1] : (tensor<19200x64xf32>) -> tensor<19200x64xf32>
    %720 = stablehlo.broadcast_in_dim %arg521, dims = [1] : (tensor<64xf32>) -> tensor<19200x64xf32>
    %721 = stablehlo.add %719, %720 : tensor<19200x64xf32>
    %722 = stablehlo.convert %721 : (tensor<19200x64xf32>) -> tensor<19200x64xbf16>
    %723 = stablehlo.reshape %722 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %724 = stablehlo.add %723, %568 : tensor<1x19200x64xbf16>
    %725 = stablehlo.convert %724 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %726 = stablehlo.convert %725 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %727 = stablehlo.reduce(%726 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %728 = stablehlo.reshape %727 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %729 = stablehlo.broadcast_in_dim %728, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %730 = stablehlo.divide %729, %14 : tensor<1x19200x1xf64>
    %731 = stablehlo.broadcast_in_dim %726, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %732 = stablehlo.broadcast_in_dim %730, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %733 = stablehlo.subtract %731, %732 : tensor<1x19200x64xf64>
    %734 = stablehlo.multiply %733, %733 : tensor<1x19200x64xf64>
    %735 = stablehlo.reduce(%734 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %736 = stablehlo.reshape %735 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %737 = stablehlo.broadcast_in_dim %736, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %738 = stablehlo.divide %737, %14 : tensor<1x19200x1xf64>
    %739 = stablehlo.convert %738 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %740 = stablehlo.reduce(%725 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %741 = stablehlo.reshape %740 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %742 = stablehlo.broadcast_in_dim %741, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %743 = stablehlo.divide %742, %30 : tensor<1x19200x1xf32>
    %744 = stablehlo.broadcast_in_dim %739, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %745 = stablehlo.add %744, %35 : tensor<1x19200x1xf32>
    %746 = stablehlo.rsqrt %745 : tensor<1x19200x1xf32>
    %747 = stablehlo.broadcast_in_dim %725, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %748 = stablehlo.broadcast_in_dim %743, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %749 = stablehlo.subtract %747, %748 : tensor<1x19200x64xf32>
    %750 = stablehlo.broadcast_in_dim %749, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %751 = stablehlo.broadcast_in_dim %746, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %752 = stablehlo.multiply %750, %751 : tensor<1x19200x64xf32>
    %753 = stablehlo.convert %arg33 : (tensor<64xbf16>) -> tensor<64xf32>
    %754 = stablehlo.broadcast_in_dim %752, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %755 = stablehlo.broadcast_in_dim %753, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %756 = stablehlo.multiply %754, %755 : tensor<1x19200x64xf32>
    %757 = stablehlo.convert %arg34 : (tensor<64xbf16>) -> tensor<64xf32>
    %758 = stablehlo.broadcast_in_dim %756, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %759 = stablehlo.broadcast_in_dim %757, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %760 = stablehlo.add %758, %759 : tensor<1x19200x64xf32>
    %761 = stablehlo.convert %760 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %762 = stablehlo.reshape %761 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %763 = stablehlo.convert %762 : (tensor<19200x64xbf16>) -> tensor<19200x64xf32>
    %764 = stablehlo.dot_general %763, %arg522, contracting_dims = [1] x [0] : (tensor<19200x64xf32>, tensor<64x256xf32>) -> tensor<19200x256xf32>
    %765 = stablehlo.broadcast_in_dim %764, dims = [0, 1] : (tensor<19200x256xf32>) -> tensor<19200x256xf32>
    %766 = stablehlo.multiply %765, %260 : tensor<19200x256xf32>
    %767 = stablehlo.broadcast_in_dim %766, dims = [0, 1] : (tensor<19200x256xf32>) -> tensor<19200x256xf32>
    %768 = stablehlo.broadcast_in_dim %arg523, dims = [1] : (tensor<256xf32>) -> tensor<19200x256xf32>
    %769 = stablehlo.add %767, %768 : tensor<19200x256xf32>
    %770 = stablehlo.convert %769 : (tensor<19200x256xf32>) -> tensor<19200x256xbf16>
    %771 = stablehlo.reshape %770 : (tensor<19200x256xbf16>) -> tensor<1x19200x256xbf16>
    %772 = stablehlo.transpose %771, dims = [0, 2, 1] : (tensor<1x19200x256xbf16>) -> tensor<1x256x19200xbf16>
    %773 = stablehlo.reshape %772 : (tensor<1x256x19200xbf16>) -> tensor<1x256x120x160xbf16>
    %774 = stablehlo.convolution(%773, %arg35) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 256 : i64} : (tensor<1x256x120x160xbf16>, tensor<256x1x3x3xbf16>) -> tensor<1x256x120x160xbf16>
    %775 = stablehlo.reshape %arg36 : (tensor<256xbf16>) -> tensor<256x1x1xbf16>
    %776 = stablehlo.broadcast_in_dim %774, dims = [0, 1, 2, 3] : (tensor<1x256x120x160xbf16>) -> tensor<1x256x120x160xbf16>
    %777 = stablehlo.broadcast_in_dim %775, dims = [1, 2, 3] : (tensor<256x1x1xbf16>) -> tensor<1x256x120x160xbf16>
    %778 = stablehlo.add %776, %777 : tensor<1x256x120x160xbf16>
    %779 = stablehlo.reshape %778 : (tensor<1x256x120x160xbf16>) -> tensor<1x256x19200xbf16>
    %780 = stablehlo.transpose %779, dims = [0, 2, 1] : (tensor<1x256x19200xbf16>) -> tensor<1x19200x256xbf16>
    %781 = stablehlo.multiply %780, %cst_4 : tensor<1x19200x256xbf16>
    %782 = stablehlo.multiply %780, %277 : tensor<1x19200x256xbf16>
    %783 = stablehlo.convert %782 : (tensor<1x19200x256xbf16>) -> tensor<1x19200x256xf32>
    %784 = stablehlo.clamp %cst_5, %783, %cst_6 : tensor<1x19200x256xf32>
    %785 = stablehlo.multiply %784, %784 : tensor<1x19200x256xf32>
    %786 = stablehlo.multiply %cst_7, %785 : tensor<1x19200x256xf32>
    %787 = stablehlo.add %786, %cst_8 : tensor<1x19200x256xf32>
    %788 = stablehlo.multiply %787, %785 : tensor<1x19200x256xf32>
    %789 = stablehlo.add %788, %cst_9 : tensor<1x19200x256xf32>
    %790 = stablehlo.multiply %789, %785 : tensor<1x19200x256xf32>
    %791 = stablehlo.add %790, %cst_10 : tensor<1x19200x256xf32>
    %792 = stablehlo.multiply %791, %785 : tensor<1x19200x256xf32>
    %793 = stablehlo.add %792, %cst_11 : tensor<1x19200x256xf32>
    %794 = stablehlo.multiply %793, %785 : tensor<1x19200x256xf32>
    %795 = stablehlo.add %794, %cst_12 : tensor<1x19200x256xf32>
    %796 = stablehlo.multiply %795, %785 : tensor<1x19200x256xf32>
    %797 = stablehlo.add %796, %cst_13 : tensor<1x19200x256xf32>
    %798 = stablehlo.multiply %cst_14, %785 : tensor<1x19200x256xf32>
    %799 = stablehlo.add %798, %cst_15 : tensor<1x19200x256xf32>
    %800 = stablehlo.multiply %799, %785 : tensor<1x19200x256xf32>
    %801 = stablehlo.add %800, %cst_16 : tensor<1x19200x256xf32>
    %802 = stablehlo.multiply %801, %785 : tensor<1x19200x256xf32>
    %803 = stablehlo.add %802, %cst_17 : tensor<1x19200x256xf32>
    %804 = stablehlo.multiply %803, %785 : tensor<1x19200x256xf32>
    %805 = stablehlo.add %804, %cst_18 : tensor<1x19200x256xf32>
    %806 = stablehlo.multiply %784, %797 : tensor<1x19200x256xf32>
    %807 = stablehlo.divide %806, %805 : tensor<1x19200x256xf32>
    %808 = stablehlo.clamp %cst_19, %807, %cst_20 : tensor<1x19200x256xf32>
    %809 = stablehlo.convert %808 : (tensor<1x19200x256xf32>) -> tensor<1x19200x256xbf16>
    %810 = stablehlo.add %809, %cst_2 : tensor<1x19200x256xbf16>
    %811 = stablehlo.multiply %810, %781 : tensor<1x19200x256xbf16>
    %812 = stablehlo.reshape %811 : (tensor<1x19200x256xbf16>) -> tensor<19200x256xbf16>
    %813 = stablehlo.dot_general %812, %arg524, contracting_dims = [1] x [0] : (tensor<19200x256xbf16>, tensor<256x64xbf16>) -> tensor<19200x64xbf16>
    %814 = stablehlo.reshape %813 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %815 = stablehlo.broadcast_in_dim %814, dims = [0, 1, 2] : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %816 = stablehlo.broadcast_in_dim %arg37, dims = [2] : (tensor<64xbf16>) -> tensor<1x19200x64xbf16>
    %817 = stablehlo.add %815, %816 : tensor<1x19200x64xbf16>
    %818 = stablehlo.reshape %817 : (tensor<1x19200x64xbf16>) -> tensor<19200x64xbf16>
    %819 = stablehlo.reshape %818 : (tensor<19200x64xbf16>) -> tensor<1x19200x64xbf16>
    %820 = stablehlo.add %819, %724 : tensor<1x19200x64xbf16>
    %821 = stablehlo.convert %820 : (tensor<1x19200x64xbf16>) -> tensor<1x19200x64xf32>
    %822 = stablehlo.convert %821 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf64>
    %823 = stablehlo.reduce(%822 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %824 = stablehlo.reshape %823 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %825 = stablehlo.broadcast_in_dim %824, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %826 = stablehlo.divide %825, %14 : tensor<1x19200x1xf64>
    %827 = stablehlo.broadcast_in_dim %822, dims = [0, 1, 2] : (tensor<1x19200x64xf64>) -> tensor<1x19200x64xf64>
    %828 = stablehlo.broadcast_in_dim %826, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x64xf64>
    %829 = stablehlo.subtract %827, %828 : tensor<1x19200x64xf64>
    %830 = stablehlo.multiply %829, %829 : tensor<1x19200x64xf64>
    %831 = stablehlo.reduce(%830 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf64>, tensor<f64>) -> tensor<1x19200xf64>
    %832 = stablehlo.reshape %831 : (tensor<1x19200xf64>) -> tensor<1x19200x1xf64>
    %833 = stablehlo.broadcast_in_dim %832, dims = [0, 1, 2] : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf64>
    %834 = stablehlo.divide %833, %14 : tensor<1x19200x1xf64>
    %835 = stablehlo.convert %834 : (tensor<1x19200x1xf64>) -> tensor<1x19200x1xf32>
    %836 = stablehlo.reduce(%821 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x19200x64xf32>, tensor<f32>) -> tensor<1x19200xf32>
    %837 = stablehlo.reshape %836 : (tensor<1x19200xf32>) -> tensor<1x19200x1xf32>
    %838 = stablehlo.broadcast_in_dim %837, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %839 = stablehlo.divide %838, %30 : tensor<1x19200x1xf32>
    %840 = stablehlo.broadcast_in_dim %835, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x1xf32>
    %841 = stablehlo.add %840, %35 : tensor<1x19200x1xf32>
    %842 = stablehlo.rsqrt %841 : tensor<1x19200x1xf32>
    %843 = stablehlo.broadcast_in_dim %821, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %844 = stablehlo.broadcast_in_dim %839, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %845 = stablehlo.subtract %843, %844 : tensor<1x19200x64xf32>
    %846 = stablehlo.broadcast_in_dim %845, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %847 = stablehlo.broadcast_in_dim %842, dims = [0, 1, 2] : (tensor<1x19200x1xf32>) -> tensor<1x19200x64xf32>
    %848 = stablehlo.multiply %846, %847 : tensor<1x19200x64xf32>
    %849 = stablehlo.convert %arg38 : (tensor<64xbf16>) -> tensor<64xf32>
    %850 = stablehlo.broadcast_in_dim %848, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %851 = stablehlo.broadcast_in_dim %849, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %852 = stablehlo.multiply %850, %851 : tensor<1x19200x64xf32>
    %853 = stablehlo.convert %arg39 : (tensor<64xbf16>) -> tensor<64xf32>
    %854 = stablehlo.broadcast_in_dim %852, dims = [0, 1, 2] : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xf32>
    %855 = stablehlo.broadcast_in_dim %853, dims = [2] : (tensor<64xf32>) -> tensor<1x19200x64xf32>
    %856 = stablehlo.add %854, %855 : tensor<1x19200x64xf32>
    %857 = stablehlo.convert %856 : (tensor<1x19200x64xf32>) -> tensor<1x19200x64xbf16>
    %858 = stablehlo.reshape %857 : (tensor<1x19200x64xbf16>) -> tensor<1x120x160x64xbf16>
    %859 = stablehlo.transpose %858, dims = [0, 3, 1, 2] : (tensor<1x120x160x64xbf16>) -> tensor<1x64x120x160xbf16>
    %860 = stablehlo.convolution(%859, %arg40) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x120x160xbf16>, tensor<128x64x3x3xbf16>) -> tensor<1x128x60x80xbf16>
    %861 = stablehlo.reshape %arg41 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %862 = stablehlo.broadcast_in_dim %860, dims = [0, 1, 2, 3] : (tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16>
    %863 = stablehlo.broadcast_in_dim %861, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x60x80xbf16>
    %864 = stablehlo.add %862, %863 : tensor<1x128x60x80xbf16>
    %865 = stablehlo.reshape %864 : (tensor<1x128x60x80xbf16>) -> tensor<1x128x4800xbf16>
    %866 = stablehlo.transpose %865, dims = [0, 2, 1] : (tensor<1x128x4800xbf16>) -> tensor<1x4800x128xbf16>
    %867 = stablehlo.convert %866 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %868 = stablehlo.convert %867 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %869 = stablehlo.reduce(%868 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %870 = stablehlo.reshape %869 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %871 = stablehlo.convert %cst_89 : (tensor<1xi64>) -> tensor<1xf64>
    %872 = stablehlo.reshape %871 : (tensor<1xf64>) -> tensor<f64>
    %873 = stablehlo.broadcast_in_dim %870, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %874 = stablehlo.broadcast_in_dim %872, dims = [] : (tensor<f64>) -> tensor<1x4800x1xf64>
    %875 = stablehlo.divide %873, %874 : tensor<1x4800x1xf64>
    %876 = stablehlo.broadcast_in_dim %868, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %877 = stablehlo.broadcast_in_dim %875, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %878 = stablehlo.subtract %876, %877 : tensor<1x4800x128xf64>
    %879 = stablehlo.multiply %878, %878 : tensor<1x4800x128xf64>
    %880 = stablehlo.reduce(%879 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %881 = stablehlo.reshape %880 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %882 = stablehlo.broadcast_in_dim %881, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %883 = stablehlo.divide %882, %874 : tensor<1x4800x1xf64>
    %884 = stablehlo.convert %883 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %885 = stablehlo.reduce(%867 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %886 = stablehlo.reshape %885 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %887 = stablehlo.convert %cst_89 : (tensor<1xi64>) -> tensor<1xf32>
    %888 = stablehlo.reshape %887 : (tensor<1xf32>) -> tensor<f32>
    %889 = stablehlo.broadcast_in_dim %886, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %890 = stablehlo.broadcast_in_dim %888, dims = [] : (tensor<f32>) -> tensor<1x4800x1xf32>
    %891 = stablehlo.divide %889, %890 : tensor<1x4800x1xf32>
    %892 = stablehlo.broadcast_in_dim %884, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %893 = stablehlo.broadcast_in_dim %33, dims = [] : (tensor<f32>) -> tensor<1x4800x1xf32>
    %894 = stablehlo.add %892, %893 : tensor<1x4800x1xf32>
    %895 = stablehlo.rsqrt %894 : tensor<1x4800x1xf32>
    %896 = stablehlo.broadcast_in_dim %867, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %897 = stablehlo.broadcast_in_dim %891, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %898 = stablehlo.subtract %896, %897 : tensor<1x4800x128xf32>
    %899 = stablehlo.broadcast_in_dim %898, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %900 = stablehlo.broadcast_in_dim %895, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %901 = stablehlo.multiply %899, %900 : tensor<1x4800x128xf32>
    %902 = stablehlo.convert %arg42 : (tensor<128xbf16>) -> tensor<128xf32>
    %903 = stablehlo.broadcast_in_dim %901, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %904 = stablehlo.broadcast_in_dim %902, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %905 = stablehlo.multiply %903, %904 : tensor<1x4800x128xf32>
    %906 = stablehlo.convert %arg43 : (tensor<128xbf16>) -> tensor<128xf32>
    %907 = stablehlo.broadcast_in_dim %905, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %908 = stablehlo.broadcast_in_dim %906, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %909 = stablehlo.add %907, %908 : tensor<1x4800x128xf32>
    %910 = stablehlo.convert %909 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %911 = stablehlo.convert %910 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %912 = stablehlo.convert %911 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %913 = stablehlo.reduce(%912 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %914 = stablehlo.reshape %913 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %915 = stablehlo.broadcast_in_dim %914, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %916 = stablehlo.divide %915, %874 : tensor<1x4800x1xf64>
    %917 = stablehlo.broadcast_in_dim %912, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %918 = stablehlo.broadcast_in_dim %916, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %919 = stablehlo.subtract %917, %918 : tensor<1x4800x128xf64>
    %920 = stablehlo.multiply %919, %919 : tensor<1x4800x128xf64>
    %921 = stablehlo.reduce(%920 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %922 = stablehlo.reshape %921 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %923 = stablehlo.broadcast_in_dim %922, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %924 = stablehlo.divide %923, %874 : tensor<1x4800x1xf64>
    %925 = stablehlo.convert %924 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %926 = stablehlo.reduce(%911 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %927 = stablehlo.reshape %926 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %928 = stablehlo.broadcast_in_dim %927, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %929 = stablehlo.divide %928, %890 : tensor<1x4800x1xf32>
    %930 = stablehlo.broadcast_in_dim %925, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %931 = stablehlo.add %930, %893 : tensor<1x4800x1xf32>
    %932 = stablehlo.rsqrt %931 : tensor<1x4800x1xf32>
    %933 = stablehlo.broadcast_in_dim %911, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %934 = stablehlo.broadcast_in_dim %929, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %935 = stablehlo.subtract %933, %934 : tensor<1x4800x128xf32>
    %936 = stablehlo.broadcast_in_dim %935, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %937 = stablehlo.broadcast_in_dim %932, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %938 = stablehlo.multiply %936, %937 : tensor<1x4800x128xf32>
    %939 = stablehlo.convert %arg44 : (tensor<128xbf16>) -> tensor<128xf32>
    %940 = stablehlo.broadcast_in_dim %938, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %941 = stablehlo.broadcast_in_dim %939, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %942 = stablehlo.multiply %940, %941 : tensor<1x4800x128xf32>
    %943 = stablehlo.convert %arg45 : (tensor<128xbf16>) -> tensor<128xf32>
    %944 = stablehlo.broadcast_in_dim %942, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %945 = stablehlo.broadcast_in_dim %943, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %946 = stablehlo.add %944, %945 : tensor<1x4800x128xf32>
    %947 = stablehlo.convert %946 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %948 = stablehlo.reshape %947 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %949 = stablehlo.convert %948 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %950 = stablehlo.dot_general %949, %arg525, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %951 = stablehlo.broadcast_in_dim %950, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %952 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<4800x128xf32>
    %953 = stablehlo.multiply %951, %952 : tensor<4800x128xf32>
    %954 = stablehlo.broadcast_in_dim %953, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %955 = stablehlo.broadcast_in_dim %arg526, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %956 = stablehlo.add %954, %955 : tensor<4800x128xf32>
    %957 = stablehlo.convert %956 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %958 = stablehlo.reshape %957 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %959 = stablehlo.reshape %958 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %960 = stablehlo.transpose %959, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %961 = stablehlo.transpose %947, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %962 = stablehlo.reshape %961 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %963 = stablehlo.convolution(%962, %arg46) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %964 = stablehlo.reshape %arg47 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %965 = stablehlo.broadcast_in_dim %963, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %966 = stablehlo.broadcast_in_dim %964, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %967 = stablehlo.add %965, %966 : tensor<1x128x15x20xbf16>
    %968 = stablehlo.reshape %967 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %969 = stablehlo.transpose %968, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %970 = stablehlo.convert %969 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %971 = stablehlo.convert %970 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %972 = stablehlo.reduce(%971 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %973 = stablehlo.reshape %972 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %974 = stablehlo.broadcast_in_dim %973, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %975 = stablehlo.broadcast_in_dim %872, dims = [] : (tensor<f64>) -> tensor<1x300x1xf64>
    %976 = stablehlo.divide %974, %975 : tensor<1x300x1xf64>
    %977 = stablehlo.broadcast_in_dim %971, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %978 = stablehlo.broadcast_in_dim %976, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %979 = stablehlo.subtract %977, %978 : tensor<1x300x128xf64>
    %980 = stablehlo.multiply %979, %979 : tensor<1x300x128xf64>
    %981 = stablehlo.reduce(%980 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %982 = stablehlo.reshape %981 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %983 = stablehlo.broadcast_in_dim %982, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %984 = stablehlo.divide %983, %975 : tensor<1x300x1xf64>
    %985 = stablehlo.convert %984 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %986 = stablehlo.reduce(%970 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %987 = stablehlo.reshape %986 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %988 = stablehlo.broadcast_in_dim %987, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %989 = stablehlo.broadcast_in_dim %888, dims = [] : (tensor<f32>) -> tensor<1x300x1xf32>
    %990 = stablehlo.divide %988, %989 : tensor<1x300x1xf32>
    %991 = stablehlo.broadcast_in_dim %985, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %992 = stablehlo.add %991, %136 : tensor<1x300x1xf32>
    %993 = stablehlo.rsqrt %992 : tensor<1x300x1xf32>
    %994 = stablehlo.broadcast_in_dim %970, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %995 = stablehlo.broadcast_in_dim %990, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %996 = stablehlo.subtract %994, %995 : tensor<1x300x128xf32>
    %997 = stablehlo.broadcast_in_dim %996, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %998 = stablehlo.broadcast_in_dim %993, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %999 = stablehlo.multiply %997, %998 : tensor<1x300x128xf32>
    %1000 = stablehlo.convert %arg48 : (tensor<128xbf16>) -> tensor<128xf32>
    %1001 = stablehlo.broadcast_in_dim %999, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1002 = stablehlo.broadcast_in_dim %1000, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1003 = stablehlo.multiply %1001, %1002 : tensor<1x300x128xf32>
    %1004 = stablehlo.convert %arg49 : (tensor<128xbf16>) -> tensor<128xf32>
    %1005 = stablehlo.broadcast_in_dim %1003, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1006 = stablehlo.broadcast_in_dim %1004, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1007 = stablehlo.add %1005, %1006 : tensor<1x300x128xf32>
    %1008 = stablehlo.convert %1007 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %1009 = stablehlo.reshape %1008 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %1010 = stablehlo.convert %1009 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %1011 = stablehlo.dot_general %1010, %arg527, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1012 = stablehlo.broadcast_in_dim %1011, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1013 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<300x128xf32>
    %1014 = stablehlo.multiply %1012, %1013 : tensor<300x128xf32>
    %1015 = stablehlo.broadcast_in_dim %1014, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1016 = stablehlo.broadcast_in_dim %arg528, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1017 = stablehlo.add %1015, %1016 : tensor<300x128xf32>
    %1018 = stablehlo.convert %1017 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1019 = stablehlo.reshape %1018 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1020 = stablehlo.reshape %1019 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1021 = stablehlo.transpose %1020, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1022 = stablehlo.dot_general %1010, %arg529, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1023 = stablehlo.broadcast_in_dim %1022, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1024 = stablehlo.multiply %1023, %1013 : tensor<300x128xf32>
    %1025 = stablehlo.broadcast_in_dim %1024, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1026 = stablehlo.broadcast_in_dim %arg530, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1027 = stablehlo.add %1025, %1026 : tensor<300x128xf32>
    %1028 = stablehlo.convert %1027 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1029 = stablehlo.reshape %1028 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1030 = stablehlo.reshape %1029 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1031 = stablehlo.transpose %1030, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1032 = stablehlo.transpose %1021, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %1033 = stablehlo.reshape %960 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %1034 = stablehlo.reshape %1032 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1035 = stablehlo.broadcast_in_dim %1034, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1036 = stablehlo.dot_general %1033, %1035, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %1037 = stablehlo.reshape %1036 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1038 = stablehlo.broadcast_in_dim %1037, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1039 = stablehlo.broadcast_in_dim %184, dims = [] : (tensor<bf16>) -> tensor<1x2x4800x300xbf16>
    %1040 = stablehlo.divide %1038, %1039 : tensor<1x2x4800x300xbf16>
    %1041 = stablehlo.convert %1040 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %1042 = stablehlo.reduce(%1041 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1043 = stablehlo.reshape %1042 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1044 = stablehlo.broadcast_in_dim %1041, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1045 = stablehlo.broadcast_in_dim %1043, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1046 = stablehlo.subtract %1044, %1045 : tensor<1x2x4800x300xf32>
    %1047 = stablehlo.exponential %1046 : tensor<1x2x4800x300xf32>
    %1048 = stablehlo.reduce(%1047 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1049 = stablehlo.reshape %1048 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1050 = stablehlo.broadcast_in_dim %1047, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1051 = stablehlo.broadcast_in_dim %1049, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1052 = stablehlo.divide %1050, %1051 : tensor<1x2x4800x300xf32>
    %1053 = stablehlo.convert %1052 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %1054 = stablehlo.reshape %1053 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %1055 = stablehlo.reshape %1031 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1056 = stablehlo.broadcast_in_dim %1055, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1057 = stablehlo.dot_general %1054, %1056, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %1058 = stablehlo.reshape %1057 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1059 = stablehlo.transpose %1058, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %1060 = stablehlo.reshape %1059 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %1061 = stablehlo.reshape %1060 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1062 = stablehlo.convert %1061 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1063 = stablehlo.dot_general %1062, %arg531, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1064 = stablehlo.broadcast_in_dim %1063, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1065 = stablehlo.multiply %1064, %952 : tensor<4800x128xf32>
    %1066 = stablehlo.broadcast_in_dim %1065, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1067 = stablehlo.broadcast_in_dim %arg532, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1068 = stablehlo.add %1066, %1067 : tensor<4800x128xf32>
    %1069 = stablehlo.convert %1068 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1070 = stablehlo.reshape %1069 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1071 = stablehlo.add %1070, %910 : tensor<1x4800x128xbf16>
    %1072 = stablehlo.convert %1071 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1073 = stablehlo.convert %1072 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1074 = stablehlo.reduce(%1073 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1075 = stablehlo.reshape %1074 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1076 = stablehlo.broadcast_in_dim %1075, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1077 = stablehlo.divide %1076, %874 : tensor<1x4800x1xf64>
    %1078 = stablehlo.broadcast_in_dim %1073, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1079 = stablehlo.broadcast_in_dim %1077, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1080 = stablehlo.subtract %1078, %1079 : tensor<1x4800x128xf64>
    %1081 = stablehlo.multiply %1080, %1080 : tensor<1x4800x128xf64>
    %1082 = stablehlo.reduce(%1081 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1083 = stablehlo.reshape %1082 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1084 = stablehlo.broadcast_in_dim %1083, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1085 = stablehlo.divide %1084, %874 : tensor<1x4800x1xf64>
    %1086 = stablehlo.convert %1085 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1087 = stablehlo.reduce(%1072 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1088 = stablehlo.reshape %1087 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1089 = stablehlo.broadcast_in_dim %1088, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1090 = stablehlo.divide %1089, %890 : tensor<1x4800x1xf32>
    %1091 = stablehlo.broadcast_in_dim %1086, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1092 = stablehlo.add %1091, %893 : tensor<1x4800x1xf32>
    %1093 = stablehlo.rsqrt %1092 : tensor<1x4800x1xf32>
    %1094 = stablehlo.broadcast_in_dim %1072, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1095 = stablehlo.broadcast_in_dim %1090, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1096 = stablehlo.subtract %1094, %1095 : tensor<1x4800x128xf32>
    %1097 = stablehlo.broadcast_in_dim %1096, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1098 = stablehlo.broadcast_in_dim %1093, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1099 = stablehlo.multiply %1097, %1098 : tensor<1x4800x128xf32>
    %1100 = stablehlo.convert %arg50 : (tensor<128xbf16>) -> tensor<128xf32>
    %1101 = stablehlo.broadcast_in_dim %1099, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1102 = stablehlo.broadcast_in_dim %1100, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1103 = stablehlo.multiply %1101, %1102 : tensor<1x4800x128xf32>
    %1104 = stablehlo.convert %arg51 : (tensor<128xbf16>) -> tensor<128xf32>
    %1105 = stablehlo.broadcast_in_dim %1103, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1106 = stablehlo.broadcast_in_dim %1104, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1107 = stablehlo.add %1105, %1106 : tensor<1x4800x128xf32>
    %1108 = stablehlo.convert %1107 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1109 = stablehlo.reshape %1108 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1110 = stablehlo.convert %1109 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1111 = stablehlo.dot_general %1110, %arg533, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %1112 = stablehlo.broadcast_in_dim %1111, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1113 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<4800x512xf32>
    %1114 = stablehlo.multiply %1112, %1113 : tensor<4800x512xf32>
    %1115 = stablehlo.broadcast_in_dim %1114, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1116 = stablehlo.broadcast_in_dim %arg534, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %1117 = stablehlo.add %1115, %1116 : tensor<4800x512xf32>
    %1118 = stablehlo.convert %1117 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %1119 = stablehlo.reshape %1118 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %1120 = stablehlo.transpose %1119, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %1121 = stablehlo.reshape %1120 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %1122 = stablehlo.convolution(%1121, %arg52) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %1123 = stablehlo.reshape %arg53 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %1124 = stablehlo.broadcast_in_dim %1122, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %1125 = stablehlo.broadcast_in_dim %1123, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %1126 = stablehlo.add %1124, %1125 : tensor<1x512x60x80xbf16>
    %1127 = stablehlo.reshape %1126 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %1128 = stablehlo.transpose %1127, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %1129 = stablehlo.multiply %1128, %cst_23 : tensor<1x4800x512xbf16>
    %1130 = stablehlo.rsqrt %cst_22 : tensor<1x4800x512xbf16>
    %1131 = stablehlo.multiply %1128, %1130 : tensor<1x4800x512xbf16>
    %1132 = stablehlo.convert %1131 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %1133 = stablehlo.clamp %cst_24, %1132, %cst_25 : tensor<1x4800x512xf32>
    %1134 = stablehlo.multiply %1133, %1133 : tensor<1x4800x512xf32>
    %1135 = stablehlo.multiply %cst_26, %1134 : tensor<1x4800x512xf32>
    %1136 = stablehlo.add %1135, %cst_27 : tensor<1x4800x512xf32>
    %1137 = stablehlo.multiply %1136, %1134 : tensor<1x4800x512xf32>
    %1138 = stablehlo.add %1137, %cst_28 : tensor<1x4800x512xf32>
    %1139 = stablehlo.multiply %1138, %1134 : tensor<1x4800x512xf32>
    %1140 = stablehlo.add %1139, %cst_29 : tensor<1x4800x512xf32>
    %1141 = stablehlo.multiply %1140, %1134 : tensor<1x4800x512xf32>
    %1142 = stablehlo.add %1141, %cst_30 : tensor<1x4800x512xf32>
    %1143 = stablehlo.multiply %1142, %1134 : tensor<1x4800x512xf32>
    %1144 = stablehlo.add %1143, %cst_31 : tensor<1x4800x512xf32>
    %1145 = stablehlo.multiply %1144, %1134 : tensor<1x4800x512xf32>
    %1146 = stablehlo.add %1145, %cst_32 : tensor<1x4800x512xf32>
    %1147 = stablehlo.multiply %cst_33, %1134 : tensor<1x4800x512xf32>
    %1148 = stablehlo.add %1147, %cst_34 : tensor<1x4800x512xf32>
    %1149 = stablehlo.multiply %1148, %1134 : tensor<1x4800x512xf32>
    %1150 = stablehlo.add %1149, %cst_35 : tensor<1x4800x512xf32>
    %1151 = stablehlo.multiply %1150, %1134 : tensor<1x4800x512xf32>
    %1152 = stablehlo.add %1151, %cst_36 : tensor<1x4800x512xf32>
    %1153 = stablehlo.multiply %1152, %1134 : tensor<1x4800x512xf32>
    %1154 = stablehlo.add %1153, %cst_37 : tensor<1x4800x512xf32>
    %1155 = stablehlo.multiply %1133, %1146 : tensor<1x4800x512xf32>
    %1156 = stablehlo.divide %1155, %1154 : tensor<1x4800x512xf32>
    %1157 = stablehlo.clamp %cst_38, %1156, %cst_39 : tensor<1x4800x512xf32>
    %1158 = stablehlo.convert %1157 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %1159 = stablehlo.add %1158, %cst_21 : tensor<1x4800x512xbf16>
    %1160 = stablehlo.multiply %1159, %1129 : tensor<1x4800x512xbf16>
    %1161 = stablehlo.reshape %1160 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %1162 = stablehlo.dot_general %1161, %arg535, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %1163 = stablehlo.reshape %1162 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1164 = stablehlo.broadcast_in_dim %1163, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1165 = stablehlo.broadcast_in_dim %arg54, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %1166 = stablehlo.add %1164, %1165 : tensor<1x4800x128xbf16>
    %1167 = stablehlo.reshape %1166 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1168 = stablehlo.reshape %1167 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1169 = stablehlo.add %1168, %1071 : tensor<1x4800x128xbf16>
    %1170 = stablehlo.convert %1169 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1171 = stablehlo.convert %1170 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1172 = stablehlo.reduce(%1171 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1173 = stablehlo.reshape %1172 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1174 = stablehlo.broadcast_in_dim %1173, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1175 = stablehlo.divide %1174, %874 : tensor<1x4800x1xf64>
    %1176 = stablehlo.broadcast_in_dim %1171, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1177 = stablehlo.broadcast_in_dim %1175, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1178 = stablehlo.subtract %1176, %1177 : tensor<1x4800x128xf64>
    %1179 = stablehlo.multiply %1178, %1178 : tensor<1x4800x128xf64>
    %1180 = stablehlo.reduce(%1179 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1181 = stablehlo.reshape %1180 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1182 = stablehlo.broadcast_in_dim %1181, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1183 = stablehlo.divide %1182, %874 : tensor<1x4800x1xf64>
    %1184 = stablehlo.convert %1183 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1185 = stablehlo.reduce(%1170 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1186 = stablehlo.reshape %1185 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1187 = stablehlo.broadcast_in_dim %1186, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1188 = stablehlo.divide %1187, %890 : tensor<1x4800x1xf32>
    %1189 = stablehlo.broadcast_in_dim %1184, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1190 = stablehlo.add %1189, %893 : tensor<1x4800x1xf32>
    %1191 = stablehlo.rsqrt %1190 : tensor<1x4800x1xf32>
    %1192 = stablehlo.broadcast_in_dim %1170, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1193 = stablehlo.broadcast_in_dim %1188, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1194 = stablehlo.subtract %1192, %1193 : tensor<1x4800x128xf32>
    %1195 = stablehlo.broadcast_in_dim %1194, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1196 = stablehlo.broadcast_in_dim %1191, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1197 = stablehlo.multiply %1195, %1196 : tensor<1x4800x128xf32>
    %1198 = stablehlo.convert %arg55 : (tensor<128xbf16>) -> tensor<128xf32>
    %1199 = stablehlo.broadcast_in_dim %1197, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1200 = stablehlo.broadcast_in_dim %1198, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1201 = stablehlo.multiply %1199, %1200 : tensor<1x4800x128xf32>
    %1202 = stablehlo.convert %arg56 : (tensor<128xbf16>) -> tensor<128xf32>
    %1203 = stablehlo.broadcast_in_dim %1201, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1204 = stablehlo.broadcast_in_dim %1202, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1205 = stablehlo.add %1203, %1204 : tensor<1x4800x128xf32>
    %1206 = stablehlo.convert %1205 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1207 = stablehlo.reshape %1206 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1208 = stablehlo.convert %1207 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1209 = stablehlo.dot_general %1208, %arg536, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1210 = stablehlo.broadcast_in_dim %1209, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1211 = stablehlo.multiply %1210, %952 : tensor<4800x128xf32>
    %1212 = stablehlo.broadcast_in_dim %1211, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1213 = stablehlo.broadcast_in_dim %arg537, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1214 = stablehlo.add %1212, %1213 : tensor<4800x128xf32>
    %1215 = stablehlo.convert %1214 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1216 = stablehlo.reshape %1215 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1217 = stablehlo.reshape %1216 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %1218 = stablehlo.transpose %1217, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1219 = stablehlo.transpose %1206, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %1220 = stablehlo.reshape %1219 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %1221 = stablehlo.convolution(%1220, %arg57) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %1222 = stablehlo.reshape %arg58 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %1223 = stablehlo.broadcast_in_dim %1221, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %1224 = stablehlo.broadcast_in_dim %1222, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %1225 = stablehlo.add %1223, %1224 : tensor<1x128x15x20xbf16>
    %1226 = stablehlo.reshape %1225 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %1227 = stablehlo.transpose %1226, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %1228 = stablehlo.convert %1227 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %1229 = stablehlo.convert %1228 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %1230 = stablehlo.reduce(%1229 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1231 = stablehlo.reshape %1230 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1232 = stablehlo.broadcast_in_dim %1231, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1233 = stablehlo.divide %1232, %975 : tensor<1x300x1xf64>
    %1234 = stablehlo.broadcast_in_dim %1229, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %1235 = stablehlo.broadcast_in_dim %1233, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %1236 = stablehlo.subtract %1234, %1235 : tensor<1x300x128xf64>
    %1237 = stablehlo.multiply %1236, %1236 : tensor<1x300x128xf64>
    %1238 = stablehlo.reduce(%1237 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1239 = stablehlo.reshape %1238 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1240 = stablehlo.broadcast_in_dim %1239, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1241 = stablehlo.divide %1240, %975 : tensor<1x300x1xf64>
    %1242 = stablehlo.convert %1241 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %1243 = stablehlo.reduce(%1228 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %1244 = stablehlo.reshape %1243 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %1245 = stablehlo.broadcast_in_dim %1244, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %1246 = stablehlo.divide %1245, %989 : tensor<1x300x1xf32>
    %1247 = stablehlo.broadcast_in_dim %1242, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %1248 = stablehlo.add %1247, %136 : tensor<1x300x1xf32>
    %1249 = stablehlo.rsqrt %1248 : tensor<1x300x1xf32>
    %1250 = stablehlo.broadcast_in_dim %1228, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1251 = stablehlo.broadcast_in_dim %1246, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %1252 = stablehlo.subtract %1250, %1251 : tensor<1x300x128xf32>
    %1253 = stablehlo.broadcast_in_dim %1252, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1254 = stablehlo.broadcast_in_dim %1249, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %1255 = stablehlo.multiply %1253, %1254 : tensor<1x300x128xf32>
    %1256 = stablehlo.convert %arg59 : (tensor<128xbf16>) -> tensor<128xf32>
    %1257 = stablehlo.broadcast_in_dim %1255, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1258 = stablehlo.broadcast_in_dim %1256, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1259 = stablehlo.multiply %1257, %1258 : tensor<1x300x128xf32>
    %1260 = stablehlo.convert %arg60 : (tensor<128xbf16>) -> tensor<128xf32>
    %1261 = stablehlo.broadcast_in_dim %1259, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1262 = stablehlo.broadcast_in_dim %1260, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1263 = stablehlo.add %1261, %1262 : tensor<1x300x128xf32>
    %1264 = stablehlo.convert %1263 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %1265 = stablehlo.reshape %1264 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %1266 = stablehlo.convert %1265 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %1267 = stablehlo.dot_general %1266, %arg538, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1268 = stablehlo.broadcast_in_dim %1267, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1269 = stablehlo.multiply %1268, %1013 : tensor<300x128xf32>
    %1270 = stablehlo.broadcast_in_dim %1269, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1271 = stablehlo.broadcast_in_dim %arg539, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1272 = stablehlo.add %1270, %1271 : tensor<300x128xf32>
    %1273 = stablehlo.convert %1272 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1274 = stablehlo.reshape %1273 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1275 = stablehlo.reshape %1274 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1276 = stablehlo.transpose %1275, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1277 = stablehlo.dot_general %1266, %arg540, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1278 = stablehlo.broadcast_in_dim %1277, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1279 = stablehlo.multiply %1278, %1013 : tensor<300x128xf32>
    %1280 = stablehlo.broadcast_in_dim %1279, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1281 = stablehlo.broadcast_in_dim %arg541, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1282 = stablehlo.add %1280, %1281 : tensor<300x128xf32>
    %1283 = stablehlo.convert %1282 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1284 = stablehlo.reshape %1283 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1285 = stablehlo.reshape %1284 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1286 = stablehlo.transpose %1285, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1287 = stablehlo.transpose %1276, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %1288 = stablehlo.reshape %1218 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %1289 = stablehlo.reshape %1287 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1290 = stablehlo.broadcast_in_dim %1289, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1291 = stablehlo.dot_general %1288, %1290, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %1292 = stablehlo.reshape %1291 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1293 = stablehlo.broadcast_in_dim %1292, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1294 = stablehlo.divide %1293, %1039 : tensor<1x2x4800x300xbf16>
    %1295 = stablehlo.convert %1294 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %1296 = stablehlo.reduce(%1295 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1297 = stablehlo.reshape %1296 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1298 = stablehlo.broadcast_in_dim %1295, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1299 = stablehlo.broadcast_in_dim %1297, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1300 = stablehlo.subtract %1298, %1299 : tensor<1x2x4800x300xf32>
    %1301 = stablehlo.exponential %1300 : tensor<1x2x4800x300xf32>
    %1302 = stablehlo.reduce(%1301 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1303 = stablehlo.reshape %1302 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1304 = stablehlo.broadcast_in_dim %1301, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1305 = stablehlo.broadcast_in_dim %1303, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1306 = stablehlo.divide %1304, %1305 : tensor<1x2x4800x300xf32>
    %1307 = stablehlo.convert %1306 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %1308 = stablehlo.reshape %1307 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %1309 = stablehlo.reshape %1286 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1310 = stablehlo.broadcast_in_dim %1309, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1311 = stablehlo.dot_general %1308, %1310, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %1312 = stablehlo.reshape %1311 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1313 = stablehlo.transpose %1312, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %1314 = stablehlo.reshape %1313 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %1315 = stablehlo.reshape %1314 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1316 = stablehlo.convert %1315 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1317 = stablehlo.dot_general %1316, %arg542, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1318 = stablehlo.broadcast_in_dim %1317, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1319 = stablehlo.multiply %1318, %952 : tensor<4800x128xf32>
    %1320 = stablehlo.broadcast_in_dim %1319, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1321 = stablehlo.broadcast_in_dim %arg543, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1322 = stablehlo.add %1320, %1321 : tensor<4800x128xf32>
    %1323 = stablehlo.convert %1322 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1324 = stablehlo.reshape %1323 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1325 = stablehlo.add %1324, %1169 : tensor<1x4800x128xbf16>
    %1326 = stablehlo.convert %1325 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1327 = stablehlo.convert %1326 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1328 = stablehlo.reduce(%1327 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1329 = stablehlo.reshape %1328 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1330 = stablehlo.broadcast_in_dim %1329, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1331 = stablehlo.divide %1330, %874 : tensor<1x4800x1xf64>
    %1332 = stablehlo.broadcast_in_dim %1327, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1333 = stablehlo.broadcast_in_dim %1331, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1334 = stablehlo.subtract %1332, %1333 : tensor<1x4800x128xf64>
    %1335 = stablehlo.multiply %1334, %1334 : tensor<1x4800x128xf64>
    %1336 = stablehlo.reduce(%1335 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1337 = stablehlo.reshape %1336 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1338 = stablehlo.broadcast_in_dim %1337, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1339 = stablehlo.divide %1338, %874 : tensor<1x4800x1xf64>
    %1340 = stablehlo.convert %1339 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1341 = stablehlo.reduce(%1326 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1342 = stablehlo.reshape %1341 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1343 = stablehlo.broadcast_in_dim %1342, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1344 = stablehlo.divide %1343, %890 : tensor<1x4800x1xf32>
    %1345 = stablehlo.broadcast_in_dim %1340, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1346 = stablehlo.add %1345, %893 : tensor<1x4800x1xf32>
    %1347 = stablehlo.rsqrt %1346 : tensor<1x4800x1xf32>
    %1348 = stablehlo.broadcast_in_dim %1326, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1349 = stablehlo.broadcast_in_dim %1344, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1350 = stablehlo.subtract %1348, %1349 : tensor<1x4800x128xf32>
    %1351 = stablehlo.broadcast_in_dim %1350, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1352 = stablehlo.broadcast_in_dim %1347, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1353 = stablehlo.multiply %1351, %1352 : tensor<1x4800x128xf32>
    %1354 = stablehlo.convert %arg61 : (tensor<128xbf16>) -> tensor<128xf32>
    %1355 = stablehlo.broadcast_in_dim %1353, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1356 = stablehlo.broadcast_in_dim %1354, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1357 = stablehlo.multiply %1355, %1356 : tensor<1x4800x128xf32>
    %1358 = stablehlo.convert %arg62 : (tensor<128xbf16>) -> tensor<128xf32>
    %1359 = stablehlo.broadcast_in_dim %1357, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1360 = stablehlo.broadcast_in_dim %1358, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1361 = stablehlo.add %1359, %1360 : tensor<1x4800x128xf32>
    %1362 = stablehlo.convert %1361 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1363 = stablehlo.reshape %1362 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1364 = stablehlo.convert %1363 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1365 = stablehlo.dot_general %1364, %arg544, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %1366 = stablehlo.broadcast_in_dim %1365, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1367 = stablehlo.multiply %1366, %1113 : tensor<4800x512xf32>
    %1368 = stablehlo.broadcast_in_dim %1367, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1369 = stablehlo.broadcast_in_dim %arg545, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %1370 = stablehlo.add %1368, %1369 : tensor<4800x512xf32>
    %1371 = stablehlo.convert %1370 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %1372 = stablehlo.reshape %1371 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %1373 = stablehlo.transpose %1372, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %1374 = stablehlo.reshape %1373 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %1375 = stablehlo.convolution(%1374, %arg63) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %1376 = stablehlo.reshape %arg64 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %1377 = stablehlo.broadcast_in_dim %1375, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %1378 = stablehlo.broadcast_in_dim %1376, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %1379 = stablehlo.add %1377, %1378 : tensor<1x512x60x80xbf16>
    %1380 = stablehlo.reshape %1379 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %1381 = stablehlo.transpose %1380, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %1382 = stablehlo.multiply %1381, %cst_23 : tensor<1x4800x512xbf16>
    %1383 = stablehlo.multiply %1381, %1130 : tensor<1x4800x512xbf16>
    %1384 = stablehlo.convert %1383 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %1385 = stablehlo.clamp %cst_24, %1384, %cst_25 : tensor<1x4800x512xf32>
    %1386 = stablehlo.multiply %1385, %1385 : tensor<1x4800x512xf32>
    %1387 = stablehlo.multiply %cst_26, %1386 : tensor<1x4800x512xf32>
    %1388 = stablehlo.add %1387, %cst_27 : tensor<1x4800x512xf32>
    %1389 = stablehlo.multiply %1388, %1386 : tensor<1x4800x512xf32>
    %1390 = stablehlo.add %1389, %cst_28 : tensor<1x4800x512xf32>
    %1391 = stablehlo.multiply %1390, %1386 : tensor<1x4800x512xf32>
    %1392 = stablehlo.add %1391, %cst_29 : tensor<1x4800x512xf32>
    %1393 = stablehlo.multiply %1392, %1386 : tensor<1x4800x512xf32>
    %1394 = stablehlo.add %1393, %cst_30 : tensor<1x4800x512xf32>
    %1395 = stablehlo.multiply %1394, %1386 : tensor<1x4800x512xf32>
    %1396 = stablehlo.add %1395, %cst_31 : tensor<1x4800x512xf32>
    %1397 = stablehlo.multiply %1396, %1386 : tensor<1x4800x512xf32>
    %1398 = stablehlo.add %1397, %cst_32 : tensor<1x4800x512xf32>
    %1399 = stablehlo.multiply %cst_33, %1386 : tensor<1x4800x512xf32>
    %1400 = stablehlo.add %1399, %cst_34 : tensor<1x4800x512xf32>
    %1401 = stablehlo.multiply %1400, %1386 : tensor<1x4800x512xf32>
    %1402 = stablehlo.add %1401, %cst_35 : tensor<1x4800x512xf32>
    %1403 = stablehlo.multiply %1402, %1386 : tensor<1x4800x512xf32>
    %1404 = stablehlo.add %1403, %cst_36 : tensor<1x4800x512xf32>
    %1405 = stablehlo.multiply %1404, %1386 : tensor<1x4800x512xf32>
    %1406 = stablehlo.add %1405, %cst_37 : tensor<1x4800x512xf32>
    %1407 = stablehlo.multiply %1385, %1398 : tensor<1x4800x512xf32>
    %1408 = stablehlo.divide %1407, %1406 : tensor<1x4800x512xf32>
    %1409 = stablehlo.clamp %cst_38, %1408, %cst_39 : tensor<1x4800x512xf32>
    %1410 = stablehlo.convert %1409 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %1411 = stablehlo.add %1410, %cst_21 : tensor<1x4800x512xbf16>
    %1412 = stablehlo.multiply %1411, %1382 : tensor<1x4800x512xbf16>
    %1413 = stablehlo.reshape %1412 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %1414 = stablehlo.dot_general %1413, %arg546, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %1415 = stablehlo.reshape %1414 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1416 = stablehlo.broadcast_in_dim %1415, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1417 = stablehlo.broadcast_in_dim %arg65, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %1418 = stablehlo.add %1416, %1417 : tensor<1x4800x128xbf16>
    %1419 = stablehlo.reshape %1418 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1420 = stablehlo.reshape %1419 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1421 = stablehlo.add %1420, %1325 : tensor<1x4800x128xbf16>
    %1422 = stablehlo.convert %1421 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1423 = stablehlo.convert %1422 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1424 = stablehlo.reduce(%1423 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1425 = stablehlo.reshape %1424 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1426 = stablehlo.broadcast_in_dim %1425, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1427 = stablehlo.divide %1426, %874 : tensor<1x4800x1xf64>
    %1428 = stablehlo.broadcast_in_dim %1423, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1429 = stablehlo.broadcast_in_dim %1427, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1430 = stablehlo.subtract %1428, %1429 : tensor<1x4800x128xf64>
    %1431 = stablehlo.multiply %1430, %1430 : tensor<1x4800x128xf64>
    %1432 = stablehlo.reduce(%1431 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1433 = stablehlo.reshape %1432 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1434 = stablehlo.broadcast_in_dim %1433, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1435 = stablehlo.divide %1434, %874 : tensor<1x4800x1xf64>
    %1436 = stablehlo.convert %1435 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1437 = stablehlo.reduce(%1422 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1438 = stablehlo.reshape %1437 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1439 = stablehlo.broadcast_in_dim %1438, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1440 = stablehlo.divide %1439, %890 : tensor<1x4800x1xf32>
    %1441 = stablehlo.broadcast_in_dim %1436, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1442 = stablehlo.add %1441, %893 : tensor<1x4800x1xf32>
    %1443 = stablehlo.rsqrt %1442 : tensor<1x4800x1xf32>
    %1444 = stablehlo.broadcast_in_dim %1422, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1445 = stablehlo.broadcast_in_dim %1440, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1446 = stablehlo.subtract %1444, %1445 : tensor<1x4800x128xf32>
    %1447 = stablehlo.broadcast_in_dim %1446, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1448 = stablehlo.broadcast_in_dim %1443, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1449 = stablehlo.multiply %1447, %1448 : tensor<1x4800x128xf32>
    %1450 = stablehlo.convert %arg66 : (tensor<128xbf16>) -> tensor<128xf32>
    %1451 = stablehlo.broadcast_in_dim %1449, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1452 = stablehlo.broadcast_in_dim %1450, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1453 = stablehlo.multiply %1451, %1452 : tensor<1x4800x128xf32>
    %1454 = stablehlo.convert %arg67 : (tensor<128xbf16>) -> tensor<128xf32>
    %1455 = stablehlo.broadcast_in_dim %1453, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1456 = stablehlo.broadcast_in_dim %1454, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1457 = stablehlo.add %1455, %1456 : tensor<1x4800x128xf32>
    %1458 = stablehlo.convert %1457 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1459 = stablehlo.reshape %1458 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1460 = stablehlo.convert %1459 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1461 = stablehlo.dot_general %1460, %arg547, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1462 = stablehlo.broadcast_in_dim %1461, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1463 = stablehlo.multiply %1462, %952 : tensor<4800x128xf32>
    %1464 = stablehlo.broadcast_in_dim %1463, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1465 = stablehlo.broadcast_in_dim %arg548, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1466 = stablehlo.add %1464, %1465 : tensor<4800x128xf32>
    %1467 = stablehlo.convert %1466 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1468 = stablehlo.reshape %1467 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1469 = stablehlo.reshape %1468 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %1470 = stablehlo.transpose %1469, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1471 = stablehlo.transpose %1458, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %1472 = stablehlo.reshape %1471 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %1473 = stablehlo.convolution(%1472, %arg68) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %1474 = stablehlo.reshape %arg69 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %1475 = stablehlo.broadcast_in_dim %1473, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %1476 = stablehlo.broadcast_in_dim %1474, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %1477 = stablehlo.add %1475, %1476 : tensor<1x128x15x20xbf16>
    %1478 = stablehlo.reshape %1477 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %1479 = stablehlo.transpose %1478, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %1480 = stablehlo.convert %1479 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %1481 = stablehlo.convert %1480 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %1482 = stablehlo.reduce(%1481 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1483 = stablehlo.reshape %1482 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1484 = stablehlo.broadcast_in_dim %1483, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1485 = stablehlo.divide %1484, %975 : tensor<1x300x1xf64>
    %1486 = stablehlo.broadcast_in_dim %1481, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %1487 = stablehlo.broadcast_in_dim %1485, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %1488 = stablehlo.subtract %1486, %1487 : tensor<1x300x128xf64>
    %1489 = stablehlo.multiply %1488, %1488 : tensor<1x300x128xf64>
    %1490 = stablehlo.reduce(%1489 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1491 = stablehlo.reshape %1490 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1492 = stablehlo.broadcast_in_dim %1491, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1493 = stablehlo.divide %1492, %975 : tensor<1x300x1xf64>
    %1494 = stablehlo.convert %1493 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %1495 = stablehlo.reduce(%1480 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %1496 = stablehlo.reshape %1495 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %1497 = stablehlo.broadcast_in_dim %1496, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %1498 = stablehlo.divide %1497, %989 : tensor<1x300x1xf32>
    %1499 = stablehlo.broadcast_in_dim %1494, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %1500 = stablehlo.add %1499, %136 : tensor<1x300x1xf32>
    %1501 = stablehlo.rsqrt %1500 : tensor<1x300x1xf32>
    %1502 = stablehlo.broadcast_in_dim %1480, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1503 = stablehlo.broadcast_in_dim %1498, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %1504 = stablehlo.subtract %1502, %1503 : tensor<1x300x128xf32>
    %1505 = stablehlo.broadcast_in_dim %1504, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1506 = stablehlo.broadcast_in_dim %1501, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %1507 = stablehlo.multiply %1505, %1506 : tensor<1x300x128xf32>
    %1508 = stablehlo.convert %arg70 : (tensor<128xbf16>) -> tensor<128xf32>
    %1509 = stablehlo.broadcast_in_dim %1507, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1510 = stablehlo.broadcast_in_dim %1508, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1511 = stablehlo.multiply %1509, %1510 : tensor<1x300x128xf32>
    %1512 = stablehlo.convert %arg71 : (tensor<128xbf16>) -> tensor<128xf32>
    %1513 = stablehlo.broadcast_in_dim %1511, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1514 = stablehlo.broadcast_in_dim %1512, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1515 = stablehlo.add %1513, %1514 : tensor<1x300x128xf32>
    %1516 = stablehlo.convert %1515 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %1517 = stablehlo.reshape %1516 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %1518 = stablehlo.convert %1517 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %1519 = stablehlo.dot_general %1518, %arg549, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1520 = stablehlo.broadcast_in_dim %1519, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1521 = stablehlo.multiply %1520, %1013 : tensor<300x128xf32>
    %1522 = stablehlo.broadcast_in_dim %1521, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1523 = stablehlo.broadcast_in_dim %arg550, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1524 = stablehlo.add %1522, %1523 : tensor<300x128xf32>
    %1525 = stablehlo.convert %1524 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1526 = stablehlo.reshape %1525 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1527 = stablehlo.reshape %1526 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1528 = stablehlo.transpose %1527, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1529 = stablehlo.dot_general %1518, %arg551, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1530 = stablehlo.broadcast_in_dim %1529, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1531 = stablehlo.multiply %1530, %1013 : tensor<300x128xf32>
    %1532 = stablehlo.broadcast_in_dim %1531, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1533 = stablehlo.broadcast_in_dim %arg552, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1534 = stablehlo.add %1532, %1533 : tensor<300x128xf32>
    %1535 = stablehlo.convert %1534 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1536 = stablehlo.reshape %1535 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1537 = stablehlo.reshape %1536 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1538 = stablehlo.transpose %1537, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1539 = stablehlo.transpose %1528, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %1540 = stablehlo.reshape %1470 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %1541 = stablehlo.reshape %1539 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1542 = stablehlo.broadcast_in_dim %1541, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1543 = stablehlo.dot_general %1540, %1542, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %1544 = stablehlo.reshape %1543 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1545 = stablehlo.broadcast_in_dim %1544, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1546 = stablehlo.divide %1545, %1039 : tensor<1x2x4800x300xbf16>
    %1547 = stablehlo.convert %1546 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %1548 = stablehlo.reduce(%1547 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1549 = stablehlo.reshape %1548 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1550 = stablehlo.broadcast_in_dim %1547, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1551 = stablehlo.broadcast_in_dim %1549, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1552 = stablehlo.subtract %1550, %1551 : tensor<1x2x4800x300xf32>
    %1553 = stablehlo.exponential %1552 : tensor<1x2x4800x300xf32>
    %1554 = stablehlo.reduce(%1553 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1555 = stablehlo.reshape %1554 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1556 = stablehlo.broadcast_in_dim %1553, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1557 = stablehlo.broadcast_in_dim %1555, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1558 = stablehlo.divide %1556, %1557 : tensor<1x2x4800x300xf32>
    %1559 = stablehlo.convert %1558 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %1560 = stablehlo.reshape %1559 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %1561 = stablehlo.reshape %1538 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1562 = stablehlo.broadcast_in_dim %1561, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1563 = stablehlo.dot_general %1560, %1562, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %1564 = stablehlo.reshape %1563 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1565 = stablehlo.transpose %1564, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %1566 = stablehlo.reshape %1565 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %1567 = stablehlo.reshape %1566 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1568 = stablehlo.convert %1567 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1569 = stablehlo.dot_general %1568, %arg553, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1570 = stablehlo.broadcast_in_dim %1569, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1571 = stablehlo.multiply %1570, %952 : tensor<4800x128xf32>
    %1572 = stablehlo.broadcast_in_dim %1571, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1573 = stablehlo.broadcast_in_dim %arg554, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1574 = stablehlo.add %1572, %1573 : tensor<4800x128xf32>
    %1575 = stablehlo.convert %1574 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1576 = stablehlo.reshape %1575 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1577 = stablehlo.add %1576, %1421 : tensor<1x4800x128xbf16>
    %1578 = stablehlo.convert %1577 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1579 = stablehlo.convert %1578 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1580 = stablehlo.reduce(%1579 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1581 = stablehlo.reshape %1580 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1582 = stablehlo.broadcast_in_dim %1581, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1583 = stablehlo.divide %1582, %874 : tensor<1x4800x1xf64>
    %1584 = stablehlo.broadcast_in_dim %1579, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1585 = stablehlo.broadcast_in_dim %1583, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1586 = stablehlo.subtract %1584, %1585 : tensor<1x4800x128xf64>
    %1587 = stablehlo.multiply %1586, %1586 : tensor<1x4800x128xf64>
    %1588 = stablehlo.reduce(%1587 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1589 = stablehlo.reshape %1588 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1590 = stablehlo.broadcast_in_dim %1589, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1591 = stablehlo.divide %1590, %874 : tensor<1x4800x1xf64>
    %1592 = stablehlo.convert %1591 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1593 = stablehlo.reduce(%1578 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1594 = stablehlo.reshape %1593 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1595 = stablehlo.broadcast_in_dim %1594, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1596 = stablehlo.divide %1595, %890 : tensor<1x4800x1xf32>
    %1597 = stablehlo.broadcast_in_dim %1592, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1598 = stablehlo.add %1597, %893 : tensor<1x4800x1xf32>
    %1599 = stablehlo.rsqrt %1598 : tensor<1x4800x1xf32>
    %1600 = stablehlo.broadcast_in_dim %1578, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1601 = stablehlo.broadcast_in_dim %1596, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1602 = stablehlo.subtract %1600, %1601 : tensor<1x4800x128xf32>
    %1603 = stablehlo.broadcast_in_dim %1602, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1604 = stablehlo.broadcast_in_dim %1599, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1605 = stablehlo.multiply %1603, %1604 : tensor<1x4800x128xf32>
    %1606 = stablehlo.convert %arg72 : (tensor<128xbf16>) -> tensor<128xf32>
    %1607 = stablehlo.broadcast_in_dim %1605, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1608 = stablehlo.broadcast_in_dim %1606, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1609 = stablehlo.multiply %1607, %1608 : tensor<1x4800x128xf32>
    %1610 = stablehlo.convert %arg73 : (tensor<128xbf16>) -> tensor<128xf32>
    %1611 = stablehlo.broadcast_in_dim %1609, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1612 = stablehlo.broadcast_in_dim %1610, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1613 = stablehlo.add %1611, %1612 : tensor<1x4800x128xf32>
    %1614 = stablehlo.convert %1613 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1615 = stablehlo.reshape %1614 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1616 = stablehlo.convert %1615 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1617 = stablehlo.dot_general %1616, %arg555, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %1618 = stablehlo.broadcast_in_dim %1617, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1619 = stablehlo.multiply %1618, %1113 : tensor<4800x512xf32>
    %1620 = stablehlo.broadcast_in_dim %1619, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1621 = stablehlo.broadcast_in_dim %arg556, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %1622 = stablehlo.add %1620, %1621 : tensor<4800x512xf32>
    %1623 = stablehlo.convert %1622 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %1624 = stablehlo.reshape %1623 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %1625 = stablehlo.transpose %1624, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %1626 = stablehlo.reshape %1625 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %1627 = stablehlo.convolution(%1626, %arg74) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %1628 = stablehlo.reshape %arg75 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %1629 = stablehlo.broadcast_in_dim %1627, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %1630 = stablehlo.broadcast_in_dim %1628, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %1631 = stablehlo.add %1629, %1630 : tensor<1x512x60x80xbf16>
    %1632 = stablehlo.reshape %1631 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %1633 = stablehlo.transpose %1632, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %1634 = stablehlo.multiply %1633, %cst_23 : tensor<1x4800x512xbf16>
    %1635 = stablehlo.multiply %1633, %1130 : tensor<1x4800x512xbf16>
    %1636 = stablehlo.convert %1635 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %1637 = stablehlo.clamp %cst_24, %1636, %cst_25 : tensor<1x4800x512xf32>
    %1638 = stablehlo.multiply %1637, %1637 : tensor<1x4800x512xf32>
    %1639 = stablehlo.multiply %cst_26, %1638 : tensor<1x4800x512xf32>
    %1640 = stablehlo.add %1639, %cst_27 : tensor<1x4800x512xf32>
    %1641 = stablehlo.multiply %1640, %1638 : tensor<1x4800x512xf32>
    %1642 = stablehlo.add %1641, %cst_28 : tensor<1x4800x512xf32>
    %1643 = stablehlo.multiply %1642, %1638 : tensor<1x4800x512xf32>
    %1644 = stablehlo.add %1643, %cst_29 : tensor<1x4800x512xf32>
    %1645 = stablehlo.multiply %1644, %1638 : tensor<1x4800x512xf32>
    %1646 = stablehlo.add %1645, %cst_30 : tensor<1x4800x512xf32>
    %1647 = stablehlo.multiply %1646, %1638 : tensor<1x4800x512xf32>
    %1648 = stablehlo.add %1647, %cst_31 : tensor<1x4800x512xf32>
    %1649 = stablehlo.multiply %1648, %1638 : tensor<1x4800x512xf32>
    %1650 = stablehlo.add %1649, %cst_32 : tensor<1x4800x512xf32>
    %1651 = stablehlo.multiply %cst_33, %1638 : tensor<1x4800x512xf32>
    %1652 = stablehlo.add %1651, %cst_34 : tensor<1x4800x512xf32>
    %1653 = stablehlo.multiply %1652, %1638 : tensor<1x4800x512xf32>
    %1654 = stablehlo.add %1653, %cst_35 : tensor<1x4800x512xf32>
    %1655 = stablehlo.multiply %1654, %1638 : tensor<1x4800x512xf32>
    %1656 = stablehlo.add %1655, %cst_36 : tensor<1x4800x512xf32>
    %1657 = stablehlo.multiply %1656, %1638 : tensor<1x4800x512xf32>
    %1658 = stablehlo.add %1657, %cst_37 : tensor<1x4800x512xf32>
    %1659 = stablehlo.multiply %1637, %1650 : tensor<1x4800x512xf32>
    %1660 = stablehlo.divide %1659, %1658 : tensor<1x4800x512xf32>
    %1661 = stablehlo.clamp %cst_38, %1660, %cst_39 : tensor<1x4800x512xf32>
    %1662 = stablehlo.convert %1661 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %1663 = stablehlo.add %1662, %cst_21 : tensor<1x4800x512xbf16>
    %1664 = stablehlo.multiply %1663, %1634 : tensor<1x4800x512xbf16>
    %1665 = stablehlo.reshape %1664 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %1666 = stablehlo.dot_general %1665, %arg557, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %1667 = stablehlo.reshape %1666 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1668 = stablehlo.broadcast_in_dim %1667, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1669 = stablehlo.broadcast_in_dim %arg76, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %1670 = stablehlo.add %1668, %1669 : tensor<1x4800x128xbf16>
    %1671 = stablehlo.reshape %1670 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1672 = stablehlo.reshape %1671 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1673 = stablehlo.add %1672, %1577 : tensor<1x4800x128xbf16>
    %1674 = stablehlo.convert %1673 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1675 = stablehlo.convert %1674 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1676 = stablehlo.reduce(%1675 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1677 = stablehlo.reshape %1676 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1678 = stablehlo.broadcast_in_dim %1677, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1679 = stablehlo.divide %1678, %874 : tensor<1x4800x1xf64>
    %1680 = stablehlo.broadcast_in_dim %1675, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1681 = stablehlo.broadcast_in_dim %1679, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1682 = stablehlo.subtract %1680, %1681 : tensor<1x4800x128xf64>
    %1683 = stablehlo.multiply %1682, %1682 : tensor<1x4800x128xf64>
    %1684 = stablehlo.reduce(%1683 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1685 = stablehlo.reshape %1684 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1686 = stablehlo.broadcast_in_dim %1685, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1687 = stablehlo.divide %1686, %874 : tensor<1x4800x1xf64>
    %1688 = stablehlo.convert %1687 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1689 = stablehlo.reduce(%1674 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1690 = stablehlo.reshape %1689 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1691 = stablehlo.broadcast_in_dim %1690, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1692 = stablehlo.divide %1691, %890 : tensor<1x4800x1xf32>
    %1693 = stablehlo.broadcast_in_dim %1688, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1694 = stablehlo.add %1693, %893 : tensor<1x4800x1xf32>
    %1695 = stablehlo.rsqrt %1694 : tensor<1x4800x1xf32>
    %1696 = stablehlo.broadcast_in_dim %1674, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1697 = stablehlo.broadcast_in_dim %1692, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1698 = stablehlo.subtract %1696, %1697 : tensor<1x4800x128xf32>
    %1699 = stablehlo.broadcast_in_dim %1698, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1700 = stablehlo.broadcast_in_dim %1695, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1701 = stablehlo.multiply %1699, %1700 : tensor<1x4800x128xf32>
    %1702 = stablehlo.convert %arg77 : (tensor<128xbf16>) -> tensor<128xf32>
    %1703 = stablehlo.broadcast_in_dim %1701, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1704 = stablehlo.broadcast_in_dim %1702, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1705 = stablehlo.multiply %1703, %1704 : tensor<1x4800x128xf32>
    %1706 = stablehlo.convert %arg78 : (tensor<128xbf16>) -> tensor<128xf32>
    %1707 = stablehlo.broadcast_in_dim %1705, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1708 = stablehlo.broadcast_in_dim %1706, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1709 = stablehlo.add %1707, %1708 : tensor<1x4800x128xf32>
    %1710 = stablehlo.convert %1709 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1711 = stablehlo.reshape %1710 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1712 = stablehlo.convert %1711 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1713 = stablehlo.dot_general %1712, %arg558, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1714 = stablehlo.broadcast_in_dim %1713, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1715 = stablehlo.multiply %1714, %952 : tensor<4800x128xf32>
    %1716 = stablehlo.broadcast_in_dim %1715, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1717 = stablehlo.broadcast_in_dim %arg559, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1718 = stablehlo.add %1716, %1717 : tensor<4800x128xf32>
    %1719 = stablehlo.convert %1718 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1720 = stablehlo.reshape %1719 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1721 = stablehlo.reshape %1720 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %1722 = stablehlo.transpose %1721, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1723 = stablehlo.transpose %1710, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %1724 = stablehlo.reshape %1723 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %1725 = stablehlo.convolution(%1724, %arg79) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %1726 = stablehlo.reshape %arg80 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %1727 = stablehlo.broadcast_in_dim %1725, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %1728 = stablehlo.broadcast_in_dim %1726, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %1729 = stablehlo.add %1727, %1728 : tensor<1x128x15x20xbf16>
    %1730 = stablehlo.reshape %1729 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %1731 = stablehlo.transpose %1730, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %1732 = stablehlo.convert %1731 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %1733 = stablehlo.convert %1732 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %1734 = stablehlo.reduce(%1733 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1735 = stablehlo.reshape %1734 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1736 = stablehlo.broadcast_in_dim %1735, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1737 = stablehlo.divide %1736, %975 : tensor<1x300x1xf64>
    %1738 = stablehlo.broadcast_in_dim %1733, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %1739 = stablehlo.broadcast_in_dim %1737, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %1740 = stablehlo.subtract %1738, %1739 : tensor<1x300x128xf64>
    %1741 = stablehlo.multiply %1740, %1740 : tensor<1x300x128xf64>
    %1742 = stablehlo.reduce(%1741 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1743 = stablehlo.reshape %1742 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1744 = stablehlo.broadcast_in_dim %1743, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1745 = stablehlo.divide %1744, %975 : tensor<1x300x1xf64>
    %1746 = stablehlo.convert %1745 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %1747 = stablehlo.reduce(%1732 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %1748 = stablehlo.reshape %1747 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %1749 = stablehlo.broadcast_in_dim %1748, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %1750 = stablehlo.divide %1749, %989 : tensor<1x300x1xf32>
    %1751 = stablehlo.broadcast_in_dim %1746, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %1752 = stablehlo.add %1751, %136 : tensor<1x300x1xf32>
    %1753 = stablehlo.rsqrt %1752 : tensor<1x300x1xf32>
    %1754 = stablehlo.broadcast_in_dim %1732, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1755 = stablehlo.broadcast_in_dim %1750, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %1756 = stablehlo.subtract %1754, %1755 : tensor<1x300x128xf32>
    %1757 = stablehlo.broadcast_in_dim %1756, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1758 = stablehlo.broadcast_in_dim %1753, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %1759 = stablehlo.multiply %1757, %1758 : tensor<1x300x128xf32>
    %1760 = stablehlo.convert %arg81 : (tensor<128xbf16>) -> tensor<128xf32>
    %1761 = stablehlo.broadcast_in_dim %1759, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1762 = stablehlo.broadcast_in_dim %1760, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1763 = stablehlo.multiply %1761, %1762 : tensor<1x300x128xf32>
    %1764 = stablehlo.convert %arg82 : (tensor<128xbf16>) -> tensor<128xf32>
    %1765 = stablehlo.broadcast_in_dim %1763, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %1766 = stablehlo.broadcast_in_dim %1764, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %1767 = stablehlo.add %1765, %1766 : tensor<1x300x128xf32>
    %1768 = stablehlo.convert %1767 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %1769 = stablehlo.reshape %1768 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %1770 = stablehlo.convert %1769 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %1771 = stablehlo.dot_general %1770, %arg560, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1772 = stablehlo.broadcast_in_dim %1771, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1773 = stablehlo.multiply %1772, %1013 : tensor<300x128xf32>
    %1774 = stablehlo.broadcast_in_dim %1773, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1775 = stablehlo.broadcast_in_dim %arg561, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1776 = stablehlo.add %1774, %1775 : tensor<300x128xf32>
    %1777 = stablehlo.convert %1776 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1778 = stablehlo.reshape %1777 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1779 = stablehlo.reshape %1778 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1780 = stablehlo.transpose %1779, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1781 = stablehlo.dot_general %1770, %arg562, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %1782 = stablehlo.broadcast_in_dim %1781, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1783 = stablehlo.multiply %1782, %1013 : tensor<300x128xf32>
    %1784 = stablehlo.broadcast_in_dim %1783, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %1785 = stablehlo.broadcast_in_dim %arg563, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %1786 = stablehlo.add %1784, %1785 : tensor<300x128xf32>
    %1787 = stablehlo.convert %1786 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %1788 = stablehlo.reshape %1787 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %1789 = stablehlo.reshape %1788 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %1790 = stablehlo.transpose %1789, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %1791 = stablehlo.transpose %1780, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %1792 = stablehlo.reshape %1722 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %1793 = stablehlo.reshape %1791 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1794 = stablehlo.broadcast_in_dim %1793, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %1795 = stablehlo.dot_general %1792, %1794, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %1796 = stablehlo.reshape %1795 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1797 = stablehlo.broadcast_in_dim %1796, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %1798 = stablehlo.divide %1797, %1039 : tensor<1x2x4800x300xbf16>
    %1799 = stablehlo.convert %1798 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %1800 = stablehlo.reduce(%1799 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1801 = stablehlo.reshape %1800 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1802 = stablehlo.broadcast_in_dim %1799, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1803 = stablehlo.broadcast_in_dim %1801, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1804 = stablehlo.subtract %1802, %1803 : tensor<1x2x4800x300xf32>
    %1805 = stablehlo.exponential %1804 : tensor<1x2x4800x300xf32>
    %1806 = stablehlo.reduce(%1805 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %1807 = stablehlo.reshape %1806 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %1808 = stablehlo.broadcast_in_dim %1805, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %1809 = stablehlo.broadcast_in_dim %1807, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %1810 = stablehlo.divide %1808, %1809 : tensor<1x2x4800x300xf32>
    %1811 = stablehlo.convert %1810 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %1812 = stablehlo.reshape %1811 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %1813 = stablehlo.reshape %1790 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1814 = stablehlo.broadcast_in_dim %1813, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %1815 = stablehlo.dot_general %1812, %1814, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %1816 = stablehlo.reshape %1815 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1817 = stablehlo.transpose %1816, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %1818 = stablehlo.reshape %1817 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %1819 = stablehlo.reshape %1818 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1820 = stablehlo.convert %1819 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1821 = stablehlo.dot_general %1820, %arg564, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1822 = stablehlo.broadcast_in_dim %1821, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1823 = stablehlo.multiply %1822, %952 : tensor<4800x128xf32>
    %1824 = stablehlo.broadcast_in_dim %1823, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1825 = stablehlo.broadcast_in_dim %arg565, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1826 = stablehlo.add %1824, %1825 : tensor<4800x128xf32>
    %1827 = stablehlo.convert %1826 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1828 = stablehlo.reshape %1827 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1829 = stablehlo.add %1828, %1673 : tensor<1x4800x128xbf16>
    %1830 = stablehlo.convert %1829 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1831 = stablehlo.convert %1830 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1832 = stablehlo.reduce(%1831 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1833 = stablehlo.reshape %1832 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1834 = stablehlo.broadcast_in_dim %1833, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1835 = stablehlo.divide %1834, %874 : tensor<1x4800x1xf64>
    %1836 = stablehlo.broadcast_in_dim %1831, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1837 = stablehlo.broadcast_in_dim %1835, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1838 = stablehlo.subtract %1836, %1837 : tensor<1x4800x128xf64>
    %1839 = stablehlo.multiply %1838, %1838 : tensor<1x4800x128xf64>
    %1840 = stablehlo.reduce(%1839 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1841 = stablehlo.reshape %1840 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1842 = stablehlo.broadcast_in_dim %1841, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1843 = stablehlo.divide %1842, %874 : tensor<1x4800x1xf64>
    %1844 = stablehlo.convert %1843 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1845 = stablehlo.reduce(%1830 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1846 = stablehlo.reshape %1845 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1847 = stablehlo.broadcast_in_dim %1846, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1848 = stablehlo.divide %1847, %890 : tensor<1x4800x1xf32>
    %1849 = stablehlo.broadcast_in_dim %1844, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1850 = stablehlo.add %1849, %893 : tensor<1x4800x1xf32>
    %1851 = stablehlo.rsqrt %1850 : tensor<1x4800x1xf32>
    %1852 = stablehlo.broadcast_in_dim %1830, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1853 = stablehlo.broadcast_in_dim %1848, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1854 = stablehlo.subtract %1852, %1853 : tensor<1x4800x128xf32>
    %1855 = stablehlo.broadcast_in_dim %1854, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1856 = stablehlo.broadcast_in_dim %1851, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1857 = stablehlo.multiply %1855, %1856 : tensor<1x4800x128xf32>
    %1858 = stablehlo.convert %arg83 : (tensor<128xbf16>) -> tensor<128xf32>
    %1859 = stablehlo.broadcast_in_dim %1857, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1860 = stablehlo.broadcast_in_dim %1858, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1861 = stablehlo.multiply %1859, %1860 : tensor<1x4800x128xf32>
    %1862 = stablehlo.convert %arg84 : (tensor<128xbf16>) -> tensor<128xf32>
    %1863 = stablehlo.broadcast_in_dim %1861, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1864 = stablehlo.broadcast_in_dim %1862, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1865 = stablehlo.add %1863, %1864 : tensor<1x4800x128xf32>
    %1866 = stablehlo.convert %1865 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1867 = stablehlo.reshape %1866 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1868 = stablehlo.convert %1867 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1869 = stablehlo.dot_general %1868, %arg566, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %1870 = stablehlo.broadcast_in_dim %1869, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1871 = stablehlo.multiply %1870, %1113 : tensor<4800x512xf32>
    %1872 = stablehlo.broadcast_in_dim %1871, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %1873 = stablehlo.broadcast_in_dim %arg567, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %1874 = stablehlo.add %1872, %1873 : tensor<4800x512xf32>
    %1875 = stablehlo.convert %1874 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %1876 = stablehlo.reshape %1875 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %1877 = stablehlo.transpose %1876, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %1878 = stablehlo.reshape %1877 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %1879 = stablehlo.convolution(%1878, %arg85) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %1880 = stablehlo.reshape %arg86 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %1881 = stablehlo.broadcast_in_dim %1879, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %1882 = stablehlo.broadcast_in_dim %1880, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %1883 = stablehlo.add %1881, %1882 : tensor<1x512x60x80xbf16>
    %1884 = stablehlo.reshape %1883 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %1885 = stablehlo.transpose %1884, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %1886 = stablehlo.multiply %1885, %cst_23 : tensor<1x4800x512xbf16>
    %1887 = stablehlo.multiply %1885, %1130 : tensor<1x4800x512xbf16>
    %1888 = stablehlo.convert %1887 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %1889 = stablehlo.clamp %cst_24, %1888, %cst_25 : tensor<1x4800x512xf32>
    %1890 = stablehlo.multiply %1889, %1889 : tensor<1x4800x512xf32>
    %1891 = stablehlo.multiply %cst_26, %1890 : tensor<1x4800x512xf32>
    %1892 = stablehlo.add %1891, %cst_27 : tensor<1x4800x512xf32>
    %1893 = stablehlo.multiply %1892, %1890 : tensor<1x4800x512xf32>
    %1894 = stablehlo.add %1893, %cst_28 : tensor<1x4800x512xf32>
    %1895 = stablehlo.multiply %1894, %1890 : tensor<1x4800x512xf32>
    %1896 = stablehlo.add %1895, %cst_29 : tensor<1x4800x512xf32>
    %1897 = stablehlo.multiply %1896, %1890 : tensor<1x4800x512xf32>
    %1898 = stablehlo.add %1897, %cst_30 : tensor<1x4800x512xf32>
    %1899 = stablehlo.multiply %1898, %1890 : tensor<1x4800x512xf32>
    %1900 = stablehlo.add %1899, %cst_31 : tensor<1x4800x512xf32>
    %1901 = stablehlo.multiply %1900, %1890 : tensor<1x4800x512xf32>
    %1902 = stablehlo.add %1901, %cst_32 : tensor<1x4800x512xf32>
    %1903 = stablehlo.multiply %cst_33, %1890 : tensor<1x4800x512xf32>
    %1904 = stablehlo.add %1903, %cst_34 : tensor<1x4800x512xf32>
    %1905 = stablehlo.multiply %1904, %1890 : tensor<1x4800x512xf32>
    %1906 = stablehlo.add %1905, %cst_35 : tensor<1x4800x512xf32>
    %1907 = stablehlo.multiply %1906, %1890 : tensor<1x4800x512xf32>
    %1908 = stablehlo.add %1907, %cst_36 : tensor<1x4800x512xf32>
    %1909 = stablehlo.multiply %1908, %1890 : tensor<1x4800x512xf32>
    %1910 = stablehlo.add %1909, %cst_37 : tensor<1x4800x512xf32>
    %1911 = stablehlo.multiply %1889, %1902 : tensor<1x4800x512xf32>
    %1912 = stablehlo.divide %1911, %1910 : tensor<1x4800x512xf32>
    %1913 = stablehlo.clamp %cst_38, %1912, %cst_39 : tensor<1x4800x512xf32>
    %1914 = stablehlo.convert %1913 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %1915 = stablehlo.add %1914, %cst_21 : tensor<1x4800x512xbf16>
    %1916 = stablehlo.multiply %1915, %1886 : tensor<1x4800x512xbf16>
    %1917 = stablehlo.reshape %1916 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %1918 = stablehlo.dot_general %1917, %arg568, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %1919 = stablehlo.reshape %1918 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1920 = stablehlo.broadcast_in_dim %1919, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1921 = stablehlo.broadcast_in_dim %arg87, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %1922 = stablehlo.add %1920, %1921 : tensor<1x4800x128xbf16>
    %1923 = stablehlo.reshape %1922 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1924 = stablehlo.reshape %1923 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1925 = stablehlo.add %1924, %1829 : tensor<1x4800x128xbf16>
    %1926 = stablehlo.convert %1925 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %1927 = stablehlo.convert %1926 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %1928 = stablehlo.reduce(%1927 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1929 = stablehlo.reshape %1928 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1930 = stablehlo.broadcast_in_dim %1929, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1931 = stablehlo.divide %1930, %874 : tensor<1x4800x1xf64>
    %1932 = stablehlo.broadcast_in_dim %1927, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %1933 = stablehlo.broadcast_in_dim %1931, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %1934 = stablehlo.subtract %1932, %1933 : tensor<1x4800x128xf64>
    %1935 = stablehlo.multiply %1934, %1934 : tensor<1x4800x128xf64>
    %1936 = stablehlo.reduce(%1935 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %1937 = stablehlo.reshape %1936 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %1938 = stablehlo.broadcast_in_dim %1937, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %1939 = stablehlo.divide %1938, %874 : tensor<1x4800x1xf64>
    %1940 = stablehlo.convert %1939 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %1941 = stablehlo.reduce(%1926 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %1942 = stablehlo.reshape %1941 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %1943 = stablehlo.broadcast_in_dim %1942, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1944 = stablehlo.divide %1943, %890 : tensor<1x4800x1xf32>
    %1945 = stablehlo.broadcast_in_dim %1940, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %1946 = stablehlo.add %1945, %893 : tensor<1x4800x1xf32>
    %1947 = stablehlo.rsqrt %1946 : tensor<1x4800x1xf32>
    %1948 = stablehlo.broadcast_in_dim %1926, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1949 = stablehlo.broadcast_in_dim %1944, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1950 = stablehlo.subtract %1948, %1949 : tensor<1x4800x128xf32>
    %1951 = stablehlo.broadcast_in_dim %1950, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1952 = stablehlo.broadcast_in_dim %1947, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %1953 = stablehlo.multiply %1951, %1952 : tensor<1x4800x128xf32>
    %1954 = stablehlo.convert %arg88 : (tensor<128xbf16>) -> tensor<128xf32>
    %1955 = stablehlo.broadcast_in_dim %1953, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1956 = stablehlo.broadcast_in_dim %1954, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1957 = stablehlo.multiply %1955, %1956 : tensor<1x4800x128xf32>
    %1958 = stablehlo.convert %arg89 : (tensor<128xbf16>) -> tensor<128xf32>
    %1959 = stablehlo.broadcast_in_dim %1957, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %1960 = stablehlo.broadcast_in_dim %1958, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %1961 = stablehlo.add %1959, %1960 : tensor<1x4800x128xf32>
    %1962 = stablehlo.convert %1961 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %1963 = stablehlo.reshape %1962 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %1964 = stablehlo.convert %1963 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %1965 = stablehlo.dot_general %1964, %arg569, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %1966 = stablehlo.broadcast_in_dim %1965, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1967 = stablehlo.multiply %1966, %952 : tensor<4800x128xf32>
    %1968 = stablehlo.broadcast_in_dim %1967, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %1969 = stablehlo.broadcast_in_dim %arg570, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %1970 = stablehlo.add %1968, %1969 : tensor<4800x128xf32>
    %1971 = stablehlo.convert %1970 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %1972 = stablehlo.reshape %1971 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %1973 = stablehlo.reshape %1972 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %1974 = stablehlo.transpose %1973, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %1975 = stablehlo.transpose %1962, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %1976 = stablehlo.reshape %1975 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %1977 = stablehlo.convolution(%1976, %arg90) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %1978 = stablehlo.reshape %arg91 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %1979 = stablehlo.broadcast_in_dim %1977, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %1980 = stablehlo.broadcast_in_dim %1978, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %1981 = stablehlo.add %1979, %1980 : tensor<1x128x15x20xbf16>
    %1982 = stablehlo.reshape %1981 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %1983 = stablehlo.transpose %1982, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %1984 = stablehlo.convert %1983 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %1985 = stablehlo.convert %1984 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %1986 = stablehlo.reduce(%1985 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1987 = stablehlo.reshape %1986 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1988 = stablehlo.broadcast_in_dim %1987, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1989 = stablehlo.divide %1988, %975 : tensor<1x300x1xf64>
    %1990 = stablehlo.broadcast_in_dim %1985, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %1991 = stablehlo.broadcast_in_dim %1989, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %1992 = stablehlo.subtract %1990, %1991 : tensor<1x300x128xf64>
    %1993 = stablehlo.multiply %1992, %1992 : tensor<1x300x128xf64>
    %1994 = stablehlo.reduce(%1993 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %1995 = stablehlo.reshape %1994 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %1996 = stablehlo.broadcast_in_dim %1995, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %1997 = stablehlo.divide %1996, %975 : tensor<1x300x1xf64>
    %1998 = stablehlo.convert %1997 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %1999 = stablehlo.reduce(%1984 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %2000 = stablehlo.reshape %1999 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %2001 = stablehlo.broadcast_in_dim %2000, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2002 = stablehlo.divide %2001, %989 : tensor<1x300x1xf32>
    %2003 = stablehlo.broadcast_in_dim %1998, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2004 = stablehlo.add %2003, %136 : tensor<1x300x1xf32>
    %2005 = stablehlo.rsqrt %2004 : tensor<1x300x1xf32>
    %2006 = stablehlo.broadcast_in_dim %1984, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2007 = stablehlo.broadcast_in_dim %2002, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2008 = stablehlo.subtract %2006, %2007 : tensor<1x300x128xf32>
    %2009 = stablehlo.broadcast_in_dim %2008, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2010 = stablehlo.broadcast_in_dim %2005, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2011 = stablehlo.multiply %2009, %2010 : tensor<1x300x128xf32>
    %2012 = stablehlo.convert %arg92 : (tensor<128xbf16>) -> tensor<128xf32>
    %2013 = stablehlo.broadcast_in_dim %2011, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2014 = stablehlo.broadcast_in_dim %2012, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2015 = stablehlo.multiply %2013, %2014 : tensor<1x300x128xf32>
    %2016 = stablehlo.convert %arg93 : (tensor<128xbf16>) -> tensor<128xf32>
    %2017 = stablehlo.broadcast_in_dim %2015, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2018 = stablehlo.broadcast_in_dim %2016, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2019 = stablehlo.add %2017, %2018 : tensor<1x300x128xf32>
    %2020 = stablehlo.convert %2019 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %2021 = stablehlo.reshape %2020 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %2022 = stablehlo.convert %2021 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %2023 = stablehlo.dot_general %2022, %arg571, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2024 = stablehlo.broadcast_in_dim %2023, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2025 = stablehlo.multiply %2024, %1013 : tensor<300x128xf32>
    %2026 = stablehlo.broadcast_in_dim %2025, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2027 = stablehlo.broadcast_in_dim %arg572, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2028 = stablehlo.add %2026, %2027 : tensor<300x128xf32>
    %2029 = stablehlo.convert %2028 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2030 = stablehlo.reshape %2029 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2031 = stablehlo.reshape %2030 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2032 = stablehlo.transpose %2031, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2033 = stablehlo.dot_general %2022, %arg573, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2034 = stablehlo.broadcast_in_dim %2033, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2035 = stablehlo.multiply %2034, %1013 : tensor<300x128xf32>
    %2036 = stablehlo.broadcast_in_dim %2035, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2037 = stablehlo.broadcast_in_dim %arg574, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2038 = stablehlo.add %2036, %2037 : tensor<300x128xf32>
    %2039 = stablehlo.convert %2038 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2040 = stablehlo.reshape %2039 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2041 = stablehlo.reshape %2040 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2042 = stablehlo.transpose %2041, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2043 = stablehlo.transpose %2032, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %2044 = stablehlo.reshape %1974 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %2045 = stablehlo.reshape %2043 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2046 = stablehlo.broadcast_in_dim %2045, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2047 = stablehlo.dot_general %2044, %2046, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %2048 = stablehlo.reshape %2047 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2049 = stablehlo.broadcast_in_dim %2048, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2050 = stablehlo.divide %2049, %1039 : tensor<1x2x4800x300xbf16>
    %2051 = stablehlo.convert %2050 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %2052 = stablehlo.reduce(%2051 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2053 = stablehlo.reshape %2052 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2054 = stablehlo.broadcast_in_dim %2051, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2055 = stablehlo.broadcast_in_dim %2053, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2056 = stablehlo.subtract %2054, %2055 : tensor<1x2x4800x300xf32>
    %2057 = stablehlo.exponential %2056 : tensor<1x2x4800x300xf32>
    %2058 = stablehlo.reduce(%2057 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2059 = stablehlo.reshape %2058 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2060 = stablehlo.broadcast_in_dim %2057, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2061 = stablehlo.broadcast_in_dim %2059, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2062 = stablehlo.divide %2060, %2061 : tensor<1x2x4800x300xf32>
    %2063 = stablehlo.convert %2062 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %2064 = stablehlo.reshape %2063 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %2065 = stablehlo.reshape %2042 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2066 = stablehlo.broadcast_in_dim %2065, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2067 = stablehlo.dot_general %2064, %2066, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %2068 = stablehlo.reshape %2067 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2069 = stablehlo.transpose %2068, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %2070 = stablehlo.reshape %2069 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %2071 = stablehlo.reshape %2070 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2072 = stablehlo.convert %2071 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2073 = stablehlo.dot_general %2072, %arg575, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2074 = stablehlo.broadcast_in_dim %2073, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2075 = stablehlo.multiply %2074, %952 : tensor<4800x128xf32>
    %2076 = stablehlo.broadcast_in_dim %2075, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2077 = stablehlo.broadcast_in_dim %arg576, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2078 = stablehlo.add %2076, %2077 : tensor<4800x128xf32>
    %2079 = stablehlo.convert %2078 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2080 = stablehlo.reshape %2079 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2081 = stablehlo.add %2080, %1925 : tensor<1x4800x128xbf16>
    %2082 = stablehlo.convert %2081 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2083 = stablehlo.convert %2082 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2084 = stablehlo.reduce(%2083 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2085 = stablehlo.reshape %2084 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2086 = stablehlo.broadcast_in_dim %2085, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2087 = stablehlo.divide %2086, %874 : tensor<1x4800x1xf64>
    %2088 = stablehlo.broadcast_in_dim %2083, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2089 = stablehlo.broadcast_in_dim %2087, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2090 = stablehlo.subtract %2088, %2089 : tensor<1x4800x128xf64>
    %2091 = stablehlo.multiply %2090, %2090 : tensor<1x4800x128xf64>
    %2092 = stablehlo.reduce(%2091 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2093 = stablehlo.reshape %2092 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2094 = stablehlo.broadcast_in_dim %2093, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2095 = stablehlo.divide %2094, %874 : tensor<1x4800x1xf64>
    %2096 = stablehlo.convert %2095 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2097 = stablehlo.reduce(%2082 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2098 = stablehlo.reshape %2097 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2099 = stablehlo.broadcast_in_dim %2098, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2100 = stablehlo.divide %2099, %890 : tensor<1x4800x1xf32>
    %2101 = stablehlo.broadcast_in_dim %2096, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2102 = stablehlo.add %2101, %893 : tensor<1x4800x1xf32>
    %2103 = stablehlo.rsqrt %2102 : tensor<1x4800x1xf32>
    %2104 = stablehlo.broadcast_in_dim %2082, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2105 = stablehlo.broadcast_in_dim %2100, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2106 = stablehlo.subtract %2104, %2105 : tensor<1x4800x128xf32>
    %2107 = stablehlo.broadcast_in_dim %2106, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2108 = stablehlo.broadcast_in_dim %2103, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2109 = stablehlo.multiply %2107, %2108 : tensor<1x4800x128xf32>
    %2110 = stablehlo.convert %arg94 : (tensor<128xbf16>) -> tensor<128xf32>
    %2111 = stablehlo.broadcast_in_dim %2109, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2112 = stablehlo.broadcast_in_dim %2110, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2113 = stablehlo.multiply %2111, %2112 : tensor<1x4800x128xf32>
    %2114 = stablehlo.convert %arg95 : (tensor<128xbf16>) -> tensor<128xf32>
    %2115 = stablehlo.broadcast_in_dim %2113, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2116 = stablehlo.broadcast_in_dim %2114, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2117 = stablehlo.add %2115, %2116 : tensor<1x4800x128xf32>
    %2118 = stablehlo.convert %2117 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2119 = stablehlo.reshape %2118 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2120 = stablehlo.convert %2119 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2121 = stablehlo.dot_general %2120, %arg577, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %2122 = stablehlo.broadcast_in_dim %2121, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2123 = stablehlo.multiply %2122, %1113 : tensor<4800x512xf32>
    %2124 = stablehlo.broadcast_in_dim %2123, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2125 = stablehlo.broadcast_in_dim %arg578, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %2126 = stablehlo.add %2124, %2125 : tensor<4800x512xf32>
    %2127 = stablehlo.convert %2126 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %2128 = stablehlo.reshape %2127 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %2129 = stablehlo.transpose %2128, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %2130 = stablehlo.reshape %2129 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %2131 = stablehlo.convolution(%2130, %arg96) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %2132 = stablehlo.reshape %arg97 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %2133 = stablehlo.broadcast_in_dim %2131, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %2134 = stablehlo.broadcast_in_dim %2132, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %2135 = stablehlo.add %2133, %2134 : tensor<1x512x60x80xbf16>
    %2136 = stablehlo.reshape %2135 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %2137 = stablehlo.transpose %2136, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %2138 = stablehlo.multiply %2137, %cst_23 : tensor<1x4800x512xbf16>
    %2139 = stablehlo.multiply %2137, %1130 : tensor<1x4800x512xbf16>
    %2140 = stablehlo.convert %2139 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %2141 = stablehlo.clamp %cst_24, %2140, %cst_25 : tensor<1x4800x512xf32>
    %2142 = stablehlo.multiply %2141, %2141 : tensor<1x4800x512xf32>
    %2143 = stablehlo.multiply %cst_26, %2142 : tensor<1x4800x512xf32>
    %2144 = stablehlo.add %2143, %cst_27 : tensor<1x4800x512xf32>
    %2145 = stablehlo.multiply %2144, %2142 : tensor<1x4800x512xf32>
    %2146 = stablehlo.add %2145, %cst_28 : tensor<1x4800x512xf32>
    %2147 = stablehlo.multiply %2146, %2142 : tensor<1x4800x512xf32>
    %2148 = stablehlo.add %2147, %cst_29 : tensor<1x4800x512xf32>
    %2149 = stablehlo.multiply %2148, %2142 : tensor<1x4800x512xf32>
    %2150 = stablehlo.add %2149, %cst_30 : tensor<1x4800x512xf32>
    %2151 = stablehlo.multiply %2150, %2142 : tensor<1x4800x512xf32>
    %2152 = stablehlo.add %2151, %cst_31 : tensor<1x4800x512xf32>
    %2153 = stablehlo.multiply %2152, %2142 : tensor<1x4800x512xf32>
    %2154 = stablehlo.add %2153, %cst_32 : tensor<1x4800x512xf32>
    %2155 = stablehlo.multiply %cst_33, %2142 : tensor<1x4800x512xf32>
    %2156 = stablehlo.add %2155, %cst_34 : tensor<1x4800x512xf32>
    %2157 = stablehlo.multiply %2156, %2142 : tensor<1x4800x512xf32>
    %2158 = stablehlo.add %2157, %cst_35 : tensor<1x4800x512xf32>
    %2159 = stablehlo.multiply %2158, %2142 : tensor<1x4800x512xf32>
    %2160 = stablehlo.add %2159, %cst_36 : tensor<1x4800x512xf32>
    %2161 = stablehlo.multiply %2160, %2142 : tensor<1x4800x512xf32>
    %2162 = stablehlo.add %2161, %cst_37 : tensor<1x4800x512xf32>
    %2163 = stablehlo.multiply %2141, %2154 : tensor<1x4800x512xf32>
    %2164 = stablehlo.divide %2163, %2162 : tensor<1x4800x512xf32>
    %2165 = stablehlo.clamp %cst_38, %2164, %cst_39 : tensor<1x4800x512xf32>
    %2166 = stablehlo.convert %2165 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %2167 = stablehlo.add %2166, %cst_21 : tensor<1x4800x512xbf16>
    %2168 = stablehlo.multiply %2167, %2138 : tensor<1x4800x512xbf16>
    %2169 = stablehlo.reshape %2168 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %2170 = stablehlo.dot_general %2169, %arg579, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %2171 = stablehlo.reshape %2170 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2172 = stablehlo.broadcast_in_dim %2171, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2173 = stablehlo.broadcast_in_dim %arg98, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %2174 = stablehlo.add %2172, %2173 : tensor<1x4800x128xbf16>
    %2175 = stablehlo.reshape %2174 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2176 = stablehlo.reshape %2175 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2177 = stablehlo.add %2176, %2081 : tensor<1x4800x128xbf16>
    %2178 = stablehlo.convert %2177 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2179 = stablehlo.convert %2178 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2180 = stablehlo.reduce(%2179 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2181 = stablehlo.reshape %2180 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2182 = stablehlo.broadcast_in_dim %2181, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2183 = stablehlo.divide %2182, %874 : tensor<1x4800x1xf64>
    %2184 = stablehlo.broadcast_in_dim %2179, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2185 = stablehlo.broadcast_in_dim %2183, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2186 = stablehlo.subtract %2184, %2185 : tensor<1x4800x128xf64>
    %2187 = stablehlo.multiply %2186, %2186 : tensor<1x4800x128xf64>
    %2188 = stablehlo.reduce(%2187 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2189 = stablehlo.reshape %2188 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2190 = stablehlo.broadcast_in_dim %2189, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2191 = stablehlo.divide %2190, %874 : tensor<1x4800x1xf64>
    %2192 = stablehlo.convert %2191 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2193 = stablehlo.reduce(%2178 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2194 = stablehlo.reshape %2193 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2195 = stablehlo.broadcast_in_dim %2194, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2196 = stablehlo.divide %2195, %890 : tensor<1x4800x1xf32>
    %2197 = stablehlo.broadcast_in_dim %2192, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2198 = stablehlo.add %2197, %893 : tensor<1x4800x1xf32>
    %2199 = stablehlo.rsqrt %2198 : tensor<1x4800x1xf32>
    %2200 = stablehlo.broadcast_in_dim %2178, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2201 = stablehlo.broadcast_in_dim %2196, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2202 = stablehlo.subtract %2200, %2201 : tensor<1x4800x128xf32>
    %2203 = stablehlo.broadcast_in_dim %2202, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2204 = stablehlo.broadcast_in_dim %2199, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2205 = stablehlo.multiply %2203, %2204 : tensor<1x4800x128xf32>
    %2206 = stablehlo.convert %arg99 : (tensor<128xbf16>) -> tensor<128xf32>
    %2207 = stablehlo.broadcast_in_dim %2205, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2208 = stablehlo.broadcast_in_dim %2206, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2209 = stablehlo.multiply %2207, %2208 : tensor<1x4800x128xf32>
    %2210 = stablehlo.convert %arg100 : (tensor<128xbf16>) -> tensor<128xf32>
    %2211 = stablehlo.broadcast_in_dim %2209, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2212 = stablehlo.broadcast_in_dim %2210, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2213 = stablehlo.add %2211, %2212 : tensor<1x4800x128xf32>
    %2214 = stablehlo.convert %2213 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2215 = stablehlo.reshape %2214 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2216 = stablehlo.convert %2215 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2217 = stablehlo.dot_general %2216, %arg580, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2218 = stablehlo.broadcast_in_dim %2217, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2219 = stablehlo.multiply %2218, %952 : tensor<4800x128xf32>
    %2220 = stablehlo.broadcast_in_dim %2219, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2221 = stablehlo.broadcast_in_dim %arg581, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2222 = stablehlo.add %2220, %2221 : tensor<4800x128xf32>
    %2223 = stablehlo.convert %2222 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2224 = stablehlo.reshape %2223 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2225 = stablehlo.reshape %2224 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %2226 = stablehlo.transpose %2225, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2227 = stablehlo.transpose %2214, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %2228 = stablehlo.reshape %2227 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %2229 = stablehlo.convolution(%2228, %arg101) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %2230 = stablehlo.reshape %arg102 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %2231 = stablehlo.broadcast_in_dim %2229, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %2232 = stablehlo.broadcast_in_dim %2230, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %2233 = stablehlo.add %2231, %2232 : tensor<1x128x15x20xbf16>
    %2234 = stablehlo.reshape %2233 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %2235 = stablehlo.transpose %2234, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %2236 = stablehlo.convert %2235 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %2237 = stablehlo.convert %2236 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %2238 = stablehlo.reduce(%2237 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %2239 = stablehlo.reshape %2238 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %2240 = stablehlo.broadcast_in_dim %2239, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %2241 = stablehlo.divide %2240, %975 : tensor<1x300x1xf64>
    %2242 = stablehlo.broadcast_in_dim %2237, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %2243 = stablehlo.broadcast_in_dim %2241, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %2244 = stablehlo.subtract %2242, %2243 : tensor<1x300x128xf64>
    %2245 = stablehlo.multiply %2244, %2244 : tensor<1x300x128xf64>
    %2246 = stablehlo.reduce(%2245 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %2247 = stablehlo.reshape %2246 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %2248 = stablehlo.broadcast_in_dim %2247, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %2249 = stablehlo.divide %2248, %975 : tensor<1x300x1xf64>
    %2250 = stablehlo.convert %2249 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %2251 = stablehlo.reduce(%2236 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %2252 = stablehlo.reshape %2251 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %2253 = stablehlo.broadcast_in_dim %2252, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2254 = stablehlo.divide %2253, %989 : tensor<1x300x1xf32>
    %2255 = stablehlo.broadcast_in_dim %2250, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2256 = stablehlo.add %2255, %136 : tensor<1x300x1xf32>
    %2257 = stablehlo.rsqrt %2256 : tensor<1x300x1xf32>
    %2258 = stablehlo.broadcast_in_dim %2236, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2259 = stablehlo.broadcast_in_dim %2254, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2260 = stablehlo.subtract %2258, %2259 : tensor<1x300x128xf32>
    %2261 = stablehlo.broadcast_in_dim %2260, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2262 = stablehlo.broadcast_in_dim %2257, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2263 = stablehlo.multiply %2261, %2262 : tensor<1x300x128xf32>
    %2264 = stablehlo.convert %arg103 : (tensor<128xbf16>) -> tensor<128xf32>
    %2265 = stablehlo.broadcast_in_dim %2263, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2266 = stablehlo.broadcast_in_dim %2264, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2267 = stablehlo.multiply %2265, %2266 : tensor<1x300x128xf32>
    %2268 = stablehlo.convert %arg104 : (tensor<128xbf16>) -> tensor<128xf32>
    %2269 = stablehlo.broadcast_in_dim %2267, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2270 = stablehlo.broadcast_in_dim %2268, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2271 = stablehlo.add %2269, %2270 : tensor<1x300x128xf32>
    %2272 = stablehlo.convert %2271 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %2273 = stablehlo.reshape %2272 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %2274 = stablehlo.convert %2273 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %2275 = stablehlo.dot_general %2274, %arg582, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2276 = stablehlo.broadcast_in_dim %2275, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2277 = stablehlo.multiply %2276, %1013 : tensor<300x128xf32>
    %2278 = stablehlo.broadcast_in_dim %2277, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2279 = stablehlo.broadcast_in_dim %arg583, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2280 = stablehlo.add %2278, %2279 : tensor<300x128xf32>
    %2281 = stablehlo.convert %2280 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2282 = stablehlo.reshape %2281 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2283 = stablehlo.reshape %2282 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2284 = stablehlo.transpose %2283, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2285 = stablehlo.dot_general %2274, %arg584, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2286 = stablehlo.broadcast_in_dim %2285, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2287 = stablehlo.multiply %2286, %1013 : tensor<300x128xf32>
    %2288 = stablehlo.broadcast_in_dim %2287, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2289 = stablehlo.broadcast_in_dim %arg585, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2290 = stablehlo.add %2288, %2289 : tensor<300x128xf32>
    %2291 = stablehlo.convert %2290 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2292 = stablehlo.reshape %2291 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2293 = stablehlo.reshape %2292 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2294 = stablehlo.transpose %2293, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2295 = stablehlo.transpose %2284, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %2296 = stablehlo.reshape %2226 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %2297 = stablehlo.reshape %2295 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2298 = stablehlo.broadcast_in_dim %2297, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2299 = stablehlo.dot_general %2296, %2298, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %2300 = stablehlo.reshape %2299 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2301 = stablehlo.broadcast_in_dim %2300, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2302 = stablehlo.divide %2301, %1039 : tensor<1x2x4800x300xbf16>
    %2303 = stablehlo.convert %2302 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %2304 = stablehlo.reduce(%2303 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2305 = stablehlo.reshape %2304 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2306 = stablehlo.broadcast_in_dim %2303, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2307 = stablehlo.broadcast_in_dim %2305, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2308 = stablehlo.subtract %2306, %2307 : tensor<1x2x4800x300xf32>
    %2309 = stablehlo.exponential %2308 : tensor<1x2x4800x300xf32>
    %2310 = stablehlo.reduce(%2309 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2311 = stablehlo.reshape %2310 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2312 = stablehlo.broadcast_in_dim %2309, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2313 = stablehlo.broadcast_in_dim %2311, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2314 = stablehlo.divide %2312, %2313 : tensor<1x2x4800x300xf32>
    %2315 = stablehlo.convert %2314 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %2316 = stablehlo.reshape %2315 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %2317 = stablehlo.reshape %2294 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2318 = stablehlo.broadcast_in_dim %2317, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2319 = stablehlo.dot_general %2316, %2318, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %2320 = stablehlo.reshape %2319 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2321 = stablehlo.transpose %2320, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %2322 = stablehlo.reshape %2321 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %2323 = stablehlo.reshape %2322 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2324 = stablehlo.convert %2323 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2325 = stablehlo.dot_general %2324, %arg586, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2326 = stablehlo.broadcast_in_dim %2325, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2327 = stablehlo.multiply %2326, %952 : tensor<4800x128xf32>
    %2328 = stablehlo.broadcast_in_dim %2327, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2329 = stablehlo.broadcast_in_dim %arg587, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2330 = stablehlo.add %2328, %2329 : tensor<4800x128xf32>
    %2331 = stablehlo.convert %2330 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2332 = stablehlo.reshape %2331 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2333 = stablehlo.add %2332, %2177 : tensor<1x4800x128xbf16>
    %2334 = stablehlo.convert %2333 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2335 = stablehlo.convert %2334 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2336 = stablehlo.reduce(%2335 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2337 = stablehlo.reshape %2336 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2338 = stablehlo.broadcast_in_dim %2337, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2339 = stablehlo.divide %2338, %874 : tensor<1x4800x1xf64>
    %2340 = stablehlo.broadcast_in_dim %2335, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2341 = stablehlo.broadcast_in_dim %2339, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2342 = stablehlo.subtract %2340, %2341 : tensor<1x4800x128xf64>
    %2343 = stablehlo.multiply %2342, %2342 : tensor<1x4800x128xf64>
    %2344 = stablehlo.reduce(%2343 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2345 = stablehlo.reshape %2344 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2346 = stablehlo.broadcast_in_dim %2345, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2347 = stablehlo.divide %2346, %874 : tensor<1x4800x1xf64>
    %2348 = stablehlo.convert %2347 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2349 = stablehlo.reduce(%2334 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2350 = stablehlo.reshape %2349 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2351 = stablehlo.broadcast_in_dim %2350, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2352 = stablehlo.divide %2351, %890 : tensor<1x4800x1xf32>
    %2353 = stablehlo.broadcast_in_dim %2348, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2354 = stablehlo.add %2353, %893 : tensor<1x4800x1xf32>
    %2355 = stablehlo.rsqrt %2354 : tensor<1x4800x1xf32>
    %2356 = stablehlo.broadcast_in_dim %2334, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2357 = stablehlo.broadcast_in_dim %2352, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2358 = stablehlo.subtract %2356, %2357 : tensor<1x4800x128xf32>
    %2359 = stablehlo.broadcast_in_dim %2358, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2360 = stablehlo.broadcast_in_dim %2355, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2361 = stablehlo.multiply %2359, %2360 : tensor<1x4800x128xf32>
    %2362 = stablehlo.convert %arg105 : (tensor<128xbf16>) -> tensor<128xf32>
    %2363 = stablehlo.broadcast_in_dim %2361, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2364 = stablehlo.broadcast_in_dim %2362, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2365 = stablehlo.multiply %2363, %2364 : tensor<1x4800x128xf32>
    %2366 = stablehlo.convert %arg106 : (tensor<128xbf16>) -> tensor<128xf32>
    %2367 = stablehlo.broadcast_in_dim %2365, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2368 = stablehlo.broadcast_in_dim %2366, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2369 = stablehlo.add %2367, %2368 : tensor<1x4800x128xf32>
    %2370 = stablehlo.convert %2369 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2371 = stablehlo.reshape %2370 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2372 = stablehlo.convert %2371 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2373 = stablehlo.dot_general %2372, %arg588, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %2374 = stablehlo.broadcast_in_dim %2373, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2375 = stablehlo.multiply %2374, %1113 : tensor<4800x512xf32>
    %2376 = stablehlo.broadcast_in_dim %2375, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2377 = stablehlo.broadcast_in_dim %arg589, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %2378 = stablehlo.add %2376, %2377 : tensor<4800x512xf32>
    %2379 = stablehlo.convert %2378 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %2380 = stablehlo.reshape %2379 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %2381 = stablehlo.transpose %2380, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %2382 = stablehlo.reshape %2381 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %2383 = stablehlo.convolution(%2382, %arg107) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %2384 = stablehlo.reshape %arg108 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %2385 = stablehlo.broadcast_in_dim %2383, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %2386 = stablehlo.broadcast_in_dim %2384, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %2387 = stablehlo.add %2385, %2386 : tensor<1x512x60x80xbf16>
    %2388 = stablehlo.reshape %2387 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %2389 = stablehlo.transpose %2388, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %2390 = stablehlo.multiply %2389, %cst_23 : tensor<1x4800x512xbf16>
    %2391 = stablehlo.multiply %2389, %1130 : tensor<1x4800x512xbf16>
    %2392 = stablehlo.convert %2391 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %2393 = stablehlo.clamp %cst_24, %2392, %cst_25 : tensor<1x4800x512xf32>
    %2394 = stablehlo.multiply %2393, %2393 : tensor<1x4800x512xf32>
    %2395 = stablehlo.multiply %cst_26, %2394 : tensor<1x4800x512xf32>
    %2396 = stablehlo.add %2395, %cst_27 : tensor<1x4800x512xf32>
    %2397 = stablehlo.multiply %2396, %2394 : tensor<1x4800x512xf32>
    %2398 = stablehlo.add %2397, %cst_28 : tensor<1x4800x512xf32>
    %2399 = stablehlo.multiply %2398, %2394 : tensor<1x4800x512xf32>
    %2400 = stablehlo.add %2399, %cst_29 : tensor<1x4800x512xf32>
    %2401 = stablehlo.multiply %2400, %2394 : tensor<1x4800x512xf32>
    %2402 = stablehlo.add %2401, %cst_30 : tensor<1x4800x512xf32>
    %2403 = stablehlo.multiply %2402, %2394 : tensor<1x4800x512xf32>
    %2404 = stablehlo.add %2403, %cst_31 : tensor<1x4800x512xf32>
    %2405 = stablehlo.multiply %2404, %2394 : tensor<1x4800x512xf32>
    %2406 = stablehlo.add %2405, %cst_32 : tensor<1x4800x512xf32>
    %2407 = stablehlo.multiply %cst_33, %2394 : tensor<1x4800x512xf32>
    %2408 = stablehlo.add %2407, %cst_34 : tensor<1x4800x512xf32>
    %2409 = stablehlo.multiply %2408, %2394 : tensor<1x4800x512xf32>
    %2410 = stablehlo.add %2409, %cst_35 : tensor<1x4800x512xf32>
    %2411 = stablehlo.multiply %2410, %2394 : tensor<1x4800x512xf32>
    %2412 = stablehlo.add %2411, %cst_36 : tensor<1x4800x512xf32>
    %2413 = stablehlo.multiply %2412, %2394 : tensor<1x4800x512xf32>
    %2414 = stablehlo.add %2413, %cst_37 : tensor<1x4800x512xf32>
    %2415 = stablehlo.multiply %2393, %2406 : tensor<1x4800x512xf32>
    %2416 = stablehlo.divide %2415, %2414 : tensor<1x4800x512xf32>
    %2417 = stablehlo.clamp %cst_38, %2416, %cst_39 : tensor<1x4800x512xf32>
    %2418 = stablehlo.convert %2417 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %2419 = stablehlo.add %2418, %cst_21 : tensor<1x4800x512xbf16>
    %2420 = stablehlo.multiply %2419, %2390 : tensor<1x4800x512xbf16>
    %2421 = stablehlo.reshape %2420 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %2422 = stablehlo.dot_general %2421, %arg590, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %2423 = stablehlo.reshape %2422 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2424 = stablehlo.broadcast_in_dim %2423, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2425 = stablehlo.broadcast_in_dim %arg109, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %2426 = stablehlo.add %2424, %2425 : tensor<1x4800x128xbf16>
    %2427 = stablehlo.reshape %2426 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2428 = stablehlo.reshape %2427 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2429 = stablehlo.add %2428, %2333 : tensor<1x4800x128xbf16>
    %2430 = stablehlo.convert %2429 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2431 = stablehlo.convert %2430 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2432 = stablehlo.reduce(%2431 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2433 = stablehlo.reshape %2432 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2434 = stablehlo.broadcast_in_dim %2433, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2435 = stablehlo.divide %2434, %874 : tensor<1x4800x1xf64>
    %2436 = stablehlo.broadcast_in_dim %2431, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2437 = stablehlo.broadcast_in_dim %2435, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2438 = stablehlo.subtract %2436, %2437 : tensor<1x4800x128xf64>
    %2439 = stablehlo.multiply %2438, %2438 : tensor<1x4800x128xf64>
    %2440 = stablehlo.reduce(%2439 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2441 = stablehlo.reshape %2440 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2442 = stablehlo.broadcast_in_dim %2441, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2443 = stablehlo.divide %2442, %874 : tensor<1x4800x1xf64>
    %2444 = stablehlo.convert %2443 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2445 = stablehlo.reduce(%2430 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2446 = stablehlo.reshape %2445 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2447 = stablehlo.broadcast_in_dim %2446, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2448 = stablehlo.divide %2447, %890 : tensor<1x4800x1xf32>
    %2449 = stablehlo.broadcast_in_dim %2444, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2450 = stablehlo.add %2449, %893 : tensor<1x4800x1xf32>
    %2451 = stablehlo.rsqrt %2450 : tensor<1x4800x1xf32>
    %2452 = stablehlo.broadcast_in_dim %2430, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2453 = stablehlo.broadcast_in_dim %2448, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2454 = stablehlo.subtract %2452, %2453 : tensor<1x4800x128xf32>
    %2455 = stablehlo.broadcast_in_dim %2454, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2456 = stablehlo.broadcast_in_dim %2451, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2457 = stablehlo.multiply %2455, %2456 : tensor<1x4800x128xf32>
    %2458 = stablehlo.convert %arg110 : (tensor<128xbf16>) -> tensor<128xf32>
    %2459 = stablehlo.broadcast_in_dim %2457, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2460 = stablehlo.broadcast_in_dim %2458, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2461 = stablehlo.multiply %2459, %2460 : tensor<1x4800x128xf32>
    %2462 = stablehlo.convert %arg111 : (tensor<128xbf16>) -> tensor<128xf32>
    %2463 = stablehlo.broadcast_in_dim %2461, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2464 = stablehlo.broadcast_in_dim %2462, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2465 = stablehlo.add %2463, %2464 : tensor<1x4800x128xf32>
    %2466 = stablehlo.convert %2465 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2467 = stablehlo.reshape %2466 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2468 = stablehlo.convert %2467 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2469 = stablehlo.dot_general %2468, %arg591, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2470 = stablehlo.broadcast_in_dim %2469, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2471 = stablehlo.multiply %2470, %952 : tensor<4800x128xf32>
    %2472 = stablehlo.broadcast_in_dim %2471, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2473 = stablehlo.broadcast_in_dim %arg592, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2474 = stablehlo.add %2472, %2473 : tensor<4800x128xf32>
    %2475 = stablehlo.convert %2474 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2476 = stablehlo.reshape %2475 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2477 = stablehlo.reshape %2476 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %2478 = stablehlo.transpose %2477, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2479 = stablehlo.transpose %2466, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %2480 = stablehlo.reshape %2479 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %2481 = stablehlo.convolution(%2480, %arg112) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %2482 = stablehlo.reshape %arg113 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %2483 = stablehlo.broadcast_in_dim %2481, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %2484 = stablehlo.broadcast_in_dim %2482, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %2485 = stablehlo.add %2483, %2484 : tensor<1x128x15x20xbf16>
    %2486 = stablehlo.reshape %2485 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %2487 = stablehlo.transpose %2486, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %2488 = stablehlo.convert %2487 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %2489 = stablehlo.convert %2488 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %2490 = stablehlo.reduce(%2489 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %2491 = stablehlo.reshape %2490 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %2492 = stablehlo.broadcast_in_dim %2491, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %2493 = stablehlo.divide %2492, %975 : tensor<1x300x1xf64>
    %2494 = stablehlo.broadcast_in_dim %2489, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %2495 = stablehlo.broadcast_in_dim %2493, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %2496 = stablehlo.subtract %2494, %2495 : tensor<1x300x128xf64>
    %2497 = stablehlo.multiply %2496, %2496 : tensor<1x300x128xf64>
    %2498 = stablehlo.reduce(%2497 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %2499 = stablehlo.reshape %2498 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %2500 = stablehlo.broadcast_in_dim %2499, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %2501 = stablehlo.divide %2500, %975 : tensor<1x300x1xf64>
    %2502 = stablehlo.convert %2501 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %2503 = stablehlo.reduce(%2488 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %2504 = stablehlo.reshape %2503 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %2505 = stablehlo.broadcast_in_dim %2504, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2506 = stablehlo.divide %2505, %989 : tensor<1x300x1xf32>
    %2507 = stablehlo.broadcast_in_dim %2502, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2508 = stablehlo.add %2507, %136 : tensor<1x300x1xf32>
    %2509 = stablehlo.rsqrt %2508 : tensor<1x300x1xf32>
    %2510 = stablehlo.broadcast_in_dim %2488, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2511 = stablehlo.broadcast_in_dim %2506, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2512 = stablehlo.subtract %2510, %2511 : tensor<1x300x128xf32>
    %2513 = stablehlo.broadcast_in_dim %2512, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2514 = stablehlo.broadcast_in_dim %2509, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2515 = stablehlo.multiply %2513, %2514 : tensor<1x300x128xf32>
    %2516 = stablehlo.convert %arg114 : (tensor<128xbf16>) -> tensor<128xf32>
    %2517 = stablehlo.broadcast_in_dim %2515, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2518 = stablehlo.broadcast_in_dim %2516, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2519 = stablehlo.multiply %2517, %2518 : tensor<1x300x128xf32>
    %2520 = stablehlo.convert %arg115 : (tensor<128xbf16>) -> tensor<128xf32>
    %2521 = stablehlo.broadcast_in_dim %2519, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2522 = stablehlo.broadcast_in_dim %2520, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2523 = stablehlo.add %2521, %2522 : tensor<1x300x128xf32>
    %2524 = stablehlo.convert %2523 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %2525 = stablehlo.reshape %2524 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %2526 = stablehlo.convert %2525 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %2527 = stablehlo.dot_general %2526, %arg593, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2528 = stablehlo.broadcast_in_dim %2527, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2529 = stablehlo.multiply %2528, %1013 : tensor<300x128xf32>
    %2530 = stablehlo.broadcast_in_dim %2529, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2531 = stablehlo.broadcast_in_dim %arg594, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2532 = stablehlo.add %2530, %2531 : tensor<300x128xf32>
    %2533 = stablehlo.convert %2532 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2534 = stablehlo.reshape %2533 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2535 = stablehlo.reshape %2534 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2536 = stablehlo.transpose %2535, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2537 = stablehlo.dot_general %2526, %arg595, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2538 = stablehlo.broadcast_in_dim %2537, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2539 = stablehlo.multiply %2538, %1013 : tensor<300x128xf32>
    %2540 = stablehlo.broadcast_in_dim %2539, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2541 = stablehlo.broadcast_in_dim %arg596, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2542 = stablehlo.add %2540, %2541 : tensor<300x128xf32>
    %2543 = stablehlo.convert %2542 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2544 = stablehlo.reshape %2543 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2545 = stablehlo.reshape %2544 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2546 = stablehlo.transpose %2545, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2547 = stablehlo.transpose %2536, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %2548 = stablehlo.reshape %2478 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %2549 = stablehlo.reshape %2547 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2550 = stablehlo.broadcast_in_dim %2549, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2551 = stablehlo.dot_general %2548, %2550, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %2552 = stablehlo.reshape %2551 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2553 = stablehlo.broadcast_in_dim %2552, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2554 = stablehlo.divide %2553, %1039 : tensor<1x2x4800x300xbf16>
    %2555 = stablehlo.convert %2554 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %2556 = stablehlo.reduce(%2555 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2557 = stablehlo.reshape %2556 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2558 = stablehlo.broadcast_in_dim %2555, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2559 = stablehlo.broadcast_in_dim %2557, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2560 = stablehlo.subtract %2558, %2559 : tensor<1x2x4800x300xf32>
    %2561 = stablehlo.exponential %2560 : tensor<1x2x4800x300xf32>
    %2562 = stablehlo.reduce(%2561 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2563 = stablehlo.reshape %2562 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2564 = stablehlo.broadcast_in_dim %2561, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2565 = stablehlo.broadcast_in_dim %2563, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2566 = stablehlo.divide %2564, %2565 : tensor<1x2x4800x300xf32>
    %2567 = stablehlo.convert %2566 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %2568 = stablehlo.reshape %2567 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %2569 = stablehlo.reshape %2546 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2570 = stablehlo.broadcast_in_dim %2569, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2571 = stablehlo.dot_general %2568, %2570, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %2572 = stablehlo.reshape %2571 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2573 = stablehlo.transpose %2572, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %2574 = stablehlo.reshape %2573 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %2575 = stablehlo.reshape %2574 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2576 = stablehlo.convert %2575 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2577 = stablehlo.dot_general %2576, %arg597, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2578 = stablehlo.broadcast_in_dim %2577, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2579 = stablehlo.multiply %2578, %952 : tensor<4800x128xf32>
    %2580 = stablehlo.broadcast_in_dim %2579, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2581 = stablehlo.broadcast_in_dim %arg598, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2582 = stablehlo.add %2580, %2581 : tensor<4800x128xf32>
    %2583 = stablehlo.convert %2582 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2584 = stablehlo.reshape %2583 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2585 = stablehlo.add %2584, %2429 : tensor<1x4800x128xbf16>
    %2586 = stablehlo.convert %2585 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2587 = stablehlo.convert %2586 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2588 = stablehlo.reduce(%2587 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2589 = stablehlo.reshape %2588 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2590 = stablehlo.broadcast_in_dim %2589, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2591 = stablehlo.divide %2590, %874 : tensor<1x4800x1xf64>
    %2592 = stablehlo.broadcast_in_dim %2587, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2593 = stablehlo.broadcast_in_dim %2591, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2594 = stablehlo.subtract %2592, %2593 : tensor<1x4800x128xf64>
    %2595 = stablehlo.multiply %2594, %2594 : tensor<1x4800x128xf64>
    %2596 = stablehlo.reduce(%2595 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2597 = stablehlo.reshape %2596 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2598 = stablehlo.broadcast_in_dim %2597, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2599 = stablehlo.divide %2598, %874 : tensor<1x4800x1xf64>
    %2600 = stablehlo.convert %2599 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2601 = stablehlo.reduce(%2586 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2602 = stablehlo.reshape %2601 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2603 = stablehlo.broadcast_in_dim %2602, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2604 = stablehlo.divide %2603, %890 : tensor<1x4800x1xf32>
    %2605 = stablehlo.broadcast_in_dim %2600, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2606 = stablehlo.add %2605, %893 : tensor<1x4800x1xf32>
    %2607 = stablehlo.rsqrt %2606 : tensor<1x4800x1xf32>
    %2608 = stablehlo.broadcast_in_dim %2586, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2609 = stablehlo.broadcast_in_dim %2604, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2610 = stablehlo.subtract %2608, %2609 : tensor<1x4800x128xf32>
    %2611 = stablehlo.broadcast_in_dim %2610, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2612 = stablehlo.broadcast_in_dim %2607, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2613 = stablehlo.multiply %2611, %2612 : tensor<1x4800x128xf32>
    %2614 = stablehlo.convert %arg116 : (tensor<128xbf16>) -> tensor<128xf32>
    %2615 = stablehlo.broadcast_in_dim %2613, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2616 = stablehlo.broadcast_in_dim %2614, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2617 = stablehlo.multiply %2615, %2616 : tensor<1x4800x128xf32>
    %2618 = stablehlo.convert %arg117 : (tensor<128xbf16>) -> tensor<128xf32>
    %2619 = stablehlo.broadcast_in_dim %2617, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2620 = stablehlo.broadcast_in_dim %2618, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2621 = stablehlo.add %2619, %2620 : tensor<1x4800x128xf32>
    %2622 = stablehlo.convert %2621 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2623 = stablehlo.reshape %2622 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2624 = stablehlo.convert %2623 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2625 = stablehlo.dot_general %2624, %arg599, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %2626 = stablehlo.broadcast_in_dim %2625, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2627 = stablehlo.multiply %2626, %1113 : tensor<4800x512xf32>
    %2628 = stablehlo.broadcast_in_dim %2627, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2629 = stablehlo.broadcast_in_dim %arg600, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %2630 = stablehlo.add %2628, %2629 : tensor<4800x512xf32>
    %2631 = stablehlo.convert %2630 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %2632 = stablehlo.reshape %2631 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %2633 = stablehlo.transpose %2632, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %2634 = stablehlo.reshape %2633 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %2635 = stablehlo.convolution(%2634, %arg118) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %2636 = stablehlo.reshape %arg119 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %2637 = stablehlo.broadcast_in_dim %2635, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %2638 = stablehlo.broadcast_in_dim %2636, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %2639 = stablehlo.add %2637, %2638 : tensor<1x512x60x80xbf16>
    %2640 = stablehlo.reshape %2639 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %2641 = stablehlo.transpose %2640, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %2642 = stablehlo.multiply %2641, %cst_23 : tensor<1x4800x512xbf16>
    %2643 = stablehlo.multiply %2641, %1130 : tensor<1x4800x512xbf16>
    %2644 = stablehlo.convert %2643 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %2645 = stablehlo.clamp %cst_24, %2644, %cst_25 : tensor<1x4800x512xf32>
    %2646 = stablehlo.multiply %2645, %2645 : tensor<1x4800x512xf32>
    %2647 = stablehlo.multiply %cst_26, %2646 : tensor<1x4800x512xf32>
    %2648 = stablehlo.add %2647, %cst_27 : tensor<1x4800x512xf32>
    %2649 = stablehlo.multiply %2648, %2646 : tensor<1x4800x512xf32>
    %2650 = stablehlo.add %2649, %cst_28 : tensor<1x4800x512xf32>
    %2651 = stablehlo.multiply %2650, %2646 : tensor<1x4800x512xf32>
    %2652 = stablehlo.add %2651, %cst_29 : tensor<1x4800x512xf32>
    %2653 = stablehlo.multiply %2652, %2646 : tensor<1x4800x512xf32>
    %2654 = stablehlo.add %2653, %cst_30 : tensor<1x4800x512xf32>
    %2655 = stablehlo.multiply %2654, %2646 : tensor<1x4800x512xf32>
    %2656 = stablehlo.add %2655, %cst_31 : tensor<1x4800x512xf32>
    %2657 = stablehlo.multiply %2656, %2646 : tensor<1x4800x512xf32>
    %2658 = stablehlo.add %2657, %cst_32 : tensor<1x4800x512xf32>
    %2659 = stablehlo.multiply %cst_33, %2646 : tensor<1x4800x512xf32>
    %2660 = stablehlo.add %2659, %cst_34 : tensor<1x4800x512xf32>
    %2661 = stablehlo.multiply %2660, %2646 : tensor<1x4800x512xf32>
    %2662 = stablehlo.add %2661, %cst_35 : tensor<1x4800x512xf32>
    %2663 = stablehlo.multiply %2662, %2646 : tensor<1x4800x512xf32>
    %2664 = stablehlo.add %2663, %cst_36 : tensor<1x4800x512xf32>
    %2665 = stablehlo.multiply %2664, %2646 : tensor<1x4800x512xf32>
    %2666 = stablehlo.add %2665, %cst_37 : tensor<1x4800x512xf32>
    %2667 = stablehlo.multiply %2645, %2658 : tensor<1x4800x512xf32>
    %2668 = stablehlo.divide %2667, %2666 : tensor<1x4800x512xf32>
    %2669 = stablehlo.clamp %cst_38, %2668, %cst_39 : tensor<1x4800x512xf32>
    %2670 = stablehlo.convert %2669 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %2671 = stablehlo.add %2670, %cst_21 : tensor<1x4800x512xbf16>
    %2672 = stablehlo.multiply %2671, %2642 : tensor<1x4800x512xbf16>
    %2673 = stablehlo.reshape %2672 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %2674 = stablehlo.dot_general %2673, %arg601, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %2675 = stablehlo.reshape %2674 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2676 = stablehlo.broadcast_in_dim %2675, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2677 = stablehlo.broadcast_in_dim %arg120, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %2678 = stablehlo.add %2676, %2677 : tensor<1x4800x128xbf16>
    %2679 = stablehlo.reshape %2678 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2680 = stablehlo.reshape %2679 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2681 = stablehlo.add %2680, %2585 : tensor<1x4800x128xbf16>
    %2682 = stablehlo.convert %2681 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2683 = stablehlo.convert %2682 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2684 = stablehlo.reduce(%2683 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2685 = stablehlo.reshape %2684 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2686 = stablehlo.broadcast_in_dim %2685, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2687 = stablehlo.divide %2686, %874 : tensor<1x4800x1xf64>
    %2688 = stablehlo.broadcast_in_dim %2683, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2689 = stablehlo.broadcast_in_dim %2687, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2690 = stablehlo.subtract %2688, %2689 : tensor<1x4800x128xf64>
    %2691 = stablehlo.multiply %2690, %2690 : tensor<1x4800x128xf64>
    %2692 = stablehlo.reduce(%2691 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2693 = stablehlo.reshape %2692 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2694 = stablehlo.broadcast_in_dim %2693, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2695 = stablehlo.divide %2694, %874 : tensor<1x4800x1xf64>
    %2696 = stablehlo.convert %2695 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2697 = stablehlo.reduce(%2682 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2698 = stablehlo.reshape %2697 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2699 = stablehlo.broadcast_in_dim %2698, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2700 = stablehlo.divide %2699, %890 : tensor<1x4800x1xf32>
    %2701 = stablehlo.broadcast_in_dim %2696, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2702 = stablehlo.add %2701, %893 : tensor<1x4800x1xf32>
    %2703 = stablehlo.rsqrt %2702 : tensor<1x4800x1xf32>
    %2704 = stablehlo.broadcast_in_dim %2682, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2705 = stablehlo.broadcast_in_dim %2700, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2706 = stablehlo.subtract %2704, %2705 : tensor<1x4800x128xf32>
    %2707 = stablehlo.broadcast_in_dim %2706, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2708 = stablehlo.broadcast_in_dim %2703, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2709 = stablehlo.multiply %2707, %2708 : tensor<1x4800x128xf32>
    %2710 = stablehlo.convert %arg121 : (tensor<128xbf16>) -> tensor<128xf32>
    %2711 = stablehlo.broadcast_in_dim %2709, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2712 = stablehlo.broadcast_in_dim %2710, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2713 = stablehlo.multiply %2711, %2712 : tensor<1x4800x128xf32>
    %2714 = stablehlo.convert %arg122 : (tensor<128xbf16>) -> tensor<128xf32>
    %2715 = stablehlo.broadcast_in_dim %2713, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2716 = stablehlo.broadcast_in_dim %2714, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2717 = stablehlo.add %2715, %2716 : tensor<1x4800x128xf32>
    %2718 = stablehlo.convert %2717 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2719 = stablehlo.reshape %2718 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2720 = stablehlo.convert %2719 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2721 = stablehlo.dot_general %2720, %arg602, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2722 = stablehlo.broadcast_in_dim %2721, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2723 = stablehlo.multiply %2722, %952 : tensor<4800x128xf32>
    %2724 = stablehlo.broadcast_in_dim %2723, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2725 = stablehlo.broadcast_in_dim %arg603, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2726 = stablehlo.add %2724, %2725 : tensor<4800x128xf32>
    %2727 = stablehlo.convert %2726 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2728 = stablehlo.reshape %2727 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2729 = stablehlo.reshape %2728 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x2x64xbf16>
    %2730 = stablehlo.transpose %2729, dims = [0, 2, 1, 3] : (tensor<1x4800x2x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2731 = stablehlo.transpose %2718, dims = [0, 2, 1] : (tensor<1x4800x128xbf16>) -> tensor<1x128x4800xbf16>
    %2732 = stablehlo.reshape %2731 : (tensor<1x128x4800xbf16>) -> tensor<1x128x60x80xbf16>
    %2733 = stablehlo.convolution(%2732, %arg123) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [4, 4], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<128x128x4x4xbf16>) -> tensor<1x128x15x20xbf16>
    %2734 = stablehlo.reshape %arg124 : (tensor<128xbf16>) -> tensor<128x1x1xbf16>
    %2735 = stablehlo.broadcast_in_dim %2733, dims = [0, 1, 2, 3] : (tensor<1x128x15x20xbf16>) -> tensor<1x128x15x20xbf16>
    %2736 = stablehlo.broadcast_in_dim %2734, dims = [1, 2, 3] : (tensor<128x1x1xbf16>) -> tensor<1x128x15x20xbf16>
    %2737 = stablehlo.add %2735, %2736 : tensor<1x128x15x20xbf16>
    %2738 = stablehlo.reshape %2737 : (tensor<1x128x15x20xbf16>) -> tensor<1x128x300xbf16>
    %2739 = stablehlo.transpose %2738, dims = [0, 2, 1] : (tensor<1x128x300xbf16>) -> tensor<1x300x128xbf16>
    %2740 = stablehlo.convert %2739 : (tensor<1x300x128xbf16>) -> tensor<1x300x128xf32>
    %2741 = stablehlo.convert %2740 : (tensor<1x300x128xf32>) -> tensor<1x300x128xf64>
    %2742 = stablehlo.reduce(%2741 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %2743 = stablehlo.reshape %2742 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %2744 = stablehlo.broadcast_in_dim %2743, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %2745 = stablehlo.divide %2744, %975 : tensor<1x300x1xf64>
    %2746 = stablehlo.broadcast_in_dim %2741, dims = [0, 1, 2] : (tensor<1x300x128xf64>) -> tensor<1x300x128xf64>
    %2747 = stablehlo.broadcast_in_dim %2745, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x128xf64>
    %2748 = stablehlo.subtract %2746, %2747 : tensor<1x300x128xf64>
    %2749 = stablehlo.multiply %2748, %2748 : tensor<1x300x128xf64>
    %2750 = stablehlo.reduce(%2749 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf64>, tensor<f64>) -> tensor<1x300xf64>
    %2751 = stablehlo.reshape %2750 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %2752 = stablehlo.broadcast_in_dim %2751, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %2753 = stablehlo.divide %2752, %975 : tensor<1x300x1xf64>
    %2754 = stablehlo.convert %2753 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %2755 = stablehlo.reduce(%2740 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x128xf32>, tensor<f32>) -> tensor<1x300xf32>
    %2756 = stablehlo.reshape %2755 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %2757 = stablehlo.broadcast_in_dim %2756, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2758 = stablehlo.divide %2757, %989 : tensor<1x300x1xf32>
    %2759 = stablehlo.broadcast_in_dim %2754, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %2760 = stablehlo.add %2759, %136 : tensor<1x300x1xf32>
    %2761 = stablehlo.rsqrt %2760 : tensor<1x300x1xf32>
    %2762 = stablehlo.broadcast_in_dim %2740, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2763 = stablehlo.broadcast_in_dim %2758, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2764 = stablehlo.subtract %2762, %2763 : tensor<1x300x128xf32>
    %2765 = stablehlo.broadcast_in_dim %2764, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2766 = stablehlo.broadcast_in_dim %2761, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x128xf32>
    %2767 = stablehlo.multiply %2765, %2766 : tensor<1x300x128xf32>
    %2768 = stablehlo.convert %arg125 : (tensor<128xbf16>) -> tensor<128xf32>
    %2769 = stablehlo.broadcast_in_dim %2767, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2770 = stablehlo.broadcast_in_dim %2768, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2771 = stablehlo.multiply %2769, %2770 : tensor<1x300x128xf32>
    %2772 = stablehlo.convert %arg126 : (tensor<128xbf16>) -> tensor<128xf32>
    %2773 = stablehlo.broadcast_in_dim %2771, dims = [0, 1, 2] : (tensor<1x300x128xf32>) -> tensor<1x300x128xf32>
    %2774 = stablehlo.broadcast_in_dim %2772, dims = [2] : (tensor<128xf32>) -> tensor<1x300x128xf32>
    %2775 = stablehlo.add %2773, %2774 : tensor<1x300x128xf32>
    %2776 = stablehlo.convert %2775 : (tensor<1x300x128xf32>) -> tensor<1x300x128xbf16>
    %2777 = stablehlo.reshape %2776 : (tensor<1x300x128xbf16>) -> tensor<300x128xbf16>
    %2778 = stablehlo.convert %2777 : (tensor<300x128xbf16>) -> tensor<300x128xf32>
    %2779 = stablehlo.dot_general %2778, %arg604, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2780 = stablehlo.broadcast_in_dim %2779, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2781 = stablehlo.multiply %2780, %1013 : tensor<300x128xf32>
    %2782 = stablehlo.broadcast_in_dim %2781, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2783 = stablehlo.broadcast_in_dim %arg605, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2784 = stablehlo.add %2782, %2783 : tensor<300x128xf32>
    %2785 = stablehlo.convert %2784 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2786 = stablehlo.reshape %2785 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2787 = stablehlo.reshape %2786 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2788 = stablehlo.transpose %2787, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2789 = stablehlo.dot_general %2778, %arg606, contracting_dims = [1] x [0] : (tensor<300x128xf32>, tensor<128x128xf32>) -> tensor<300x128xf32>
    %2790 = stablehlo.broadcast_in_dim %2789, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2791 = stablehlo.multiply %2790, %1013 : tensor<300x128xf32>
    %2792 = stablehlo.broadcast_in_dim %2791, dims = [0, 1] : (tensor<300x128xf32>) -> tensor<300x128xf32>
    %2793 = stablehlo.broadcast_in_dim %arg607, dims = [1] : (tensor<128xf32>) -> tensor<300x128xf32>
    %2794 = stablehlo.add %2792, %2793 : tensor<300x128xf32>
    %2795 = stablehlo.convert %2794 : (tensor<300x128xf32>) -> tensor<300x128xbf16>
    %2796 = stablehlo.reshape %2795 : (tensor<300x128xbf16>) -> tensor<1x300x128xbf16>
    %2797 = stablehlo.reshape %2796 : (tensor<1x300x128xbf16>) -> tensor<1x300x2x64xbf16>
    %2798 = stablehlo.transpose %2797, dims = [0, 2, 1, 3] : (tensor<1x300x2x64xbf16>) -> tensor<1x2x300x64xbf16>
    %2799 = stablehlo.transpose %2788, dims = [0, 1, 3, 2] : (tensor<1x2x300x64xbf16>) -> tensor<1x2x64x300xbf16>
    %2800 = stablehlo.reshape %2730 : (tensor<1x2x4800x64xbf16>) -> tensor<2x4800x64xbf16>
    %2801 = stablehlo.reshape %2799 : (tensor<1x2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2802 = stablehlo.broadcast_in_dim %2801, dims = [0, 1, 2] : (tensor<2x64x300xbf16>) -> tensor<2x64x300xbf16>
    %2803 = stablehlo.dot_general %2800, %2802, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x64xbf16>, tensor<2x64x300xbf16>) -> tensor<2x4800x300xbf16>
    %2804 = stablehlo.reshape %2803 : (tensor<2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2805 = stablehlo.broadcast_in_dim %2804, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xbf16>
    %2806 = stablehlo.divide %2805, %1039 : tensor<1x2x4800x300xbf16>
    %2807 = stablehlo.convert %2806 : (tensor<1x2x4800x300xbf16>) -> tensor<1x2x4800x300xf32>
    %2808 = stablehlo.reduce(%2807 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2809 = stablehlo.reshape %2808 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2810 = stablehlo.broadcast_in_dim %2807, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2811 = stablehlo.broadcast_in_dim %2809, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2812 = stablehlo.subtract %2810, %2811 : tensor<1x2x4800x300xf32>
    %2813 = stablehlo.exponential %2812 : tensor<1x2x4800x300xf32>
    %2814 = stablehlo.reduce(%2813 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x2x4800x300xf32>, tensor<f32>) -> tensor<1x2x4800xf32>
    %2815 = stablehlo.reshape %2814 : (tensor<1x2x4800xf32>) -> tensor<1x2x4800x1xf32>
    %2816 = stablehlo.broadcast_in_dim %2813, dims = [0, 1, 2, 3] : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xf32>
    %2817 = stablehlo.broadcast_in_dim %2815, dims = [0, 1, 2, 3] : (tensor<1x2x4800x1xf32>) -> tensor<1x2x4800x300xf32>
    %2818 = stablehlo.divide %2816, %2817 : tensor<1x2x4800x300xf32>
    %2819 = stablehlo.convert %2818 : (tensor<1x2x4800x300xf32>) -> tensor<1x2x4800x300xbf16>
    %2820 = stablehlo.reshape %2819 : (tensor<1x2x4800x300xbf16>) -> tensor<2x4800x300xbf16>
    %2821 = stablehlo.reshape %2798 : (tensor<1x2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2822 = stablehlo.broadcast_in_dim %2821, dims = [0, 1, 2] : (tensor<2x300x64xbf16>) -> tensor<2x300x64xbf16>
    %2823 = stablehlo.dot_general %2820, %2822, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<2x4800x300xbf16>, tensor<2x300x64xbf16>) -> tensor<2x4800x64xbf16>
    %2824 = stablehlo.reshape %2823 : (tensor<2x4800x64xbf16>) -> tensor<1x2x4800x64xbf16>
    %2825 = stablehlo.transpose %2824, dims = [0, 2, 1, 3] : (tensor<1x2x4800x64xbf16>) -> tensor<1x4800x2x64xbf16>
    %2826 = stablehlo.reshape %2825 : (tensor<1x4800x2x64xbf16>) -> tensor<1x4800x128xbf16>
    %2827 = stablehlo.reshape %2826 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2828 = stablehlo.convert %2827 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2829 = stablehlo.dot_general %2828, %arg608, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x128xf32>) -> tensor<4800x128xf32>
    %2830 = stablehlo.broadcast_in_dim %2829, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2831 = stablehlo.multiply %2830, %952 : tensor<4800x128xf32>
    %2832 = stablehlo.broadcast_in_dim %2831, dims = [0, 1] : (tensor<4800x128xf32>) -> tensor<4800x128xf32>
    %2833 = stablehlo.broadcast_in_dim %arg609, dims = [1] : (tensor<128xf32>) -> tensor<4800x128xf32>
    %2834 = stablehlo.add %2832, %2833 : tensor<4800x128xf32>
    %2835 = stablehlo.convert %2834 : (tensor<4800x128xf32>) -> tensor<4800x128xbf16>
    %2836 = stablehlo.reshape %2835 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2837 = stablehlo.add %2836, %2681 : tensor<1x4800x128xbf16>
    %2838 = stablehlo.convert %2837 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2839 = stablehlo.convert %2838 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2840 = stablehlo.reduce(%2839 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2841 = stablehlo.reshape %2840 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2842 = stablehlo.broadcast_in_dim %2841, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2843 = stablehlo.divide %2842, %874 : tensor<1x4800x1xf64>
    %2844 = stablehlo.broadcast_in_dim %2839, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2845 = stablehlo.broadcast_in_dim %2843, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2846 = stablehlo.subtract %2844, %2845 : tensor<1x4800x128xf64>
    %2847 = stablehlo.multiply %2846, %2846 : tensor<1x4800x128xf64>
    %2848 = stablehlo.reduce(%2847 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2849 = stablehlo.reshape %2848 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2850 = stablehlo.broadcast_in_dim %2849, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2851 = stablehlo.divide %2850, %874 : tensor<1x4800x1xf64>
    %2852 = stablehlo.convert %2851 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2853 = stablehlo.reduce(%2838 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2854 = stablehlo.reshape %2853 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2855 = stablehlo.broadcast_in_dim %2854, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2856 = stablehlo.divide %2855, %890 : tensor<1x4800x1xf32>
    %2857 = stablehlo.broadcast_in_dim %2852, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2858 = stablehlo.add %2857, %893 : tensor<1x4800x1xf32>
    %2859 = stablehlo.rsqrt %2858 : tensor<1x4800x1xf32>
    %2860 = stablehlo.broadcast_in_dim %2838, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2861 = stablehlo.broadcast_in_dim %2856, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2862 = stablehlo.subtract %2860, %2861 : tensor<1x4800x128xf32>
    %2863 = stablehlo.broadcast_in_dim %2862, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2864 = stablehlo.broadcast_in_dim %2859, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2865 = stablehlo.multiply %2863, %2864 : tensor<1x4800x128xf32>
    %2866 = stablehlo.convert %arg127 : (tensor<128xbf16>) -> tensor<128xf32>
    %2867 = stablehlo.broadcast_in_dim %2865, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2868 = stablehlo.broadcast_in_dim %2866, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2869 = stablehlo.multiply %2867, %2868 : tensor<1x4800x128xf32>
    %2870 = stablehlo.convert %arg128 : (tensor<128xbf16>) -> tensor<128xf32>
    %2871 = stablehlo.broadcast_in_dim %2869, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2872 = stablehlo.broadcast_in_dim %2870, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2873 = stablehlo.add %2871, %2872 : tensor<1x4800x128xf32>
    %2874 = stablehlo.convert %2873 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2875 = stablehlo.reshape %2874 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2876 = stablehlo.convert %2875 : (tensor<4800x128xbf16>) -> tensor<4800x128xf32>
    %2877 = stablehlo.dot_general %2876, %arg610, contracting_dims = [1] x [0] : (tensor<4800x128xf32>, tensor<128x512xf32>) -> tensor<4800x512xf32>
    %2878 = stablehlo.broadcast_in_dim %2877, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2879 = stablehlo.multiply %2878, %1113 : tensor<4800x512xf32>
    %2880 = stablehlo.broadcast_in_dim %2879, dims = [0, 1] : (tensor<4800x512xf32>) -> tensor<4800x512xf32>
    %2881 = stablehlo.broadcast_in_dim %arg611, dims = [1] : (tensor<512xf32>) -> tensor<4800x512xf32>
    %2882 = stablehlo.add %2880, %2881 : tensor<4800x512xf32>
    %2883 = stablehlo.convert %2882 : (tensor<4800x512xf32>) -> tensor<4800x512xbf16>
    %2884 = stablehlo.reshape %2883 : (tensor<4800x512xbf16>) -> tensor<1x4800x512xbf16>
    %2885 = stablehlo.transpose %2884, dims = [0, 2, 1] : (tensor<1x4800x512xbf16>) -> tensor<1x512x4800xbf16>
    %2886 = stablehlo.reshape %2885 : (tensor<1x512x4800xbf16>) -> tensor<1x512x60x80xbf16>
    %2887 = stablehlo.convolution(%2886, %arg129) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 512 : i64} : (tensor<1x512x60x80xbf16>, tensor<512x1x3x3xbf16>) -> tensor<1x512x60x80xbf16>
    %2888 = stablehlo.reshape %arg130 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %2889 = stablehlo.broadcast_in_dim %2887, dims = [0, 1, 2, 3] : (tensor<1x512x60x80xbf16>) -> tensor<1x512x60x80xbf16>
    %2890 = stablehlo.broadcast_in_dim %2888, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x60x80xbf16>
    %2891 = stablehlo.add %2889, %2890 : tensor<1x512x60x80xbf16>
    %2892 = stablehlo.reshape %2891 : (tensor<1x512x60x80xbf16>) -> tensor<1x512x4800xbf16>
    %2893 = stablehlo.transpose %2892, dims = [0, 2, 1] : (tensor<1x512x4800xbf16>) -> tensor<1x4800x512xbf16>
    %2894 = stablehlo.multiply %2893, %cst_23 : tensor<1x4800x512xbf16>
    %2895 = stablehlo.multiply %2893, %1130 : tensor<1x4800x512xbf16>
    %2896 = stablehlo.convert %2895 : (tensor<1x4800x512xbf16>) -> tensor<1x4800x512xf32>
    %2897 = stablehlo.clamp %cst_24, %2896, %cst_25 : tensor<1x4800x512xf32>
    %2898 = stablehlo.multiply %2897, %2897 : tensor<1x4800x512xf32>
    %2899 = stablehlo.multiply %cst_26, %2898 : tensor<1x4800x512xf32>
    %2900 = stablehlo.add %2899, %cst_27 : tensor<1x4800x512xf32>
    %2901 = stablehlo.multiply %2900, %2898 : tensor<1x4800x512xf32>
    %2902 = stablehlo.add %2901, %cst_28 : tensor<1x4800x512xf32>
    %2903 = stablehlo.multiply %2902, %2898 : tensor<1x4800x512xf32>
    %2904 = stablehlo.add %2903, %cst_29 : tensor<1x4800x512xf32>
    %2905 = stablehlo.multiply %2904, %2898 : tensor<1x4800x512xf32>
    %2906 = stablehlo.add %2905, %cst_30 : tensor<1x4800x512xf32>
    %2907 = stablehlo.multiply %2906, %2898 : tensor<1x4800x512xf32>
    %2908 = stablehlo.add %2907, %cst_31 : tensor<1x4800x512xf32>
    %2909 = stablehlo.multiply %2908, %2898 : tensor<1x4800x512xf32>
    %2910 = stablehlo.add %2909, %cst_32 : tensor<1x4800x512xf32>
    %2911 = stablehlo.multiply %cst_33, %2898 : tensor<1x4800x512xf32>
    %2912 = stablehlo.add %2911, %cst_34 : tensor<1x4800x512xf32>
    %2913 = stablehlo.multiply %2912, %2898 : tensor<1x4800x512xf32>
    %2914 = stablehlo.add %2913, %cst_35 : tensor<1x4800x512xf32>
    %2915 = stablehlo.multiply %2914, %2898 : tensor<1x4800x512xf32>
    %2916 = stablehlo.add %2915, %cst_36 : tensor<1x4800x512xf32>
    %2917 = stablehlo.multiply %2916, %2898 : tensor<1x4800x512xf32>
    %2918 = stablehlo.add %2917, %cst_37 : tensor<1x4800x512xf32>
    %2919 = stablehlo.multiply %2897, %2910 : tensor<1x4800x512xf32>
    %2920 = stablehlo.divide %2919, %2918 : tensor<1x4800x512xf32>
    %2921 = stablehlo.clamp %cst_38, %2920, %cst_39 : tensor<1x4800x512xf32>
    %2922 = stablehlo.convert %2921 : (tensor<1x4800x512xf32>) -> tensor<1x4800x512xbf16>
    %2923 = stablehlo.add %2922, %cst_21 : tensor<1x4800x512xbf16>
    %2924 = stablehlo.multiply %2923, %2894 : tensor<1x4800x512xbf16>
    %2925 = stablehlo.reshape %2924 : (tensor<1x4800x512xbf16>) -> tensor<4800x512xbf16>
    %2926 = stablehlo.dot_general %2925, %arg612, contracting_dims = [1] x [0] : (tensor<4800x512xbf16>, tensor<512x128xbf16>) -> tensor<4800x128xbf16>
    %2927 = stablehlo.reshape %2926 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2928 = stablehlo.broadcast_in_dim %2927, dims = [0, 1, 2] : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2929 = stablehlo.broadcast_in_dim %arg131, dims = [2] : (tensor<128xbf16>) -> tensor<1x4800x128xbf16>
    %2930 = stablehlo.add %2928, %2929 : tensor<1x4800x128xbf16>
    %2931 = stablehlo.reshape %2930 : (tensor<1x4800x128xbf16>) -> tensor<4800x128xbf16>
    %2932 = stablehlo.reshape %2931 : (tensor<4800x128xbf16>) -> tensor<1x4800x128xbf16>
    %2933 = stablehlo.add %2932, %2837 : tensor<1x4800x128xbf16>
    %2934 = stablehlo.convert %2933 : (tensor<1x4800x128xbf16>) -> tensor<1x4800x128xf32>
    %2935 = stablehlo.convert %2934 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf64>
    %2936 = stablehlo.reduce(%2935 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2937 = stablehlo.reshape %2936 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2938 = stablehlo.broadcast_in_dim %2937, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2939 = stablehlo.divide %2938, %874 : tensor<1x4800x1xf64>
    %2940 = stablehlo.broadcast_in_dim %2935, dims = [0, 1, 2] : (tensor<1x4800x128xf64>) -> tensor<1x4800x128xf64>
    %2941 = stablehlo.broadcast_in_dim %2939, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x128xf64>
    %2942 = stablehlo.subtract %2940, %2941 : tensor<1x4800x128xf64>
    %2943 = stablehlo.multiply %2942, %2942 : tensor<1x4800x128xf64>
    %2944 = stablehlo.reduce(%2943 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf64>, tensor<f64>) -> tensor<1x4800xf64>
    %2945 = stablehlo.reshape %2944 : (tensor<1x4800xf64>) -> tensor<1x4800x1xf64>
    %2946 = stablehlo.broadcast_in_dim %2945, dims = [0, 1, 2] : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf64>
    %2947 = stablehlo.divide %2946, %874 : tensor<1x4800x1xf64>
    %2948 = stablehlo.convert %2947 : (tensor<1x4800x1xf64>) -> tensor<1x4800x1xf32>
    %2949 = stablehlo.reduce(%2934 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x4800x128xf32>, tensor<f32>) -> tensor<1x4800xf32>
    %2950 = stablehlo.reshape %2949 : (tensor<1x4800xf32>) -> tensor<1x4800x1xf32>
    %2951 = stablehlo.broadcast_in_dim %2950, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2952 = stablehlo.divide %2951, %890 : tensor<1x4800x1xf32>
    %2953 = stablehlo.broadcast_in_dim %2948, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x1xf32>
    %2954 = stablehlo.add %2953, %893 : tensor<1x4800x1xf32>
    %2955 = stablehlo.rsqrt %2954 : tensor<1x4800x1xf32>
    %2956 = stablehlo.broadcast_in_dim %2934, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2957 = stablehlo.broadcast_in_dim %2952, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2958 = stablehlo.subtract %2956, %2957 : tensor<1x4800x128xf32>
    %2959 = stablehlo.broadcast_in_dim %2958, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2960 = stablehlo.broadcast_in_dim %2955, dims = [0, 1, 2] : (tensor<1x4800x1xf32>) -> tensor<1x4800x128xf32>
    %2961 = stablehlo.multiply %2959, %2960 : tensor<1x4800x128xf32>
    %2962 = stablehlo.convert %arg132 : (tensor<128xbf16>) -> tensor<128xf32>
    %2963 = stablehlo.broadcast_in_dim %2961, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2964 = stablehlo.broadcast_in_dim %2962, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2965 = stablehlo.multiply %2963, %2964 : tensor<1x4800x128xf32>
    %2966 = stablehlo.convert %arg133 : (tensor<128xbf16>) -> tensor<128xf32>
    %2967 = stablehlo.broadcast_in_dim %2965, dims = [0, 1, 2] : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xf32>
    %2968 = stablehlo.broadcast_in_dim %2966, dims = [2] : (tensor<128xf32>) -> tensor<1x4800x128xf32>
    %2969 = stablehlo.add %2967, %2968 : tensor<1x4800x128xf32>
    %2970 = stablehlo.convert %2969 : (tensor<1x4800x128xf32>) -> tensor<1x4800x128xbf16>
    %2971 = stablehlo.reshape %2970 : (tensor<1x4800x128xbf16>) -> tensor<1x60x80x128xbf16>
    %2972 = stablehlo.transpose %2971, dims = [0, 3, 1, 2] : (tensor<1x60x80x128xbf16>) -> tensor<1x128x60x80xbf16>
    %2973 = stablehlo.convolution(%2972, %arg134) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<320x128x3x3xbf16>) -> tensor<1x320x30x40xbf16>
    %2974 = stablehlo.reshape %arg135 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %2975 = stablehlo.broadcast_in_dim %2973, dims = [0, 1, 2, 3] : (tensor<1x320x30x40xbf16>) -> tensor<1x320x30x40xbf16>
    %2976 = stablehlo.broadcast_in_dim %2974, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x30x40xbf16>
    %2977 = stablehlo.add %2975, %2976 : tensor<1x320x30x40xbf16>
    %2978 = stablehlo.reshape %2977 : (tensor<1x320x30x40xbf16>) -> tensor<1x320x1200xbf16>
    %2979 = stablehlo.transpose %2978, dims = [0, 2, 1] : (tensor<1x320x1200xbf16>) -> tensor<1x1200x320xbf16>
    %2980 = stablehlo.convert %2979 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %2981 = stablehlo.convert %2980 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %2982 = stablehlo.reduce(%2981 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %2983 = stablehlo.reshape %2982 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %2984 = stablehlo.convert %cst_90 : (tensor<1xi64>) -> tensor<1xf64>
    %2985 = stablehlo.reshape %2984 : (tensor<1xf64>) -> tensor<f64>
    %2986 = stablehlo.broadcast_in_dim %2983, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %2987 = stablehlo.broadcast_in_dim %2985, dims = [] : (tensor<f64>) -> tensor<1x1200x1xf64>
    %2988 = stablehlo.divide %2986, %2987 : tensor<1x1200x1xf64>
    %2989 = stablehlo.broadcast_in_dim %2981, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %2990 = stablehlo.broadcast_in_dim %2988, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %2991 = stablehlo.subtract %2989, %2990 : tensor<1x1200x320xf64>
    %2992 = stablehlo.multiply %2991, %2991 : tensor<1x1200x320xf64>
    %2993 = stablehlo.reduce(%2992 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %2994 = stablehlo.reshape %2993 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %2995 = stablehlo.broadcast_in_dim %2994, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %2996 = stablehlo.divide %2995, %2987 : tensor<1x1200x1xf64>
    %2997 = stablehlo.convert %2996 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %2998 = stablehlo.reduce(%2980 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %2999 = stablehlo.reshape %2998 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3000 = stablehlo.convert %cst_90 : (tensor<1xi64>) -> tensor<1xf32>
    %3001 = stablehlo.reshape %3000 : (tensor<1xf32>) -> tensor<f32>
    %3002 = stablehlo.broadcast_in_dim %2999, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3003 = stablehlo.broadcast_in_dim %3001, dims = [] : (tensor<f32>) -> tensor<1x1200x1xf32>
    %3004 = stablehlo.divide %3002, %3003 : tensor<1x1200x1xf32>
    %3005 = stablehlo.broadcast_in_dim %2997, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3006 = stablehlo.broadcast_in_dim %33, dims = [] : (tensor<f32>) -> tensor<1x1200x1xf32>
    %3007 = stablehlo.add %3005, %3006 : tensor<1x1200x1xf32>
    %3008 = stablehlo.rsqrt %3007 : tensor<1x1200x1xf32>
    %3009 = stablehlo.broadcast_in_dim %2980, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3010 = stablehlo.broadcast_in_dim %3004, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3011 = stablehlo.subtract %3009, %3010 : tensor<1x1200x320xf32>
    %3012 = stablehlo.broadcast_in_dim %3011, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3013 = stablehlo.broadcast_in_dim %3008, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3014 = stablehlo.multiply %3012, %3013 : tensor<1x1200x320xf32>
    %3015 = stablehlo.convert %arg136 : (tensor<320xbf16>) -> tensor<320xf32>
    %3016 = stablehlo.broadcast_in_dim %3014, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3017 = stablehlo.broadcast_in_dim %3015, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3018 = stablehlo.multiply %3016, %3017 : tensor<1x1200x320xf32>
    %3019 = stablehlo.convert %arg137 : (tensor<320xbf16>) -> tensor<320xf32>
    %3020 = stablehlo.broadcast_in_dim %3018, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3021 = stablehlo.broadcast_in_dim %3019, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3022 = stablehlo.add %3020, %3021 : tensor<1x1200x320xf32>
    %3023 = stablehlo.convert %3022 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3024 = stablehlo.convert %3023 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3025 = stablehlo.convert %3024 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3026 = stablehlo.reduce(%3025 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3027 = stablehlo.reshape %3026 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3028 = stablehlo.broadcast_in_dim %3027, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3029 = stablehlo.divide %3028, %2987 : tensor<1x1200x1xf64>
    %3030 = stablehlo.broadcast_in_dim %3025, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3031 = stablehlo.broadcast_in_dim %3029, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3032 = stablehlo.subtract %3030, %3031 : tensor<1x1200x320xf64>
    %3033 = stablehlo.multiply %3032, %3032 : tensor<1x1200x320xf64>
    %3034 = stablehlo.reduce(%3033 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3035 = stablehlo.reshape %3034 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3036 = stablehlo.broadcast_in_dim %3035, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3037 = stablehlo.divide %3036, %2987 : tensor<1x1200x1xf64>
    %3038 = stablehlo.convert %3037 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3039 = stablehlo.reduce(%3024 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3040 = stablehlo.reshape %3039 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3041 = stablehlo.broadcast_in_dim %3040, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3042 = stablehlo.divide %3041, %3003 : tensor<1x1200x1xf32>
    %3043 = stablehlo.broadcast_in_dim %3038, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3044 = stablehlo.add %3043, %3006 : tensor<1x1200x1xf32>
    %3045 = stablehlo.rsqrt %3044 : tensor<1x1200x1xf32>
    %3046 = stablehlo.broadcast_in_dim %3024, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3047 = stablehlo.broadcast_in_dim %3042, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3048 = stablehlo.subtract %3046, %3047 : tensor<1x1200x320xf32>
    %3049 = stablehlo.broadcast_in_dim %3048, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3050 = stablehlo.broadcast_in_dim %3045, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3051 = stablehlo.multiply %3049, %3050 : tensor<1x1200x320xf32>
    %3052 = stablehlo.convert %arg138 : (tensor<320xbf16>) -> tensor<320xf32>
    %3053 = stablehlo.broadcast_in_dim %3051, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3054 = stablehlo.broadcast_in_dim %3052, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3055 = stablehlo.multiply %3053, %3054 : tensor<1x1200x320xf32>
    %3056 = stablehlo.convert %arg139 : (tensor<320xbf16>) -> tensor<320xf32>
    %3057 = stablehlo.broadcast_in_dim %3055, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3058 = stablehlo.broadcast_in_dim %3056, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3059 = stablehlo.add %3057, %3058 : tensor<1x1200x320xf32>
    %3060 = stablehlo.convert %3059 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3061 = stablehlo.reshape %3060 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3062 = stablehlo.convert %3061 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3063 = stablehlo.dot_general %3062, %arg613, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3064 = stablehlo.broadcast_in_dim %3063, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3065 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<1200x320xf32>
    %3066 = stablehlo.multiply %3064, %3065 : tensor<1200x320xf32>
    %3067 = stablehlo.broadcast_in_dim %3066, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3068 = stablehlo.broadcast_in_dim %arg614, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3069 = stablehlo.add %3067, %3068 : tensor<1200x320xf32>
    %3070 = stablehlo.convert %3069 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3071 = stablehlo.reshape %3070 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3072 = stablehlo.reshape %3071 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %3073 = stablehlo.transpose %3072, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3074 = stablehlo.transpose %3060, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %3075 = stablehlo.reshape %3074 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %3076 = stablehlo.convolution(%3075, %arg140) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %3077 = stablehlo.reshape %arg141 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %3078 = stablehlo.broadcast_in_dim %3076, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %3079 = stablehlo.broadcast_in_dim %3077, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %3080 = stablehlo.add %3078, %3079 : tensor<1x320x15x20xbf16>
    %3081 = stablehlo.reshape %3080 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %3082 = stablehlo.transpose %3081, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %3083 = stablehlo.convert %3082 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %3084 = stablehlo.convert %3083 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %3085 = stablehlo.reduce(%3084 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3086 = stablehlo.reshape %3085 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3087 = stablehlo.broadcast_in_dim %3086, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3088 = stablehlo.broadcast_in_dim %2985, dims = [] : (tensor<f64>) -> tensor<1x300x1xf64>
    %3089 = stablehlo.divide %3087, %3088 : tensor<1x300x1xf64>
    %3090 = stablehlo.broadcast_in_dim %3084, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %3091 = stablehlo.broadcast_in_dim %3089, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %3092 = stablehlo.subtract %3090, %3091 : tensor<1x300x320xf64>
    %3093 = stablehlo.multiply %3092, %3092 : tensor<1x300x320xf64>
    %3094 = stablehlo.reduce(%3093 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3095 = stablehlo.reshape %3094 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3096 = stablehlo.broadcast_in_dim %3095, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3097 = stablehlo.divide %3096, %3088 : tensor<1x300x1xf64>
    %3098 = stablehlo.convert %3097 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %3099 = stablehlo.reduce(%3083 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %3100 = stablehlo.reshape %3099 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %3101 = stablehlo.broadcast_in_dim %3100, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3102 = stablehlo.broadcast_in_dim %3001, dims = [] : (tensor<f32>) -> tensor<1x300x1xf32>
    %3103 = stablehlo.divide %3101, %3102 : tensor<1x300x1xf32>
    %3104 = stablehlo.broadcast_in_dim %3098, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3105 = stablehlo.add %3104, %136 : tensor<1x300x1xf32>
    %3106 = stablehlo.rsqrt %3105 : tensor<1x300x1xf32>
    %3107 = stablehlo.broadcast_in_dim %3083, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3108 = stablehlo.broadcast_in_dim %3103, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3109 = stablehlo.subtract %3107, %3108 : tensor<1x300x320xf32>
    %3110 = stablehlo.broadcast_in_dim %3109, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3111 = stablehlo.broadcast_in_dim %3106, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3112 = stablehlo.multiply %3110, %3111 : tensor<1x300x320xf32>
    %3113 = stablehlo.convert %arg142 : (tensor<320xbf16>) -> tensor<320xf32>
    %3114 = stablehlo.broadcast_in_dim %3112, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3115 = stablehlo.broadcast_in_dim %3113, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3116 = stablehlo.multiply %3114, %3115 : tensor<1x300x320xf32>
    %3117 = stablehlo.convert %arg143 : (tensor<320xbf16>) -> tensor<320xf32>
    %3118 = stablehlo.broadcast_in_dim %3116, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3119 = stablehlo.broadcast_in_dim %3117, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3120 = stablehlo.add %3118, %3119 : tensor<1x300x320xf32>
    %3121 = stablehlo.convert %3120 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %3122 = stablehlo.reshape %3121 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %3123 = stablehlo.convert %3122 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %3124 = stablehlo.dot_general %3123, %arg615, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3125 = stablehlo.broadcast_in_dim %3124, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3126 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<300x320xf32>
    %3127 = stablehlo.multiply %3125, %3126 : tensor<300x320xf32>
    %3128 = stablehlo.broadcast_in_dim %3127, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3129 = stablehlo.broadcast_in_dim %arg616, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3130 = stablehlo.add %3128, %3129 : tensor<300x320xf32>
    %3131 = stablehlo.convert %3130 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3132 = stablehlo.reshape %3131 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3133 = stablehlo.reshape %3132 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3134 = stablehlo.transpose %3133, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3135 = stablehlo.dot_general %3123, %arg617, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3136 = stablehlo.broadcast_in_dim %3135, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3137 = stablehlo.multiply %3136, %3126 : tensor<300x320xf32>
    %3138 = stablehlo.broadcast_in_dim %3137, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3139 = stablehlo.broadcast_in_dim %arg618, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3140 = stablehlo.add %3138, %3139 : tensor<300x320xf32>
    %3141 = stablehlo.convert %3140 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3142 = stablehlo.reshape %3141 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3143 = stablehlo.reshape %3142 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3144 = stablehlo.transpose %3143, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3145 = stablehlo.transpose %3134, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %3146 = stablehlo.reshape %3073 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %3147 = stablehlo.reshape %3145 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3148 = stablehlo.broadcast_in_dim %3147, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3149 = stablehlo.dot_general %3146, %3148, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %3150 = stablehlo.reshape %3149 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3151 = stablehlo.broadcast_in_dim %3150, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3152 = stablehlo.broadcast_in_dim %184, dims = [] : (tensor<bf16>) -> tensor<1x5x1200x300xbf16>
    %3153 = stablehlo.divide %3151, %3152 : tensor<1x5x1200x300xbf16>
    %3154 = stablehlo.convert %3153 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %3155 = stablehlo.reduce(%3154 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3156 = stablehlo.reshape %3155 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3157 = stablehlo.broadcast_in_dim %3154, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3158 = stablehlo.broadcast_in_dim %3156, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3159 = stablehlo.subtract %3157, %3158 : tensor<1x5x1200x300xf32>
    %3160 = stablehlo.exponential %3159 : tensor<1x5x1200x300xf32>
    %3161 = stablehlo.reduce(%3160 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3162 = stablehlo.reshape %3161 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3163 = stablehlo.broadcast_in_dim %3160, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3164 = stablehlo.broadcast_in_dim %3162, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3165 = stablehlo.divide %3163, %3164 : tensor<1x5x1200x300xf32>
    %3166 = stablehlo.convert %3165 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %3167 = stablehlo.reshape %3166 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %3168 = stablehlo.reshape %3144 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3169 = stablehlo.broadcast_in_dim %3168, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3170 = stablehlo.dot_general %3167, %3169, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %3171 = stablehlo.reshape %3170 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3172 = stablehlo.transpose %3171, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %3173 = stablehlo.reshape %3172 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %3174 = stablehlo.reshape %3173 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3175 = stablehlo.convert %3174 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3176 = stablehlo.dot_general %3175, %arg619, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3177 = stablehlo.broadcast_in_dim %3176, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3178 = stablehlo.multiply %3177, %3065 : tensor<1200x320xf32>
    %3179 = stablehlo.broadcast_in_dim %3178, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3180 = stablehlo.broadcast_in_dim %arg620, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3181 = stablehlo.add %3179, %3180 : tensor<1200x320xf32>
    %3182 = stablehlo.convert %3181 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3183 = stablehlo.reshape %3182 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3184 = stablehlo.add %3183, %3023 : tensor<1x1200x320xbf16>
    %3185 = stablehlo.convert %3184 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3186 = stablehlo.convert %3185 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3187 = stablehlo.reduce(%3186 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3188 = stablehlo.reshape %3187 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3189 = stablehlo.broadcast_in_dim %3188, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3190 = stablehlo.divide %3189, %2987 : tensor<1x1200x1xf64>
    %3191 = stablehlo.broadcast_in_dim %3186, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3192 = stablehlo.broadcast_in_dim %3190, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3193 = stablehlo.subtract %3191, %3192 : tensor<1x1200x320xf64>
    %3194 = stablehlo.multiply %3193, %3193 : tensor<1x1200x320xf64>
    %3195 = stablehlo.reduce(%3194 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3196 = stablehlo.reshape %3195 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3197 = stablehlo.broadcast_in_dim %3196, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3198 = stablehlo.divide %3197, %2987 : tensor<1x1200x1xf64>
    %3199 = stablehlo.convert %3198 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3200 = stablehlo.reduce(%3185 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3201 = stablehlo.reshape %3200 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3202 = stablehlo.broadcast_in_dim %3201, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3203 = stablehlo.divide %3202, %3003 : tensor<1x1200x1xf32>
    %3204 = stablehlo.broadcast_in_dim %3199, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3205 = stablehlo.add %3204, %3006 : tensor<1x1200x1xf32>
    %3206 = stablehlo.rsqrt %3205 : tensor<1x1200x1xf32>
    %3207 = stablehlo.broadcast_in_dim %3185, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3208 = stablehlo.broadcast_in_dim %3203, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3209 = stablehlo.subtract %3207, %3208 : tensor<1x1200x320xf32>
    %3210 = stablehlo.broadcast_in_dim %3209, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3211 = stablehlo.broadcast_in_dim %3206, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3212 = stablehlo.multiply %3210, %3211 : tensor<1x1200x320xf32>
    %3213 = stablehlo.convert %arg144 : (tensor<320xbf16>) -> tensor<320xf32>
    %3214 = stablehlo.broadcast_in_dim %3212, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3215 = stablehlo.broadcast_in_dim %3213, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3216 = stablehlo.multiply %3214, %3215 : tensor<1x1200x320xf32>
    %3217 = stablehlo.convert %arg145 : (tensor<320xbf16>) -> tensor<320xf32>
    %3218 = stablehlo.broadcast_in_dim %3216, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3219 = stablehlo.broadcast_in_dim %3217, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3220 = stablehlo.add %3218, %3219 : tensor<1x1200x320xf32>
    %3221 = stablehlo.convert %3220 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3222 = stablehlo.reshape %3221 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3223 = stablehlo.convert %3222 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3224 = stablehlo.dot_general %3223, %arg621, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %3225 = stablehlo.broadcast_in_dim %3224, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3226 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<1200x1280xf32>
    %3227 = stablehlo.multiply %3225, %3226 : tensor<1200x1280xf32>
    %3228 = stablehlo.broadcast_in_dim %3227, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3229 = stablehlo.broadcast_in_dim %arg622, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %3230 = stablehlo.add %3228, %3229 : tensor<1200x1280xf32>
    %3231 = stablehlo.convert %3230 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %3232 = stablehlo.reshape %3231 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %3233 = stablehlo.transpose %3232, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %3234 = stablehlo.reshape %3233 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %3235 = stablehlo.convolution(%3234, %arg146) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %3236 = stablehlo.reshape %arg147 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %3237 = stablehlo.broadcast_in_dim %3235, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %3238 = stablehlo.broadcast_in_dim %3236, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %3239 = stablehlo.add %3237, %3238 : tensor<1x1280x30x40xbf16>
    %3240 = stablehlo.reshape %3239 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %3241 = stablehlo.transpose %3240, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %3242 = stablehlo.multiply %3241, %cst_42 : tensor<1x1200x1280xbf16>
    %3243 = stablehlo.rsqrt %cst_41 : tensor<1x1200x1280xbf16>
    %3244 = stablehlo.multiply %3241, %3243 : tensor<1x1200x1280xbf16>
    %3245 = stablehlo.convert %3244 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %3246 = stablehlo.clamp %cst_43, %3245, %cst_44 : tensor<1x1200x1280xf32>
    %3247 = stablehlo.multiply %3246, %3246 : tensor<1x1200x1280xf32>
    %3248 = stablehlo.multiply %cst_45, %3247 : tensor<1x1200x1280xf32>
    %3249 = stablehlo.add %3248, %cst_46 : tensor<1x1200x1280xf32>
    %3250 = stablehlo.multiply %3249, %3247 : tensor<1x1200x1280xf32>
    %3251 = stablehlo.add %3250, %cst_47 : tensor<1x1200x1280xf32>
    %3252 = stablehlo.multiply %3251, %3247 : tensor<1x1200x1280xf32>
    %3253 = stablehlo.add %3252, %cst_48 : tensor<1x1200x1280xf32>
    %3254 = stablehlo.multiply %3253, %3247 : tensor<1x1200x1280xf32>
    %3255 = stablehlo.add %3254, %cst_49 : tensor<1x1200x1280xf32>
    %3256 = stablehlo.multiply %3255, %3247 : tensor<1x1200x1280xf32>
    %3257 = stablehlo.add %3256, %cst_50 : tensor<1x1200x1280xf32>
    %3258 = stablehlo.multiply %3257, %3247 : tensor<1x1200x1280xf32>
    %3259 = stablehlo.add %3258, %cst_51 : tensor<1x1200x1280xf32>
    %3260 = stablehlo.multiply %cst_52, %3247 : tensor<1x1200x1280xf32>
    %3261 = stablehlo.add %3260, %cst_53 : tensor<1x1200x1280xf32>
    %3262 = stablehlo.multiply %3261, %3247 : tensor<1x1200x1280xf32>
    %3263 = stablehlo.add %3262, %cst_54 : tensor<1x1200x1280xf32>
    %3264 = stablehlo.multiply %3263, %3247 : tensor<1x1200x1280xf32>
    %3265 = stablehlo.add %3264, %cst_55 : tensor<1x1200x1280xf32>
    %3266 = stablehlo.multiply %3265, %3247 : tensor<1x1200x1280xf32>
    %3267 = stablehlo.add %3266, %cst_56 : tensor<1x1200x1280xf32>
    %3268 = stablehlo.multiply %3246, %3259 : tensor<1x1200x1280xf32>
    %3269 = stablehlo.divide %3268, %3267 : tensor<1x1200x1280xf32>
    %3270 = stablehlo.clamp %cst_57, %3269, %cst_58 : tensor<1x1200x1280xf32>
    %3271 = stablehlo.convert %3270 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %3272 = stablehlo.add %3271, %cst_40 : tensor<1x1200x1280xbf16>
    %3273 = stablehlo.multiply %3272, %3242 : tensor<1x1200x1280xbf16>
    %3274 = stablehlo.reshape %3273 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %3275 = stablehlo.dot_general %3274, %arg623, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %3276 = stablehlo.reshape %3275 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3277 = stablehlo.broadcast_in_dim %3276, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3278 = stablehlo.broadcast_in_dim %arg148, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %3279 = stablehlo.add %3277, %3278 : tensor<1x1200x320xbf16>
    %3280 = stablehlo.reshape %3279 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3281 = stablehlo.reshape %3280 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3282 = stablehlo.add %3281, %3184 : tensor<1x1200x320xbf16>
    %3283 = stablehlo.convert %3282 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3284 = stablehlo.convert %3283 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3285 = stablehlo.reduce(%3284 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3286 = stablehlo.reshape %3285 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3287 = stablehlo.broadcast_in_dim %3286, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3288 = stablehlo.divide %3287, %2987 : tensor<1x1200x1xf64>
    %3289 = stablehlo.broadcast_in_dim %3284, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3290 = stablehlo.broadcast_in_dim %3288, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3291 = stablehlo.subtract %3289, %3290 : tensor<1x1200x320xf64>
    %3292 = stablehlo.multiply %3291, %3291 : tensor<1x1200x320xf64>
    %3293 = stablehlo.reduce(%3292 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3294 = stablehlo.reshape %3293 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3295 = stablehlo.broadcast_in_dim %3294, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3296 = stablehlo.divide %3295, %2987 : tensor<1x1200x1xf64>
    %3297 = stablehlo.convert %3296 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3298 = stablehlo.reduce(%3283 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3299 = stablehlo.reshape %3298 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3300 = stablehlo.broadcast_in_dim %3299, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3301 = stablehlo.divide %3300, %3003 : tensor<1x1200x1xf32>
    %3302 = stablehlo.broadcast_in_dim %3297, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3303 = stablehlo.add %3302, %3006 : tensor<1x1200x1xf32>
    %3304 = stablehlo.rsqrt %3303 : tensor<1x1200x1xf32>
    %3305 = stablehlo.broadcast_in_dim %3283, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3306 = stablehlo.broadcast_in_dim %3301, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3307 = stablehlo.subtract %3305, %3306 : tensor<1x1200x320xf32>
    %3308 = stablehlo.broadcast_in_dim %3307, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3309 = stablehlo.broadcast_in_dim %3304, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3310 = stablehlo.multiply %3308, %3309 : tensor<1x1200x320xf32>
    %3311 = stablehlo.convert %arg149 : (tensor<320xbf16>) -> tensor<320xf32>
    %3312 = stablehlo.broadcast_in_dim %3310, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3313 = stablehlo.broadcast_in_dim %3311, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3314 = stablehlo.multiply %3312, %3313 : tensor<1x1200x320xf32>
    %3315 = stablehlo.convert %arg150 : (tensor<320xbf16>) -> tensor<320xf32>
    %3316 = stablehlo.broadcast_in_dim %3314, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3317 = stablehlo.broadcast_in_dim %3315, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3318 = stablehlo.add %3316, %3317 : tensor<1x1200x320xf32>
    %3319 = stablehlo.convert %3318 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3320 = stablehlo.reshape %3319 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3321 = stablehlo.convert %3320 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3322 = stablehlo.dot_general %3321, %arg624, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3323 = stablehlo.broadcast_in_dim %3322, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3324 = stablehlo.multiply %3323, %3065 : tensor<1200x320xf32>
    %3325 = stablehlo.broadcast_in_dim %3324, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3326 = stablehlo.broadcast_in_dim %arg625, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3327 = stablehlo.add %3325, %3326 : tensor<1200x320xf32>
    %3328 = stablehlo.convert %3327 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3329 = stablehlo.reshape %3328 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3330 = stablehlo.reshape %3329 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %3331 = stablehlo.transpose %3330, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3332 = stablehlo.transpose %3319, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %3333 = stablehlo.reshape %3332 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %3334 = stablehlo.convolution(%3333, %arg151) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %3335 = stablehlo.reshape %arg152 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %3336 = stablehlo.broadcast_in_dim %3334, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %3337 = stablehlo.broadcast_in_dim %3335, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %3338 = stablehlo.add %3336, %3337 : tensor<1x320x15x20xbf16>
    %3339 = stablehlo.reshape %3338 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %3340 = stablehlo.transpose %3339, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %3341 = stablehlo.convert %3340 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %3342 = stablehlo.convert %3341 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %3343 = stablehlo.reduce(%3342 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3344 = stablehlo.reshape %3343 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3345 = stablehlo.broadcast_in_dim %3344, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3346 = stablehlo.divide %3345, %3088 : tensor<1x300x1xf64>
    %3347 = stablehlo.broadcast_in_dim %3342, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %3348 = stablehlo.broadcast_in_dim %3346, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %3349 = stablehlo.subtract %3347, %3348 : tensor<1x300x320xf64>
    %3350 = stablehlo.multiply %3349, %3349 : tensor<1x300x320xf64>
    %3351 = stablehlo.reduce(%3350 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3352 = stablehlo.reshape %3351 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3353 = stablehlo.broadcast_in_dim %3352, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3354 = stablehlo.divide %3353, %3088 : tensor<1x300x1xf64>
    %3355 = stablehlo.convert %3354 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %3356 = stablehlo.reduce(%3341 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %3357 = stablehlo.reshape %3356 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %3358 = stablehlo.broadcast_in_dim %3357, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3359 = stablehlo.divide %3358, %3102 : tensor<1x300x1xf32>
    %3360 = stablehlo.broadcast_in_dim %3355, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3361 = stablehlo.add %3360, %136 : tensor<1x300x1xf32>
    %3362 = stablehlo.rsqrt %3361 : tensor<1x300x1xf32>
    %3363 = stablehlo.broadcast_in_dim %3341, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3364 = stablehlo.broadcast_in_dim %3359, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3365 = stablehlo.subtract %3363, %3364 : tensor<1x300x320xf32>
    %3366 = stablehlo.broadcast_in_dim %3365, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3367 = stablehlo.broadcast_in_dim %3362, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3368 = stablehlo.multiply %3366, %3367 : tensor<1x300x320xf32>
    %3369 = stablehlo.convert %arg153 : (tensor<320xbf16>) -> tensor<320xf32>
    %3370 = stablehlo.broadcast_in_dim %3368, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3371 = stablehlo.broadcast_in_dim %3369, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3372 = stablehlo.multiply %3370, %3371 : tensor<1x300x320xf32>
    %3373 = stablehlo.convert %arg154 : (tensor<320xbf16>) -> tensor<320xf32>
    %3374 = stablehlo.broadcast_in_dim %3372, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3375 = stablehlo.broadcast_in_dim %3373, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3376 = stablehlo.add %3374, %3375 : tensor<1x300x320xf32>
    %3377 = stablehlo.convert %3376 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %3378 = stablehlo.reshape %3377 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %3379 = stablehlo.convert %3378 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %3380 = stablehlo.dot_general %3379, %arg626, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3381 = stablehlo.broadcast_in_dim %3380, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3382 = stablehlo.multiply %3381, %3126 : tensor<300x320xf32>
    %3383 = stablehlo.broadcast_in_dim %3382, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3384 = stablehlo.broadcast_in_dim %arg627, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3385 = stablehlo.add %3383, %3384 : tensor<300x320xf32>
    %3386 = stablehlo.convert %3385 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3387 = stablehlo.reshape %3386 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3388 = stablehlo.reshape %3387 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3389 = stablehlo.transpose %3388, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3390 = stablehlo.dot_general %3379, %arg628, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3391 = stablehlo.broadcast_in_dim %3390, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3392 = stablehlo.multiply %3391, %3126 : tensor<300x320xf32>
    %3393 = stablehlo.broadcast_in_dim %3392, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3394 = stablehlo.broadcast_in_dim %arg629, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3395 = stablehlo.add %3393, %3394 : tensor<300x320xf32>
    %3396 = stablehlo.convert %3395 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3397 = stablehlo.reshape %3396 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3398 = stablehlo.reshape %3397 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3399 = stablehlo.transpose %3398, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3400 = stablehlo.transpose %3389, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %3401 = stablehlo.reshape %3331 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %3402 = stablehlo.reshape %3400 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3403 = stablehlo.broadcast_in_dim %3402, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3404 = stablehlo.dot_general %3401, %3403, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %3405 = stablehlo.reshape %3404 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3406 = stablehlo.broadcast_in_dim %3405, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3407 = stablehlo.divide %3406, %3152 : tensor<1x5x1200x300xbf16>
    %3408 = stablehlo.convert %3407 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %3409 = stablehlo.reduce(%3408 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3410 = stablehlo.reshape %3409 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3411 = stablehlo.broadcast_in_dim %3408, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3412 = stablehlo.broadcast_in_dim %3410, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3413 = stablehlo.subtract %3411, %3412 : tensor<1x5x1200x300xf32>
    %3414 = stablehlo.exponential %3413 : tensor<1x5x1200x300xf32>
    %3415 = stablehlo.reduce(%3414 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3416 = stablehlo.reshape %3415 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3417 = stablehlo.broadcast_in_dim %3414, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3418 = stablehlo.broadcast_in_dim %3416, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3419 = stablehlo.divide %3417, %3418 : tensor<1x5x1200x300xf32>
    %3420 = stablehlo.convert %3419 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %3421 = stablehlo.reshape %3420 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %3422 = stablehlo.reshape %3399 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3423 = stablehlo.broadcast_in_dim %3422, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3424 = stablehlo.dot_general %3421, %3423, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %3425 = stablehlo.reshape %3424 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3426 = stablehlo.transpose %3425, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %3427 = stablehlo.reshape %3426 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %3428 = stablehlo.reshape %3427 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3429 = stablehlo.convert %3428 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3430 = stablehlo.dot_general %3429, %arg630, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3431 = stablehlo.broadcast_in_dim %3430, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3432 = stablehlo.multiply %3431, %3065 : tensor<1200x320xf32>
    %3433 = stablehlo.broadcast_in_dim %3432, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3434 = stablehlo.broadcast_in_dim %arg631, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3435 = stablehlo.add %3433, %3434 : tensor<1200x320xf32>
    %3436 = stablehlo.convert %3435 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3437 = stablehlo.reshape %3436 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3438 = stablehlo.add %3437, %3282 : tensor<1x1200x320xbf16>
    %3439 = stablehlo.convert %3438 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3440 = stablehlo.convert %3439 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3441 = stablehlo.reduce(%3440 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3442 = stablehlo.reshape %3441 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3443 = stablehlo.broadcast_in_dim %3442, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3444 = stablehlo.divide %3443, %2987 : tensor<1x1200x1xf64>
    %3445 = stablehlo.broadcast_in_dim %3440, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3446 = stablehlo.broadcast_in_dim %3444, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3447 = stablehlo.subtract %3445, %3446 : tensor<1x1200x320xf64>
    %3448 = stablehlo.multiply %3447, %3447 : tensor<1x1200x320xf64>
    %3449 = stablehlo.reduce(%3448 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3450 = stablehlo.reshape %3449 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3451 = stablehlo.broadcast_in_dim %3450, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3452 = stablehlo.divide %3451, %2987 : tensor<1x1200x1xf64>
    %3453 = stablehlo.convert %3452 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3454 = stablehlo.reduce(%3439 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3455 = stablehlo.reshape %3454 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3456 = stablehlo.broadcast_in_dim %3455, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3457 = stablehlo.divide %3456, %3003 : tensor<1x1200x1xf32>
    %3458 = stablehlo.broadcast_in_dim %3453, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3459 = stablehlo.add %3458, %3006 : tensor<1x1200x1xf32>
    %3460 = stablehlo.rsqrt %3459 : tensor<1x1200x1xf32>
    %3461 = stablehlo.broadcast_in_dim %3439, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3462 = stablehlo.broadcast_in_dim %3457, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3463 = stablehlo.subtract %3461, %3462 : tensor<1x1200x320xf32>
    %3464 = stablehlo.broadcast_in_dim %3463, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3465 = stablehlo.broadcast_in_dim %3460, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3466 = stablehlo.multiply %3464, %3465 : tensor<1x1200x320xf32>
    %3467 = stablehlo.convert %arg155 : (tensor<320xbf16>) -> tensor<320xf32>
    %3468 = stablehlo.broadcast_in_dim %3466, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3469 = stablehlo.broadcast_in_dim %3467, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3470 = stablehlo.multiply %3468, %3469 : tensor<1x1200x320xf32>
    %3471 = stablehlo.convert %arg156 : (tensor<320xbf16>) -> tensor<320xf32>
    %3472 = stablehlo.broadcast_in_dim %3470, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3473 = stablehlo.broadcast_in_dim %3471, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3474 = stablehlo.add %3472, %3473 : tensor<1x1200x320xf32>
    %3475 = stablehlo.convert %3474 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3476 = stablehlo.reshape %3475 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3477 = stablehlo.convert %3476 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3478 = stablehlo.dot_general %3477, %arg632, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %3479 = stablehlo.broadcast_in_dim %3478, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3480 = stablehlo.multiply %3479, %3226 : tensor<1200x1280xf32>
    %3481 = stablehlo.broadcast_in_dim %3480, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3482 = stablehlo.broadcast_in_dim %arg633, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %3483 = stablehlo.add %3481, %3482 : tensor<1200x1280xf32>
    %3484 = stablehlo.convert %3483 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %3485 = stablehlo.reshape %3484 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %3486 = stablehlo.transpose %3485, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %3487 = stablehlo.reshape %3486 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %3488 = stablehlo.convolution(%3487, %arg157) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %3489 = stablehlo.reshape %arg158 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %3490 = stablehlo.broadcast_in_dim %3488, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %3491 = stablehlo.broadcast_in_dim %3489, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %3492 = stablehlo.add %3490, %3491 : tensor<1x1280x30x40xbf16>
    %3493 = stablehlo.reshape %3492 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %3494 = stablehlo.transpose %3493, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %3495 = stablehlo.multiply %3494, %cst_42 : tensor<1x1200x1280xbf16>
    %3496 = stablehlo.multiply %3494, %3243 : tensor<1x1200x1280xbf16>
    %3497 = stablehlo.convert %3496 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %3498 = stablehlo.clamp %cst_43, %3497, %cst_44 : tensor<1x1200x1280xf32>
    %3499 = stablehlo.multiply %3498, %3498 : tensor<1x1200x1280xf32>
    %3500 = stablehlo.multiply %cst_45, %3499 : tensor<1x1200x1280xf32>
    %3501 = stablehlo.add %3500, %cst_46 : tensor<1x1200x1280xf32>
    %3502 = stablehlo.multiply %3501, %3499 : tensor<1x1200x1280xf32>
    %3503 = stablehlo.add %3502, %cst_47 : tensor<1x1200x1280xf32>
    %3504 = stablehlo.multiply %3503, %3499 : tensor<1x1200x1280xf32>
    %3505 = stablehlo.add %3504, %cst_48 : tensor<1x1200x1280xf32>
    %3506 = stablehlo.multiply %3505, %3499 : tensor<1x1200x1280xf32>
    %3507 = stablehlo.add %3506, %cst_49 : tensor<1x1200x1280xf32>
    %3508 = stablehlo.multiply %3507, %3499 : tensor<1x1200x1280xf32>
    %3509 = stablehlo.add %3508, %cst_50 : tensor<1x1200x1280xf32>
    %3510 = stablehlo.multiply %3509, %3499 : tensor<1x1200x1280xf32>
    %3511 = stablehlo.add %3510, %cst_51 : tensor<1x1200x1280xf32>
    %3512 = stablehlo.multiply %cst_52, %3499 : tensor<1x1200x1280xf32>
    %3513 = stablehlo.add %3512, %cst_53 : tensor<1x1200x1280xf32>
    %3514 = stablehlo.multiply %3513, %3499 : tensor<1x1200x1280xf32>
    %3515 = stablehlo.add %3514, %cst_54 : tensor<1x1200x1280xf32>
    %3516 = stablehlo.multiply %3515, %3499 : tensor<1x1200x1280xf32>
    %3517 = stablehlo.add %3516, %cst_55 : tensor<1x1200x1280xf32>
    %3518 = stablehlo.multiply %3517, %3499 : tensor<1x1200x1280xf32>
    %3519 = stablehlo.add %3518, %cst_56 : tensor<1x1200x1280xf32>
    %3520 = stablehlo.multiply %3498, %3511 : tensor<1x1200x1280xf32>
    %3521 = stablehlo.divide %3520, %3519 : tensor<1x1200x1280xf32>
    %3522 = stablehlo.clamp %cst_57, %3521, %cst_58 : tensor<1x1200x1280xf32>
    %3523 = stablehlo.convert %3522 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %3524 = stablehlo.add %3523, %cst_40 : tensor<1x1200x1280xbf16>
    %3525 = stablehlo.multiply %3524, %3495 : tensor<1x1200x1280xbf16>
    %3526 = stablehlo.reshape %3525 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %3527 = stablehlo.dot_general %3526, %arg634, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %3528 = stablehlo.reshape %3527 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3529 = stablehlo.broadcast_in_dim %3528, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3530 = stablehlo.broadcast_in_dim %arg159, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %3531 = stablehlo.add %3529, %3530 : tensor<1x1200x320xbf16>
    %3532 = stablehlo.reshape %3531 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3533 = stablehlo.reshape %3532 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3534 = stablehlo.add %3533, %3438 : tensor<1x1200x320xbf16>
    %3535 = stablehlo.convert %3534 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3536 = stablehlo.convert %3535 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3537 = stablehlo.reduce(%3536 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3538 = stablehlo.reshape %3537 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3539 = stablehlo.broadcast_in_dim %3538, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3540 = stablehlo.divide %3539, %2987 : tensor<1x1200x1xf64>
    %3541 = stablehlo.broadcast_in_dim %3536, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3542 = stablehlo.broadcast_in_dim %3540, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3543 = stablehlo.subtract %3541, %3542 : tensor<1x1200x320xf64>
    %3544 = stablehlo.multiply %3543, %3543 : tensor<1x1200x320xf64>
    %3545 = stablehlo.reduce(%3544 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3546 = stablehlo.reshape %3545 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3547 = stablehlo.broadcast_in_dim %3546, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3548 = stablehlo.divide %3547, %2987 : tensor<1x1200x1xf64>
    %3549 = stablehlo.convert %3548 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3550 = stablehlo.reduce(%3535 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3551 = stablehlo.reshape %3550 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3552 = stablehlo.broadcast_in_dim %3551, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3553 = stablehlo.divide %3552, %3003 : tensor<1x1200x1xf32>
    %3554 = stablehlo.broadcast_in_dim %3549, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3555 = stablehlo.add %3554, %3006 : tensor<1x1200x1xf32>
    %3556 = stablehlo.rsqrt %3555 : tensor<1x1200x1xf32>
    %3557 = stablehlo.broadcast_in_dim %3535, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3558 = stablehlo.broadcast_in_dim %3553, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3559 = stablehlo.subtract %3557, %3558 : tensor<1x1200x320xf32>
    %3560 = stablehlo.broadcast_in_dim %3559, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3561 = stablehlo.broadcast_in_dim %3556, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3562 = stablehlo.multiply %3560, %3561 : tensor<1x1200x320xf32>
    %3563 = stablehlo.convert %arg160 : (tensor<320xbf16>) -> tensor<320xf32>
    %3564 = stablehlo.broadcast_in_dim %3562, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3565 = stablehlo.broadcast_in_dim %3563, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3566 = stablehlo.multiply %3564, %3565 : tensor<1x1200x320xf32>
    %3567 = stablehlo.convert %arg161 : (tensor<320xbf16>) -> tensor<320xf32>
    %3568 = stablehlo.broadcast_in_dim %3566, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3569 = stablehlo.broadcast_in_dim %3567, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3570 = stablehlo.add %3568, %3569 : tensor<1x1200x320xf32>
    %3571 = stablehlo.convert %3570 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3572 = stablehlo.reshape %3571 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3573 = stablehlo.convert %3572 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3574 = stablehlo.dot_general %3573, %arg635, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3575 = stablehlo.broadcast_in_dim %3574, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3576 = stablehlo.multiply %3575, %3065 : tensor<1200x320xf32>
    %3577 = stablehlo.broadcast_in_dim %3576, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3578 = stablehlo.broadcast_in_dim %arg636, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3579 = stablehlo.add %3577, %3578 : tensor<1200x320xf32>
    %3580 = stablehlo.convert %3579 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3581 = stablehlo.reshape %3580 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3582 = stablehlo.reshape %3581 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %3583 = stablehlo.transpose %3582, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3584 = stablehlo.transpose %3571, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %3585 = stablehlo.reshape %3584 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %3586 = stablehlo.convolution(%3585, %arg162) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %3587 = stablehlo.reshape %arg163 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %3588 = stablehlo.broadcast_in_dim %3586, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %3589 = stablehlo.broadcast_in_dim %3587, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %3590 = stablehlo.add %3588, %3589 : tensor<1x320x15x20xbf16>
    %3591 = stablehlo.reshape %3590 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %3592 = stablehlo.transpose %3591, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %3593 = stablehlo.convert %3592 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %3594 = stablehlo.convert %3593 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %3595 = stablehlo.reduce(%3594 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3596 = stablehlo.reshape %3595 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3597 = stablehlo.broadcast_in_dim %3596, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3598 = stablehlo.divide %3597, %3088 : tensor<1x300x1xf64>
    %3599 = stablehlo.broadcast_in_dim %3594, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %3600 = stablehlo.broadcast_in_dim %3598, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %3601 = stablehlo.subtract %3599, %3600 : tensor<1x300x320xf64>
    %3602 = stablehlo.multiply %3601, %3601 : tensor<1x300x320xf64>
    %3603 = stablehlo.reduce(%3602 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3604 = stablehlo.reshape %3603 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3605 = stablehlo.broadcast_in_dim %3604, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3606 = stablehlo.divide %3605, %3088 : tensor<1x300x1xf64>
    %3607 = stablehlo.convert %3606 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %3608 = stablehlo.reduce(%3593 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %3609 = stablehlo.reshape %3608 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %3610 = stablehlo.broadcast_in_dim %3609, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3611 = stablehlo.divide %3610, %3102 : tensor<1x300x1xf32>
    %3612 = stablehlo.broadcast_in_dim %3607, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3613 = stablehlo.add %3612, %136 : tensor<1x300x1xf32>
    %3614 = stablehlo.rsqrt %3613 : tensor<1x300x1xf32>
    %3615 = stablehlo.broadcast_in_dim %3593, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3616 = stablehlo.broadcast_in_dim %3611, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3617 = stablehlo.subtract %3615, %3616 : tensor<1x300x320xf32>
    %3618 = stablehlo.broadcast_in_dim %3617, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3619 = stablehlo.broadcast_in_dim %3614, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3620 = stablehlo.multiply %3618, %3619 : tensor<1x300x320xf32>
    %3621 = stablehlo.convert %arg164 : (tensor<320xbf16>) -> tensor<320xf32>
    %3622 = stablehlo.broadcast_in_dim %3620, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3623 = stablehlo.broadcast_in_dim %3621, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3624 = stablehlo.multiply %3622, %3623 : tensor<1x300x320xf32>
    %3625 = stablehlo.convert %arg165 : (tensor<320xbf16>) -> tensor<320xf32>
    %3626 = stablehlo.broadcast_in_dim %3624, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3627 = stablehlo.broadcast_in_dim %3625, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3628 = stablehlo.add %3626, %3627 : tensor<1x300x320xf32>
    %3629 = stablehlo.convert %3628 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %3630 = stablehlo.reshape %3629 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %3631 = stablehlo.convert %3630 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %3632 = stablehlo.dot_general %3631, %arg637, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3633 = stablehlo.broadcast_in_dim %3632, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3634 = stablehlo.multiply %3633, %3126 : tensor<300x320xf32>
    %3635 = stablehlo.broadcast_in_dim %3634, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3636 = stablehlo.broadcast_in_dim %arg638, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3637 = stablehlo.add %3635, %3636 : tensor<300x320xf32>
    %3638 = stablehlo.convert %3637 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3639 = stablehlo.reshape %3638 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3640 = stablehlo.reshape %3639 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3641 = stablehlo.transpose %3640, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3642 = stablehlo.dot_general %3631, %arg639, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3643 = stablehlo.broadcast_in_dim %3642, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3644 = stablehlo.multiply %3643, %3126 : tensor<300x320xf32>
    %3645 = stablehlo.broadcast_in_dim %3644, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3646 = stablehlo.broadcast_in_dim %arg640, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3647 = stablehlo.add %3645, %3646 : tensor<300x320xf32>
    %3648 = stablehlo.convert %3647 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3649 = stablehlo.reshape %3648 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3650 = stablehlo.reshape %3649 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3651 = stablehlo.transpose %3650, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3652 = stablehlo.transpose %3641, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %3653 = stablehlo.reshape %3583 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %3654 = stablehlo.reshape %3652 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3655 = stablehlo.broadcast_in_dim %3654, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3656 = stablehlo.dot_general %3653, %3655, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %3657 = stablehlo.reshape %3656 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3658 = stablehlo.broadcast_in_dim %3657, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3659 = stablehlo.divide %3658, %3152 : tensor<1x5x1200x300xbf16>
    %3660 = stablehlo.convert %3659 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %3661 = stablehlo.reduce(%3660 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3662 = stablehlo.reshape %3661 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3663 = stablehlo.broadcast_in_dim %3660, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3664 = stablehlo.broadcast_in_dim %3662, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3665 = stablehlo.subtract %3663, %3664 : tensor<1x5x1200x300xf32>
    %3666 = stablehlo.exponential %3665 : tensor<1x5x1200x300xf32>
    %3667 = stablehlo.reduce(%3666 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3668 = stablehlo.reshape %3667 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3669 = stablehlo.broadcast_in_dim %3666, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3670 = stablehlo.broadcast_in_dim %3668, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3671 = stablehlo.divide %3669, %3670 : tensor<1x5x1200x300xf32>
    %3672 = stablehlo.convert %3671 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %3673 = stablehlo.reshape %3672 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %3674 = stablehlo.reshape %3651 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3675 = stablehlo.broadcast_in_dim %3674, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3676 = stablehlo.dot_general %3673, %3675, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %3677 = stablehlo.reshape %3676 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3678 = stablehlo.transpose %3677, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %3679 = stablehlo.reshape %3678 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %3680 = stablehlo.reshape %3679 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3681 = stablehlo.convert %3680 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3682 = stablehlo.dot_general %3681, %arg641, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3683 = stablehlo.broadcast_in_dim %3682, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3684 = stablehlo.multiply %3683, %3065 : tensor<1200x320xf32>
    %3685 = stablehlo.broadcast_in_dim %3684, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3686 = stablehlo.broadcast_in_dim %arg642, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3687 = stablehlo.add %3685, %3686 : tensor<1200x320xf32>
    %3688 = stablehlo.convert %3687 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3689 = stablehlo.reshape %3688 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3690 = stablehlo.add %3689, %3534 : tensor<1x1200x320xbf16>
    %3691 = stablehlo.convert %3690 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3692 = stablehlo.convert %3691 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3693 = stablehlo.reduce(%3692 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3694 = stablehlo.reshape %3693 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3695 = stablehlo.broadcast_in_dim %3694, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3696 = stablehlo.divide %3695, %2987 : tensor<1x1200x1xf64>
    %3697 = stablehlo.broadcast_in_dim %3692, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3698 = stablehlo.broadcast_in_dim %3696, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3699 = stablehlo.subtract %3697, %3698 : tensor<1x1200x320xf64>
    %3700 = stablehlo.multiply %3699, %3699 : tensor<1x1200x320xf64>
    %3701 = stablehlo.reduce(%3700 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3702 = stablehlo.reshape %3701 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3703 = stablehlo.broadcast_in_dim %3702, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3704 = stablehlo.divide %3703, %2987 : tensor<1x1200x1xf64>
    %3705 = stablehlo.convert %3704 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3706 = stablehlo.reduce(%3691 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3707 = stablehlo.reshape %3706 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3708 = stablehlo.broadcast_in_dim %3707, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3709 = stablehlo.divide %3708, %3003 : tensor<1x1200x1xf32>
    %3710 = stablehlo.broadcast_in_dim %3705, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3711 = stablehlo.add %3710, %3006 : tensor<1x1200x1xf32>
    %3712 = stablehlo.rsqrt %3711 : tensor<1x1200x1xf32>
    %3713 = stablehlo.broadcast_in_dim %3691, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3714 = stablehlo.broadcast_in_dim %3709, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3715 = stablehlo.subtract %3713, %3714 : tensor<1x1200x320xf32>
    %3716 = stablehlo.broadcast_in_dim %3715, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3717 = stablehlo.broadcast_in_dim %3712, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3718 = stablehlo.multiply %3716, %3717 : tensor<1x1200x320xf32>
    %3719 = stablehlo.convert %arg166 : (tensor<320xbf16>) -> tensor<320xf32>
    %3720 = stablehlo.broadcast_in_dim %3718, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3721 = stablehlo.broadcast_in_dim %3719, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3722 = stablehlo.multiply %3720, %3721 : tensor<1x1200x320xf32>
    %3723 = stablehlo.convert %arg167 : (tensor<320xbf16>) -> tensor<320xf32>
    %3724 = stablehlo.broadcast_in_dim %3722, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3725 = stablehlo.broadcast_in_dim %3723, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3726 = stablehlo.add %3724, %3725 : tensor<1x1200x320xf32>
    %3727 = stablehlo.convert %3726 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3728 = stablehlo.reshape %3727 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3729 = stablehlo.convert %3728 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3730 = stablehlo.dot_general %3729, %arg643, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %3731 = stablehlo.broadcast_in_dim %3730, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3732 = stablehlo.multiply %3731, %3226 : tensor<1200x1280xf32>
    %3733 = stablehlo.broadcast_in_dim %3732, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3734 = stablehlo.broadcast_in_dim %arg644, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %3735 = stablehlo.add %3733, %3734 : tensor<1200x1280xf32>
    %3736 = stablehlo.convert %3735 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %3737 = stablehlo.reshape %3736 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %3738 = stablehlo.transpose %3737, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %3739 = stablehlo.reshape %3738 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %3740 = stablehlo.convolution(%3739, %arg168) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %3741 = stablehlo.reshape %arg169 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %3742 = stablehlo.broadcast_in_dim %3740, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %3743 = stablehlo.broadcast_in_dim %3741, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %3744 = stablehlo.add %3742, %3743 : tensor<1x1280x30x40xbf16>
    %3745 = stablehlo.reshape %3744 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %3746 = stablehlo.transpose %3745, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %3747 = stablehlo.multiply %3746, %cst_42 : tensor<1x1200x1280xbf16>
    %3748 = stablehlo.multiply %3746, %3243 : tensor<1x1200x1280xbf16>
    %3749 = stablehlo.convert %3748 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %3750 = stablehlo.clamp %cst_43, %3749, %cst_44 : tensor<1x1200x1280xf32>
    %3751 = stablehlo.multiply %3750, %3750 : tensor<1x1200x1280xf32>
    %3752 = stablehlo.multiply %cst_45, %3751 : tensor<1x1200x1280xf32>
    %3753 = stablehlo.add %3752, %cst_46 : tensor<1x1200x1280xf32>
    %3754 = stablehlo.multiply %3753, %3751 : tensor<1x1200x1280xf32>
    %3755 = stablehlo.add %3754, %cst_47 : tensor<1x1200x1280xf32>
    %3756 = stablehlo.multiply %3755, %3751 : tensor<1x1200x1280xf32>
    %3757 = stablehlo.add %3756, %cst_48 : tensor<1x1200x1280xf32>
    %3758 = stablehlo.multiply %3757, %3751 : tensor<1x1200x1280xf32>
    %3759 = stablehlo.add %3758, %cst_49 : tensor<1x1200x1280xf32>
    %3760 = stablehlo.multiply %3759, %3751 : tensor<1x1200x1280xf32>
    %3761 = stablehlo.add %3760, %cst_50 : tensor<1x1200x1280xf32>
    %3762 = stablehlo.multiply %3761, %3751 : tensor<1x1200x1280xf32>
    %3763 = stablehlo.add %3762, %cst_51 : tensor<1x1200x1280xf32>
    %3764 = stablehlo.multiply %cst_52, %3751 : tensor<1x1200x1280xf32>
    %3765 = stablehlo.add %3764, %cst_53 : tensor<1x1200x1280xf32>
    %3766 = stablehlo.multiply %3765, %3751 : tensor<1x1200x1280xf32>
    %3767 = stablehlo.add %3766, %cst_54 : tensor<1x1200x1280xf32>
    %3768 = stablehlo.multiply %3767, %3751 : tensor<1x1200x1280xf32>
    %3769 = stablehlo.add %3768, %cst_55 : tensor<1x1200x1280xf32>
    %3770 = stablehlo.multiply %3769, %3751 : tensor<1x1200x1280xf32>
    %3771 = stablehlo.add %3770, %cst_56 : tensor<1x1200x1280xf32>
    %3772 = stablehlo.multiply %3750, %3763 : tensor<1x1200x1280xf32>
    %3773 = stablehlo.divide %3772, %3771 : tensor<1x1200x1280xf32>
    %3774 = stablehlo.clamp %cst_57, %3773, %cst_58 : tensor<1x1200x1280xf32>
    %3775 = stablehlo.convert %3774 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %3776 = stablehlo.add %3775, %cst_40 : tensor<1x1200x1280xbf16>
    %3777 = stablehlo.multiply %3776, %3747 : tensor<1x1200x1280xbf16>
    %3778 = stablehlo.reshape %3777 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %3779 = stablehlo.dot_general %3778, %arg645, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %3780 = stablehlo.reshape %3779 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3781 = stablehlo.broadcast_in_dim %3780, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3782 = stablehlo.broadcast_in_dim %arg170, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %3783 = stablehlo.add %3781, %3782 : tensor<1x1200x320xbf16>
    %3784 = stablehlo.reshape %3783 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3785 = stablehlo.reshape %3784 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3786 = stablehlo.add %3785, %3690 : tensor<1x1200x320xbf16>
    %3787 = stablehlo.convert %3786 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3788 = stablehlo.convert %3787 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3789 = stablehlo.reduce(%3788 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3790 = stablehlo.reshape %3789 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3791 = stablehlo.broadcast_in_dim %3790, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3792 = stablehlo.divide %3791, %2987 : tensor<1x1200x1xf64>
    %3793 = stablehlo.broadcast_in_dim %3788, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3794 = stablehlo.broadcast_in_dim %3792, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3795 = stablehlo.subtract %3793, %3794 : tensor<1x1200x320xf64>
    %3796 = stablehlo.multiply %3795, %3795 : tensor<1x1200x320xf64>
    %3797 = stablehlo.reduce(%3796 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3798 = stablehlo.reshape %3797 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3799 = stablehlo.broadcast_in_dim %3798, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3800 = stablehlo.divide %3799, %2987 : tensor<1x1200x1xf64>
    %3801 = stablehlo.convert %3800 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3802 = stablehlo.reduce(%3787 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3803 = stablehlo.reshape %3802 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3804 = stablehlo.broadcast_in_dim %3803, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3805 = stablehlo.divide %3804, %3003 : tensor<1x1200x1xf32>
    %3806 = stablehlo.broadcast_in_dim %3801, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3807 = stablehlo.add %3806, %3006 : tensor<1x1200x1xf32>
    %3808 = stablehlo.rsqrt %3807 : tensor<1x1200x1xf32>
    %3809 = stablehlo.broadcast_in_dim %3787, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3810 = stablehlo.broadcast_in_dim %3805, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3811 = stablehlo.subtract %3809, %3810 : tensor<1x1200x320xf32>
    %3812 = stablehlo.broadcast_in_dim %3811, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3813 = stablehlo.broadcast_in_dim %3808, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3814 = stablehlo.multiply %3812, %3813 : tensor<1x1200x320xf32>
    %3815 = stablehlo.convert %arg171 : (tensor<320xbf16>) -> tensor<320xf32>
    %3816 = stablehlo.broadcast_in_dim %3814, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3817 = stablehlo.broadcast_in_dim %3815, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3818 = stablehlo.multiply %3816, %3817 : tensor<1x1200x320xf32>
    %3819 = stablehlo.convert %arg172 : (tensor<320xbf16>) -> tensor<320xf32>
    %3820 = stablehlo.broadcast_in_dim %3818, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3821 = stablehlo.broadcast_in_dim %3819, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3822 = stablehlo.add %3820, %3821 : tensor<1x1200x320xf32>
    %3823 = stablehlo.convert %3822 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3824 = stablehlo.reshape %3823 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3825 = stablehlo.convert %3824 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3826 = stablehlo.dot_general %3825, %arg646, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3827 = stablehlo.broadcast_in_dim %3826, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3828 = stablehlo.multiply %3827, %3065 : tensor<1200x320xf32>
    %3829 = stablehlo.broadcast_in_dim %3828, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3830 = stablehlo.broadcast_in_dim %arg647, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3831 = stablehlo.add %3829, %3830 : tensor<1200x320xf32>
    %3832 = stablehlo.convert %3831 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3833 = stablehlo.reshape %3832 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3834 = stablehlo.reshape %3833 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %3835 = stablehlo.transpose %3834, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3836 = stablehlo.transpose %3823, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %3837 = stablehlo.reshape %3836 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %3838 = stablehlo.convolution(%3837, %arg173) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %3839 = stablehlo.reshape %arg174 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %3840 = stablehlo.broadcast_in_dim %3838, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %3841 = stablehlo.broadcast_in_dim %3839, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %3842 = stablehlo.add %3840, %3841 : tensor<1x320x15x20xbf16>
    %3843 = stablehlo.reshape %3842 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %3844 = stablehlo.transpose %3843, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %3845 = stablehlo.convert %3844 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %3846 = stablehlo.convert %3845 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %3847 = stablehlo.reduce(%3846 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3848 = stablehlo.reshape %3847 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3849 = stablehlo.broadcast_in_dim %3848, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3850 = stablehlo.divide %3849, %3088 : tensor<1x300x1xf64>
    %3851 = stablehlo.broadcast_in_dim %3846, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %3852 = stablehlo.broadcast_in_dim %3850, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %3853 = stablehlo.subtract %3851, %3852 : tensor<1x300x320xf64>
    %3854 = stablehlo.multiply %3853, %3853 : tensor<1x300x320xf64>
    %3855 = stablehlo.reduce(%3854 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %3856 = stablehlo.reshape %3855 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %3857 = stablehlo.broadcast_in_dim %3856, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %3858 = stablehlo.divide %3857, %3088 : tensor<1x300x1xf64>
    %3859 = stablehlo.convert %3858 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %3860 = stablehlo.reduce(%3845 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %3861 = stablehlo.reshape %3860 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %3862 = stablehlo.broadcast_in_dim %3861, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3863 = stablehlo.divide %3862, %3102 : tensor<1x300x1xf32>
    %3864 = stablehlo.broadcast_in_dim %3859, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %3865 = stablehlo.add %3864, %136 : tensor<1x300x1xf32>
    %3866 = stablehlo.rsqrt %3865 : tensor<1x300x1xf32>
    %3867 = stablehlo.broadcast_in_dim %3845, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3868 = stablehlo.broadcast_in_dim %3863, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3869 = stablehlo.subtract %3867, %3868 : tensor<1x300x320xf32>
    %3870 = stablehlo.broadcast_in_dim %3869, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3871 = stablehlo.broadcast_in_dim %3866, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %3872 = stablehlo.multiply %3870, %3871 : tensor<1x300x320xf32>
    %3873 = stablehlo.convert %arg175 : (tensor<320xbf16>) -> tensor<320xf32>
    %3874 = stablehlo.broadcast_in_dim %3872, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3875 = stablehlo.broadcast_in_dim %3873, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3876 = stablehlo.multiply %3874, %3875 : tensor<1x300x320xf32>
    %3877 = stablehlo.convert %arg176 : (tensor<320xbf16>) -> tensor<320xf32>
    %3878 = stablehlo.broadcast_in_dim %3876, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %3879 = stablehlo.broadcast_in_dim %3877, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %3880 = stablehlo.add %3878, %3879 : tensor<1x300x320xf32>
    %3881 = stablehlo.convert %3880 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %3882 = stablehlo.reshape %3881 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %3883 = stablehlo.convert %3882 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %3884 = stablehlo.dot_general %3883, %arg648, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3885 = stablehlo.broadcast_in_dim %3884, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3886 = stablehlo.multiply %3885, %3126 : tensor<300x320xf32>
    %3887 = stablehlo.broadcast_in_dim %3886, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3888 = stablehlo.broadcast_in_dim %arg649, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3889 = stablehlo.add %3887, %3888 : tensor<300x320xf32>
    %3890 = stablehlo.convert %3889 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3891 = stablehlo.reshape %3890 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3892 = stablehlo.reshape %3891 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3893 = stablehlo.transpose %3892, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3894 = stablehlo.dot_general %3883, %arg650, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %3895 = stablehlo.broadcast_in_dim %3894, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3896 = stablehlo.multiply %3895, %3126 : tensor<300x320xf32>
    %3897 = stablehlo.broadcast_in_dim %3896, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %3898 = stablehlo.broadcast_in_dim %arg651, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %3899 = stablehlo.add %3897, %3898 : tensor<300x320xf32>
    %3900 = stablehlo.convert %3899 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %3901 = stablehlo.reshape %3900 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %3902 = stablehlo.reshape %3901 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %3903 = stablehlo.transpose %3902, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %3904 = stablehlo.transpose %3893, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %3905 = stablehlo.reshape %3835 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %3906 = stablehlo.reshape %3904 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3907 = stablehlo.broadcast_in_dim %3906, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %3908 = stablehlo.dot_general %3905, %3907, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %3909 = stablehlo.reshape %3908 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3910 = stablehlo.broadcast_in_dim %3909, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %3911 = stablehlo.divide %3910, %3152 : tensor<1x5x1200x300xbf16>
    %3912 = stablehlo.convert %3911 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %3913 = stablehlo.reduce(%3912 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3914 = stablehlo.reshape %3913 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3915 = stablehlo.broadcast_in_dim %3912, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3916 = stablehlo.broadcast_in_dim %3914, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3917 = stablehlo.subtract %3915, %3916 : tensor<1x5x1200x300xf32>
    %3918 = stablehlo.exponential %3917 : tensor<1x5x1200x300xf32>
    %3919 = stablehlo.reduce(%3918 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %3920 = stablehlo.reshape %3919 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %3921 = stablehlo.broadcast_in_dim %3918, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %3922 = stablehlo.broadcast_in_dim %3920, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %3923 = stablehlo.divide %3921, %3922 : tensor<1x5x1200x300xf32>
    %3924 = stablehlo.convert %3923 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %3925 = stablehlo.reshape %3924 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %3926 = stablehlo.reshape %3903 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3927 = stablehlo.broadcast_in_dim %3926, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %3928 = stablehlo.dot_general %3925, %3927, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %3929 = stablehlo.reshape %3928 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %3930 = stablehlo.transpose %3929, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %3931 = stablehlo.reshape %3930 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %3932 = stablehlo.reshape %3931 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3933 = stablehlo.convert %3932 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3934 = stablehlo.dot_general %3933, %arg652, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %3935 = stablehlo.broadcast_in_dim %3934, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3936 = stablehlo.multiply %3935, %3065 : tensor<1200x320xf32>
    %3937 = stablehlo.broadcast_in_dim %3936, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %3938 = stablehlo.broadcast_in_dim %arg653, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %3939 = stablehlo.add %3937, %3938 : tensor<1200x320xf32>
    %3940 = stablehlo.convert %3939 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %3941 = stablehlo.reshape %3940 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %3942 = stablehlo.add %3941, %3786 : tensor<1x1200x320xbf16>
    %3943 = stablehlo.convert %3942 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %3944 = stablehlo.convert %3943 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %3945 = stablehlo.reduce(%3944 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3946 = stablehlo.reshape %3945 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3947 = stablehlo.broadcast_in_dim %3946, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3948 = stablehlo.divide %3947, %2987 : tensor<1x1200x1xf64>
    %3949 = stablehlo.broadcast_in_dim %3944, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %3950 = stablehlo.broadcast_in_dim %3948, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %3951 = stablehlo.subtract %3949, %3950 : tensor<1x1200x320xf64>
    %3952 = stablehlo.multiply %3951, %3951 : tensor<1x1200x320xf64>
    %3953 = stablehlo.reduce(%3952 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %3954 = stablehlo.reshape %3953 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %3955 = stablehlo.broadcast_in_dim %3954, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %3956 = stablehlo.divide %3955, %2987 : tensor<1x1200x1xf64>
    %3957 = stablehlo.convert %3956 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %3958 = stablehlo.reduce(%3943 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %3959 = stablehlo.reshape %3958 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %3960 = stablehlo.broadcast_in_dim %3959, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3961 = stablehlo.divide %3960, %3003 : tensor<1x1200x1xf32>
    %3962 = stablehlo.broadcast_in_dim %3957, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %3963 = stablehlo.add %3962, %3006 : tensor<1x1200x1xf32>
    %3964 = stablehlo.rsqrt %3963 : tensor<1x1200x1xf32>
    %3965 = stablehlo.broadcast_in_dim %3943, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3966 = stablehlo.broadcast_in_dim %3961, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3967 = stablehlo.subtract %3965, %3966 : tensor<1x1200x320xf32>
    %3968 = stablehlo.broadcast_in_dim %3967, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3969 = stablehlo.broadcast_in_dim %3964, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %3970 = stablehlo.multiply %3968, %3969 : tensor<1x1200x320xf32>
    %3971 = stablehlo.convert %arg177 : (tensor<320xbf16>) -> tensor<320xf32>
    %3972 = stablehlo.broadcast_in_dim %3970, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3973 = stablehlo.broadcast_in_dim %3971, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3974 = stablehlo.multiply %3972, %3973 : tensor<1x1200x320xf32>
    %3975 = stablehlo.convert %arg178 : (tensor<320xbf16>) -> tensor<320xf32>
    %3976 = stablehlo.broadcast_in_dim %3974, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %3977 = stablehlo.broadcast_in_dim %3975, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %3978 = stablehlo.add %3976, %3977 : tensor<1x1200x320xf32>
    %3979 = stablehlo.convert %3978 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %3980 = stablehlo.reshape %3979 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %3981 = stablehlo.convert %3980 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %3982 = stablehlo.dot_general %3981, %arg654, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %3983 = stablehlo.broadcast_in_dim %3982, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3984 = stablehlo.multiply %3983, %3226 : tensor<1200x1280xf32>
    %3985 = stablehlo.broadcast_in_dim %3984, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %3986 = stablehlo.broadcast_in_dim %arg655, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %3987 = stablehlo.add %3985, %3986 : tensor<1200x1280xf32>
    %3988 = stablehlo.convert %3987 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %3989 = stablehlo.reshape %3988 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %3990 = stablehlo.transpose %3989, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %3991 = stablehlo.reshape %3990 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %3992 = stablehlo.convolution(%3991, %arg179) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %3993 = stablehlo.reshape %arg180 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %3994 = stablehlo.broadcast_in_dim %3992, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %3995 = stablehlo.broadcast_in_dim %3993, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %3996 = stablehlo.add %3994, %3995 : tensor<1x1280x30x40xbf16>
    %3997 = stablehlo.reshape %3996 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %3998 = stablehlo.transpose %3997, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %3999 = stablehlo.multiply %3998, %cst_42 : tensor<1x1200x1280xbf16>
    %4000 = stablehlo.multiply %3998, %3243 : tensor<1x1200x1280xbf16>
    %4001 = stablehlo.convert %4000 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %4002 = stablehlo.clamp %cst_43, %4001, %cst_44 : tensor<1x1200x1280xf32>
    %4003 = stablehlo.multiply %4002, %4002 : tensor<1x1200x1280xf32>
    %4004 = stablehlo.multiply %cst_45, %4003 : tensor<1x1200x1280xf32>
    %4005 = stablehlo.add %4004, %cst_46 : tensor<1x1200x1280xf32>
    %4006 = stablehlo.multiply %4005, %4003 : tensor<1x1200x1280xf32>
    %4007 = stablehlo.add %4006, %cst_47 : tensor<1x1200x1280xf32>
    %4008 = stablehlo.multiply %4007, %4003 : tensor<1x1200x1280xf32>
    %4009 = stablehlo.add %4008, %cst_48 : tensor<1x1200x1280xf32>
    %4010 = stablehlo.multiply %4009, %4003 : tensor<1x1200x1280xf32>
    %4011 = stablehlo.add %4010, %cst_49 : tensor<1x1200x1280xf32>
    %4012 = stablehlo.multiply %4011, %4003 : tensor<1x1200x1280xf32>
    %4013 = stablehlo.add %4012, %cst_50 : tensor<1x1200x1280xf32>
    %4014 = stablehlo.multiply %4013, %4003 : tensor<1x1200x1280xf32>
    %4015 = stablehlo.add %4014, %cst_51 : tensor<1x1200x1280xf32>
    %4016 = stablehlo.multiply %cst_52, %4003 : tensor<1x1200x1280xf32>
    %4017 = stablehlo.add %4016, %cst_53 : tensor<1x1200x1280xf32>
    %4018 = stablehlo.multiply %4017, %4003 : tensor<1x1200x1280xf32>
    %4019 = stablehlo.add %4018, %cst_54 : tensor<1x1200x1280xf32>
    %4020 = stablehlo.multiply %4019, %4003 : tensor<1x1200x1280xf32>
    %4021 = stablehlo.add %4020, %cst_55 : tensor<1x1200x1280xf32>
    %4022 = stablehlo.multiply %4021, %4003 : tensor<1x1200x1280xf32>
    %4023 = stablehlo.add %4022, %cst_56 : tensor<1x1200x1280xf32>
    %4024 = stablehlo.multiply %4002, %4015 : tensor<1x1200x1280xf32>
    %4025 = stablehlo.divide %4024, %4023 : tensor<1x1200x1280xf32>
    %4026 = stablehlo.clamp %cst_57, %4025, %cst_58 : tensor<1x1200x1280xf32>
    %4027 = stablehlo.convert %4026 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %4028 = stablehlo.add %4027, %cst_40 : tensor<1x1200x1280xbf16>
    %4029 = stablehlo.multiply %4028, %3999 : tensor<1x1200x1280xbf16>
    %4030 = stablehlo.reshape %4029 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %4031 = stablehlo.dot_general %4030, %arg656, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %4032 = stablehlo.reshape %4031 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4033 = stablehlo.broadcast_in_dim %4032, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4034 = stablehlo.broadcast_in_dim %arg181, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %4035 = stablehlo.add %4033, %4034 : tensor<1x1200x320xbf16>
    %4036 = stablehlo.reshape %4035 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4037 = stablehlo.reshape %4036 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4038 = stablehlo.add %4037, %3942 : tensor<1x1200x320xbf16>
    %4039 = stablehlo.convert %4038 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4040 = stablehlo.convert %4039 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4041 = stablehlo.reduce(%4040 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4042 = stablehlo.reshape %4041 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4043 = stablehlo.broadcast_in_dim %4042, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4044 = stablehlo.divide %4043, %2987 : tensor<1x1200x1xf64>
    %4045 = stablehlo.broadcast_in_dim %4040, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4046 = stablehlo.broadcast_in_dim %4044, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4047 = stablehlo.subtract %4045, %4046 : tensor<1x1200x320xf64>
    %4048 = stablehlo.multiply %4047, %4047 : tensor<1x1200x320xf64>
    %4049 = stablehlo.reduce(%4048 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4050 = stablehlo.reshape %4049 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4051 = stablehlo.broadcast_in_dim %4050, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4052 = stablehlo.divide %4051, %2987 : tensor<1x1200x1xf64>
    %4053 = stablehlo.convert %4052 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4054 = stablehlo.reduce(%4039 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4055 = stablehlo.reshape %4054 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4056 = stablehlo.broadcast_in_dim %4055, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4057 = stablehlo.divide %4056, %3003 : tensor<1x1200x1xf32>
    %4058 = stablehlo.broadcast_in_dim %4053, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4059 = stablehlo.add %4058, %3006 : tensor<1x1200x1xf32>
    %4060 = stablehlo.rsqrt %4059 : tensor<1x1200x1xf32>
    %4061 = stablehlo.broadcast_in_dim %4039, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4062 = stablehlo.broadcast_in_dim %4057, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4063 = stablehlo.subtract %4061, %4062 : tensor<1x1200x320xf32>
    %4064 = stablehlo.broadcast_in_dim %4063, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4065 = stablehlo.broadcast_in_dim %4060, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4066 = stablehlo.multiply %4064, %4065 : tensor<1x1200x320xf32>
    %4067 = stablehlo.convert %arg182 : (tensor<320xbf16>) -> tensor<320xf32>
    %4068 = stablehlo.broadcast_in_dim %4066, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4069 = stablehlo.broadcast_in_dim %4067, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4070 = stablehlo.multiply %4068, %4069 : tensor<1x1200x320xf32>
    %4071 = stablehlo.convert %arg183 : (tensor<320xbf16>) -> tensor<320xf32>
    %4072 = stablehlo.broadcast_in_dim %4070, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4073 = stablehlo.broadcast_in_dim %4071, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4074 = stablehlo.add %4072, %4073 : tensor<1x1200x320xf32>
    %4075 = stablehlo.convert %4074 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4076 = stablehlo.reshape %4075 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4077 = stablehlo.convert %4076 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4078 = stablehlo.dot_general %4077, %arg657, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4079 = stablehlo.broadcast_in_dim %4078, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4080 = stablehlo.multiply %4079, %3065 : tensor<1200x320xf32>
    %4081 = stablehlo.broadcast_in_dim %4080, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4082 = stablehlo.broadcast_in_dim %arg658, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4083 = stablehlo.add %4081, %4082 : tensor<1200x320xf32>
    %4084 = stablehlo.convert %4083 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4085 = stablehlo.reshape %4084 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4086 = stablehlo.reshape %4085 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %4087 = stablehlo.transpose %4086, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4088 = stablehlo.transpose %4075, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %4089 = stablehlo.reshape %4088 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %4090 = stablehlo.convolution(%4089, %arg184) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %4091 = stablehlo.reshape %arg185 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %4092 = stablehlo.broadcast_in_dim %4090, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %4093 = stablehlo.broadcast_in_dim %4091, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %4094 = stablehlo.add %4092, %4093 : tensor<1x320x15x20xbf16>
    %4095 = stablehlo.reshape %4094 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %4096 = stablehlo.transpose %4095, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %4097 = stablehlo.convert %4096 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %4098 = stablehlo.convert %4097 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %4099 = stablehlo.reduce(%4098 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4100 = stablehlo.reshape %4099 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4101 = stablehlo.broadcast_in_dim %4100, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4102 = stablehlo.divide %4101, %3088 : tensor<1x300x1xf64>
    %4103 = stablehlo.broadcast_in_dim %4098, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %4104 = stablehlo.broadcast_in_dim %4102, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %4105 = stablehlo.subtract %4103, %4104 : tensor<1x300x320xf64>
    %4106 = stablehlo.multiply %4105, %4105 : tensor<1x300x320xf64>
    %4107 = stablehlo.reduce(%4106 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4108 = stablehlo.reshape %4107 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4109 = stablehlo.broadcast_in_dim %4108, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4110 = stablehlo.divide %4109, %3088 : tensor<1x300x1xf64>
    %4111 = stablehlo.convert %4110 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %4112 = stablehlo.reduce(%4097 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %4113 = stablehlo.reshape %4112 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %4114 = stablehlo.broadcast_in_dim %4113, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4115 = stablehlo.divide %4114, %3102 : tensor<1x300x1xf32>
    %4116 = stablehlo.broadcast_in_dim %4111, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4117 = stablehlo.add %4116, %136 : tensor<1x300x1xf32>
    %4118 = stablehlo.rsqrt %4117 : tensor<1x300x1xf32>
    %4119 = stablehlo.broadcast_in_dim %4097, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4120 = stablehlo.broadcast_in_dim %4115, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4121 = stablehlo.subtract %4119, %4120 : tensor<1x300x320xf32>
    %4122 = stablehlo.broadcast_in_dim %4121, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4123 = stablehlo.broadcast_in_dim %4118, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4124 = stablehlo.multiply %4122, %4123 : tensor<1x300x320xf32>
    %4125 = stablehlo.convert %arg186 : (tensor<320xbf16>) -> tensor<320xf32>
    %4126 = stablehlo.broadcast_in_dim %4124, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4127 = stablehlo.broadcast_in_dim %4125, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4128 = stablehlo.multiply %4126, %4127 : tensor<1x300x320xf32>
    %4129 = stablehlo.convert %arg187 : (tensor<320xbf16>) -> tensor<320xf32>
    %4130 = stablehlo.broadcast_in_dim %4128, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4131 = stablehlo.broadcast_in_dim %4129, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4132 = stablehlo.add %4130, %4131 : tensor<1x300x320xf32>
    %4133 = stablehlo.convert %4132 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %4134 = stablehlo.reshape %4133 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %4135 = stablehlo.convert %4134 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %4136 = stablehlo.dot_general %4135, %arg659, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4137 = stablehlo.broadcast_in_dim %4136, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4138 = stablehlo.multiply %4137, %3126 : tensor<300x320xf32>
    %4139 = stablehlo.broadcast_in_dim %4138, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4140 = stablehlo.broadcast_in_dim %arg660, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4141 = stablehlo.add %4139, %4140 : tensor<300x320xf32>
    %4142 = stablehlo.convert %4141 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4143 = stablehlo.reshape %4142 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4144 = stablehlo.reshape %4143 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4145 = stablehlo.transpose %4144, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4146 = stablehlo.dot_general %4135, %arg661, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4147 = stablehlo.broadcast_in_dim %4146, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4148 = stablehlo.multiply %4147, %3126 : tensor<300x320xf32>
    %4149 = stablehlo.broadcast_in_dim %4148, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4150 = stablehlo.broadcast_in_dim %arg662, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4151 = stablehlo.add %4149, %4150 : tensor<300x320xf32>
    %4152 = stablehlo.convert %4151 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4153 = stablehlo.reshape %4152 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4154 = stablehlo.reshape %4153 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4155 = stablehlo.transpose %4154, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4156 = stablehlo.transpose %4145, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %4157 = stablehlo.reshape %4087 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %4158 = stablehlo.reshape %4156 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4159 = stablehlo.broadcast_in_dim %4158, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4160 = stablehlo.dot_general %4157, %4159, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %4161 = stablehlo.reshape %4160 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4162 = stablehlo.broadcast_in_dim %4161, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4163 = stablehlo.divide %4162, %3152 : tensor<1x5x1200x300xbf16>
    %4164 = stablehlo.convert %4163 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %4165 = stablehlo.reduce(%4164 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4166 = stablehlo.reshape %4165 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4167 = stablehlo.broadcast_in_dim %4164, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4168 = stablehlo.broadcast_in_dim %4166, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4169 = stablehlo.subtract %4167, %4168 : tensor<1x5x1200x300xf32>
    %4170 = stablehlo.exponential %4169 : tensor<1x5x1200x300xf32>
    %4171 = stablehlo.reduce(%4170 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4172 = stablehlo.reshape %4171 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4173 = stablehlo.broadcast_in_dim %4170, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4174 = stablehlo.broadcast_in_dim %4172, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4175 = stablehlo.divide %4173, %4174 : tensor<1x5x1200x300xf32>
    %4176 = stablehlo.convert %4175 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %4177 = stablehlo.reshape %4176 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %4178 = stablehlo.reshape %4155 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4179 = stablehlo.broadcast_in_dim %4178, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4180 = stablehlo.dot_general %4177, %4179, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %4181 = stablehlo.reshape %4180 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4182 = stablehlo.transpose %4181, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %4183 = stablehlo.reshape %4182 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %4184 = stablehlo.reshape %4183 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4185 = stablehlo.convert %4184 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4186 = stablehlo.dot_general %4185, %arg663, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4187 = stablehlo.broadcast_in_dim %4186, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4188 = stablehlo.multiply %4187, %3065 : tensor<1200x320xf32>
    %4189 = stablehlo.broadcast_in_dim %4188, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4190 = stablehlo.broadcast_in_dim %arg664, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4191 = stablehlo.add %4189, %4190 : tensor<1200x320xf32>
    %4192 = stablehlo.convert %4191 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4193 = stablehlo.reshape %4192 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4194 = stablehlo.add %4193, %4038 : tensor<1x1200x320xbf16>
    %4195 = stablehlo.convert %4194 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4196 = stablehlo.convert %4195 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4197 = stablehlo.reduce(%4196 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4198 = stablehlo.reshape %4197 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4199 = stablehlo.broadcast_in_dim %4198, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4200 = stablehlo.divide %4199, %2987 : tensor<1x1200x1xf64>
    %4201 = stablehlo.broadcast_in_dim %4196, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4202 = stablehlo.broadcast_in_dim %4200, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4203 = stablehlo.subtract %4201, %4202 : tensor<1x1200x320xf64>
    %4204 = stablehlo.multiply %4203, %4203 : tensor<1x1200x320xf64>
    %4205 = stablehlo.reduce(%4204 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4206 = stablehlo.reshape %4205 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4207 = stablehlo.broadcast_in_dim %4206, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4208 = stablehlo.divide %4207, %2987 : tensor<1x1200x1xf64>
    %4209 = stablehlo.convert %4208 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4210 = stablehlo.reduce(%4195 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4211 = stablehlo.reshape %4210 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4212 = stablehlo.broadcast_in_dim %4211, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4213 = stablehlo.divide %4212, %3003 : tensor<1x1200x1xf32>
    %4214 = stablehlo.broadcast_in_dim %4209, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4215 = stablehlo.add %4214, %3006 : tensor<1x1200x1xf32>
    %4216 = stablehlo.rsqrt %4215 : tensor<1x1200x1xf32>
    %4217 = stablehlo.broadcast_in_dim %4195, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4218 = stablehlo.broadcast_in_dim %4213, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4219 = stablehlo.subtract %4217, %4218 : tensor<1x1200x320xf32>
    %4220 = stablehlo.broadcast_in_dim %4219, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4221 = stablehlo.broadcast_in_dim %4216, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4222 = stablehlo.multiply %4220, %4221 : tensor<1x1200x320xf32>
    %4223 = stablehlo.convert %arg188 : (tensor<320xbf16>) -> tensor<320xf32>
    %4224 = stablehlo.broadcast_in_dim %4222, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4225 = stablehlo.broadcast_in_dim %4223, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4226 = stablehlo.multiply %4224, %4225 : tensor<1x1200x320xf32>
    %4227 = stablehlo.convert %arg189 : (tensor<320xbf16>) -> tensor<320xf32>
    %4228 = stablehlo.broadcast_in_dim %4226, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4229 = stablehlo.broadcast_in_dim %4227, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4230 = stablehlo.add %4228, %4229 : tensor<1x1200x320xf32>
    %4231 = stablehlo.convert %4230 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4232 = stablehlo.reshape %4231 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4233 = stablehlo.convert %4232 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4234 = stablehlo.dot_general %4233, %arg665, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %4235 = stablehlo.broadcast_in_dim %4234, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4236 = stablehlo.multiply %4235, %3226 : tensor<1200x1280xf32>
    %4237 = stablehlo.broadcast_in_dim %4236, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4238 = stablehlo.broadcast_in_dim %arg666, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %4239 = stablehlo.add %4237, %4238 : tensor<1200x1280xf32>
    %4240 = stablehlo.convert %4239 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %4241 = stablehlo.reshape %4240 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %4242 = stablehlo.transpose %4241, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %4243 = stablehlo.reshape %4242 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %4244 = stablehlo.convolution(%4243, %arg190) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %4245 = stablehlo.reshape %arg191 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %4246 = stablehlo.broadcast_in_dim %4244, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %4247 = stablehlo.broadcast_in_dim %4245, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %4248 = stablehlo.add %4246, %4247 : tensor<1x1280x30x40xbf16>
    %4249 = stablehlo.reshape %4248 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %4250 = stablehlo.transpose %4249, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %4251 = stablehlo.multiply %4250, %cst_42 : tensor<1x1200x1280xbf16>
    %4252 = stablehlo.multiply %4250, %3243 : tensor<1x1200x1280xbf16>
    %4253 = stablehlo.convert %4252 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %4254 = stablehlo.clamp %cst_43, %4253, %cst_44 : tensor<1x1200x1280xf32>
    %4255 = stablehlo.multiply %4254, %4254 : tensor<1x1200x1280xf32>
    %4256 = stablehlo.multiply %cst_45, %4255 : tensor<1x1200x1280xf32>
    %4257 = stablehlo.add %4256, %cst_46 : tensor<1x1200x1280xf32>
    %4258 = stablehlo.multiply %4257, %4255 : tensor<1x1200x1280xf32>
    %4259 = stablehlo.add %4258, %cst_47 : tensor<1x1200x1280xf32>
    %4260 = stablehlo.multiply %4259, %4255 : tensor<1x1200x1280xf32>
    %4261 = stablehlo.add %4260, %cst_48 : tensor<1x1200x1280xf32>
    %4262 = stablehlo.multiply %4261, %4255 : tensor<1x1200x1280xf32>
    %4263 = stablehlo.add %4262, %cst_49 : tensor<1x1200x1280xf32>
    %4264 = stablehlo.multiply %4263, %4255 : tensor<1x1200x1280xf32>
    %4265 = stablehlo.add %4264, %cst_50 : tensor<1x1200x1280xf32>
    %4266 = stablehlo.multiply %4265, %4255 : tensor<1x1200x1280xf32>
    %4267 = stablehlo.add %4266, %cst_51 : tensor<1x1200x1280xf32>
    %4268 = stablehlo.multiply %cst_52, %4255 : tensor<1x1200x1280xf32>
    %4269 = stablehlo.add %4268, %cst_53 : tensor<1x1200x1280xf32>
    %4270 = stablehlo.multiply %4269, %4255 : tensor<1x1200x1280xf32>
    %4271 = stablehlo.add %4270, %cst_54 : tensor<1x1200x1280xf32>
    %4272 = stablehlo.multiply %4271, %4255 : tensor<1x1200x1280xf32>
    %4273 = stablehlo.add %4272, %cst_55 : tensor<1x1200x1280xf32>
    %4274 = stablehlo.multiply %4273, %4255 : tensor<1x1200x1280xf32>
    %4275 = stablehlo.add %4274, %cst_56 : tensor<1x1200x1280xf32>
    %4276 = stablehlo.multiply %4254, %4267 : tensor<1x1200x1280xf32>
    %4277 = stablehlo.divide %4276, %4275 : tensor<1x1200x1280xf32>
    %4278 = stablehlo.clamp %cst_57, %4277, %cst_58 : tensor<1x1200x1280xf32>
    %4279 = stablehlo.convert %4278 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %4280 = stablehlo.add %4279, %cst_40 : tensor<1x1200x1280xbf16>
    %4281 = stablehlo.multiply %4280, %4251 : tensor<1x1200x1280xbf16>
    %4282 = stablehlo.reshape %4281 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %4283 = stablehlo.dot_general %4282, %arg667, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %4284 = stablehlo.reshape %4283 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4285 = stablehlo.broadcast_in_dim %4284, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4286 = stablehlo.broadcast_in_dim %arg192, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %4287 = stablehlo.add %4285, %4286 : tensor<1x1200x320xbf16>
    %4288 = stablehlo.reshape %4287 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4289 = stablehlo.reshape %4288 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4290 = stablehlo.add %4289, %4194 : tensor<1x1200x320xbf16>
    %4291 = stablehlo.convert %4290 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4292 = stablehlo.convert %4291 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4293 = stablehlo.reduce(%4292 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4294 = stablehlo.reshape %4293 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4295 = stablehlo.broadcast_in_dim %4294, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4296 = stablehlo.divide %4295, %2987 : tensor<1x1200x1xf64>
    %4297 = stablehlo.broadcast_in_dim %4292, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4298 = stablehlo.broadcast_in_dim %4296, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4299 = stablehlo.subtract %4297, %4298 : tensor<1x1200x320xf64>
    %4300 = stablehlo.multiply %4299, %4299 : tensor<1x1200x320xf64>
    %4301 = stablehlo.reduce(%4300 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4302 = stablehlo.reshape %4301 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4303 = stablehlo.broadcast_in_dim %4302, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4304 = stablehlo.divide %4303, %2987 : tensor<1x1200x1xf64>
    %4305 = stablehlo.convert %4304 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4306 = stablehlo.reduce(%4291 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4307 = stablehlo.reshape %4306 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4308 = stablehlo.broadcast_in_dim %4307, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4309 = stablehlo.divide %4308, %3003 : tensor<1x1200x1xf32>
    %4310 = stablehlo.broadcast_in_dim %4305, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4311 = stablehlo.add %4310, %3006 : tensor<1x1200x1xf32>
    %4312 = stablehlo.rsqrt %4311 : tensor<1x1200x1xf32>
    %4313 = stablehlo.broadcast_in_dim %4291, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4314 = stablehlo.broadcast_in_dim %4309, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4315 = stablehlo.subtract %4313, %4314 : tensor<1x1200x320xf32>
    %4316 = stablehlo.broadcast_in_dim %4315, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4317 = stablehlo.broadcast_in_dim %4312, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4318 = stablehlo.multiply %4316, %4317 : tensor<1x1200x320xf32>
    %4319 = stablehlo.convert %arg193 : (tensor<320xbf16>) -> tensor<320xf32>
    %4320 = stablehlo.broadcast_in_dim %4318, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4321 = stablehlo.broadcast_in_dim %4319, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4322 = stablehlo.multiply %4320, %4321 : tensor<1x1200x320xf32>
    %4323 = stablehlo.convert %arg194 : (tensor<320xbf16>) -> tensor<320xf32>
    %4324 = stablehlo.broadcast_in_dim %4322, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4325 = stablehlo.broadcast_in_dim %4323, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4326 = stablehlo.add %4324, %4325 : tensor<1x1200x320xf32>
    %4327 = stablehlo.convert %4326 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4328 = stablehlo.reshape %4327 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4329 = stablehlo.convert %4328 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4330 = stablehlo.dot_general %4329, %arg668, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4331 = stablehlo.broadcast_in_dim %4330, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4332 = stablehlo.multiply %4331, %3065 : tensor<1200x320xf32>
    %4333 = stablehlo.broadcast_in_dim %4332, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4334 = stablehlo.broadcast_in_dim %arg669, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4335 = stablehlo.add %4333, %4334 : tensor<1200x320xf32>
    %4336 = stablehlo.convert %4335 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4337 = stablehlo.reshape %4336 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4338 = stablehlo.reshape %4337 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %4339 = stablehlo.transpose %4338, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4340 = stablehlo.transpose %4327, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %4341 = stablehlo.reshape %4340 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %4342 = stablehlo.convolution(%4341, %arg195) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %4343 = stablehlo.reshape %arg196 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %4344 = stablehlo.broadcast_in_dim %4342, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %4345 = stablehlo.broadcast_in_dim %4343, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %4346 = stablehlo.add %4344, %4345 : tensor<1x320x15x20xbf16>
    %4347 = stablehlo.reshape %4346 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %4348 = stablehlo.transpose %4347, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %4349 = stablehlo.convert %4348 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %4350 = stablehlo.convert %4349 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %4351 = stablehlo.reduce(%4350 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4352 = stablehlo.reshape %4351 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4353 = stablehlo.broadcast_in_dim %4352, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4354 = stablehlo.divide %4353, %3088 : tensor<1x300x1xf64>
    %4355 = stablehlo.broadcast_in_dim %4350, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %4356 = stablehlo.broadcast_in_dim %4354, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %4357 = stablehlo.subtract %4355, %4356 : tensor<1x300x320xf64>
    %4358 = stablehlo.multiply %4357, %4357 : tensor<1x300x320xf64>
    %4359 = stablehlo.reduce(%4358 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4360 = stablehlo.reshape %4359 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4361 = stablehlo.broadcast_in_dim %4360, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4362 = stablehlo.divide %4361, %3088 : tensor<1x300x1xf64>
    %4363 = stablehlo.convert %4362 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %4364 = stablehlo.reduce(%4349 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %4365 = stablehlo.reshape %4364 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %4366 = stablehlo.broadcast_in_dim %4365, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4367 = stablehlo.divide %4366, %3102 : tensor<1x300x1xf32>
    %4368 = stablehlo.broadcast_in_dim %4363, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4369 = stablehlo.add %4368, %136 : tensor<1x300x1xf32>
    %4370 = stablehlo.rsqrt %4369 : tensor<1x300x1xf32>
    %4371 = stablehlo.broadcast_in_dim %4349, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4372 = stablehlo.broadcast_in_dim %4367, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4373 = stablehlo.subtract %4371, %4372 : tensor<1x300x320xf32>
    %4374 = stablehlo.broadcast_in_dim %4373, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4375 = stablehlo.broadcast_in_dim %4370, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4376 = stablehlo.multiply %4374, %4375 : tensor<1x300x320xf32>
    %4377 = stablehlo.convert %arg197 : (tensor<320xbf16>) -> tensor<320xf32>
    %4378 = stablehlo.broadcast_in_dim %4376, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4379 = stablehlo.broadcast_in_dim %4377, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4380 = stablehlo.multiply %4378, %4379 : tensor<1x300x320xf32>
    %4381 = stablehlo.convert %arg198 : (tensor<320xbf16>) -> tensor<320xf32>
    %4382 = stablehlo.broadcast_in_dim %4380, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4383 = stablehlo.broadcast_in_dim %4381, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4384 = stablehlo.add %4382, %4383 : tensor<1x300x320xf32>
    %4385 = stablehlo.convert %4384 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %4386 = stablehlo.reshape %4385 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %4387 = stablehlo.convert %4386 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %4388 = stablehlo.dot_general %4387, %arg670, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4389 = stablehlo.broadcast_in_dim %4388, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4390 = stablehlo.multiply %4389, %3126 : tensor<300x320xf32>
    %4391 = stablehlo.broadcast_in_dim %4390, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4392 = stablehlo.broadcast_in_dim %arg671, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4393 = stablehlo.add %4391, %4392 : tensor<300x320xf32>
    %4394 = stablehlo.convert %4393 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4395 = stablehlo.reshape %4394 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4396 = stablehlo.reshape %4395 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4397 = stablehlo.transpose %4396, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4398 = stablehlo.dot_general %4387, %arg672, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4399 = stablehlo.broadcast_in_dim %4398, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4400 = stablehlo.multiply %4399, %3126 : tensor<300x320xf32>
    %4401 = stablehlo.broadcast_in_dim %4400, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4402 = stablehlo.broadcast_in_dim %arg673, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4403 = stablehlo.add %4401, %4402 : tensor<300x320xf32>
    %4404 = stablehlo.convert %4403 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4405 = stablehlo.reshape %4404 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4406 = stablehlo.reshape %4405 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4407 = stablehlo.transpose %4406, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4408 = stablehlo.transpose %4397, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %4409 = stablehlo.reshape %4339 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %4410 = stablehlo.reshape %4408 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4411 = stablehlo.broadcast_in_dim %4410, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4412 = stablehlo.dot_general %4409, %4411, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %4413 = stablehlo.reshape %4412 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4414 = stablehlo.broadcast_in_dim %4413, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4415 = stablehlo.divide %4414, %3152 : tensor<1x5x1200x300xbf16>
    %4416 = stablehlo.convert %4415 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %4417 = stablehlo.reduce(%4416 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4418 = stablehlo.reshape %4417 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4419 = stablehlo.broadcast_in_dim %4416, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4420 = stablehlo.broadcast_in_dim %4418, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4421 = stablehlo.subtract %4419, %4420 : tensor<1x5x1200x300xf32>
    %4422 = stablehlo.exponential %4421 : tensor<1x5x1200x300xf32>
    %4423 = stablehlo.reduce(%4422 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4424 = stablehlo.reshape %4423 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4425 = stablehlo.broadcast_in_dim %4422, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4426 = stablehlo.broadcast_in_dim %4424, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4427 = stablehlo.divide %4425, %4426 : tensor<1x5x1200x300xf32>
    %4428 = stablehlo.convert %4427 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %4429 = stablehlo.reshape %4428 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %4430 = stablehlo.reshape %4407 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4431 = stablehlo.broadcast_in_dim %4430, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4432 = stablehlo.dot_general %4429, %4431, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %4433 = stablehlo.reshape %4432 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4434 = stablehlo.transpose %4433, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %4435 = stablehlo.reshape %4434 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %4436 = stablehlo.reshape %4435 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4437 = stablehlo.convert %4436 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4438 = stablehlo.dot_general %4437, %arg674, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4439 = stablehlo.broadcast_in_dim %4438, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4440 = stablehlo.multiply %4439, %3065 : tensor<1200x320xf32>
    %4441 = stablehlo.broadcast_in_dim %4440, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4442 = stablehlo.broadcast_in_dim %arg675, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4443 = stablehlo.add %4441, %4442 : tensor<1200x320xf32>
    %4444 = stablehlo.convert %4443 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4445 = stablehlo.reshape %4444 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4446 = stablehlo.add %4445, %4290 : tensor<1x1200x320xbf16>
    %4447 = stablehlo.convert %4446 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4448 = stablehlo.convert %4447 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4449 = stablehlo.reduce(%4448 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4450 = stablehlo.reshape %4449 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4451 = stablehlo.broadcast_in_dim %4450, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4452 = stablehlo.divide %4451, %2987 : tensor<1x1200x1xf64>
    %4453 = stablehlo.broadcast_in_dim %4448, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4454 = stablehlo.broadcast_in_dim %4452, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4455 = stablehlo.subtract %4453, %4454 : tensor<1x1200x320xf64>
    %4456 = stablehlo.multiply %4455, %4455 : tensor<1x1200x320xf64>
    %4457 = stablehlo.reduce(%4456 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4458 = stablehlo.reshape %4457 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4459 = stablehlo.broadcast_in_dim %4458, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4460 = stablehlo.divide %4459, %2987 : tensor<1x1200x1xf64>
    %4461 = stablehlo.convert %4460 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4462 = stablehlo.reduce(%4447 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4463 = stablehlo.reshape %4462 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4464 = stablehlo.broadcast_in_dim %4463, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4465 = stablehlo.divide %4464, %3003 : tensor<1x1200x1xf32>
    %4466 = stablehlo.broadcast_in_dim %4461, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4467 = stablehlo.add %4466, %3006 : tensor<1x1200x1xf32>
    %4468 = stablehlo.rsqrt %4467 : tensor<1x1200x1xf32>
    %4469 = stablehlo.broadcast_in_dim %4447, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4470 = stablehlo.broadcast_in_dim %4465, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4471 = stablehlo.subtract %4469, %4470 : tensor<1x1200x320xf32>
    %4472 = stablehlo.broadcast_in_dim %4471, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4473 = stablehlo.broadcast_in_dim %4468, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4474 = stablehlo.multiply %4472, %4473 : tensor<1x1200x320xf32>
    %4475 = stablehlo.convert %arg199 : (tensor<320xbf16>) -> tensor<320xf32>
    %4476 = stablehlo.broadcast_in_dim %4474, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4477 = stablehlo.broadcast_in_dim %4475, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4478 = stablehlo.multiply %4476, %4477 : tensor<1x1200x320xf32>
    %4479 = stablehlo.convert %arg200 : (tensor<320xbf16>) -> tensor<320xf32>
    %4480 = stablehlo.broadcast_in_dim %4478, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4481 = stablehlo.broadcast_in_dim %4479, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4482 = stablehlo.add %4480, %4481 : tensor<1x1200x320xf32>
    %4483 = stablehlo.convert %4482 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4484 = stablehlo.reshape %4483 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4485 = stablehlo.convert %4484 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4486 = stablehlo.dot_general %4485, %arg676, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %4487 = stablehlo.broadcast_in_dim %4486, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4488 = stablehlo.multiply %4487, %3226 : tensor<1200x1280xf32>
    %4489 = stablehlo.broadcast_in_dim %4488, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4490 = stablehlo.broadcast_in_dim %arg677, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %4491 = stablehlo.add %4489, %4490 : tensor<1200x1280xf32>
    %4492 = stablehlo.convert %4491 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %4493 = stablehlo.reshape %4492 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %4494 = stablehlo.transpose %4493, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %4495 = stablehlo.reshape %4494 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %4496 = stablehlo.convolution(%4495, %arg201) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %4497 = stablehlo.reshape %arg202 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %4498 = stablehlo.broadcast_in_dim %4496, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %4499 = stablehlo.broadcast_in_dim %4497, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %4500 = stablehlo.add %4498, %4499 : tensor<1x1280x30x40xbf16>
    %4501 = stablehlo.reshape %4500 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %4502 = stablehlo.transpose %4501, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %4503 = stablehlo.multiply %4502, %cst_42 : tensor<1x1200x1280xbf16>
    %4504 = stablehlo.multiply %4502, %3243 : tensor<1x1200x1280xbf16>
    %4505 = stablehlo.convert %4504 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %4506 = stablehlo.clamp %cst_43, %4505, %cst_44 : tensor<1x1200x1280xf32>
    %4507 = stablehlo.multiply %4506, %4506 : tensor<1x1200x1280xf32>
    %4508 = stablehlo.multiply %cst_45, %4507 : tensor<1x1200x1280xf32>
    %4509 = stablehlo.add %4508, %cst_46 : tensor<1x1200x1280xf32>
    %4510 = stablehlo.multiply %4509, %4507 : tensor<1x1200x1280xf32>
    %4511 = stablehlo.add %4510, %cst_47 : tensor<1x1200x1280xf32>
    %4512 = stablehlo.multiply %4511, %4507 : tensor<1x1200x1280xf32>
    %4513 = stablehlo.add %4512, %cst_48 : tensor<1x1200x1280xf32>
    %4514 = stablehlo.multiply %4513, %4507 : tensor<1x1200x1280xf32>
    %4515 = stablehlo.add %4514, %cst_49 : tensor<1x1200x1280xf32>
    %4516 = stablehlo.multiply %4515, %4507 : tensor<1x1200x1280xf32>
    %4517 = stablehlo.add %4516, %cst_50 : tensor<1x1200x1280xf32>
    %4518 = stablehlo.multiply %4517, %4507 : tensor<1x1200x1280xf32>
    %4519 = stablehlo.add %4518, %cst_51 : tensor<1x1200x1280xf32>
    %4520 = stablehlo.multiply %cst_52, %4507 : tensor<1x1200x1280xf32>
    %4521 = stablehlo.add %4520, %cst_53 : tensor<1x1200x1280xf32>
    %4522 = stablehlo.multiply %4521, %4507 : tensor<1x1200x1280xf32>
    %4523 = stablehlo.add %4522, %cst_54 : tensor<1x1200x1280xf32>
    %4524 = stablehlo.multiply %4523, %4507 : tensor<1x1200x1280xf32>
    %4525 = stablehlo.add %4524, %cst_55 : tensor<1x1200x1280xf32>
    %4526 = stablehlo.multiply %4525, %4507 : tensor<1x1200x1280xf32>
    %4527 = stablehlo.add %4526, %cst_56 : tensor<1x1200x1280xf32>
    %4528 = stablehlo.multiply %4506, %4519 : tensor<1x1200x1280xf32>
    %4529 = stablehlo.divide %4528, %4527 : tensor<1x1200x1280xf32>
    %4530 = stablehlo.clamp %cst_57, %4529, %cst_58 : tensor<1x1200x1280xf32>
    %4531 = stablehlo.convert %4530 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %4532 = stablehlo.add %4531, %cst_40 : tensor<1x1200x1280xbf16>
    %4533 = stablehlo.multiply %4532, %4503 : tensor<1x1200x1280xbf16>
    %4534 = stablehlo.reshape %4533 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %4535 = stablehlo.dot_general %4534, %arg678, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %4536 = stablehlo.reshape %4535 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4537 = stablehlo.broadcast_in_dim %4536, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4538 = stablehlo.broadcast_in_dim %arg203, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %4539 = stablehlo.add %4537, %4538 : tensor<1x1200x320xbf16>
    %4540 = stablehlo.reshape %4539 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4541 = stablehlo.reshape %4540 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4542 = stablehlo.add %4541, %4446 : tensor<1x1200x320xbf16>
    %4543 = stablehlo.convert %4542 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4544 = stablehlo.convert %4543 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4545 = stablehlo.reduce(%4544 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4546 = stablehlo.reshape %4545 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4547 = stablehlo.broadcast_in_dim %4546, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4548 = stablehlo.divide %4547, %2987 : tensor<1x1200x1xf64>
    %4549 = stablehlo.broadcast_in_dim %4544, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4550 = stablehlo.broadcast_in_dim %4548, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4551 = stablehlo.subtract %4549, %4550 : tensor<1x1200x320xf64>
    %4552 = stablehlo.multiply %4551, %4551 : tensor<1x1200x320xf64>
    %4553 = stablehlo.reduce(%4552 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4554 = stablehlo.reshape %4553 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4555 = stablehlo.broadcast_in_dim %4554, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4556 = stablehlo.divide %4555, %2987 : tensor<1x1200x1xf64>
    %4557 = stablehlo.convert %4556 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4558 = stablehlo.reduce(%4543 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4559 = stablehlo.reshape %4558 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4560 = stablehlo.broadcast_in_dim %4559, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4561 = stablehlo.divide %4560, %3003 : tensor<1x1200x1xf32>
    %4562 = stablehlo.broadcast_in_dim %4557, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4563 = stablehlo.add %4562, %3006 : tensor<1x1200x1xf32>
    %4564 = stablehlo.rsqrt %4563 : tensor<1x1200x1xf32>
    %4565 = stablehlo.broadcast_in_dim %4543, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4566 = stablehlo.broadcast_in_dim %4561, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4567 = stablehlo.subtract %4565, %4566 : tensor<1x1200x320xf32>
    %4568 = stablehlo.broadcast_in_dim %4567, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4569 = stablehlo.broadcast_in_dim %4564, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4570 = stablehlo.multiply %4568, %4569 : tensor<1x1200x320xf32>
    %4571 = stablehlo.convert %arg204 : (tensor<320xbf16>) -> tensor<320xf32>
    %4572 = stablehlo.broadcast_in_dim %4570, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4573 = stablehlo.broadcast_in_dim %4571, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4574 = stablehlo.multiply %4572, %4573 : tensor<1x1200x320xf32>
    %4575 = stablehlo.convert %arg205 : (tensor<320xbf16>) -> tensor<320xf32>
    %4576 = stablehlo.broadcast_in_dim %4574, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4577 = stablehlo.broadcast_in_dim %4575, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4578 = stablehlo.add %4576, %4577 : tensor<1x1200x320xf32>
    %4579 = stablehlo.convert %4578 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4580 = stablehlo.reshape %4579 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4581 = stablehlo.convert %4580 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4582 = stablehlo.dot_general %4581, %arg679, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4583 = stablehlo.broadcast_in_dim %4582, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4584 = stablehlo.multiply %4583, %3065 : tensor<1200x320xf32>
    %4585 = stablehlo.broadcast_in_dim %4584, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4586 = stablehlo.broadcast_in_dim %arg680, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4587 = stablehlo.add %4585, %4586 : tensor<1200x320xf32>
    %4588 = stablehlo.convert %4587 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4589 = stablehlo.reshape %4588 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4590 = stablehlo.reshape %4589 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %4591 = stablehlo.transpose %4590, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4592 = stablehlo.transpose %4579, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %4593 = stablehlo.reshape %4592 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %4594 = stablehlo.convolution(%4593, %arg206) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %4595 = stablehlo.reshape %arg207 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %4596 = stablehlo.broadcast_in_dim %4594, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %4597 = stablehlo.broadcast_in_dim %4595, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %4598 = stablehlo.add %4596, %4597 : tensor<1x320x15x20xbf16>
    %4599 = stablehlo.reshape %4598 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %4600 = stablehlo.transpose %4599, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %4601 = stablehlo.convert %4600 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %4602 = stablehlo.convert %4601 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %4603 = stablehlo.reduce(%4602 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4604 = stablehlo.reshape %4603 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4605 = stablehlo.broadcast_in_dim %4604, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4606 = stablehlo.divide %4605, %3088 : tensor<1x300x1xf64>
    %4607 = stablehlo.broadcast_in_dim %4602, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %4608 = stablehlo.broadcast_in_dim %4606, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %4609 = stablehlo.subtract %4607, %4608 : tensor<1x300x320xf64>
    %4610 = stablehlo.multiply %4609, %4609 : tensor<1x300x320xf64>
    %4611 = stablehlo.reduce(%4610 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4612 = stablehlo.reshape %4611 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4613 = stablehlo.broadcast_in_dim %4612, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4614 = stablehlo.divide %4613, %3088 : tensor<1x300x1xf64>
    %4615 = stablehlo.convert %4614 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %4616 = stablehlo.reduce(%4601 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %4617 = stablehlo.reshape %4616 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %4618 = stablehlo.broadcast_in_dim %4617, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4619 = stablehlo.divide %4618, %3102 : tensor<1x300x1xf32>
    %4620 = stablehlo.broadcast_in_dim %4615, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4621 = stablehlo.add %4620, %136 : tensor<1x300x1xf32>
    %4622 = stablehlo.rsqrt %4621 : tensor<1x300x1xf32>
    %4623 = stablehlo.broadcast_in_dim %4601, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4624 = stablehlo.broadcast_in_dim %4619, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4625 = stablehlo.subtract %4623, %4624 : tensor<1x300x320xf32>
    %4626 = stablehlo.broadcast_in_dim %4625, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4627 = stablehlo.broadcast_in_dim %4622, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4628 = stablehlo.multiply %4626, %4627 : tensor<1x300x320xf32>
    %4629 = stablehlo.convert %arg208 : (tensor<320xbf16>) -> tensor<320xf32>
    %4630 = stablehlo.broadcast_in_dim %4628, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4631 = stablehlo.broadcast_in_dim %4629, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4632 = stablehlo.multiply %4630, %4631 : tensor<1x300x320xf32>
    %4633 = stablehlo.convert %arg209 : (tensor<320xbf16>) -> tensor<320xf32>
    %4634 = stablehlo.broadcast_in_dim %4632, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4635 = stablehlo.broadcast_in_dim %4633, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4636 = stablehlo.add %4634, %4635 : tensor<1x300x320xf32>
    %4637 = stablehlo.convert %4636 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %4638 = stablehlo.reshape %4637 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %4639 = stablehlo.convert %4638 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %4640 = stablehlo.dot_general %4639, %arg681, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4641 = stablehlo.broadcast_in_dim %4640, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4642 = stablehlo.multiply %4641, %3126 : tensor<300x320xf32>
    %4643 = stablehlo.broadcast_in_dim %4642, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4644 = stablehlo.broadcast_in_dim %arg682, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4645 = stablehlo.add %4643, %4644 : tensor<300x320xf32>
    %4646 = stablehlo.convert %4645 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4647 = stablehlo.reshape %4646 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4648 = stablehlo.reshape %4647 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4649 = stablehlo.transpose %4648, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4650 = stablehlo.dot_general %4639, %arg683, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4651 = stablehlo.broadcast_in_dim %4650, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4652 = stablehlo.multiply %4651, %3126 : tensor<300x320xf32>
    %4653 = stablehlo.broadcast_in_dim %4652, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4654 = stablehlo.broadcast_in_dim %arg684, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4655 = stablehlo.add %4653, %4654 : tensor<300x320xf32>
    %4656 = stablehlo.convert %4655 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4657 = stablehlo.reshape %4656 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4658 = stablehlo.reshape %4657 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4659 = stablehlo.transpose %4658, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4660 = stablehlo.transpose %4649, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %4661 = stablehlo.reshape %4591 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %4662 = stablehlo.reshape %4660 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4663 = stablehlo.broadcast_in_dim %4662, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4664 = stablehlo.dot_general %4661, %4663, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %4665 = stablehlo.reshape %4664 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4666 = stablehlo.broadcast_in_dim %4665, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4667 = stablehlo.divide %4666, %3152 : tensor<1x5x1200x300xbf16>
    %4668 = stablehlo.convert %4667 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %4669 = stablehlo.reduce(%4668 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4670 = stablehlo.reshape %4669 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4671 = stablehlo.broadcast_in_dim %4668, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4672 = stablehlo.broadcast_in_dim %4670, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4673 = stablehlo.subtract %4671, %4672 : tensor<1x5x1200x300xf32>
    %4674 = stablehlo.exponential %4673 : tensor<1x5x1200x300xf32>
    %4675 = stablehlo.reduce(%4674 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4676 = stablehlo.reshape %4675 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4677 = stablehlo.broadcast_in_dim %4674, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4678 = stablehlo.broadcast_in_dim %4676, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4679 = stablehlo.divide %4677, %4678 : tensor<1x5x1200x300xf32>
    %4680 = stablehlo.convert %4679 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %4681 = stablehlo.reshape %4680 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %4682 = stablehlo.reshape %4659 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4683 = stablehlo.broadcast_in_dim %4682, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4684 = stablehlo.dot_general %4681, %4683, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %4685 = stablehlo.reshape %4684 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4686 = stablehlo.transpose %4685, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %4687 = stablehlo.reshape %4686 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %4688 = stablehlo.reshape %4687 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4689 = stablehlo.convert %4688 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4690 = stablehlo.dot_general %4689, %arg685, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4691 = stablehlo.broadcast_in_dim %4690, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4692 = stablehlo.multiply %4691, %3065 : tensor<1200x320xf32>
    %4693 = stablehlo.broadcast_in_dim %4692, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4694 = stablehlo.broadcast_in_dim %arg686, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4695 = stablehlo.add %4693, %4694 : tensor<1200x320xf32>
    %4696 = stablehlo.convert %4695 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4697 = stablehlo.reshape %4696 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4698 = stablehlo.add %4697, %4542 : tensor<1x1200x320xbf16>
    %4699 = stablehlo.convert %4698 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4700 = stablehlo.convert %4699 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4701 = stablehlo.reduce(%4700 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4702 = stablehlo.reshape %4701 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4703 = stablehlo.broadcast_in_dim %4702, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4704 = stablehlo.divide %4703, %2987 : tensor<1x1200x1xf64>
    %4705 = stablehlo.broadcast_in_dim %4700, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4706 = stablehlo.broadcast_in_dim %4704, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4707 = stablehlo.subtract %4705, %4706 : tensor<1x1200x320xf64>
    %4708 = stablehlo.multiply %4707, %4707 : tensor<1x1200x320xf64>
    %4709 = stablehlo.reduce(%4708 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4710 = stablehlo.reshape %4709 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4711 = stablehlo.broadcast_in_dim %4710, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4712 = stablehlo.divide %4711, %2987 : tensor<1x1200x1xf64>
    %4713 = stablehlo.convert %4712 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4714 = stablehlo.reduce(%4699 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4715 = stablehlo.reshape %4714 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4716 = stablehlo.broadcast_in_dim %4715, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4717 = stablehlo.divide %4716, %3003 : tensor<1x1200x1xf32>
    %4718 = stablehlo.broadcast_in_dim %4713, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4719 = stablehlo.add %4718, %3006 : tensor<1x1200x1xf32>
    %4720 = stablehlo.rsqrt %4719 : tensor<1x1200x1xf32>
    %4721 = stablehlo.broadcast_in_dim %4699, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4722 = stablehlo.broadcast_in_dim %4717, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4723 = stablehlo.subtract %4721, %4722 : tensor<1x1200x320xf32>
    %4724 = stablehlo.broadcast_in_dim %4723, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4725 = stablehlo.broadcast_in_dim %4720, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4726 = stablehlo.multiply %4724, %4725 : tensor<1x1200x320xf32>
    %4727 = stablehlo.convert %arg210 : (tensor<320xbf16>) -> tensor<320xf32>
    %4728 = stablehlo.broadcast_in_dim %4726, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4729 = stablehlo.broadcast_in_dim %4727, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4730 = stablehlo.multiply %4728, %4729 : tensor<1x1200x320xf32>
    %4731 = stablehlo.convert %arg211 : (tensor<320xbf16>) -> tensor<320xf32>
    %4732 = stablehlo.broadcast_in_dim %4730, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4733 = stablehlo.broadcast_in_dim %4731, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4734 = stablehlo.add %4732, %4733 : tensor<1x1200x320xf32>
    %4735 = stablehlo.convert %4734 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4736 = stablehlo.reshape %4735 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4737 = stablehlo.convert %4736 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4738 = stablehlo.dot_general %4737, %arg687, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %4739 = stablehlo.broadcast_in_dim %4738, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4740 = stablehlo.multiply %4739, %3226 : tensor<1200x1280xf32>
    %4741 = stablehlo.broadcast_in_dim %4740, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4742 = stablehlo.broadcast_in_dim %arg688, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %4743 = stablehlo.add %4741, %4742 : tensor<1200x1280xf32>
    %4744 = stablehlo.convert %4743 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %4745 = stablehlo.reshape %4744 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %4746 = stablehlo.transpose %4745, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %4747 = stablehlo.reshape %4746 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %4748 = stablehlo.convolution(%4747, %arg212) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %4749 = stablehlo.reshape %arg213 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %4750 = stablehlo.broadcast_in_dim %4748, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %4751 = stablehlo.broadcast_in_dim %4749, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %4752 = stablehlo.add %4750, %4751 : tensor<1x1280x30x40xbf16>
    %4753 = stablehlo.reshape %4752 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %4754 = stablehlo.transpose %4753, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %4755 = stablehlo.multiply %4754, %cst_42 : tensor<1x1200x1280xbf16>
    %4756 = stablehlo.multiply %4754, %3243 : tensor<1x1200x1280xbf16>
    %4757 = stablehlo.convert %4756 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %4758 = stablehlo.clamp %cst_43, %4757, %cst_44 : tensor<1x1200x1280xf32>
    %4759 = stablehlo.multiply %4758, %4758 : tensor<1x1200x1280xf32>
    %4760 = stablehlo.multiply %cst_45, %4759 : tensor<1x1200x1280xf32>
    %4761 = stablehlo.add %4760, %cst_46 : tensor<1x1200x1280xf32>
    %4762 = stablehlo.multiply %4761, %4759 : tensor<1x1200x1280xf32>
    %4763 = stablehlo.add %4762, %cst_47 : tensor<1x1200x1280xf32>
    %4764 = stablehlo.multiply %4763, %4759 : tensor<1x1200x1280xf32>
    %4765 = stablehlo.add %4764, %cst_48 : tensor<1x1200x1280xf32>
    %4766 = stablehlo.multiply %4765, %4759 : tensor<1x1200x1280xf32>
    %4767 = stablehlo.add %4766, %cst_49 : tensor<1x1200x1280xf32>
    %4768 = stablehlo.multiply %4767, %4759 : tensor<1x1200x1280xf32>
    %4769 = stablehlo.add %4768, %cst_50 : tensor<1x1200x1280xf32>
    %4770 = stablehlo.multiply %4769, %4759 : tensor<1x1200x1280xf32>
    %4771 = stablehlo.add %4770, %cst_51 : tensor<1x1200x1280xf32>
    %4772 = stablehlo.multiply %cst_52, %4759 : tensor<1x1200x1280xf32>
    %4773 = stablehlo.add %4772, %cst_53 : tensor<1x1200x1280xf32>
    %4774 = stablehlo.multiply %4773, %4759 : tensor<1x1200x1280xf32>
    %4775 = stablehlo.add %4774, %cst_54 : tensor<1x1200x1280xf32>
    %4776 = stablehlo.multiply %4775, %4759 : tensor<1x1200x1280xf32>
    %4777 = stablehlo.add %4776, %cst_55 : tensor<1x1200x1280xf32>
    %4778 = stablehlo.multiply %4777, %4759 : tensor<1x1200x1280xf32>
    %4779 = stablehlo.add %4778, %cst_56 : tensor<1x1200x1280xf32>
    %4780 = stablehlo.multiply %4758, %4771 : tensor<1x1200x1280xf32>
    %4781 = stablehlo.divide %4780, %4779 : tensor<1x1200x1280xf32>
    %4782 = stablehlo.clamp %cst_57, %4781, %cst_58 : tensor<1x1200x1280xf32>
    %4783 = stablehlo.convert %4782 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %4784 = stablehlo.add %4783, %cst_40 : tensor<1x1200x1280xbf16>
    %4785 = stablehlo.multiply %4784, %4755 : tensor<1x1200x1280xbf16>
    %4786 = stablehlo.reshape %4785 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %4787 = stablehlo.dot_general %4786, %arg689, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %4788 = stablehlo.reshape %4787 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4789 = stablehlo.broadcast_in_dim %4788, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4790 = stablehlo.broadcast_in_dim %arg214, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %4791 = stablehlo.add %4789, %4790 : tensor<1x1200x320xbf16>
    %4792 = stablehlo.reshape %4791 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4793 = stablehlo.reshape %4792 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4794 = stablehlo.add %4793, %4698 : tensor<1x1200x320xbf16>
    %4795 = stablehlo.convert %4794 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4796 = stablehlo.convert %4795 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4797 = stablehlo.reduce(%4796 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4798 = stablehlo.reshape %4797 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4799 = stablehlo.broadcast_in_dim %4798, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4800 = stablehlo.divide %4799, %2987 : tensor<1x1200x1xf64>
    %4801 = stablehlo.broadcast_in_dim %4796, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4802 = stablehlo.broadcast_in_dim %4800, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4803 = stablehlo.subtract %4801, %4802 : tensor<1x1200x320xf64>
    %4804 = stablehlo.multiply %4803, %4803 : tensor<1x1200x320xf64>
    %4805 = stablehlo.reduce(%4804 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4806 = stablehlo.reshape %4805 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4807 = stablehlo.broadcast_in_dim %4806, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4808 = stablehlo.divide %4807, %2987 : tensor<1x1200x1xf64>
    %4809 = stablehlo.convert %4808 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4810 = stablehlo.reduce(%4795 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4811 = stablehlo.reshape %4810 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4812 = stablehlo.broadcast_in_dim %4811, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4813 = stablehlo.divide %4812, %3003 : tensor<1x1200x1xf32>
    %4814 = stablehlo.broadcast_in_dim %4809, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4815 = stablehlo.add %4814, %3006 : tensor<1x1200x1xf32>
    %4816 = stablehlo.rsqrt %4815 : tensor<1x1200x1xf32>
    %4817 = stablehlo.broadcast_in_dim %4795, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4818 = stablehlo.broadcast_in_dim %4813, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4819 = stablehlo.subtract %4817, %4818 : tensor<1x1200x320xf32>
    %4820 = stablehlo.broadcast_in_dim %4819, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4821 = stablehlo.broadcast_in_dim %4816, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4822 = stablehlo.multiply %4820, %4821 : tensor<1x1200x320xf32>
    %4823 = stablehlo.convert %arg215 : (tensor<320xbf16>) -> tensor<320xf32>
    %4824 = stablehlo.broadcast_in_dim %4822, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4825 = stablehlo.broadcast_in_dim %4823, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4826 = stablehlo.multiply %4824, %4825 : tensor<1x1200x320xf32>
    %4827 = stablehlo.convert %arg216 : (tensor<320xbf16>) -> tensor<320xf32>
    %4828 = stablehlo.broadcast_in_dim %4826, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4829 = stablehlo.broadcast_in_dim %4827, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4830 = stablehlo.add %4828, %4829 : tensor<1x1200x320xf32>
    %4831 = stablehlo.convert %4830 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4832 = stablehlo.reshape %4831 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4833 = stablehlo.convert %4832 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4834 = stablehlo.dot_general %4833, %arg690, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4835 = stablehlo.broadcast_in_dim %4834, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4836 = stablehlo.multiply %4835, %3065 : tensor<1200x320xf32>
    %4837 = stablehlo.broadcast_in_dim %4836, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4838 = stablehlo.broadcast_in_dim %arg691, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4839 = stablehlo.add %4837, %4838 : tensor<1200x320xf32>
    %4840 = stablehlo.convert %4839 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4841 = stablehlo.reshape %4840 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4842 = stablehlo.reshape %4841 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %4843 = stablehlo.transpose %4842, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4844 = stablehlo.transpose %4831, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %4845 = stablehlo.reshape %4844 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %4846 = stablehlo.convolution(%4845, %arg217) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %4847 = stablehlo.reshape %arg218 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %4848 = stablehlo.broadcast_in_dim %4846, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %4849 = stablehlo.broadcast_in_dim %4847, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %4850 = stablehlo.add %4848, %4849 : tensor<1x320x15x20xbf16>
    %4851 = stablehlo.reshape %4850 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %4852 = stablehlo.transpose %4851, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %4853 = stablehlo.convert %4852 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %4854 = stablehlo.convert %4853 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %4855 = stablehlo.reduce(%4854 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4856 = stablehlo.reshape %4855 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4857 = stablehlo.broadcast_in_dim %4856, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4858 = stablehlo.divide %4857, %3088 : tensor<1x300x1xf64>
    %4859 = stablehlo.broadcast_in_dim %4854, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %4860 = stablehlo.broadcast_in_dim %4858, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %4861 = stablehlo.subtract %4859, %4860 : tensor<1x300x320xf64>
    %4862 = stablehlo.multiply %4861, %4861 : tensor<1x300x320xf64>
    %4863 = stablehlo.reduce(%4862 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %4864 = stablehlo.reshape %4863 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %4865 = stablehlo.broadcast_in_dim %4864, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %4866 = stablehlo.divide %4865, %3088 : tensor<1x300x1xf64>
    %4867 = stablehlo.convert %4866 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %4868 = stablehlo.reduce(%4853 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %4869 = stablehlo.reshape %4868 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %4870 = stablehlo.broadcast_in_dim %4869, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4871 = stablehlo.divide %4870, %3102 : tensor<1x300x1xf32>
    %4872 = stablehlo.broadcast_in_dim %4867, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %4873 = stablehlo.add %4872, %136 : tensor<1x300x1xf32>
    %4874 = stablehlo.rsqrt %4873 : tensor<1x300x1xf32>
    %4875 = stablehlo.broadcast_in_dim %4853, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4876 = stablehlo.broadcast_in_dim %4871, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4877 = stablehlo.subtract %4875, %4876 : tensor<1x300x320xf32>
    %4878 = stablehlo.broadcast_in_dim %4877, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4879 = stablehlo.broadcast_in_dim %4874, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %4880 = stablehlo.multiply %4878, %4879 : tensor<1x300x320xf32>
    %4881 = stablehlo.convert %arg219 : (tensor<320xbf16>) -> tensor<320xf32>
    %4882 = stablehlo.broadcast_in_dim %4880, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4883 = stablehlo.broadcast_in_dim %4881, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4884 = stablehlo.multiply %4882, %4883 : tensor<1x300x320xf32>
    %4885 = stablehlo.convert %arg220 : (tensor<320xbf16>) -> tensor<320xf32>
    %4886 = stablehlo.broadcast_in_dim %4884, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %4887 = stablehlo.broadcast_in_dim %4885, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %4888 = stablehlo.add %4886, %4887 : tensor<1x300x320xf32>
    %4889 = stablehlo.convert %4888 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %4890 = stablehlo.reshape %4889 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %4891 = stablehlo.convert %4890 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %4892 = stablehlo.dot_general %4891, %arg692, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4893 = stablehlo.broadcast_in_dim %4892, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4894 = stablehlo.multiply %4893, %3126 : tensor<300x320xf32>
    %4895 = stablehlo.broadcast_in_dim %4894, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4896 = stablehlo.broadcast_in_dim %arg693, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4897 = stablehlo.add %4895, %4896 : tensor<300x320xf32>
    %4898 = stablehlo.convert %4897 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4899 = stablehlo.reshape %4898 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4900 = stablehlo.reshape %4899 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4901 = stablehlo.transpose %4900, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4902 = stablehlo.dot_general %4891, %arg694, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %4903 = stablehlo.broadcast_in_dim %4902, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4904 = stablehlo.multiply %4903, %3126 : tensor<300x320xf32>
    %4905 = stablehlo.broadcast_in_dim %4904, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %4906 = stablehlo.broadcast_in_dim %arg695, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %4907 = stablehlo.add %4905, %4906 : tensor<300x320xf32>
    %4908 = stablehlo.convert %4907 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %4909 = stablehlo.reshape %4908 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %4910 = stablehlo.reshape %4909 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %4911 = stablehlo.transpose %4910, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %4912 = stablehlo.transpose %4901, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %4913 = stablehlo.reshape %4843 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %4914 = stablehlo.reshape %4912 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4915 = stablehlo.broadcast_in_dim %4914, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %4916 = stablehlo.dot_general %4913, %4915, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %4917 = stablehlo.reshape %4916 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4918 = stablehlo.broadcast_in_dim %4917, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %4919 = stablehlo.divide %4918, %3152 : tensor<1x5x1200x300xbf16>
    %4920 = stablehlo.convert %4919 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %4921 = stablehlo.reduce(%4920 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4922 = stablehlo.reshape %4921 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4923 = stablehlo.broadcast_in_dim %4920, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4924 = stablehlo.broadcast_in_dim %4922, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4925 = stablehlo.subtract %4923, %4924 : tensor<1x5x1200x300xf32>
    %4926 = stablehlo.exponential %4925 : tensor<1x5x1200x300xf32>
    %4927 = stablehlo.reduce(%4926 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %4928 = stablehlo.reshape %4927 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %4929 = stablehlo.broadcast_in_dim %4926, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %4930 = stablehlo.broadcast_in_dim %4928, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %4931 = stablehlo.divide %4929, %4930 : tensor<1x5x1200x300xf32>
    %4932 = stablehlo.convert %4931 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %4933 = stablehlo.reshape %4932 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %4934 = stablehlo.reshape %4911 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4935 = stablehlo.broadcast_in_dim %4934, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %4936 = stablehlo.dot_general %4933, %4935, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %4937 = stablehlo.reshape %4936 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %4938 = stablehlo.transpose %4937, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %4939 = stablehlo.reshape %4938 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %4940 = stablehlo.reshape %4939 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4941 = stablehlo.convert %4940 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4942 = stablehlo.dot_general %4941, %arg696, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %4943 = stablehlo.broadcast_in_dim %4942, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4944 = stablehlo.multiply %4943, %3065 : tensor<1200x320xf32>
    %4945 = stablehlo.broadcast_in_dim %4944, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %4946 = stablehlo.broadcast_in_dim %arg697, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %4947 = stablehlo.add %4945, %4946 : tensor<1200x320xf32>
    %4948 = stablehlo.convert %4947 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %4949 = stablehlo.reshape %4948 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %4950 = stablehlo.add %4949, %4794 : tensor<1x1200x320xbf16>
    %4951 = stablehlo.convert %4950 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %4952 = stablehlo.convert %4951 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %4953 = stablehlo.reduce(%4952 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4954 = stablehlo.reshape %4953 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4955 = stablehlo.broadcast_in_dim %4954, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4956 = stablehlo.divide %4955, %2987 : tensor<1x1200x1xf64>
    %4957 = stablehlo.broadcast_in_dim %4952, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %4958 = stablehlo.broadcast_in_dim %4956, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %4959 = stablehlo.subtract %4957, %4958 : tensor<1x1200x320xf64>
    %4960 = stablehlo.multiply %4959, %4959 : tensor<1x1200x320xf64>
    %4961 = stablehlo.reduce(%4960 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %4962 = stablehlo.reshape %4961 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %4963 = stablehlo.broadcast_in_dim %4962, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %4964 = stablehlo.divide %4963, %2987 : tensor<1x1200x1xf64>
    %4965 = stablehlo.convert %4964 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %4966 = stablehlo.reduce(%4951 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %4967 = stablehlo.reshape %4966 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %4968 = stablehlo.broadcast_in_dim %4967, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4969 = stablehlo.divide %4968, %3003 : tensor<1x1200x1xf32>
    %4970 = stablehlo.broadcast_in_dim %4965, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %4971 = stablehlo.add %4970, %3006 : tensor<1x1200x1xf32>
    %4972 = stablehlo.rsqrt %4971 : tensor<1x1200x1xf32>
    %4973 = stablehlo.broadcast_in_dim %4951, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4974 = stablehlo.broadcast_in_dim %4969, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4975 = stablehlo.subtract %4973, %4974 : tensor<1x1200x320xf32>
    %4976 = stablehlo.broadcast_in_dim %4975, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4977 = stablehlo.broadcast_in_dim %4972, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %4978 = stablehlo.multiply %4976, %4977 : tensor<1x1200x320xf32>
    %4979 = stablehlo.convert %arg221 : (tensor<320xbf16>) -> tensor<320xf32>
    %4980 = stablehlo.broadcast_in_dim %4978, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4981 = stablehlo.broadcast_in_dim %4979, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4982 = stablehlo.multiply %4980, %4981 : tensor<1x1200x320xf32>
    %4983 = stablehlo.convert %arg222 : (tensor<320xbf16>) -> tensor<320xf32>
    %4984 = stablehlo.broadcast_in_dim %4982, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %4985 = stablehlo.broadcast_in_dim %4983, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %4986 = stablehlo.add %4984, %4985 : tensor<1x1200x320xf32>
    %4987 = stablehlo.convert %4986 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %4988 = stablehlo.reshape %4987 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %4989 = stablehlo.convert %4988 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %4990 = stablehlo.dot_general %4989, %arg698, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %4991 = stablehlo.broadcast_in_dim %4990, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4992 = stablehlo.multiply %4991, %3226 : tensor<1200x1280xf32>
    %4993 = stablehlo.broadcast_in_dim %4992, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %4994 = stablehlo.broadcast_in_dim %arg699, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %4995 = stablehlo.add %4993, %4994 : tensor<1200x1280xf32>
    %4996 = stablehlo.convert %4995 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %4997 = stablehlo.reshape %4996 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %4998 = stablehlo.transpose %4997, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %4999 = stablehlo.reshape %4998 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %5000 = stablehlo.convolution(%4999, %arg223) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %5001 = stablehlo.reshape %arg224 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %5002 = stablehlo.broadcast_in_dim %5000, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %5003 = stablehlo.broadcast_in_dim %5001, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %5004 = stablehlo.add %5002, %5003 : tensor<1x1280x30x40xbf16>
    %5005 = stablehlo.reshape %5004 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %5006 = stablehlo.transpose %5005, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %5007 = stablehlo.multiply %5006, %cst_42 : tensor<1x1200x1280xbf16>
    %5008 = stablehlo.multiply %5006, %3243 : tensor<1x1200x1280xbf16>
    %5009 = stablehlo.convert %5008 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %5010 = stablehlo.clamp %cst_43, %5009, %cst_44 : tensor<1x1200x1280xf32>
    %5011 = stablehlo.multiply %5010, %5010 : tensor<1x1200x1280xf32>
    %5012 = stablehlo.multiply %cst_45, %5011 : tensor<1x1200x1280xf32>
    %5013 = stablehlo.add %5012, %cst_46 : tensor<1x1200x1280xf32>
    %5014 = stablehlo.multiply %5013, %5011 : tensor<1x1200x1280xf32>
    %5015 = stablehlo.add %5014, %cst_47 : tensor<1x1200x1280xf32>
    %5016 = stablehlo.multiply %5015, %5011 : tensor<1x1200x1280xf32>
    %5017 = stablehlo.add %5016, %cst_48 : tensor<1x1200x1280xf32>
    %5018 = stablehlo.multiply %5017, %5011 : tensor<1x1200x1280xf32>
    %5019 = stablehlo.add %5018, %cst_49 : tensor<1x1200x1280xf32>
    %5020 = stablehlo.multiply %5019, %5011 : tensor<1x1200x1280xf32>
    %5021 = stablehlo.add %5020, %cst_50 : tensor<1x1200x1280xf32>
    %5022 = stablehlo.multiply %5021, %5011 : tensor<1x1200x1280xf32>
    %5023 = stablehlo.add %5022, %cst_51 : tensor<1x1200x1280xf32>
    %5024 = stablehlo.multiply %cst_52, %5011 : tensor<1x1200x1280xf32>
    %5025 = stablehlo.add %5024, %cst_53 : tensor<1x1200x1280xf32>
    %5026 = stablehlo.multiply %5025, %5011 : tensor<1x1200x1280xf32>
    %5027 = stablehlo.add %5026, %cst_54 : tensor<1x1200x1280xf32>
    %5028 = stablehlo.multiply %5027, %5011 : tensor<1x1200x1280xf32>
    %5029 = stablehlo.add %5028, %cst_55 : tensor<1x1200x1280xf32>
    %5030 = stablehlo.multiply %5029, %5011 : tensor<1x1200x1280xf32>
    %5031 = stablehlo.add %5030, %cst_56 : tensor<1x1200x1280xf32>
    %5032 = stablehlo.multiply %5010, %5023 : tensor<1x1200x1280xf32>
    %5033 = stablehlo.divide %5032, %5031 : tensor<1x1200x1280xf32>
    %5034 = stablehlo.clamp %cst_57, %5033, %cst_58 : tensor<1x1200x1280xf32>
    %5035 = stablehlo.convert %5034 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %5036 = stablehlo.add %5035, %cst_40 : tensor<1x1200x1280xbf16>
    %5037 = stablehlo.multiply %5036, %5007 : tensor<1x1200x1280xbf16>
    %5038 = stablehlo.reshape %5037 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %5039 = stablehlo.dot_general %5038, %arg700, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %5040 = stablehlo.reshape %5039 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5041 = stablehlo.broadcast_in_dim %5040, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5042 = stablehlo.broadcast_in_dim %arg225, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %5043 = stablehlo.add %5041, %5042 : tensor<1x1200x320xbf16>
    %5044 = stablehlo.reshape %5043 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5045 = stablehlo.reshape %5044 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5046 = stablehlo.add %5045, %4950 : tensor<1x1200x320xbf16>
    %5047 = stablehlo.convert %5046 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5048 = stablehlo.convert %5047 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5049 = stablehlo.reduce(%5048 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5050 = stablehlo.reshape %5049 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5051 = stablehlo.broadcast_in_dim %5050, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5052 = stablehlo.divide %5051, %2987 : tensor<1x1200x1xf64>
    %5053 = stablehlo.broadcast_in_dim %5048, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5054 = stablehlo.broadcast_in_dim %5052, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5055 = stablehlo.subtract %5053, %5054 : tensor<1x1200x320xf64>
    %5056 = stablehlo.multiply %5055, %5055 : tensor<1x1200x320xf64>
    %5057 = stablehlo.reduce(%5056 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5058 = stablehlo.reshape %5057 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5059 = stablehlo.broadcast_in_dim %5058, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5060 = stablehlo.divide %5059, %2987 : tensor<1x1200x1xf64>
    %5061 = stablehlo.convert %5060 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5062 = stablehlo.reduce(%5047 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5063 = stablehlo.reshape %5062 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5064 = stablehlo.broadcast_in_dim %5063, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5065 = stablehlo.divide %5064, %3003 : tensor<1x1200x1xf32>
    %5066 = stablehlo.broadcast_in_dim %5061, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5067 = stablehlo.add %5066, %3006 : tensor<1x1200x1xf32>
    %5068 = stablehlo.rsqrt %5067 : tensor<1x1200x1xf32>
    %5069 = stablehlo.broadcast_in_dim %5047, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5070 = stablehlo.broadcast_in_dim %5065, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5071 = stablehlo.subtract %5069, %5070 : tensor<1x1200x320xf32>
    %5072 = stablehlo.broadcast_in_dim %5071, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5073 = stablehlo.broadcast_in_dim %5068, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5074 = stablehlo.multiply %5072, %5073 : tensor<1x1200x320xf32>
    %5075 = stablehlo.convert %arg226 : (tensor<320xbf16>) -> tensor<320xf32>
    %5076 = stablehlo.broadcast_in_dim %5074, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5077 = stablehlo.broadcast_in_dim %5075, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5078 = stablehlo.multiply %5076, %5077 : tensor<1x1200x320xf32>
    %5079 = stablehlo.convert %arg227 : (tensor<320xbf16>) -> tensor<320xf32>
    %5080 = stablehlo.broadcast_in_dim %5078, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5081 = stablehlo.broadcast_in_dim %5079, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5082 = stablehlo.add %5080, %5081 : tensor<1x1200x320xf32>
    %5083 = stablehlo.convert %5082 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5084 = stablehlo.reshape %5083 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5085 = stablehlo.convert %5084 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5086 = stablehlo.dot_general %5085, %arg701, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5087 = stablehlo.broadcast_in_dim %5086, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5088 = stablehlo.multiply %5087, %3065 : tensor<1200x320xf32>
    %5089 = stablehlo.broadcast_in_dim %5088, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5090 = stablehlo.broadcast_in_dim %arg702, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5091 = stablehlo.add %5089, %5090 : tensor<1200x320xf32>
    %5092 = stablehlo.convert %5091 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5093 = stablehlo.reshape %5092 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5094 = stablehlo.reshape %5093 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %5095 = stablehlo.transpose %5094, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5096 = stablehlo.transpose %5083, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %5097 = stablehlo.reshape %5096 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %5098 = stablehlo.convolution(%5097, %arg228) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %5099 = stablehlo.reshape %arg229 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %5100 = stablehlo.broadcast_in_dim %5098, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %5101 = stablehlo.broadcast_in_dim %5099, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %5102 = stablehlo.add %5100, %5101 : tensor<1x320x15x20xbf16>
    %5103 = stablehlo.reshape %5102 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %5104 = stablehlo.transpose %5103, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %5105 = stablehlo.convert %5104 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %5106 = stablehlo.convert %5105 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %5107 = stablehlo.reduce(%5106 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5108 = stablehlo.reshape %5107 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5109 = stablehlo.broadcast_in_dim %5108, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5110 = stablehlo.divide %5109, %3088 : tensor<1x300x1xf64>
    %5111 = stablehlo.broadcast_in_dim %5106, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %5112 = stablehlo.broadcast_in_dim %5110, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %5113 = stablehlo.subtract %5111, %5112 : tensor<1x300x320xf64>
    %5114 = stablehlo.multiply %5113, %5113 : tensor<1x300x320xf64>
    %5115 = stablehlo.reduce(%5114 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5116 = stablehlo.reshape %5115 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5117 = stablehlo.broadcast_in_dim %5116, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5118 = stablehlo.divide %5117, %3088 : tensor<1x300x1xf64>
    %5119 = stablehlo.convert %5118 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %5120 = stablehlo.reduce(%5105 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %5121 = stablehlo.reshape %5120 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %5122 = stablehlo.broadcast_in_dim %5121, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5123 = stablehlo.divide %5122, %3102 : tensor<1x300x1xf32>
    %5124 = stablehlo.broadcast_in_dim %5119, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5125 = stablehlo.add %5124, %136 : tensor<1x300x1xf32>
    %5126 = stablehlo.rsqrt %5125 : tensor<1x300x1xf32>
    %5127 = stablehlo.broadcast_in_dim %5105, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5128 = stablehlo.broadcast_in_dim %5123, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5129 = stablehlo.subtract %5127, %5128 : tensor<1x300x320xf32>
    %5130 = stablehlo.broadcast_in_dim %5129, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5131 = stablehlo.broadcast_in_dim %5126, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5132 = stablehlo.multiply %5130, %5131 : tensor<1x300x320xf32>
    %5133 = stablehlo.convert %arg230 : (tensor<320xbf16>) -> tensor<320xf32>
    %5134 = stablehlo.broadcast_in_dim %5132, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5135 = stablehlo.broadcast_in_dim %5133, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5136 = stablehlo.multiply %5134, %5135 : tensor<1x300x320xf32>
    %5137 = stablehlo.convert %arg231 : (tensor<320xbf16>) -> tensor<320xf32>
    %5138 = stablehlo.broadcast_in_dim %5136, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5139 = stablehlo.broadcast_in_dim %5137, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5140 = stablehlo.add %5138, %5139 : tensor<1x300x320xf32>
    %5141 = stablehlo.convert %5140 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %5142 = stablehlo.reshape %5141 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %5143 = stablehlo.convert %5142 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %5144 = stablehlo.dot_general %5143, %arg703, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5145 = stablehlo.broadcast_in_dim %5144, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5146 = stablehlo.multiply %5145, %3126 : tensor<300x320xf32>
    %5147 = stablehlo.broadcast_in_dim %5146, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5148 = stablehlo.broadcast_in_dim %arg704, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5149 = stablehlo.add %5147, %5148 : tensor<300x320xf32>
    %5150 = stablehlo.convert %5149 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5151 = stablehlo.reshape %5150 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5152 = stablehlo.reshape %5151 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5153 = stablehlo.transpose %5152, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5154 = stablehlo.dot_general %5143, %arg705, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5155 = stablehlo.broadcast_in_dim %5154, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5156 = stablehlo.multiply %5155, %3126 : tensor<300x320xf32>
    %5157 = stablehlo.broadcast_in_dim %5156, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5158 = stablehlo.broadcast_in_dim %arg706, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5159 = stablehlo.add %5157, %5158 : tensor<300x320xf32>
    %5160 = stablehlo.convert %5159 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5161 = stablehlo.reshape %5160 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5162 = stablehlo.reshape %5161 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5163 = stablehlo.transpose %5162, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5164 = stablehlo.transpose %5153, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %5165 = stablehlo.reshape %5095 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %5166 = stablehlo.reshape %5164 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5167 = stablehlo.broadcast_in_dim %5166, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5168 = stablehlo.dot_general %5165, %5167, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %5169 = stablehlo.reshape %5168 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5170 = stablehlo.broadcast_in_dim %5169, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5171 = stablehlo.divide %5170, %3152 : tensor<1x5x1200x300xbf16>
    %5172 = stablehlo.convert %5171 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %5173 = stablehlo.reduce(%5172 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5174 = stablehlo.reshape %5173 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5175 = stablehlo.broadcast_in_dim %5172, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5176 = stablehlo.broadcast_in_dim %5174, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5177 = stablehlo.subtract %5175, %5176 : tensor<1x5x1200x300xf32>
    %5178 = stablehlo.exponential %5177 : tensor<1x5x1200x300xf32>
    %5179 = stablehlo.reduce(%5178 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5180 = stablehlo.reshape %5179 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5181 = stablehlo.broadcast_in_dim %5178, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5182 = stablehlo.broadcast_in_dim %5180, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5183 = stablehlo.divide %5181, %5182 : tensor<1x5x1200x300xf32>
    %5184 = stablehlo.convert %5183 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %5185 = stablehlo.reshape %5184 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %5186 = stablehlo.reshape %5163 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5187 = stablehlo.broadcast_in_dim %5186, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5188 = stablehlo.dot_general %5185, %5187, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %5189 = stablehlo.reshape %5188 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5190 = stablehlo.transpose %5189, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %5191 = stablehlo.reshape %5190 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %5192 = stablehlo.reshape %5191 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5193 = stablehlo.convert %5192 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5194 = stablehlo.dot_general %5193, %arg707, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5195 = stablehlo.broadcast_in_dim %5194, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5196 = stablehlo.multiply %5195, %3065 : tensor<1200x320xf32>
    %5197 = stablehlo.broadcast_in_dim %5196, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5198 = stablehlo.broadcast_in_dim %arg708, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5199 = stablehlo.add %5197, %5198 : tensor<1200x320xf32>
    %5200 = stablehlo.convert %5199 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5201 = stablehlo.reshape %5200 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5202 = stablehlo.add %5201, %5046 : tensor<1x1200x320xbf16>
    %5203 = stablehlo.convert %5202 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5204 = stablehlo.convert %5203 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5205 = stablehlo.reduce(%5204 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5206 = stablehlo.reshape %5205 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5207 = stablehlo.broadcast_in_dim %5206, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5208 = stablehlo.divide %5207, %2987 : tensor<1x1200x1xf64>
    %5209 = stablehlo.broadcast_in_dim %5204, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5210 = stablehlo.broadcast_in_dim %5208, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5211 = stablehlo.subtract %5209, %5210 : tensor<1x1200x320xf64>
    %5212 = stablehlo.multiply %5211, %5211 : tensor<1x1200x320xf64>
    %5213 = stablehlo.reduce(%5212 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5214 = stablehlo.reshape %5213 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5215 = stablehlo.broadcast_in_dim %5214, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5216 = stablehlo.divide %5215, %2987 : tensor<1x1200x1xf64>
    %5217 = stablehlo.convert %5216 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5218 = stablehlo.reduce(%5203 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5219 = stablehlo.reshape %5218 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5220 = stablehlo.broadcast_in_dim %5219, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5221 = stablehlo.divide %5220, %3003 : tensor<1x1200x1xf32>
    %5222 = stablehlo.broadcast_in_dim %5217, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5223 = stablehlo.add %5222, %3006 : tensor<1x1200x1xf32>
    %5224 = stablehlo.rsqrt %5223 : tensor<1x1200x1xf32>
    %5225 = stablehlo.broadcast_in_dim %5203, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5226 = stablehlo.broadcast_in_dim %5221, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5227 = stablehlo.subtract %5225, %5226 : tensor<1x1200x320xf32>
    %5228 = stablehlo.broadcast_in_dim %5227, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5229 = stablehlo.broadcast_in_dim %5224, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5230 = stablehlo.multiply %5228, %5229 : tensor<1x1200x320xf32>
    %5231 = stablehlo.convert %arg232 : (tensor<320xbf16>) -> tensor<320xf32>
    %5232 = stablehlo.broadcast_in_dim %5230, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5233 = stablehlo.broadcast_in_dim %5231, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5234 = stablehlo.multiply %5232, %5233 : tensor<1x1200x320xf32>
    %5235 = stablehlo.convert %arg233 : (tensor<320xbf16>) -> tensor<320xf32>
    %5236 = stablehlo.broadcast_in_dim %5234, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5237 = stablehlo.broadcast_in_dim %5235, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5238 = stablehlo.add %5236, %5237 : tensor<1x1200x320xf32>
    %5239 = stablehlo.convert %5238 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5240 = stablehlo.reshape %5239 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5241 = stablehlo.convert %5240 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5242 = stablehlo.dot_general %5241, %arg709, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %5243 = stablehlo.broadcast_in_dim %5242, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %5244 = stablehlo.multiply %5243, %3226 : tensor<1200x1280xf32>
    %5245 = stablehlo.broadcast_in_dim %5244, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %5246 = stablehlo.broadcast_in_dim %arg710, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %5247 = stablehlo.add %5245, %5246 : tensor<1200x1280xf32>
    %5248 = stablehlo.convert %5247 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %5249 = stablehlo.reshape %5248 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %5250 = stablehlo.transpose %5249, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %5251 = stablehlo.reshape %5250 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %5252 = stablehlo.convolution(%5251, %arg234) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %5253 = stablehlo.reshape %arg235 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %5254 = stablehlo.broadcast_in_dim %5252, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %5255 = stablehlo.broadcast_in_dim %5253, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %5256 = stablehlo.add %5254, %5255 : tensor<1x1280x30x40xbf16>
    %5257 = stablehlo.reshape %5256 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %5258 = stablehlo.transpose %5257, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %5259 = stablehlo.multiply %5258, %cst_42 : tensor<1x1200x1280xbf16>
    %5260 = stablehlo.multiply %5258, %3243 : tensor<1x1200x1280xbf16>
    %5261 = stablehlo.convert %5260 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %5262 = stablehlo.clamp %cst_43, %5261, %cst_44 : tensor<1x1200x1280xf32>
    %5263 = stablehlo.multiply %5262, %5262 : tensor<1x1200x1280xf32>
    %5264 = stablehlo.multiply %cst_45, %5263 : tensor<1x1200x1280xf32>
    %5265 = stablehlo.add %5264, %cst_46 : tensor<1x1200x1280xf32>
    %5266 = stablehlo.multiply %5265, %5263 : tensor<1x1200x1280xf32>
    %5267 = stablehlo.add %5266, %cst_47 : tensor<1x1200x1280xf32>
    %5268 = stablehlo.multiply %5267, %5263 : tensor<1x1200x1280xf32>
    %5269 = stablehlo.add %5268, %cst_48 : tensor<1x1200x1280xf32>
    %5270 = stablehlo.multiply %5269, %5263 : tensor<1x1200x1280xf32>
    %5271 = stablehlo.add %5270, %cst_49 : tensor<1x1200x1280xf32>
    %5272 = stablehlo.multiply %5271, %5263 : tensor<1x1200x1280xf32>
    %5273 = stablehlo.add %5272, %cst_50 : tensor<1x1200x1280xf32>
    %5274 = stablehlo.multiply %5273, %5263 : tensor<1x1200x1280xf32>
    %5275 = stablehlo.add %5274, %cst_51 : tensor<1x1200x1280xf32>
    %5276 = stablehlo.multiply %cst_52, %5263 : tensor<1x1200x1280xf32>
    %5277 = stablehlo.add %5276, %cst_53 : tensor<1x1200x1280xf32>
    %5278 = stablehlo.multiply %5277, %5263 : tensor<1x1200x1280xf32>
    %5279 = stablehlo.add %5278, %cst_54 : tensor<1x1200x1280xf32>
    %5280 = stablehlo.multiply %5279, %5263 : tensor<1x1200x1280xf32>
    %5281 = stablehlo.add %5280, %cst_55 : tensor<1x1200x1280xf32>
    %5282 = stablehlo.multiply %5281, %5263 : tensor<1x1200x1280xf32>
    %5283 = stablehlo.add %5282, %cst_56 : tensor<1x1200x1280xf32>
    %5284 = stablehlo.multiply %5262, %5275 : tensor<1x1200x1280xf32>
    %5285 = stablehlo.divide %5284, %5283 : tensor<1x1200x1280xf32>
    %5286 = stablehlo.clamp %cst_57, %5285, %cst_58 : tensor<1x1200x1280xf32>
    %5287 = stablehlo.convert %5286 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %5288 = stablehlo.add %5287, %cst_40 : tensor<1x1200x1280xbf16>
    %5289 = stablehlo.multiply %5288, %5259 : tensor<1x1200x1280xbf16>
    %5290 = stablehlo.reshape %5289 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %5291 = stablehlo.dot_general %5290, %arg711, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %5292 = stablehlo.reshape %5291 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5293 = stablehlo.broadcast_in_dim %5292, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5294 = stablehlo.broadcast_in_dim %arg236, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %5295 = stablehlo.add %5293, %5294 : tensor<1x1200x320xbf16>
    %5296 = stablehlo.reshape %5295 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5297 = stablehlo.reshape %5296 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5298 = stablehlo.add %5297, %5202 : tensor<1x1200x320xbf16>
    %5299 = stablehlo.convert %5298 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5300 = stablehlo.convert %5299 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5301 = stablehlo.reduce(%5300 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5302 = stablehlo.reshape %5301 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5303 = stablehlo.broadcast_in_dim %5302, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5304 = stablehlo.divide %5303, %2987 : tensor<1x1200x1xf64>
    %5305 = stablehlo.broadcast_in_dim %5300, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5306 = stablehlo.broadcast_in_dim %5304, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5307 = stablehlo.subtract %5305, %5306 : tensor<1x1200x320xf64>
    %5308 = stablehlo.multiply %5307, %5307 : tensor<1x1200x320xf64>
    %5309 = stablehlo.reduce(%5308 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5310 = stablehlo.reshape %5309 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5311 = stablehlo.broadcast_in_dim %5310, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5312 = stablehlo.divide %5311, %2987 : tensor<1x1200x1xf64>
    %5313 = stablehlo.convert %5312 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5314 = stablehlo.reduce(%5299 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5315 = stablehlo.reshape %5314 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5316 = stablehlo.broadcast_in_dim %5315, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5317 = stablehlo.divide %5316, %3003 : tensor<1x1200x1xf32>
    %5318 = stablehlo.broadcast_in_dim %5313, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5319 = stablehlo.add %5318, %3006 : tensor<1x1200x1xf32>
    %5320 = stablehlo.rsqrt %5319 : tensor<1x1200x1xf32>
    %5321 = stablehlo.broadcast_in_dim %5299, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5322 = stablehlo.broadcast_in_dim %5317, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5323 = stablehlo.subtract %5321, %5322 : tensor<1x1200x320xf32>
    %5324 = stablehlo.broadcast_in_dim %5323, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5325 = stablehlo.broadcast_in_dim %5320, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5326 = stablehlo.multiply %5324, %5325 : tensor<1x1200x320xf32>
    %5327 = stablehlo.convert %arg237 : (tensor<320xbf16>) -> tensor<320xf32>
    %5328 = stablehlo.broadcast_in_dim %5326, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5329 = stablehlo.broadcast_in_dim %5327, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5330 = stablehlo.multiply %5328, %5329 : tensor<1x1200x320xf32>
    %5331 = stablehlo.convert %arg238 : (tensor<320xbf16>) -> tensor<320xf32>
    %5332 = stablehlo.broadcast_in_dim %5330, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5333 = stablehlo.broadcast_in_dim %5331, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5334 = stablehlo.add %5332, %5333 : tensor<1x1200x320xf32>
    %5335 = stablehlo.convert %5334 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5336 = stablehlo.reshape %5335 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5337 = stablehlo.convert %5336 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5338 = stablehlo.dot_general %5337, %arg712, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5339 = stablehlo.broadcast_in_dim %5338, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5340 = stablehlo.multiply %5339, %3065 : tensor<1200x320xf32>
    %5341 = stablehlo.broadcast_in_dim %5340, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5342 = stablehlo.broadcast_in_dim %arg713, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5343 = stablehlo.add %5341, %5342 : tensor<1200x320xf32>
    %5344 = stablehlo.convert %5343 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5345 = stablehlo.reshape %5344 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5346 = stablehlo.reshape %5345 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %5347 = stablehlo.transpose %5346, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5348 = stablehlo.transpose %5335, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %5349 = stablehlo.reshape %5348 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %5350 = stablehlo.convolution(%5349, %arg239) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %5351 = stablehlo.reshape %arg240 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %5352 = stablehlo.broadcast_in_dim %5350, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %5353 = stablehlo.broadcast_in_dim %5351, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %5354 = stablehlo.add %5352, %5353 : tensor<1x320x15x20xbf16>
    %5355 = stablehlo.reshape %5354 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %5356 = stablehlo.transpose %5355, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %5357 = stablehlo.convert %5356 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %5358 = stablehlo.convert %5357 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %5359 = stablehlo.reduce(%5358 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5360 = stablehlo.reshape %5359 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5361 = stablehlo.broadcast_in_dim %5360, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5362 = stablehlo.divide %5361, %3088 : tensor<1x300x1xf64>
    %5363 = stablehlo.broadcast_in_dim %5358, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %5364 = stablehlo.broadcast_in_dim %5362, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %5365 = stablehlo.subtract %5363, %5364 : tensor<1x300x320xf64>
    %5366 = stablehlo.multiply %5365, %5365 : tensor<1x300x320xf64>
    %5367 = stablehlo.reduce(%5366 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5368 = stablehlo.reshape %5367 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5369 = stablehlo.broadcast_in_dim %5368, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5370 = stablehlo.divide %5369, %3088 : tensor<1x300x1xf64>
    %5371 = stablehlo.convert %5370 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %5372 = stablehlo.reduce(%5357 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %5373 = stablehlo.reshape %5372 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %5374 = stablehlo.broadcast_in_dim %5373, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5375 = stablehlo.divide %5374, %3102 : tensor<1x300x1xf32>
    %5376 = stablehlo.broadcast_in_dim %5371, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5377 = stablehlo.add %5376, %136 : tensor<1x300x1xf32>
    %5378 = stablehlo.rsqrt %5377 : tensor<1x300x1xf32>
    %5379 = stablehlo.broadcast_in_dim %5357, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5380 = stablehlo.broadcast_in_dim %5375, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5381 = stablehlo.subtract %5379, %5380 : tensor<1x300x320xf32>
    %5382 = stablehlo.broadcast_in_dim %5381, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5383 = stablehlo.broadcast_in_dim %5378, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5384 = stablehlo.multiply %5382, %5383 : tensor<1x300x320xf32>
    %5385 = stablehlo.convert %arg241 : (tensor<320xbf16>) -> tensor<320xf32>
    %5386 = stablehlo.broadcast_in_dim %5384, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5387 = stablehlo.broadcast_in_dim %5385, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5388 = stablehlo.multiply %5386, %5387 : tensor<1x300x320xf32>
    %5389 = stablehlo.convert %arg242 : (tensor<320xbf16>) -> tensor<320xf32>
    %5390 = stablehlo.broadcast_in_dim %5388, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5391 = stablehlo.broadcast_in_dim %5389, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5392 = stablehlo.add %5390, %5391 : tensor<1x300x320xf32>
    %5393 = stablehlo.convert %5392 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %5394 = stablehlo.reshape %5393 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %5395 = stablehlo.convert %5394 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %5396 = stablehlo.dot_general %5395, %arg714, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5397 = stablehlo.broadcast_in_dim %5396, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5398 = stablehlo.multiply %5397, %3126 : tensor<300x320xf32>
    %5399 = stablehlo.broadcast_in_dim %5398, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5400 = stablehlo.broadcast_in_dim %arg715, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5401 = stablehlo.add %5399, %5400 : tensor<300x320xf32>
    %5402 = stablehlo.convert %5401 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5403 = stablehlo.reshape %5402 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5404 = stablehlo.reshape %5403 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5405 = stablehlo.transpose %5404, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5406 = stablehlo.dot_general %5395, %arg716, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5407 = stablehlo.broadcast_in_dim %5406, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5408 = stablehlo.multiply %5407, %3126 : tensor<300x320xf32>
    %5409 = stablehlo.broadcast_in_dim %5408, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5410 = stablehlo.broadcast_in_dim %arg717, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5411 = stablehlo.add %5409, %5410 : tensor<300x320xf32>
    %5412 = stablehlo.convert %5411 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5413 = stablehlo.reshape %5412 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5414 = stablehlo.reshape %5413 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5415 = stablehlo.transpose %5414, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5416 = stablehlo.transpose %5405, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %5417 = stablehlo.reshape %5347 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %5418 = stablehlo.reshape %5416 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5419 = stablehlo.broadcast_in_dim %5418, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5420 = stablehlo.dot_general %5417, %5419, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %5421 = stablehlo.reshape %5420 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5422 = stablehlo.broadcast_in_dim %5421, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5423 = stablehlo.divide %5422, %3152 : tensor<1x5x1200x300xbf16>
    %5424 = stablehlo.convert %5423 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %5425 = stablehlo.reduce(%5424 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5426 = stablehlo.reshape %5425 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5427 = stablehlo.broadcast_in_dim %5424, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5428 = stablehlo.broadcast_in_dim %5426, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5429 = stablehlo.subtract %5427, %5428 : tensor<1x5x1200x300xf32>
    %5430 = stablehlo.exponential %5429 : tensor<1x5x1200x300xf32>
    %5431 = stablehlo.reduce(%5430 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5432 = stablehlo.reshape %5431 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5433 = stablehlo.broadcast_in_dim %5430, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5434 = stablehlo.broadcast_in_dim %5432, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5435 = stablehlo.divide %5433, %5434 : tensor<1x5x1200x300xf32>
    %5436 = stablehlo.convert %5435 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %5437 = stablehlo.reshape %5436 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %5438 = stablehlo.reshape %5415 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5439 = stablehlo.broadcast_in_dim %5438, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5440 = stablehlo.dot_general %5437, %5439, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %5441 = stablehlo.reshape %5440 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5442 = stablehlo.transpose %5441, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %5443 = stablehlo.reshape %5442 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %5444 = stablehlo.reshape %5443 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5445 = stablehlo.convert %5444 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5446 = stablehlo.dot_general %5445, %arg718, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5447 = stablehlo.broadcast_in_dim %5446, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5448 = stablehlo.multiply %5447, %3065 : tensor<1200x320xf32>
    %5449 = stablehlo.broadcast_in_dim %5448, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5450 = stablehlo.broadcast_in_dim %arg719, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5451 = stablehlo.add %5449, %5450 : tensor<1200x320xf32>
    %5452 = stablehlo.convert %5451 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5453 = stablehlo.reshape %5452 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5454 = stablehlo.add %5453, %5298 : tensor<1x1200x320xbf16>
    %5455 = stablehlo.convert %5454 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5456 = stablehlo.convert %5455 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5457 = stablehlo.reduce(%5456 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5458 = stablehlo.reshape %5457 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5459 = stablehlo.broadcast_in_dim %5458, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5460 = stablehlo.divide %5459, %2987 : tensor<1x1200x1xf64>
    %5461 = stablehlo.broadcast_in_dim %5456, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5462 = stablehlo.broadcast_in_dim %5460, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5463 = stablehlo.subtract %5461, %5462 : tensor<1x1200x320xf64>
    %5464 = stablehlo.multiply %5463, %5463 : tensor<1x1200x320xf64>
    %5465 = stablehlo.reduce(%5464 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5466 = stablehlo.reshape %5465 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5467 = stablehlo.broadcast_in_dim %5466, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5468 = stablehlo.divide %5467, %2987 : tensor<1x1200x1xf64>
    %5469 = stablehlo.convert %5468 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5470 = stablehlo.reduce(%5455 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5471 = stablehlo.reshape %5470 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5472 = stablehlo.broadcast_in_dim %5471, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5473 = stablehlo.divide %5472, %3003 : tensor<1x1200x1xf32>
    %5474 = stablehlo.broadcast_in_dim %5469, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5475 = stablehlo.add %5474, %3006 : tensor<1x1200x1xf32>
    %5476 = stablehlo.rsqrt %5475 : tensor<1x1200x1xf32>
    %5477 = stablehlo.broadcast_in_dim %5455, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5478 = stablehlo.broadcast_in_dim %5473, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5479 = stablehlo.subtract %5477, %5478 : tensor<1x1200x320xf32>
    %5480 = stablehlo.broadcast_in_dim %5479, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5481 = stablehlo.broadcast_in_dim %5476, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5482 = stablehlo.multiply %5480, %5481 : tensor<1x1200x320xf32>
    %5483 = stablehlo.convert %arg243 : (tensor<320xbf16>) -> tensor<320xf32>
    %5484 = stablehlo.broadcast_in_dim %5482, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5485 = stablehlo.broadcast_in_dim %5483, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5486 = stablehlo.multiply %5484, %5485 : tensor<1x1200x320xf32>
    %5487 = stablehlo.convert %arg244 : (tensor<320xbf16>) -> tensor<320xf32>
    %5488 = stablehlo.broadcast_in_dim %5486, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5489 = stablehlo.broadcast_in_dim %5487, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5490 = stablehlo.add %5488, %5489 : tensor<1x1200x320xf32>
    %5491 = stablehlo.convert %5490 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5492 = stablehlo.reshape %5491 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5493 = stablehlo.convert %5492 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5494 = stablehlo.dot_general %5493, %arg720, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %5495 = stablehlo.broadcast_in_dim %5494, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %5496 = stablehlo.multiply %5495, %3226 : tensor<1200x1280xf32>
    %5497 = stablehlo.broadcast_in_dim %5496, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %5498 = stablehlo.broadcast_in_dim %arg721, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %5499 = stablehlo.add %5497, %5498 : tensor<1200x1280xf32>
    %5500 = stablehlo.convert %5499 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %5501 = stablehlo.reshape %5500 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %5502 = stablehlo.transpose %5501, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %5503 = stablehlo.reshape %5502 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %5504 = stablehlo.convolution(%5503, %arg245) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %5505 = stablehlo.reshape %arg246 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %5506 = stablehlo.broadcast_in_dim %5504, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %5507 = stablehlo.broadcast_in_dim %5505, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %5508 = stablehlo.add %5506, %5507 : tensor<1x1280x30x40xbf16>
    %5509 = stablehlo.reshape %5508 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %5510 = stablehlo.transpose %5509, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %5511 = stablehlo.multiply %5510, %cst_42 : tensor<1x1200x1280xbf16>
    %5512 = stablehlo.multiply %5510, %3243 : tensor<1x1200x1280xbf16>
    %5513 = stablehlo.convert %5512 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %5514 = stablehlo.clamp %cst_43, %5513, %cst_44 : tensor<1x1200x1280xf32>
    %5515 = stablehlo.multiply %5514, %5514 : tensor<1x1200x1280xf32>
    %5516 = stablehlo.multiply %cst_45, %5515 : tensor<1x1200x1280xf32>
    %5517 = stablehlo.add %5516, %cst_46 : tensor<1x1200x1280xf32>
    %5518 = stablehlo.multiply %5517, %5515 : tensor<1x1200x1280xf32>
    %5519 = stablehlo.add %5518, %cst_47 : tensor<1x1200x1280xf32>
    %5520 = stablehlo.multiply %5519, %5515 : tensor<1x1200x1280xf32>
    %5521 = stablehlo.add %5520, %cst_48 : tensor<1x1200x1280xf32>
    %5522 = stablehlo.multiply %5521, %5515 : tensor<1x1200x1280xf32>
    %5523 = stablehlo.add %5522, %cst_49 : tensor<1x1200x1280xf32>
    %5524 = stablehlo.multiply %5523, %5515 : tensor<1x1200x1280xf32>
    %5525 = stablehlo.add %5524, %cst_50 : tensor<1x1200x1280xf32>
    %5526 = stablehlo.multiply %5525, %5515 : tensor<1x1200x1280xf32>
    %5527 = stablehlo.add %5526, %cst_51 : tensor<1x1200x1280xf32>
    %5528 = stablehlo.multiply %cst_52, %5515 : tensor<1x1200x1280xf32>
    %5529 = stablehlo.add %5528, %cst_53 : tensor<1x1200x1280xf32>
    %5530 = stablehlo.multiply %5529, %5515 : tensor<1x1200x1280xf32>
    %5531 = stablehlo.add %5530, %cst_54 : tensor<1x1200x1280xf32>
    %5532 = stablehlo.multiply %5531, %5515 : tensor<1x1200x1280xf32>
    %5533 = stablehlo.add %5532, %cst_55 : tensor<1x1200x1280xf32>
    %5534 = stablehlo.multiply %5533, %5515 : tensor<1x1200x1280xf32>
    %5535 = stablehlo.add %5534, %cst_56 : tensor<1x1200x1280xf32>
    %5536 = stablehlo.multiply %5514, %5527 : tensor<1x1200x1280xf32>
    %5537 = stablehlo.divide %5536, %5535 : tensor<1x1200x1280xf32>
    %5538 = stablehlo.clamp %cst_57, %5537, %cst_58 : tensor<1x1200x1280xf32>
    %5539 = stablehlo.convert %5538 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %5540 = stablehlo.add %5539, %cst_40 : tensor<1x1200x1280xbf16>
    %5541 = stablehlo.multiply %5540, %5511 : tensor<1x1200x1280xbf16>
    %5542 = stablehlo.reshape %5541 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %5543 = stablehlo.dot_general %5542, %arg722, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %5544 = stablehlo.reshape %5543 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5545 = stablehlo.broadcast_in_dim %5544, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5546 = stablehlo.broadcast_in_dim %arg247, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %5547 = stablehlo.add %5545, %5546 : tensor<1x1200x320xbf16>
    %5548 = stablehlo.reshape %5547 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5549 = stablehlo.reshape %5548 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5550 = stablehlo.add %5549, %5454 : tensor<1x1200x320xbf16>
    %5551 = stablehlo.convert %5550 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5552 = stablehlo.convert %5551 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5553 = stablehlo.reduce(%5552 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5554 = stablehlo.reshape %5553 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5555 = stablehlo.broadcast_in_dim %5554, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5556 = stablehlo.divide %5555, %2987 : tensor<1x1200x1xf64>
    %5557 = stablehlo.broadcast_in_dim %5552, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5558 = stablehlo.broadcast_in_dim %5556, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5559 = stablehlo.subtract %5557, %5558 : tensor<1x1200x320xf64>
    %5560 = stablehlo.multiply %5559, %5559 : tensor<1x1200x320xf64>
    %5561 = stablehlo.reduce(%5560 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5562 = stablehlo.reshape %5561 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5563 = stablehlo.broadcast_in_dim %5562, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5564 = stablehlo.divide %5563, %2987 : tensor<1x1200x1xf64>
    %5565 = stablehlo.convert %5564 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5566 = stablehlo.reduce(%5551 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5567 = stablehlo.reshape %5566 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5568 = stablehlo.broadcast_in_dim %5567, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5569 = stablehlo.divide %5568, %3003 : tensor<1x1200x1xf32>
    %5570 = stablehlo.broadcast_in_dim %5565, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5571 = stablehlo.add %5570, %3006 : tensor<1x1200x1xf32>
    %5572 = stablehlo.rsqrt %5571 : tensor<1x1200x1xf32>
    %5573 = stablehlo.broadcast_in_dim %5551, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5574 = stablehlo.broadcast_in_dim %5569, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5575 = stablehlo.subtract %5573, %5574 : tensor<1x1200x320xf32>
    %5576 = stablehlo.broadcast_in_dim %5575, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5577 = stablehlo.broadcast_in_dim %5572, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5578 = stablehlo.multiply %5576, %5577 : tensor<1x1200x320xf32>
    %5579 = stablehlo.convert %arg248 : (tensor<320xbf16>) -> tensor<320xf32>
    %5580 = stablehlo.broadcast_in_dim %5578, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5581 = stablehlo.broadcast_in_dim %5579, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5582 = stablehlo.multiply %5580, %5581 : tensor<1x1200x320xf32>
    %5583 = stablehlo.convert %arg249 : (tensor<320xbf16>) -> tensor<320xf32>
    %5584 = stablehlo.broadcast_in_dim %5582, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5585 = stablehlo.broadcast_in_dim %5583, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5586 = stablehlo.add %5584, %5585 : tensor<1x1200x320xf32>
    %5587 = stablehlo.convert %5586 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5588 = stablehlo.reshape %5587 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5589 = stablehlo.convert %5588 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5590 = stablehlo.dot_general %5589, %arg723, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5591 = stablehlo.broadcast_in_dim %5590, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5592 = stablehlo.multiply %5591, %3065 : tensor<1200x320xf32>
    %5593 = stablehlo.broadcast_in_dim %5592, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5594 = stablehlo.broadcast_in_dim %arg724, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5595 = stablehlo.add %5593, %5594 : tensor<1200x320xf32>
    %5596 = stablehlo.convert %5595 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5597 = stablehlo.reshape %5596 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5598 = stablehlo.reshape %5597 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %5599 = stablehlo.transpose %5598, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5600 = stablehlo.transpose %5587, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %5601 = stablehlo.reshape %5600 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %5602 = stablehlo.convolution(%5601, %arg250) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %5603 = stablehlo.reshape %arg251 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %5604 = stablehlo.broadcast_in_dim %5602, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %5605 = stablehlo.broadcast_in_dim %5603, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %5606 = stablehlo.add %5604, %5605 : tensor<1x320x15x20xbf16>
    %5607 = stablehlo.reshape %5606 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %5608 = stablehlo.transpose %5607, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %5609 = stablehlo.convert %5608 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %5610 = stablehlo.convert %5609 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %5611 = stablehlo.reduce(%5610 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5612 = stablehlo.reshape %5611 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5613 = stablehlo.broadcast_in_dim %5612, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5614 = stablehlo.divide %5613, %3088 : tensor<1x300x1xf64>
    %5615 = stablehlo.broadcast_in_dim %5610, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %5616 = stablehlo.broadcast_in_dim %5614, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %5617 = stablehlo.subtract %5615, %5616 : tensor<1x300x320xf64>
    %5618 = stablehlo.multiply %5617, %5617 : tensor<1x300x320xf64>
    %5619 = stablehlo.reduce(%5618 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5620 = stablehlo.reshape %5619 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5621 = stablehlo.broadcast_in_dim %5620, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5622 = stablehlo.divide %5621, %3088 : tensor<1x300x1xf64>
    %5623 = stablehlo.convert %5622 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %5624 = stablehlo.reduce(%5609 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %5625 = stablehlo.reshape %5624 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %5626 = stablehlo.broadcast_in_dim %5625, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5627 = stablehlo.divide %5626, %3102 : tensor<1x300x1xf32>
    %5628 = stablehlo.broadcast_in_dim %5623, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5629 = stablehlo.add %5628, %136 : tensor<1x300x1xf32>
    %5630 = stablehlo.rsqrt %5629 : tensor<1x300x1xf32>
    %5631 = stablehlo.broadcast_in_dim %5609, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5632 = stablehlo.broadcast_in_dim %5627, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5633 = stablehlo.subtract %5631, %5632 : tensor<1x300x320xf32>
    %5634 = stablehlo.broadcast_in_dim %5633, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5635 = stablehlo.broadcast_in_dim %5630, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5636 = stablehlo.multiply %5634, %5635 : tensor<1x300x320xf32>
    %5637 = stablehlo.convert %arg252 : (tensor<320xbf16>) -> tensor<320xf32>
    %5638 = stablehlo.broadcast_in_dim %5636, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5639 = stablehlo.broadcast_in_dim %5637, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5640 = stablehlo.multiply %5638, %5639 : tensor<1x300x320xf32>
    %5641 = stablehlo.convert %arg253 : (tensor<320xbf16>) -> tensor<320xf32>
    %5642 = stablehlo.broadcast_in_dim %5640, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5643 = stablehlo.broadcast_in_dim %5641, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5644 = stablehlo.add %5642, %5643 : tensor<1x300x320xf32>
    %5645 = stablehlo.convert %5644 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %5646 = stablehlo.reshape %5645 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %5647 = stablehlo.convert %5646 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %5648 = stablehlo.dot_general %5647, %arg725, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5649 = stablehlo.broadcast_in_dim %5648, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5650 = stablehlo.multiply %5649, %3126 : tensor<300x320xf32>
    %5651 = stablehlo.broadcast_in_dim %5650, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5652 = stablehlo.broadcast_in_dim %arg726, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5653 = stablehlo.add %5651, %5652 : tensor<300x320xf32>
    %5654 = stablehlo.convert %5653 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5655 = stablehlo.reshape %5654 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5656 = stablehlo.reshape %5655 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5657 = stablehlo.transpose %5656, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5658 = stablehlo.dot_general %5647, %arg727, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5659 = stablehlo.broadcast_in_dim %5658, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5660 = stablehlo.multiply %5659, %3126 : tensor<300x320xf32>
    %5661 = stablehlo.broadcast_in_dim %5660, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5662 = stablehlo.broadcast_in_dim %arg728, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5663 = stablehlo.add %5661, %5662 : tensor<300x320xf32>
    %5664 = stablehlo.convert %5663 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5665 = stablehlo.reshape %5664 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5666 = stablehlo.reshape %5665 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5667 = stablehlo.transpose %5666, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5668 = stablehlo.transpose %5657, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %5669 = stablehlo.reshape %5599 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %5670 = stablehlo.reshape %5668 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5671 = stablehlo.broadcast_in_dim %5670, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5672 = stablehlo.dot_general %5669, %5671, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %5673 = stablehlo.reshape %5672 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5674 = stablehlo.broadcast_in_dim %5673, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5675 = stablehlo.divide %5674, %3152 : tensor<1x5x1200x300xbf16>
    %5676 = stablehlo.convert %5675 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %5677 = stablehlo.reduce(%5676 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5678 = stablehlo.reshape %5677 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5679 = stablehlo.broadcast_in_dim %5676, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5680 = stablehlo.broadcast_in_dim %5678, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5681 = stablehlo.subtract %5679, %5680 : tensor<1x5x1200x300xf32>
    %5682 = stablehlo.exponential %5681 : tensor<1x5x1200x300xf32>
    %5683 = stablehlo.reduce(%5682 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5684 = stablehlo.reshape %5683 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5685 = stablehlo.broadcast_in_dim %5682, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5686 = stablehlo.broadcast_in_dim %5684, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5687 = stablehlo.divide %5685, %5686 : tensor<1x5x1200x300xf32>
    %5688 = stablehlo.convert %5687 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %5689 = stablehlo.reshape %5688 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %5690 = stablehlo.reshape %5667 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5691 = stablehlo.broadcast_in_dim %5690, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5692 = stablehlo.dot_general %5689, %5691, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %5693 = stablehlo.reshape %5692 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5694 = stablehlo.transpose %5693, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %5695 = stablehlo.reshape %5694 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %5696 = stablehlo.reshape %5695 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5697 = stablehlo.convert %5696 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5698 = stablehlo.dot_general %5697, %arg729, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5699 = stablehlo.broadcast_in_dim %5698, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5700 = stablehlo.multiply %5699, %3065 : tensor<1200x320xf32>
    %5701 = stablehlo.broadcast_in_dim %5700, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5702 = stablehlo.broadcast_in_dim %arg730, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5703 = stablehlo.add %5701, %5702 : tensor<1200x320xf32>
    %5704 = stablehlo.convert %5703 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5705 = stablehlo.reshape %5704 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5706 = stablehlo.add %5705, %5550 : tensor<1x1200x320xbf16>
    %5707 = stablehlo.convert %5706 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5708 = stablehlo.convert %5707 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5709 = stablehlo.reduce(%5708 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5710 = stablehlo.reshape %5709 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5711 = stablehlo.broadcast_in_dim %5710, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5712 = stablehlo.divide %5711, %2987 : tensor<1x1200x1xf64>
    %5713 = stablehlo.broadcast_in_dim %5708, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5714 = stablehlo.broadcast_in_dim %5712, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5715 = stablehlo.subtract %5713, %5714 : tensor<1x1200x320xf64>
    %5716 = stablehlo.multiply %5715, %5715 : tensor<1x1200x320xf64>
    %5717 = stablehlo.reduce(%5716 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5718 = stablehlo.reshape %5717 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5719 = stablehlo.broadcast_in_dim %5718, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5720 = stablehlo.divide %5719, %2987 : tensor<1x1200x1xf64>
    %5721 = stablehlo.convert %5720 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5722 = stablehlo.reduce(%5707 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5723 = stablehlo.reshape %5722 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5724 = stablehlo.broadcast_in_dim %5723, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5725 = stablehlo.divide %5724, %3003 : tensor<1x1200x1xf32>
    %5726 = stablehlo.broadcast_in_dim %5721, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5727 = stablehlo.add %5726, %3006 : tensor<1x1200x1xf32>
    %5728 = stablehlo.rsqrt %5727 : tensor<1x1200x1xf32>
    %5729 = stablehlo.broadcast_in_dim %5707, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5730 = stablehlo.broadcast_in_dim %5725, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5731 = stablehlo.subtract %5729, %5730 : tensor<1x1200x320xf32>
    %5732 = stablehlo.broadcast_in_dim %5731, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5733 = stablehlo.broadcast_in_dim %5728, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5734 = stablehlo.multiply %5732, %5733 : tensor<1x1200x320xf32>
    %5735 = stablehlo.convert %arg254 : (tensor<320xbf16>) -> tensor<320xf32>
    %5736 = stablehlo.broadcast_in_dim %5734, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5737 = stablehlo.broadcast_in_dim %5735, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5738 = stablehlo.multiply %5736, %5737 : tensor<1x1200x320xf32>
    %5739 = stablehlo.convert %arg255 : (tensor<320xbf16>) -> tensor<320xf32>
    %5740 = stablehlo.broadcast_in_dim %5738, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5741 = stablehlo.broadcast_in_dim %5739, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5742 = stablehlo.add %5740, %5741 : tensor<1x1200x320xf32>
    %5743 = stablehlo.convert %5742 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5744 = stablehlo.reshape %5743 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5745 = stablehlo.convert %5744 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5746 = stablehlo.dot_general %5745, %arg731, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %5747 = stablehlo.broadcast_in_dim %5746, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %5748 = stablehlo.multiply %5747, %3226 : tensor<1200x1280xf32>
    %5749 = stablehlo.broadcast_in_dim %5748, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %5750 = stablehlo.broadcast_in_dim %arg732, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %5751 = stablehlo.add %5749, %5750 : tensor<1200x1280xf32>
    %5752 = stablehlo.convert %5751 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %5753 = stablehlo.reshape %5752 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %5754 = stablehlo.transpose %5753, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %5755 = stablehlo.reshape %5754 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %5756 = stablehlo.convolution(%5755, %arg256) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %5757 = stablehlo.reshape %arg257 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %5758 = stablehlo.broadcast_in_dim %5756, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %5759 = stablehlo.broadcast_in_dim %5757, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %5760 = stablehlo.add %5758, %5759 : tensor<1x1280x30x40xbf16>
    %5761 = stablehlo.reshape %5760 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %5762 = stablehlo.transpose %5761, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %5763 = stablehlo.multiply %5762, %cst_42 : tensor<1x1200x1280xbf16>
    %5764 = stablehlo.multiply %5762, %3243 : tensor<1x1200x1280xbf16>
    %5765 = stablehlo.convert %5764 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %5766 = stablehlo.clamp %cst_43, %5765, %cst_44 : tensor<1x1200x1280xf32>
    %5767 = stablehlo.multiply %5766, %5766 : tensor<1x1200x1280xf32>
    %5768 = stablehlo.multiply %cst_45, %5767 : tensor<1x1200x1280xf32>
    %5769 = stablehlo.add %5768, %cst_46 : tensor<1x1200x1280xf32>
    %5770 = stablehlo.multiply %5769, %5767 : tensor<1x1200x1280xf32>
    %5771 = stablehlo.add %5770, %cst_47 : tensor<1x1200x1280xf32>
    %5772 = stablehlo.multiply %5771, %5767 : tensor<1x1200x1280xf32>
    %5773 = stablehlo.add %5772, %cst_48 : tensor<1x1200x1280xf32>
    %5774 = stablehlo.multiply %5773, %5767 : tensor<1x1200x1280xf32>
    %5775 = stablehlo.add %5774, %cst_49 : tensor<1x1200x1280xf32>
    %5776 = stablehlo.multiply %5775, %5767 : tensor<1x1200x1280xf32>
    %5777 = stablehlo.add %5776, %cst_50 : tensor<1x1200x1280xf32>
    %5778 = stablehlo.multiply %5777, %5767 : tensor<1x1200x1280xf32>
    %5779 = stablehlo.add %5778, %cst_51 : tensor<1x1200x1280xf32>
    %5780 = stablehlo.multiply %cst_52, %5767 : tensor<1x1200x1280xf32>
    %5781 = stablehlo.add %5780, %cst_53 : tensor<1x1200x1280xf32>
    %5782 = stablehlo.multiply %5781, %5767 : tensor<1x1200x1280xf32>
    %5783 = stablehlo.add %5782, %cst_54 : tensor<1x1200x1280xf32>
    %5784 = stablehlo.multiply %5783, %5767 : tensor<1x1200x1280xf32>
    %5785 = stablehlo.add %5784, %cst_55 : tensor<1x1200x1280xf32>
    %5786 = stablehlo.multiply %5785, %5767 : tensor<1x1200x1280xf32>
    %5787 = stablehlo.add %5786, %cst_56 : tensor<1x1200x1280xf32>
    %5788 = stablehlo.multiply %5766, %5779 : tensor<1x1200x1280xf32>
    %5789 = stablehlo.divide %5788, %5787 : tensor<1x1200x1280xf32>
    %5790 = stablehlo.clamp %cst_57, %5789, %cst_58 : tensor<1x1200x1280xf32>
    %5791 = stablehlo.convert %5790 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %5792 = stablehlo.add %5791, %cst_40 : tensor<1x1200x1280xbf16>
    %5793 = stablehlo.multiply %5792, %5763 : tensor<1x1200x1280xbf16>
    %5794 = stablehlo.reshape %5793 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %5795 = stablehlo.dot_general %5794, %arg733, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %5796 = stablehlo.reshape %5795 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5797 = stablehlo.broadcast_in_dim %5796, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5798 = stablehlo.broadcast_in_dim %arg258, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %5799 = stablehlo.add %5797, %5798 : tensor<1x1200x320xbf16>
    %5800 = stablehlo.reshape %5799 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5801 = stablehlo.reshape %5800 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5802 = stablehlo.add %5801, %5706 : tensor<1x1200x320xbf16>
    %5803 = stablehlo.convert %5802 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5804 = stablehlo.convert %5803 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5805 = stablehlo.reduce(%5804 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5806 = stablehlo.reshape %5805 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5807 = stablehlo.broadcast_in_dim %5806, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5808 = stablehlo.divide %5807, %2987 : tensor<1x1200x1xf64>
    %5809 = stablehlo.broadcast_in_dim %5804, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5810 = stablehlo.broadcast_in_dim %5808, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5811 = stablehlo.subtract %5809, %5810 : tensor<1x1200x320xf64>
    %5812 = stablehlo.multiply %5811, %5811 : tensor<1x1200x320xf64>
    %5813 = stablehlo.reduce(%5812 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5814 = stablehlo.reshape %5813 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5815 = stablehlo.broadcast_in_dim %5814, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5816 = stablehlo.divide %5815, %2987 : tensor<1x1200x1xf64>
    %5817 = stablehlo.convert %5816 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5818 = stablehlo.reduce(%5803 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5819 = stablehlo.reshape %5818 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5820 = stablehlo.broadcast_in_dim %5819, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5821 = stablehlo.divide %5820, %3003 : tensor<1x1200x1xf32>
    %5822 = stablehlo.broadcast_in_dim %5817, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5823 = stablehlo.add %5822, %3006 : tensor<1x1200x1xf32>
    %5824 = stablehlo.rsqrt %5823 : tensor<1x1200x1xf32>
    %5825 = stablehlo.broadcast_in_dim %5803, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5826 = stablehlo.broadcast_in_dim %5821, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5827 = stablehlo.subtract %5825, %5826 : tensor<1x1200x320xf32>
    %5828 = stablehlo.broadcast_in_dim %5827, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5829 = stablehlo.broadcast_in_dim %5824, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5830 = stablehlo.multiply %5828, %5829 : tensor<1x1200x320xf32>
    %5831 = stablehlo.convert %arg259 : (tensor<320xbf16>) -> tensor<320xf32>
    %5832 = stablehlo.broadcast_in_dim %5830, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5833 = stablehlo.broadcast_in_dim %5831, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5834 = stablehlo.multiply %5832, %5833 : tensor<1x1200x320xf32>
    %5835 = stablehlo.convert %arg260 : (tensor<320xbf16>) -> tensor<320xf32>
    %5836 = stablehlo.broadcast_in_dim %5834, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5837 = stablehlo.broadcast_in_dim %5835, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5838 = stablehlo.add %5836, %5837 : tensor<1x1200x320xf32>
    %5839 = stablehlo.convert %5838 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5840 = stablehlo.reshape %5839 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5841 = stablehlo.convert %5840 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5842 = stablehlo.dot_general %5841, %arg734, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5843 = stablehlo.broadcast_in_dim %5842, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5844 = stablehlo.multiply %5843, %3065 : tensor<1200x320xf32>
    %5845 = stablehlo.broadcast_in_dim %5844, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5846 = stablehlo.broadcast_in_dim %arg735, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5847 = stablehlo.add %5845, %5846 : tensor<1200x320xf32>
    %5848 = stablehlo.convert %5847 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5849 = stablehlo.reshape %5848 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5850 = stablehlo.reshape %5849 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %5851 = stablehlo.transpose %5850, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5852 = stablehlo.transpose %5839, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %5853 = stablehlo.reshape %5852 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %5854 = stablehlo.convolution(%5853, %arg261) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %5855 = stablehlo.reshape %arg262 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %5856 = stablehlo.broadcast_in_dim %5854, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %5857 = stablehlo.broadcast_in_dim %5855, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %5858 = stablehlo.add %5856, %5857 : tensor<1x320x15x20xbf16>
    %5859 = stablehlo.reshape %5858 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %5860 = stablehlo.transpose %5859, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %5861 = stablehlo.convert %5860 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %5862 = stablehlo.convert %5861 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %5863 = stablehlo.reduce(%5862 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5864 = stablehlo.reshape %5863 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5865 = stablehlo.broadcast_in_dim %5864, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5866 = stablehlo.divide %5865, %3088 : tensor<1x300x1xf64>
    %5867 = stablehlo.broadcast_in_dim %5862, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %5868 = stablehlo.broadcast_in_dim %5866, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %5869 = stablehlo.subtract %5867, %5868 : tensor<1x300x320xf64>
    %5870 = stablehlo.multiply %5869, %5869 : tensor<1x300x320xf64>
    %5871 = stablehlo.reduce(%5870 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %5872 = stablehlo.reshape %5871 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %5873 = stablehlo.broadcast_in_dim %5872, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %5874 = stablehlo.divide %5873, %3088 : tensor<1x300x1xf64>
    %5875 = stablehlo.convert %5874 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %5876 = stablehlo.reduce(%5861 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %5877 = stablehlo.reshape %5876 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %5878 = stablehlo.broadcast_in_dim %5877, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5879 = stablehlo.divide %5878, %3102 : tensor<1x300x1xf32>
    %5880 = stablehlo.broadcast_in_dim %5875, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %5881 = stablehlo.add %5880, %136 : tensor<1x300x1xf32>
    %5882 = stablehlo.rsqrt %5881 : tensor<1x300x1xf32>
    %5883 = stablehlo.broadcast_in_dim %5861, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5884 = stablehlo.broadcast_in_dim %5879, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5885 = stablehlo.subtract %5883, %5884 : tensor<1x300x320xf32>
    %5886 = stablehlo.broadcast_in_dim %5885, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5887 = stablehlo.broadcast_in_dim %5882, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %5888 = stablehlo.multiply %5886, %5887 : tensor<1x300x320xf32>
    %5889 = stablehlo.convert %arg263 : (tensor<320xbf16>) -> tensor<320xf32>
    %5890 = stablehlo.broadcast_in_dim %5888, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5891 = stablehlo.broadcast_in_dim %5889, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5892 = stablehlo.multiply %5890, %5891 : tensor<1x300x320xf32>
    %5893 = stablehlo.convert %arg264 : (tensor<320xbf16>) -> tensor<320xf32>
    %5894 = stablehlo.broadcast_in_dim %5892, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %5895 = stablehlo.broadcast_in_dim %5893, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %5896 = stablehlo.add %5894, %5895 : tensor<1x300x320xf32>
    %5897 = stablehlo.convert %5896 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %5898 = stablehlo.reshape %5897 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %5899 = stablehlo.convert %5898 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %5900 = stablehlo.dot_general %5899, %arg736, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5901 = stablehlo.broadcast_in_dim %5900, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5902 = stablehlo.multiply %5901, %3126 : tensor<300x320xf32>
    %5903 = stablehlo.broadcast_in_dim %5902, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5904 = stablehlo.broadcast_in_dim %arg737, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5905 = stablehlo.add %5903, %5904 : tensor<300x320xf32>
    %5906 = stablehlo.convert %5905 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5907 = stablehlo.reshape %5906 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5908 = stablehlo.reshape %5907 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5909 = stablehlo.transpose %5908, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5910 = stablehlo.dot_general %5899, %arg738, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %5911 = stablehlo.broadcast_in_dim %5910, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5912 = stablehlo.multiply %5911, %3126 : tensor<300x320xf32>
    %5913 = stablehlo.broadcast_in_dim %5912, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %5914 = stablehlo.broadcast_in_dim %arg739, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %5915 = stablehlo.add %5913, %5914 : tensor<300x320xf32>
    %5916 = stablehlo.convert %5915 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %5917 = stablehlo.reshape %5916 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %5918 = stablehlo.reshape %5917 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %5919 = stablehlo.transpose %5918, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %5920 = stablehlo.transpose %5909, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %5921 = stablehlo.reshape %5851 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %5922 = stablehlo.reshape %5920 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5923 = stablehlo.broadcast_in_dim %5922, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %5924 = stablehlo.dot_general %5921, %5923, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %5925 = stablehlo.reshape %5924 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5926 = stablehlo.broadcast_in_dim %5925, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %5927 = stablehlo.divide %5926, %3152 : tensor<1x5x1200x300xbf16>
    %5928 = stablehlo.convert %5927 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %5929 = stablehlo.reduce(%5928 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5930 = stablehlo.reshape %5929 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5931 = stablehlo.broadcast_in_dim %5928, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5932 = stablehlo.broadcast_in_dim %5930, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5933 = stablehlo.subtract %5931, %5932 : tensor<1x5x1200x300xf32>
    %5934 = stablehlo.exponential %5933 : tensor<1x5x1200x300xf32>
    %5935 = stablehlo.reduce(%5934 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %5936 = stablehlo.reshape %5935 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %5937 = stablehlo.broadcast_in_dim %5934, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %5938 = stablehlo.broadcast_in_dim %5936, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %5939 = stablehlo.divide %5937, %5938 : tensor<1x5x1200x300xf32>
    %5940 = stablehlo.convert %5939 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %5941 = stablehlo.reshape %5940 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %5942 = stablehlo.reshape %5919 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5943 = stablehlo.broadcast_in_dim %5942, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %5944 = stablehlo.dot_general %5941, %5943, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %5945 = stablehlo.reshape %5944 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %5946 = stablehlo.transpose %5945, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %5947 = stablehlo.reshape %5946 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %5948 = stablehlo.reshape %5947 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5949 = stablehlo.convert %5948 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5950 = stablehlo.dot_general %5949, %arg740, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %5951 = stablehlo.broadcast_in_dim %5950, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5952 = stablehlo.multiply %5951, %3065 : tensor<1200x320xf32>
    %5953 = stablehlo.broadcast_in_dim %5952, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %5954 = stablehlo.broadcast_in_dim %arg741, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %5955 = stablehlo.add %5953, %5954 : tensor<1200x320xf32>
    %5956 = stablehlo.convert %5955 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %5957 = stablehlo.reshape %5956 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %5958 = stablehlo.add %5957, %5802 : tensor<1x1200x320xbf16>
    %5959 = stablehlo.convert %5958 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %5960 = stablehlo.convert %5959 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %5961 = stablehlo.reduce(%5960 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5962 = stablehlo.reshape %5961 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5963 = stablehlo.broadcast_in_dim %5962, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5964 = stablehlo.divide %5963, %2987 : tensor<1x1200x1xf64>
    %5965 = stablehlo.broadcast_in_dim %5960, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %5966 = stablehlo.broadcast_in_dim %5964, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %5967 = stablehlo.subtract %5965, %5966 : tensor<1x1200x320xf64>
    %5968 = stablehlo.multiply %5967, %5967 : tensor<1x1200x320xf64>
    %5969 = stablehlo.reduce(%5968 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %5970 = stablehlo.reshape %5969 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %5971 = stablehlo.broadcast_in_dim %5970, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %5972 = stablehlo.divide %5971, %2987 : tensor<1x1200x1xf64>
    %5973 = stablehlo.convert %5972 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %5974 = stablehlo.reduce(%5959 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %5975 = stablehlo.reshape %5974 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %5976 = stablehlo.broadcast_in_dim %5975, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5977 = stablehlo.divide %5976, %3003 : tensor<1x1200x1xf32>
    %5978 = stablehlo.broadcast_in_dim %5973, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %5979 = stablehlo.add %5978, %3006 : tensor<1x1200x1xf32>
    %5980 = stablehlo.rsqrt %5979 : tensor<1x1200x1xf32>
    %5981 = stablehlo.broadcast_in_dim %5959, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5982 = stablehlo.broadcast_in_dim %5977, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5983 = stablehlo.subtract %5981, %5982 : tensor<1x1200x320xf32>
    %5984 = stablehlo.broadcast_in_dim %5983, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5985 = stablehlo.broadcast_in_dim %5980, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %5986 = stablehlo.multiply %5984, %5985 : tensor<1x1200x320xf32>
    %5987 = stablehlo.convert %arg265 : (tensor<320xbf16>) -> tensor<320xf32>
    %5988 = stablehlo.broadcast_in_dim %5986, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5989 = stablehlo.broadcast_in_dim %5987, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5990 = stablehlo.multiply %5988, %5989 : tensor<1x1200x320xf32>
    %5991 = stablehlo.convert %arg266 : (tensor<320xbf16>) -> tensor<320xf32>
    %5992 = stablehlo.broadcast_in_dim %5990, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %5993 = stablehlo.broadcast_in_dim %5991, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %5994 = stablehlo.add %5992, %5993 : tensor<1x1200x320xf32>
    %5995 = stablehlo.convert %5994 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %5996 = stablehlo.reshape %5995 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %5997 = stablehlo.convert %5996 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %5998 = stablehlo.dot_general %5997, %arg742, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %5999 = stablehlo.broadcast_in_dim %5998, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6000 = stablehlo.multiply %5999, %3226 : tensor<1200x1280xf32>
    %6001 = stablehlo.broadcast_in_dim %6000, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6002 = stablehlo.broadcast_in_dim %arg743, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %6003 = stablehlo.add %6001, %6002 : tensor<1200x1280xf32>
    %6004 = stablehlo.convert %6003 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %6005 = stablehlo.reshape %6004 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %6006 = stablehlo.transpose %6005, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %6007 = stablehlo.reshape %6006 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %6008 = stablehlo.convolution(%6007, %arg267) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %6009 = stablehlo.reshape %arg268 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %6010 = stablehlo.broadcast_in_dim %6008, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %6011 = stablehlo.broadcast_in_dim %6009, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %6012 = stablehlo.add %6010, %6011 : tensor<1x1280x30x40xbf16>
    %6013 = stablehlo.reshape %6012 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %6014 = stablehlo.transpose %6013, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %6015 = stablehlo.multiply %6014, %cst_42 : tensor<1x1200x1280xbf16>
    %6016 = stablehlo.multiply %6014, %3243 : tensor<1x1200x1280xbf16>
    %6017 = stablehlo.convert %6016 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %6018 = stablehlo.clamp %cst_43, %6017, %cst_44 : tensor<1x1200x1280xf32>
    %6019 = stablehlo.multiply %6018, %6018 : tensor<1x1200x1280xf32>
    %6020 = stablehlo.multiply %cst_45, %6019 : tensor<1x1200x1280xf32>
    %6021 = stablehlo.add %6020, %cst_46 : tensor<1x1200x1280xf32>
    %6022 = stablehlo.multiply %6021, %6019 : tensor<1x1200x1280xf32>
    %6023 = stablehlo.add %6022, %cst_47 : tensor<1x1200x1280xf32>
    %6024 = stablehlo.multiply %6023, %6019 : tensor<1x1200x1280xf32>
    %6025 = stablehlo.add %6024, %cst_48 : tensor<1x1200x1280xf32>
    %6026 = stablehlo.multiply %6025, %6019 : tensor<1x1200x1280xf32>
    %6027 = stablehlo.add %6026, %cst_49 : tensor<1x1200x1280xf32>
    %6028 = stablehlo.multiply %6027, %6019 : tensor<1x1200x1280xf32>
    %6029 = stablehlo.add %6028, %cst_50 : tensor<1x1200x1280xf32>
    %6030 = stablehlo.multiply %6029, %6019 : tensor<1x1200x1280xf32>
    %6031 = stablehlo.add %6030, %cst_51 : tensor<1x1200x1280xf32>
    %6032 = stablehlo.multiply %cst_52, %6019 : tensor<1x1200x1280xf32>
    %6033 = stablehlo.add %6032, %cst_53 : tensor<1x1200x1280xf32>
    %6034 = stablehlo.multiply %6033, %6019 : tensor<1x1200x1280xf32>
    %6035 = stablehlo.add %6034, %cst_54 : tensor<1x1200x1280xf32>
    %6036 = stablehlo.multiply %6035, %6019 : tensor<1x1200x1280xf32>
    %6037 = stablehlo.add %6036, %cst_55 : tensor<1x1200x1280xf32>
    %6038 = stablehlo.multiply %6037, %6019 : tensor<1x1200x1280xf32>
    %6039 = stablehlo.add %6038, %cst_56 : tensor<1x1200x1280xf32>
    %6040 = stablehlo.multiply %6018, %6031 : tensor<1x1200x1280xf32>
    %6041 = stablehlo.divide %6040, %6039 : tensor<1x1200x1280xf32>
    %6042 = stablehlo.clamp %cst_57, %6041, %cst_58 : tensor<1x1200x1280xf32>
    %6043 = stablehlo.convert %6042 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %6044 = stablehlo.add %6043, %cst_40 : tensor<1x1200x1280xbf16>
    %6045 = stablehlo.multiply %6044, %6015 : tensor<1x1200x1280xbf16>
    %6046 = stablehlo.reshape %6045 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %6047 = stablehlo.dot_general %6046, %arg744, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %6048 = stablehlo.reshape %6047 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6049 = stablehlo.broadcast_in_dim %6048, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6050 = stablehlo.broadcast_in_dim %arg269, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %6051 = stablehlo.add %6049, %6050 : tensor<1x1200x320xbf16>
    %6052 = stablehlo.reshape %6051 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6053 = stablehlo.reshape %6052 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6054 = stablehlo.add %6053, %5958 : tensor<1x1200x320xbf16>
    %6055 = stablehlo.convert %6054 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6056 = stablehlo.convert %6055 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6057 = stablehlo.reduce(%6056 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6058 = stablehlo.reshape %6057 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6059 = stablehlo.broadcast_in_dim %6058, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6060 = stablehlo.divide %6059, %2987 : tensor<1x1200x1xf64>
    %6061 = stablehlo.broadcast_in_dim %6056, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6062 = stablehlo.broadcast_in_dim %6060, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6063 = stablehlo.subtract %6061, %6062 : tensor<1x1200x320xf64>
    %6064 = stablehlo.multiply %6063, %6063 : tensor<1x1200x320xf64>
    %6065 = stablehlo.reduce(%6064 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6066 = stablehlo.reshape %6065 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6067 = stablehlo.broadcast_in_dim %6066, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6068 = stablehlo.divide %6067, %2987 : tensor<1x1200x1xf64>
    %6069 = stablehlo.convert %6068 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6070 = stablehlo.reduce(%6055 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6071 = stablehlo.reshape %6070 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6072 = stablehlo.broadcast_in_dim %6071, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6073 = stablehlo.divide %6072, %3003 : tensor<1x1200x1xf32>
    %6074 = stablehlo.broadcast_in_dim %6069, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6075 = stablehlo.add %6074, %3006 : tensor<1x1200x1xf32>
    %6076 = stablehlo.rsqrt %6075 : tensor<1x1200x1xf32>
    %6077 = stablehlo.broadcast_in_dim %6055, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6078 = stablehlo.broadcast_in_dim %6073, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6079 = stablehlo.subtract %6077, %6078 : tensor<1x1200x320xf32>
    %6080 = stablehlo.broadcast_in_dim %6079, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6081 = stablehlo.broadcast_in_dim %6076, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6082 = stablehlo.multiply %6080, %6081 : tensor<1x1200x320xf32>
    %6083 = stablehlo.convert %arg270 : (tensor<320xbf16>) -> tensor<320xf32>
    %6084 = stablehlo.broadcast_in_dim %6082, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6085 = stablehlo.broadcast_in_dim %6083, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6086 = stablehlo.multiply %6084, %6085 : tensor<1x1200x320xf32>
    %6087 = stablehlo.convert %arg271 : (tensor<320xbf16>) -> tensor<320xf32>
    %6088 = stablehlo.broadcast_in_dim %6086, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6089 = stablehlo.broadcast_in_dim %6087, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6090 = stablehlo.add %6088, %6089 : tensor<1x1200x320xf32>
    %6091 = stablehlo.convert %6090 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6092 = stablehlo.reshape %6091 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6093 = stablehlo.convert %6092 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6094 = stablehlo.dot_general %6093, %arg745, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6095 = stablehlo.broadcast_in_dim %6094, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6096 = stablehlo.multiply %6095, %3065 : tensor<1200x320xf32>
    %6097 = stablehlo.broadcast_in_dim %6096, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6098 = stablehlo.broadcast_in_dim %arg746, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6099 = stablehlo.add %6097, %6098 : tensor<1200x320xf32>
    %6100 = stablehlo.convert %6099 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6101 = stablehlo.reshape %6100 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6102 = stablehlo.reshape %6101 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %6103 = stablehlo.transpose %6102, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6104 = stablehlo.transpose %6091, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %6105 = stablehlo.reshape %6104 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %6106 = stablehlo.convolution(%6105, %arg272) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %6107 = stablehlo.reshape %arg273 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %6108 = stablehlo.broadcast_in_dim %6106, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %6109 = stablehlo.broadcast_in_dim %6107, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %6110 = stablehlo.add %6108, %6109 : tensor<1x320x15x20xbf16>
    %6111 = stablehlo.reshape %6110 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %6112 = stablehlo.transpose %6111, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %6113 = stablehlo.convert %6112 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %6114 = stablehlo.convert %6113 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %6115 = stablehlo.reduce(%6114 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6116 = stablehlo.reshape %6115 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6117 = stablehlo.broadcast_in_dim %6116, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6118 = stablehlo.divide %6117, %3088 : tensor<1x300x1xf64>
    %6119 = stablehlo.broadcast_in_dim %6114, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %6120 = stablehlo.broadcast_in_dim %6118, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %6121 = stablehlo.subtract %6119, %6120 : tensor<1x300x320xf64>
    %6122 = stablehlo.multiply %6121, %6121 : tensor<1x300x320xf64>
    %6123 = stablehlo.reduce(%6122 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6124 = stablehlo.reshape %6123 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6125 = stablehlo.broadcast_in_dim %6124, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6126 = stablehlo.divide %6125, %3088 : tensor<1x300x1xf64>
    %6127 = stablehlo.convert %6126 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %6128 = stablehlo.reduce(%6113 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %6129 = stablehlo.reshape %6128 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %6130 = stablehlo.broadcast_in_dim %6129, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6131 = stablehlo.divide %6130, %3102 : tensor<1x300x1xf32>
    %6132 = stablehlo.broadcast_in_dim %6127, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6133 = stablehlo.add %6132, %136 : tensor<1x300x1xf32>
    %6134 = stablehlo.rsqrt %6133 : tensor<1x300x1xf32>
    %6135 = stablehlo.broadcast_in_dim %6113, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6136 = stablehlo.broadcast_in_dim %6131, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6137 = stablehlo.subtract %6135, %6136 : tensor<1x300x320xf32>
    %6138 = stablehlo.broadcast_in_dim %6137, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6139 = stablehlo.broadcast_in_dim %6134, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6140 = stablehlo.multiply %6138, %6139 : tensor<1x300x320xf32>
    %6141 = stablehlo.convert %arg274 : (tensor<320xbf16>) -> tensor<320xf32>
    %6142 = stablehlo.broadcast_in_dim %6140, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6143 = stablehlo.broadcast_in_dim %6141, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6144 = stablehlo.multiply %6142, %6143 : tensor<1x300x320xf32>
    %6145 = stablehlo.convert %arg275 : (tensor<320xbf16>) -> tensor<320xf32>
    %6146 = stablehlo.broadcast_in_dim %6144, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6147 = stablehlo.broadcast_in_dim %6145, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6148 = stablehlo.add %6146, %6147 : tensor<1x300x320xf32>
    %6149 = stablehlo.convert %6148 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %6150 = stablehlo.reshape %6149 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %6151 = stablehlo.convert %6150 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %6152 = stablehlo.dot_general %6151, %arg747, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6153 = stablehlo.broadcast_in_dim %6152, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6154 = stablehlo.multiply %6153, %3126 : tensor<300x320xf32>
    %6155 = stablehlo.broadcast_in_dim %6154, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6156 = stablehlo.broadcast_in_dim %arg748, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6157 = stablehlo.add %6155, %6156 : tensor<300x320xf32>
    %6158 = stablehlo.convert %6157 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6159 = stablehlo.reshape %6158 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6160 = stablehlo.reshape %6159 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6161 = stablehlo.transpose %6160, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6162 = stablehlo.dot_general %6151, %arg749, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6163 = stablehlo.broadcast_in_dim %6162, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6164 = stablehlo.multiply %6163, %3126 : tensor<300x320xf32>
    %6165 = stablehlo.broadcast_in_dim %6164, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6166 = stablehlo.broadcast_in_dim %arg750, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6167 = stablehlo.add %6165, %6166 : tensor<300x320xf32>
    %6168 = stablehlo.convert %6167 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6169 = stablehlo.reshape %6168 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6170 = stablehlo.reshape %6169 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6171 = stablehlo.transpose %6170, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6172 = stablehlo.transpose %6161, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %6173 = stablehlo.reshape %6103 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %6174 = stablehlo.reshape %6172 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6175 = stablehlo.broadcast_in_dim %6174, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6176 = stablehlo.dot_general %6173, %6175, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %6177 = stablehlo.reshape %6176 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6178 = stablehlo.broadcast_in_dim %6177, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6179 = stablehlo.divide %6178, %3152 : tensor<1x5x1200x300xbf16>
    %6180 = stablehlo.convert %6179 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %6181 = stablehlo.reduce(%6180 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6182 = stablehlo.reshape %6181 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6183 = stablehlo.broadcast_in_dim %6180, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6184 = stablehlo.broadcast_in_dim %6182, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6185 = stablehlo.subtract %6183, %6184 : tensor<1x5x1200x300xf32>
    %6186 = stablehlo.exponential %6185 : tensor<1x5x1200x300xf32>
    %6187 = stablehlo.reduce(%6186 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6188 = stablehlo.reshape %6187 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6189 = stablehlo.broadcast_in_dim %6186, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6190 = stablehlo.broadcast_in_dim %6188, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6191 = stablehlo.divide %6189, %6190 : tensor<1x5x1200x300xf32>
    %6192 = stablehlo.convert %6191 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %6193 = stablehlo.reshape %6192 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %6194 = stablehlo.reshape %6171 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6195 = stablehlo.broadcast_in_dim %6194, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6196 = stablehlo.dot_general %6193, %6195, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %6197 = stablehlo.reshape %6196 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6198 = stablehlo.transpose %6197, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %6199 = stablehlo.reshape %6198 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %6200 = stablehlo.reshape %6199 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6201 = stablehlo.convert %6200 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6202 = stablehlo.dot_general %6201, %arg751, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6203 = stablehlo.broadcast_in_dim %6202, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6204 = stablehlo.multiply %6203, %3065 : tensor<1200x320xf32>
    %6205 = stablehlo.broadcast_in_dim %6204, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6206 = stablehlo.broadcast_in_dim %arg752, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6207 = stablehlo.add %6205, %6206 : tensor<1200x320xf32>
    %6208 = stablehlo.convert %6207 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6209 = stablehlo.reshape %6208 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6210 = stablehlo.add %6209, %6054 : tensor<1x1200x320xbf16>
    %6211 = stablehlo.convert %6210 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6212 = stablehlo.convert %6211 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6213 = stablehlo.reduce(%6212 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6214 = stablehlo.reshape %6213 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6215 = stablehlo.broadcast_in_dim %6214, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6216 = stablehlo.divide %6215, %2987 : tensor<1x1200x1xf64>
    %6217 = stablehlo.broadcast_in_dim %6212, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6218 = stablehlo.broadcast_in_dim %6216, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6219 = stablehlo.subtract %6217, %6218 : tensor<1x1200x320xf64>
    %6220 = stablehlo.multiply %6219, %6219 : tensor<1x1200x320xf64>
    %6221 = stablehlo.reduce(%6220 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6222 = stablehlo.reshape %6221 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6223 = stablehlo.broadcast_in_dim %6222, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6224 = stablehlo.divide %6223, %2987 : tensor<1x1200x1xf64>
    %6225 = stablehlo.convert %6224 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6226 = stablehlo.reduce(%6211 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6227 = stablehlo.reshape %6226 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6228 = stablehlo.broadcast_in_dim %6227, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6229 = stablehlo.divide %6228, %3003 : tensor<1x1200x1xf32>
    %6230 = stablehlo.broadcast_in_dim %6225, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6231 = stablehlo.add %6230, %3006 : tensor<1x1200x1xf32>
    %6232 = stablehlo.rsqrt %6231 : tensor<1x1200x1xf32>
    %6233 = stablehlo.broadcast_in_dim %6211, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6234 = stablehlo.broadcast_in_dim %6229, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6235 = stablehlo.subtract %6233, %6234 : tensor<1x1200x320xf32>
    %6236 = stablehlo.broadcast_in_dim %6235, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6237 = stablehlo.broadcast_in_dim %6232, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6238 = stablehlo.multiply %6236, %6237 : tensor<1x1200x320xf32>
    %6239 = stablehlo.convert %arg276 : (tensor<320xbf16>) -> tensor<320xf32>
    %6240 = stablehlo.broadcast_in_dim %6238, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6241 = stablehlo.broadcast_in_dim %6239, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6242 = stablehlo.multiply %6240, %6241 : tensor<1x1200x320xf32>
    %6243 = stablehlo.convert %arg277 : (tensor<320xbf16>) -> tensor<320xf32>
    %6244 = stablehlo.broadcast_in_dim %6242, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6245 = stablehlo.broadcast_in_dim %6243, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6246 = stablehlo.add %6244, %6245 : tensor<1x1200x320xf32>
    %6247 = stablehlo.convert %6246 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6248 = stablehlo.reshape %6247 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6249 = stablehlo.convert %6248 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6250 = stablehlo.dot_general %6249, %arg753, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %6251 = stablehlo.broadcast_in_dim %6250, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6252 = stablehlo.multiply %6251, %3226 : tensor<1200x1280xf32>
    %6253 = stablehlo.broadcast_in_dim %6252, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6254 = stablehlo.broadcast_in_dim %arg754, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %6255 = stablehlo.add %6253, %6254 : tensor<1200x1280xf32>
    %6256 = stablehlo.convert %6255 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %6257 = stablehlo.reshape %6256 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %6258 = stablehlo.transpose %6257, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %6259 = stablehlo.reshape %6258 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %6260 = stablehlo.convolution(%6259, %arg278) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %6261 = stablehlo.reshape %arg279 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %6262 = stablehlo.broadcast_in_dim %6260, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %6263 = stablehlo.broadcast_in_dim %6261, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %6264 = stablehlo.add %6262, %6263 : tensor<1x1280x30x40xbf16>
    %6265 = stablehlo.reshape %6264 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %6266 = stablehlo.transpose %6265, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %6267 = stablehlo.multiply %6266, %cst_42 : tensor<1x1200x1280xbf16>
    %6268 = stablehlo.multiply %6266, %3243 : tensor<1x1200x1280xbf16>
    %6269 = stablehlo.convert %6268 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %6270 = stablehlo.clamp %cst_43, %6269, %cst_44 : tensor<1x1200x1280xf32>
    %6271 = stablehlo.multiply %6270, %6270 : tensor<1x1200x1280xf32>
    %6272 = stablehlo.multiply %cst_45, %6271 : tensor<1x1200x1280xf32>
    %6273 = stablehlo.add %6272, %cst_46 : tensor<1x1200x1280xf32>
    %6274 = stablehlo.multiply %6273, %6271 : tensor<1x1200x1280xf32>
    %6275 = stablehlo.add %6274, %cst_47 : tensor<1x1200x1280xf32>
    %6276 = stablehlo.multiply %6275, %6271 : tensor<1x1200x1280xf32>
    %6277 = stablehlo.add %6276, %cst_48 : tensor<1x1200x1280xf32>
    %6278 = stablehlo.multiply %6277, %6271 : tensor<1x1200x1280xf32>
    %6279 = stablehlo.add %6278, %cst_49 : tensor<1x1200x1280xf32>
    %6280 = stablehlo.multiply %6279, %6271 : tensor<1x1200x1280xf32>
    %6281 = stablehlo.add %6280, %cst_50 : tensor<1x1200x1280xf32>
    %6282 = stablehlo.multiply %6281, %6271 : tensor<1x1200x1280xf32>
    %6283 = stablehlo.add %6282, %cst_51 : tensor<1x1200x1280xf32>
    %6284 = stablehlo.multiply %cst_52, %6271 : tensor<1x1200x1280xf32>
    %6285 = stablehlo.add %6284, %cst_53 : tensor<1x1200x1280xf32>
    %6286 = stablehlo.multiply %6285, %6271 : tensor<1x1200x1280xf32>
    %6287 = stablehlo.add %6286, %cst_54 : tensor<1x1200x1280xf32>
    %6288 = stablehlo.multiply %6287, %6271 : tensor<1x1200x1280xf32>
    %6289 = stablehlo.add %6288, %cst_55 : tensor<1x1200x1280xf32>
    %6290 = stablehlo.multiply %6289, %6271 : tensor<1x1200x1280xf32>
    %6291 = stablehlo.add %6290, %cst_56 : tensor<1x1200x1280xf32>
    %6292 = stablehlo.multiply %6270, %6283 : tensor<1x1200x1280xf32>
    %6293 = stablehlo.divide %6292, %6291 : tensor<1x1200x1280xf32>
    %6294 = stablehlo.clamp %cst_57, %6293, %cst_58 : tensor<1x1200x1280xf32>
    %6295 = stablehlo.convert %6294 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %6296 = stablehlo.add %6295, %cst_40 : tensor<1x1200x1280xbf16>
    %6297 = stablehlo.multiply %6296, %6267 : tensor<1x1200x1280xbf16>
    %6298 = stablehlo.reshape %6297 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %6299 = stablehlo.dot_general %6298, %arg755, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %6300 = stablehlo.reshape %6299 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6301 = stablehlo.broadcast_in_dim %6300, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6302 = stablehlo.broadcast_in_dim %arg280, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %6303 = stablehlo.add %6301, %6302 : tensor<1x1200x320xbf16>
    %6304 = stablehlo.reshape %6303 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6305 = stablehlo.reshape %6304 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6306 = stablehlo.add %6305, %6210 : tensor<1x1200x320xbf16>
    %6307 = stablehlo.convert %6306 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6308 = stablehlo.convert %6307 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6309 = stablehlo.reduce(%6308 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6310 = stablehlo.reshape %6309 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6311 = stablehlo.broadcast_in_dim %6310, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6312 = stablehlo.divide %6311, %2987 : tensor<1x1200x1xf64>
    %6313 = stablehlo.broadcast_in_dim %6308, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6314 = stablehlo.broadcast_in_dim %6312, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6315 = stablehlo.subtract %6313, %6314 : tensor<1x1200x320xf64>
    %6316 = stablehlo.multiply %6315, %6315 : tensor<1x1200x320xf64>
    %6317 = stablehlo.reduce(%6316 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6318 = stablehlo.reshape %6317 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6319 = stablehlo.broadcast_in_dim %6318, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6320 = stablehlo.divide %6319, %2987 : tensor<1x1200x1xf64>
    %6321 = stablehlo.convert %6320 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6322 = stablehlo.reduce(%6307 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6323 = stablehlo.reshape %6322 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6324 = stablehlo.broadcast_in_dim %6323, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6325 = stablehlo.divide %6324, %3003 : tensor<1x1200x1xf32>
    %6326 = stablehlo.broadcast_in_dim %6321, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6327 = stablehlo.add %6326, %3006 : tensor<1x1200x1xf32>
    %6328 = stablehlo.rsqrt %6327 : tensor<1x1200x1xf32>
    %6329 = stablehlo.broadcast_in_dim %6307, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6330 = stablehlo.broadcast_in_dim %6325, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6331 = stablehlo.subtract %6329, %6330 : tensor<1x1200x320xf32>
    %6332 = stablehlo.broadcast_in_dim %6331, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6333 = stablehlo.broadcast_in_dim %6328, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6334 = stablehlo.multiply %6332, %6333 : tensor<1x1200x320xf32>
    %6335 = stablehlo.convert %arg281 : (tensor<320xbf16>) -> tensor<320xf32>
    %6336 = stablehlo.broadcast_in_dim %6334, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6337 = stablehlo.broadcast_in_dim %6335, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6338 = stablehlo.multiply %6336, %6337 : tensor<1x1200x320xf32>
    %6339 = stablehlo.convert %arg282 : (tensor<320xbf16>) -> tensor<320xf32>
    %6340 = stablehlo.broadcast_in_dim %6338, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6341 = stablehlo.broadcast_in_dim %6339, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6342 = stablehlo.add %6340, %6341 : tensor<1x1200x320xf32>
    %6343 = stablehlo.convert %6342 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6344 = stablehlo.reshape %6343 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6345 = stablehlo.convert %6344 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6346 = stablehlo.dot_general %6345, %arg756, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6347 = stablehlo.broadcast_in_dim %6346, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6348 = stablehlo.multiply %6347, %3065 : tensor<1200x320xf32>
    %6349 = stablehlo.broadcast_in_dim %6348, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6350 = stablehlo.broadcast_in_dim %arg757, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6351 = stablehlo.add %6349, %6350 : tensor<1200x320xf32>
    %6352 = stablehlo.convert %6351 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6353 = stablehlo.reshape %6352 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6354 = stablehlo.reshape %6353 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %6355 = stablehlo.transpose %6354, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6356 = stablehlo.transpose %6343, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %6357 = stablehlo.reshape %6356 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %6358 = stablehlo.convolution(%6357, %arg283) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %6359 = stablehlo.reshape %arg284 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %6360 = stablehlo.broadcast_in_dim %6358, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %6361 = stablehlo.broadcast_in_dim %6359, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %6362 = stablehlo.add %6360, %6361 : tensor<1x320x15x20xbf16>
    %6363 = stablehlo.reshape %6362 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %6364 = stablehlo.transpose %6363, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %6365 = stablehlo.convert %6364 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %6366 = stablehlo.convert %6365 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %6367 = stablehlo.reduce(%6366 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6368 = stablehlo.reshape %6367 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6369 = stablehlo.broadcast_in_dim %6368, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6370 = stablehlo.divide %6369, %3088 : tensor<1x300x1xf64>
    %6371 = stablehlo.broadcast_in_dim %6366, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %6372 = stablehlo.broadcast_in_dim %6370, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %6373 = stablehlo.subtract %6371, %6372 : tensor<1x300x320xf64>
    %6374 = stablehlo.multiply %6373, %6373 : tensor<1x300x320xf64>
    %6375 = stablehlo.reduce(%6374 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6376 = stablehlo.reshape %6375 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6377 = stablehlo.broadcast_in_dim %6376, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6378 = stablehlo.divide %6377, %3088 : tensor<1x300x1xf64>
    %6379 = stablehlo.convert %6378 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %6380 = stablehlo.reduce(%6365 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %6381 = stablehlo.reshape %6380 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %6382 = stablehlo.broadcast_in_dim %6381, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6383 = stablehlo.divide %6382, %3102 : tensor<1x300x1xf32>
    %6384 = stablehlo.broadcast_in_dim %6379, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6385 = stablehlo.add %6384, %136 : tensor<1x300x1xf32>
    %6386 = stablehlo.rsqrt %6385 : tensor<1x300x1xf32>
    %6387 = stablehlo.broadcast_in_dim %6365, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6388 = stablehlo.broadcast_in_dim %6383, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6389 = stablehlo.subtract %6387, %6388 : tensor<1x300x320xf32>
    %6390 = stablehlo.broadcast_in_dim %6389, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6391 = stablehlo.broadcast_in_dim %6386, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6392 = stablehlo.multiply %6390, %6391 : tensor<1x300x320xf32>
    %6393 = stablehlo.convert %arg285 : (tensor<320xbf16>) -> tensor<320xf32>
    %6394 = stablehlo.broadcast_in_dim %6392, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6395 = stablehlo.broadcast_in_dim %6393, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6396 = stablehlo.multiply %6394, %6395 : tensor<1x300x320xf32>
    %6397 = stablehlo.convert %arg286 : (tensor<320xbf16>) -> tensor<320xf32>
    %6398 = stablehlo.broadcast_in_dim %6396, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6399 = stablehlo.broadcast_in_dim %6397, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6400 = stablehlo.add %6398, %6399 : tensor<1x300x320xf32>
    %6401 = stablehlo.convert %6400 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %6402 = stablehlo.reshape %6401 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %6403 = stablehlo.convert %6402 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %6404 = stablehlo.dot_general %6403, %arg758, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6405 = stablehlo.broadcast_in_dim %6404, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6406 = stablehlo.multiply %6405, %3126 : tensor<300x320xf32>
    %6407 = stablehlo.broadcast_in_dim %6406, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6408 = stablehlo.broadcast_in_dim %arg759, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6409 = stablehlo.add %6407, %6408 : tensor<300x320xf32>
    %6410 = stablehlo.convert %6409 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6411 = stablehlo.reshape %6410 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6412 = stablehlo.reshape %6411 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6413 = stablehlo.transpose %6412, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6414 = stablehlo.dot_general %6403, %arg760, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6415 = stablehlo.broadcast_in_dim %6414, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6416 = stablehlo.multiply %6415, %3126 : tensor<300x320xf32>
    %6417 = stablehlo.broadcast_in_dim %6416, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6418 = stablehlo.broadcast_in_dim %arg761, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6419 = stablehlo.add %6417, %6418 : tensor<300x320xf32>
    %6420 = stablehlo.convert %6419 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6421 = stablehlo.reshape %6420 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6422 = stablehlo.reshape %6421 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6423 = stablehlo.transpose %6422, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6424 = stablehlo.transpose %6413, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %6425 = stablehlo.reshape %6355 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %6426 = stablehlo.reshape %6424 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6427 = stablehlo.broadcast_in_dim %6426, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6428 = stablehlo.dot_general %6425, %6427, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %6429 = stablehlo.reshape %6428 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6430 = stablehlo.broadcast_in_dim %6429, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6431 = stablehlo.divide %6430, %3152 : tensor<1x5x1200x300xbf16>
    %6432 = stablehlo.convert %6431 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %6433 = stablehlo.reduce(%6432 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6434 = stablehlo.reshape %6433 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6435 = stablehlo.broadcast_in_dim %6432, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6436 = stablehlo.broadcast_in_dim %6434, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6437 = stablehlo.subtract %6435, %6436 : tensor<1x5x1200x300xf32>
    %6438 = stablehlo.exponential %6437 : tensor<1x5x1200x300xf32>
    %6439 = stablehlo.reduce(%6438 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6440 = stablehlo.reshape %6439 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6441 = stablehlo.broadcast_in_dim %6438, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6442 = stablehlo.broadcast_in_dim %6440, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6443 = stablehlo.divide %6441, %6442 : tensor<1x5x1200x300xf32>
    %6444 = stablehlo.convert %6443 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %6445 = stablehlo.reshape %6444 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %6446 = stablehlo.reshape %6423 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6447 = stablehlo.broadcast_in_dim %6446, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6448 = stablehlo.dot_general %6445, %6447, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %6449 = stablehlo.reshape %6448 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6450 = stablehlo.transpose %6449, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %6451 = stablehlo.reshape %6450 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %6452 = stablehlo.reshape %6451 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6453 = stablehlo.convert %6452 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6454 = stablehlo.dot_general %6453, %arg762, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6455 = stablehlo.broadcast_in_dim %6454, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6456 = stablehlo.multiply %6455, %3065 : tensor<1200x320xf32>
    %6457 = stablehlo.broadcast_in_dim %6456, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6458 = stablehlo.broadcast_in_dim %arg763, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6459 = stablehlo.add %6457, %6458 : tensor<1200x320xf32>
    %6460 = stablehlo.convert %6459 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6461 = stablehlo.reshape %6460 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6462 = stablehlo.add %6461, %6306 : tensor<1x1200x320xbf16>
    %6463 = stablehlo.convert %6462 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6464 = stablehlo.convert %6463 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6465 = stablehlo.reduce(%6464 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6466 = stablehlo.reshape %6465 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6467 = stablehlo.broadcast_in_dim %6466, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6468 = stablehlo.divide %6467, %2987 : tensor<1x1200x1xf64>
    %6469 = stablehlo.broadcast_in_dim %6464, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6470 = stablehlo.broadcast_in_dim %6468, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6471 = stablehlo.subtract %6469, %6470 : tensor<1x1200x320xf64>
    %6472 = stablehlo.multiply %6471, %6471 : tensor<1x1200x320xf64>
    %6473 = stablehlo.reduce(%6472 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6474 = stablehlo.reshape %6473 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6475 = stablehlo.broadcast_in_dim %6474, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6476 = stablehlo.divide %6475, %2987 : tensor<1x1200x1xf64>
    %6477 = stablehlo.convert %6476 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6478 = stablehlo.reduce(%6463 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6479 = stablehlo.reshape %6478 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6480 = stablehlo.broadcast_in_dim %6479, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6481 = stablehlo.divide %6480, %3003 : tensor<1x1200x1xf32>
    %6482 = stablehlo.broadcast_in_dim %6477, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6483 = stablehlo.add %6482, %3006 : tensor<1x1200x1xf32>
    %6484 = stablehlo.rsqrt %6483 : tensor<1x1200x1xf32>
    %6485 = stablehlo.broadcast_in_dim %6463, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6486 = stablehlo.broadcast_in_dim %6481, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6487 = stablehlo.subtract %6485, %6486 : tensor<1x1200x320xf32>
    %6488 = stablehlo.broadcast_in_dim %6487, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6489 = stablehlo.broadcast_in_dim %6484, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6490 = stablehlo.multiply %6488, %6489 : tensor<1x1200x320xf32>
    %6491 = stablehlo.convert %arg287 : (tensor<320xbf16>) -> tensor<320xf32>
    %6492 = stablehlo.broadcast_in_dim %6490, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6493 = stablehlo.broadcast_in_dim %6491, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6494 = stablehlo.multiply %6492, %6493 : tensor<1x1200x320xf32>
    %6495 = stablehlo.convert %arg288 : (tensor<320xbf16>) -> tensor<320xf32>
    %6496 = stablehlo.broadcast_in_dim %6494, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6497 = stablehlo.broadcast_in_dim %6495, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6498 = stablehlo.add %6496, %6497 : tensor<1x1200x320xf32>
    %6499 = stablehlo.convert %6498 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6500 = stablehlo.reshape %6499 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6501 = stablehlo.convert %6500 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6502 = stablehlo.dot_general %6501, %arg764, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %6503 = stablehlo.broadcast_in_dim %6502, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6504 = stablehlo.multiply %6503, %3226 : tensor<1200x1280xf32>
    %6505 = stablehlo.broadcast_in_dim %6504, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6506 = stablehlo.broadcast_in_dim %arg765, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %6507 = stablehlo.add %6505, %6506 : tensor<1200x1280xf32>
    %6508 = stablehlo.convert %6507 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %6509 = stablehlo.reshape %6508 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %6510 = stablehlo.transpose %6509, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %6511 = stablehlo.reshape %6510 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %6512 = stablehlo.convolution(%6511, %arg289) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %6513 = stablehlo.reshape %arg290 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %6514 = stablehlo.broadcast_in_dim %6512, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %6515 = stablehlo.broadcast_in_dim %6513, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %6516 = stablehlo.add %6514, %6515 : tensor<1x1280x30x40xbf16>
    %6517 = stablehlo.reshape %6516 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %6518 = stablehlo.transpose %6517, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %6519 = stablehlo.multiply %6518, %cst_42 : tensor<1x1200x1280xbf16>
    %6520 = stablehlo.multiply %6518, %3243 : tensor<1x1200x1280xbf16>
    %6521 = stablehlo.convert %6520 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %6522 = stablehlo.clamp %cst_43, %6521, %cst_44 : tensor<1x1200x1280xf32>
    %6523 = stablehlo.multiply %6522, %6522 : tensor<1x1200x1280xf32>
    %6524 = stablehlo.multiply %cst_45, %6523 : tensor<1x1200x1280xf32>
    %6525 = stablehlo.add %6524, %cst_46 : tensor<1x1200x1280xf32>
    %6526 = stablehlo.multiply %6525, %6523 : tensor<1x1200x1280xf32>
    %6527 = stablehlo.add %6526, %cst_47 : tensor<1x1200x1280xf32>
    %6528 = stablehlo.multiply %6527, %6523 : tensor<1x1200x1280xf32>
    %6529 = stablehlo.add %6528, %cst_48 : tensor<1x1200x1280xf32>
    %6530 = stablehlo.multiply %6529, %6523 : tensor<1x1200x1280xf32>
    %6531 = stablehlo.add %6530, %cst_49 : tensor<1x1200x1280xf32>
    %6532 = stablehlo.multiply %6531, %6523 : tensor<1x1200x1280xf32>
    %6533 = stablehlo.add %6532, %cst_50 : tensor<1x1200x1280xf32>
    %6534 = stablehlo.multiply %6533, %6523 : tensor<1x1200x1280xf32>
    %6535 = stablehlo.add %6534, %cst_51 : tensor<1x1200x1280xf32>
    %6536 = stablehlo.multiply %cst_52, %6523 : tensor<1x1200x1280xf32>
    %6537 = stablehlo.add %6536, %cst_53 : tensor<1x1200x1280xf32>
    %6538 = stablehlo.multiply %6537, %6523 : tensor<1x1200x1280xf32>
    %6539 = stablehlo.add %6538, %cst_54 : tensor<1x1200x1280xf32>
    %6540 = stablehlo.multiply %6539, %6523 : tensor<1x1200x1280xf32>
    %6541 = stablehlo.add %6540, %cst_55 : tensor<1x1200x1280xf32>
    %6542 = stablehlo.multiply %6541, %6523 : tensor<1x1200x1280xf32>
    %6543 = stablehlo.add %6542, %cst_56 : tensor<1x1200x1280xf32>
    %6544 = stablehlo.multiply %6522, %6535 : tensor<1x1200x1280xf32>
    %6545 = stablehlo.divide %6544, %6543 : tensor<1x1200x1280xf32>
    %6546 = stablehlo.clamp %cst_57, %6545, %cst_58 : tensor<1x1200x1280xf32>
    %6547 = stablehlo.convert %6546 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %6548 = stablehlo.add %6547, %cst_40 : tensor<1x1200x1280xbf16>
    %6549 = stablehlo.multiply %6548, %6519 : tensor<1x1200x1280xbf16>
    %6550 = stablehlo.reshape %6549 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %6551 = stablehlo.dot_general %6550, %arg766, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %6552 = stablehlo.reshape %6551 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6553 = stablehlo.broadcast_in_dim %6552, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6554 = stablehlo.broadcast_in_dim %arg291, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %6555 = stablehlo.add %6553, %6554 : tensor<1x1200x320xbf16>
    %6556 = stablehlo.reshape %6555 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6557 = stablehlo.reshape %6556 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6558 = stablehlo.add %6557, %6462 : tensor<1x1200x320xbf16>
    %6559 = stablehlo.convert %6558 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6560 = stablehlo.convert %6559 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6561 = stablehlo.reduce(%6560 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6562 = stablehlo.reshape %6561 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6563 = stablehlo.broadcast_in_dim %6562, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6564 = stablehlo.divide %6563, %2987 : tensor<1x1200x1xf64>
    %6565 = stablehlo.broadcast_in_dim %6560, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6566 = stablehlo.broadcast_in_dim %6564, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6567 = stablehlo.subtract %6565, %6566 : tensor<1x1200x320xf64>
    %6568 = stablehlo.multiply %6567, %6567 : tensor<1x1200x320xf64>
    %6569 = stablehlo.reduce(%6568 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6570 = stablehlo.reshape %6569 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6571 = stablehlo.broadcast_in_dim %6570, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6572 = stablehlo.divide %6571, %2987 : tensor<1x1200x1xf64>
    %6573 = stablehlo.convert %6572 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6574 = stablehlo.reduce(%6559 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6575 = stablehlo.reshape %6574 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6576 = stablehlo.broadcast_in_dim %6575, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6577 = stablehlo.divide %6576, %3003 : tensor<1x1200x1xf32>
    %6578 = stablehlo.broadcast_in_dim %6573, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6579 = stablehlo.add %6578, %3006 : tensor<1x1200x1xf32>
    %6580 = stablehlo.rsqrt %6579 : tensor<1x1200x1xf32>
    %6581 = stablehlo.broadcast_in_dim %6559, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6582 = stablehlo.broadcast_in_dim %6577, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6583 = stablehlo.subtract %6581, %6582 : tensor<1x1200x320xf32>
    %6584 = stablehlo.broadcast_in_dim %6583, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6585 = stablehlo.broadcast_in_dim %6580, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6586 = stablehlo.multiply %6584, %6585 : tensor<1x1200x320xf32>
    %6587 = stablehlo.convert %arg292 : (tensor<320xbf16>) -> tensor<320xf32>
    %6588 = stablehlo.broadcast_in_dim %6586, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6589 = stablehlo.broadcast_in_dim %6587, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6590 = stablehlo.multiply %6588, %6589 : tensor<1x1200x320xf32>
    %6591 = stablehlo.convert %arg293 : (tensor<320xbf16>) -> tensor<320xf32>
    %6592 = stablehlo.broadcast_in_dim %6590, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6593 = stablehlo.broadcast_in_dim %6591, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6594 = stablehlo.add %6592, %6593 : tensor<1x1200x320xf32>
    %6595 = stablehlo.convert %6594 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6596 = stablehlo.reshape %6595 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6597 = stablehlo.convert %6596 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6598 = stablehlo.dot_general %6597, %arg767, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6599 = stablehlo.broadcast_in_dim %6598, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6600 = stablehlo.multiply %6599, %3065 : tensor<1200x320xf32>
    %6601 = stablehlo.broadcast_in_dim %6600, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6602 = stablehlo.broadcast_in_dim %arg768, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6603 = stablehlo.add %6601, %6602 : tensor<1200x320xf32>
    %6604 = stablehlo.convert %6603 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6605 = stablehlo.reshape %6604 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6606 = stablehlo.reshape %6605 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %6607 = stablehlo.transpose %6606, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6608 = stablehlo.transpose %6595, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %6609 = stablehlo.reshape %6608 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %6610 = stablehlo.convolution(%6609, %arg294) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %6611 = stablehlo.reshape %arg295 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %6612 = stablehlo.broadcast_in_dim %6610, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %6613 = stablehlo.broadcast_in_dim %6611, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %6614 = stablehlo.add %6612, %6613 : tensor<1x320x15x20xbf16>
    %6615 = stablehlo.reshape %6614 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %6616 = stablehlo.transpose %6615, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %6617 = stablehlo.convert %6616 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %6618 = stablehlo.convert %6617 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %6619 = stablehlo.reduce(%6618 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6620 = stablehlo.reshape %6619 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6621 = stablehlo.broadcast_in_dim %6620, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6622 = stablehlo.divide %6621, %3088 : tensor<1x300x1xf64>
    %6623 = stablehlo.broadcast_in_dim %6618, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %6624 = stablehlo.broadcast_in_dim %6622, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %6625 = stablehlo.subtract %6623, %6624 : tensor<1x300x320xf64>
    %6626 = stablehlo.multiply %6625, %6625 : tensor<1x300x320xf64>
    %6627 = stablehlo.reduce(%6626 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6628 = stablehlo.reshape %6627 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6629 = stablehlo.broadcast_in_dim %6628, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6630 = stablehlo.divide %6629, %3088 : tensor<1x300x1xf64>
    %6631 = stablehlo.convert %6630 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %6632 = stablehlo.reduce(%6617 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %6633 = stablehlo.reshape %6632 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %6634 = stablehlo.broadcast_in_dim %6633, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6635 = stablehlo.divide %6634, %3102 : tensor<1x300x1xf32>
    %6636 = stablehlo.broadcast_in_dim %6631, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6637 = stablehlo.add %6636, %136 : tensor<1x300x1xf32>
    %6638 = stablehlo.rsqrt %6637 : tensor<1x300x1xf32>
    %6639 = stablehlo.broadcast_in_dim %6617, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6640 = stablehlo.broadcast_in_dim %6635, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6641 = stablehlo.subtract %6639, %6640 : tensor<1x300x320xf32>
    %6642 = stablehlo.broadcast_in_dim %6641, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6643 = stablehlo.broadcast_in_dim %6638, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6644 = stablehlo.multiply %6642, %6643 : tensor<1x300x320xf32>
    %6645 = stablehlo.convert %arg296 : (tensor<320xbf16>) -> tensor<320xf32>
    %6646 = stablehlo.broadcast_in_dim %6644, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6647 = stablehlo.broadcast_in_dim %6645, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6648 = stablehlo.multiply %6646, %6647 : tensor<1x300x320xf32>
    %6649 = stablehlo.convert %arg297 : (tensor<320xbf16>) -> tensor<320xf32>
    %6650 = stablehlo.broadcast_in_dim %6648, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6651 = stablehlo.broadcast_in_dim %6649, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6652 = stablehlo.add %6650, %6651 : tensor<1x300x320xf32>
    %6653 = stablehlo.convert %6652 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %6654 = stablehlo.reshape %6653 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %6655 = stablehlo.convert %6654 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %6656 = stablehlo.dot_general %6655, %arg769, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6657 = stablehlo.broadcast_in_dim %6656, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6658 = stablehlo.multiply %6657, %3126 : tensor<300x320xf32>
    %6659 = stablehlo.broadcast_in_dim %6658, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6660 = stablehlo.broadcast_in_dim %arg770, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6661 = stablehlo.add %6659, %6660 : tensor<300x320xf32>
    %6662 = stablehlo.convert %6661 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6663 = stablehlo.reshape %6662 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6664 = stablehlo.reshape %6663 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6665 = stablehlo.transpose %6664, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6666 = stablehlo.dot_general %6655, %arg771, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6667 = stablehlo.broadcast_in_dim %6666, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6668 = stablehlo.multiply %6667, %3126 : tensor<300x320xf32>
    %6669 = stablehlo.broadcast_in_dim %6668, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6670 = stablehlo.broadcast_in_dim %arg772, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6671 = stablehlo.add %6669, %6670 : tensor<300x320xf32>
    %6672 = stablehlo.convert %6671 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6673 = stablehlo.reshape %6672 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6674 = stablehlo.reshape %6673 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6675 = stablehlo.transpose %6674, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6676 = stablehlo.transpose %6665, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %6677 = stablehlo.reshape %6607 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %6678 = stablehlo.reshape %6676 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6679 = stablehlo.broadcast_in_dim %6678, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6680 = stablehlo.dot_general %6677, %6679, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %6681 = stablehlo.reshape %6680 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6682 = stablehlo.broadcast_in_dim %6681, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6683 = stablehlo.divide %6682, %3152 : tensor<1x5x1200x300xbf16>
    %6684 = stablehlo.convert %6683 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %6685 = stablehlo.reduce(%6684 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6686 = stablehlo.reshape %6685 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6687 = stablehlo.broadcast_in_dim %6684, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6688 = stablehlo.broadcast_in_dim %6686, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6689 = stablehlo.subtract %6687, %6688 : tensor<1x5x1200x300xf32>
    %6690 = stablehlo.exponential %6689 : tensor<1x5x1200x300xf32>
    %6691 = stablehlo.reduce(%6690 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6692 = stablehlo.reshape %6691 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6693 = stablehlo.broadcast_in_dim %6690, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6694 = stablehlo.broadcast_in_dim %6692, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6695 = stablehlo.divide %6693, %6694 : tensor<1x5x1200x300xf32>
    %6696 = stablehlo.convert %6695 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %6697 = stablehlo.reshape %6696 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %6698 = stablehlo.reshape %6675 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6699 = stablehlo.broadcast_in_dim %6698, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6700 = stablehlo.dot_general %6697, %6699, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %6701 = stablehlo.reshape %6700 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6702 = stablehlo.transpose %6701, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %6703 = stablehlo.reshape %6702 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %6704 = stablehlo.reshape %6703 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6705 = stablehlo.convert %6704 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6706 = stablehlo.dot_general %6705, %arg773, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6707 = stablehlo.broadcast_in_dim %6706, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6708 = stablehlo.multiply %6707, %3065 : tensor<1200x320xf32>
    %6709 = stablehlo.broadcast_in_dim %6708, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6710 = stablehlo.broadcast_in_dim %arg774, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6711 = stablehlo.add %6709, %6710 : tensor<1200x320xf32>
    %6712 = stablehlo.convert %6711 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6713 = stablehlo.reshape %6712 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6714 = stablehlo.add %6713, %6558 : tensor<1x1200x320xbf16>
    %6715 = stablehlo.convert %6714 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6716 = stablehlo.convert %6715 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6717 = stablehlo.reduce(%6716 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6718 = stablehlo.reshape %6717 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6719 = stablehlo.broadcast_in_dim %6718, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6720 = stablehlo.divide %6719, %2987 : tensor<1x1200x1xf64>
    %6721 = stablehlo.broadcast_in_dim %6716, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6722 = stablehlo.broadcast_in_dim %6720, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6723 = stablehlo.subtract %6721, %6722 : tensor<1x1200x320xf64>
    %6724 = stablehlo.multiply %6723, %6723 : tensor<1x1200x320xf64>
    %6725 = stablehlo.reduce(%6724 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6726 = stablehlo.reshape %6725 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6727 = stablehlo.broadcast_in_dim %6726, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6728 = stablehlo.divide %6727, %2987 : tensor<1x1200x1xf64>
    %6729 = stablehlo.convert %6728 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6730 = stablehlo.reduce(%6715 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6731 = stablehlo.reshape %6730 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6732 = stablehlo.broadcast_in_dim %6731, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6733 = stablehlo.divide %6732, %3003 : tensor<1x1200x1xf32>
    %6734 = stablehlo.broadcast_in_dim %6729, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6735 = stablehlo.add %6734, %3006 : tensor<1x1200x1xf32>
    %6736 = stablehlo.rsqrt %6735 : tensor<1x1200x1xf32>
    %6737 = stablehlo.broadcast_in_dim %6715, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6738 = stablehlo.broadcast_in_dim %6733, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6739 = stablehlo.subtract %6737, %6738 : tensor<1x1200x320xf32>
    %6740 = stablehlo.broadcast_in_dim %6739, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6741 = stablehlo.broadcast_in_dim %6736, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6742 = stablehlo.multiply %6740, %6741 : tensor<1x1200x320xf32>
    %6743 = stablehlo.convert %arg298 : (tensor<320xbf16>) -> tensor<320xf32>
    %6744 = stablehlo.broadcast_in_dim %6742, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6745 = stablehlo.broadcast_in_dim %6743, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6746 = stablehlo.multiply %6744, %6745 : tensor<1x1200x320xf32>
    %6747 = stablehlo.convert %arg299 : (tensor<320xbf16>) -> tensor<320xf32>
    %6748 = stablehlo.broadcast_in_dim %6746, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6749 = stablehlo.broadcast_in_dim %6747, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6750 = stablehlo.add %6748, %6749 : tensor<1x1200x320xf32>
    %6751 = stablehlo.convert %6750 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6752 = stablehlo.reshape %6751 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6753 = stablehlo.convert %6752 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6754 = stablehlo.dot_general %6753, %arg775, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %6755 = stablehlo.broadcast_in_dim %6754, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6756 = stablehlo.multiply %6755, %3226 : tensor<1200x1280xf32>
    %6757 = stablehlo.broadcast_in_dim %6756, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %6758 = stablehlo.broadcast_in_dim %arg776, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %6759 = stablehlo.add %6757, %6758 : tensor<1200x1280xf32>
    %6760 = stablehlo.convert %6759 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %6761 = stablehlo.reshape %6760 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %6762 = stablehlo.transpose %6761, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %6763 = stablehlo.reshape %6762 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %6764 = stablehlo.convolution(%6763, %arg300) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %6765 = stablehlo.reshape %arg301 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %6766 = stablehlo.broadcast_in_dim %6764, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %6767 = stablehlo.broadcast_in_dim %6765, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %6768 = stablehlo.add %6766, %6767 : tensor<1x1280x30x40xbf16>
    %6769 = stablehlo.reshape %6768 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %6770 = stablehlo.transpose %6769, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %6771 = stablehlo.multiply %6770, %cst_42 : tensor<1x1200x1280xbf16>
    %6772 = stablehlo.multiply %6770, %3243 : tensor<1x1200x1280xbf16>
    %6773 = stablehlo.convert %6772 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %6774 = stablehlo.clamp %cst_43, %6773, %cst_44 : tensor<1x1200x1280xf32>
    %6775 = stablehlo.multiply %6774, %6774 : tensor<1x1200x1280xf32>
    %6776 = stablehlo.multiply %cst_45, %6775 : tensor<1x1200x1280xf32>
    %6777 = stablehlo.add %6776, %cst_46 : tensor<1x1200x1280xf32>
    %6778 = stablehlo.multiply %6777, %6775 : tensor<1x1200x1280xf32>
    %6779 = stablehlo.add %6778, %cst_47 : tensor<1x1200x1280xf32>
    %6780 = stablehlo.multiply %6779, %6775 : tensor<1x1200x1280xf32>
    %6781 = stablehlo.add %6780, %cst_48 : tensor<1x1200x1280xf32>
    %6782 = stablehlo.multiply %6781, %6775 : tensor<1x1200x1280xf32>
    %6783 = stablehlo.add %6782, %cst_49 : tensor<1x1200x1280xf32>
    %6784 = stablehlo.multiply %6783, %6775 : tensor<1x1200x1280xf32>
    %6785 = stablehlo.add %6784, %cst_50 : tensor<1x1200x1280xf32>
    %6786 = stablehlo.multiply %6785, %6775 : tensor<1x1200x1280xf32>
    %6787 = stablehlo.add %6786, %cst_51 : tensor<1x1200x1280xf32>
    %6788 = stablehlo.multiply %cst_52, %6775 : tensor<1x1200x1280xf32>
    %6789 = stablehlo.add %6788, %cst_53 : tensor<1x1200x1280xf32>
    %6790 = stablehlo.multiply %6789, %6775 : tensor<1x1200x1280xf32>
    %6791 = stablehlo.add %6790, %cst_54 : tensor<1x1200x1280xf32>
    %6792 = stablehlo.multiply %6791, %6775 : tensor<1x1200x1280xf32>
    %6793 = stablehlo.add %6792, %cst_55 : tensor<1x1200x1280xf32>
    %6794 = stablehlo.multiply %6793, %6775 : tensor<1x1200x1280xf32>
    %6795 = stablehlo.add %6794, %cst_56 : tensor<1x1200x1280xf32>
    %6796 = stablehlo.multiply %6774, %6787 : tensor<1x1200x1280xf32>
    %6797 = stablehlo.divide %6796, %6795 : tensor<1x1200x1280xf32>
    %6798 = stablehlo.clamp %cst_57, %6797, %cst_58 : tensor<1x1200x1280xf32>
    %6799 = stablehlo.convert %6798 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %6800 = stablehlo.add %6799, %cst_40 : tensor<1x1200x1280xbf16>
    %6801 = stablehlo.multiply %6800, %6771 : tensor<1x1200x1280xbf16>
    %6802 = stablehlo.reshape %6801 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %6803 = stablehlo.dot_general %6802, %arg777, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %6804 = stablehlo.reshape %6803 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6805 = stablehlo.broadcast_in_dim %6804, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6806 = stablehlo.broadcast_in_dim %arg302, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %6807 = stablehlo.add %6805, %6806 : tensor<1x1200x320xbf16>
    %6808 = stablehlo.reshape %6807 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6809 = stablehlo.reshape %6808 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6810 = stablehlo.add %6809, %6714 : tensor<1x1200x320xbf16>
    %6811 = stablehlo.convert %6810 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6812 = stablehlo.convert %6811 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6813 = stablehlo.reduce(%6812 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6814 = stablehlo.reshape %6813 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6815 = stablehlo.broadcast_in_dim %6814, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6816 = stablehlo.divide %6815, %2987 : tensor<1x1200x1xf64>
    %6817 = stablehlo.broadcast_in_dim %6812, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6818 = stablehlo.broadcast_in_dim %6816, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6819 = stablehlo.subtract %6817, %6818 : tensor<1x1200x320xf64>
    %6820 = stablehlo.multiply %6819, %6819 : tensor<1x1200x320xf64>
    %6821 = stablehlo.reduce(%6820 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6822 = stablehlo.reshape %6821 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6823 = stablehlo.broadcast_in_dim %6822, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6824 = stablehlo.divide %6823, %2987 : tensor<1x1200x1xf64>
    %6825 = stablehlo.convert %6824 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6826 = stablehlo.reduce(%6811 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6827 = stablehlo.reshape %6826 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6828 = stablehlo.broadcast_in_dim %6827, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6829 = stablehlo.divide %6828, %3003 : tensor<1x1200x1xf32>
    %6830 = stablehlo.broadcast_in_dim %6825, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6831 = stablehlo.add %6830, %3006 : tensor<1x1200x1xf32>
    %6832 = stablehlo.rsqrt %6831 : tensor<1x1200x1xf32>
    %6833 = stablehlo.broadcast_in_dim %6811, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6834 = stablehlo.broadcast_in_dim %6829, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6835 = stablehlo.subtract %6833, %6834 : tensor<1x1200x320xf32>
    %6836 = stablehlo.broadcast_in_dim %6835, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6837 = stablehlo.broadcast_in_dim %6832, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6838 = stablehlo.multiply %6836, %6837 : tensor<1x1200x320xf32>
    %6839 = stablehlo.convert %arg303 : (tensor<320xbf16>) -> tensor<320xf32>
    %6840 = stablehlo.broadcast_in_dim %6838, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6841 = stablehlo.broadcast_in_dim %6839, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6842 = stablehlo.multiply %6840, %6841 : tensor<1x1200x320xf32>
    %6843 = stablehlo.convert %arg304 : (tensor<320xbf16>) -> tensor<320xf32>
    %6844 = stablehlo.broadcast_in_dim %6842, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6845 = stablehlo.broadcast_in_dim %6843, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6846 = stablehlo.add %6844, %6845 : tensor<1x1200x320xf32>
    %6847 = stablehlo.convert %6846 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %6848 = stablehlo.reshape %6847 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6849 = stablehlo.convert %6848 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6850 = stablehlo.dot_general %6849, %arg778, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6851 = stablehlo.broadcast_in_dim %6850, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6852 = stablehlo.multiply %6851, %3065 : tensor<1200x320xf32>
    %6853 = stablehlo.broadcast_in_dim %6852, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6854 = stablehlo.broadcast_in_dim %arg779, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6855 = stablehlo.add %6853, %6854 : tensor<1200x320xf32>
    %6856 = stablehlo.convert %6855 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6857 = stablehlo.reshape %6856 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6858 = stablehlo.reshape %6857 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %6859 = stablehlo.transpose %6858, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6860 = stablehlo.transpose %6847, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %6861 = stablehlo.reshape %6860 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %6862 = stablehlo.convolution(%6861, %arg305) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %6863 = stablehlo.reshape %arg306 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %6864 = stablehlo.broadcast_in_dim %6862, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %6865 = stablehlo.broadcast_in_dim %6863, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %6866 = stablehlo.add %6864, %6865 : tensor<1x320x15x20xbf16>
    %6867 = stablehlo.reshape %6866 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %6868 = stablehlo.transpose %6867, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %6869 = stablehlo.convert %6868 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %6870 = stablehlo.convert %6869 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %6871 = stablehlo.reduce(%6870 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6872 = stablehlo.reshape %6871 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6873 = stablehlo.broadcast_in_dim %6872, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6874 = stablehlo.divide %6873, %3088 : tensor<1x300x1xf64>
    %6875 = stablehlo.broadcast_in_dim %6870, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %6876 = stablehlo.broadcast_in_dim %6874, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %6877 = stablehlo.subtract %6875, %6876 : tensor<1x300x320xf64>
    %6878 = stablehlo.multiply %6877, %6877 : tensor<1x300x320xf64>
    %6879 = stablehlo.reduce(%6878 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %6880 = stablehlo.reshape %6879 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %6881 = stablehlo.broadcast_in_dim %6880, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %6882 = stablehlo.divide %6881, %3088 : tensor<1x300x1xf64>
    %6883 = stablehlo.convert %6882 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %6884 = stablehlo.reduce(%6869 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %6885 = stablehlo.reshape %6884 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %6886 = stablehlo.broadcast_in_dim %6885, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6887 = stablehlo.divide %6886, %3102 : tensor<1x300x1xf32>
    %6888 = stablehlo.broadcast_in_dim %6883, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %6889 = stablehlo.add %6888, %136 : tensor<1x300x1xf32>
    %6890 = stablehlo.rsqrt %6889 : tensor<1x300x1xf32>
    %6891 = stablehlo.broadcast_in_dim %6869, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6892 = stablehlo.broadcast_in_dim %6887, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6893 = stablehlo.subtract %6891, %6892 : tensor<1x300x320xf32>
    %6894 = stablehlo.broadcast_in_dim %6893, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6895 = stablehlo.broadcast_in_dim %6890, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %6896 = stablehlo.multiply %6894, %6895 : tensor<1x300x320xf32>
    %6897 = stablehlo.convert %arg307 : (tensor<320xbf16>) -> tensor<320xf32>
    %6898 = stablehlo.broadcast_in_dim %6896, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6899 = stablehlo.broadcast_in_dim %6897, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6900 = stablehlo.multiply %6898, %6899 : tensor<1x300x320xf32>
    %6901 = stablehlo.convert %arg308 : (tensor<320xbf16>) -> tensor<320xf32>
    %6902 = stablehlo.broadcast_in_dim %6900, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %6903 = stablehlo.broadcast_in_dim %6901, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %6904 = stablehlo.add %6902, %6903 : tensor<1x300x320xf32>
    %6905 = stablehlo.convert %6904 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %6906 = stablehlo.reshape %6905 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %6907 = stablehlo.convert %6906 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %6908 = stablehlo.dot_general %6907, %arg780, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6909 = stablehlo.broadcast_in_dim %6908, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6910 = stablehlo.multiply %6909, %3126 : tensor<300x320xf32>
    %6911 = stablehlo.broadcast_in_dim %6910, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6912 = stablehlo.broadcast_in_dim %arg781, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6913 = stablehlo.add %6911, %6912 : tensor<300x320xf32>
    %6914 = stablehlo.convert %6913 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6915 = stablehlo.reshape %6914 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6916 = stablehlo.reshape %6915 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6917 = stablehlo.transpose %6916, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6918 = stablehlo.dot_general %6907, %arg782, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %6919 = stablehlo.broadcast_in_dim %6918, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6920 = stablehlo.multiply %6919, %3126 : tensor<300x320xf32>
    %6921 = stablehlo.broadcast_in_dim %6920, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %6922 = stablehlo.broadcast_in_dim %arg783, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %6923 = stablehlo.add %6921, %6922 : tensor<300x320xf32>
    %6924 = stablehlo.convert %6923 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %6925 = stablehlo.reshape %6924 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %6926 = stablehlo.reshape %6925 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %6927 = stablehlo.transpose %6926, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %6928 = stablehlo.transpose %6917, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %6929 = stablehlo.reshape %6859 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %6930 = stablehlo.reshape %6928 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6931 = stablehlo.broadcast_in_dim %6930, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %6932 = stablehlo.dot_general %6929, %6931, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %6933 = stablehlo.reshape %6932 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6934 = stablehlo.broadcast_in_dim %6933, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %6935 = stablehlo.divide %6934, %3152 : tensor<1x5x1200x300xbf16>
    %6936 = stablehlo.convert %6935 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %6937 = stablehlo.reduce(%6936 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6938 = stablehlo.reshape %6937 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6939 = stablehlo.broadcast_in_dim %6936, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6940 = stablehlo.broadcast_in_dim %6938, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6941 = stablehlo.subtract %6939, %6940 : tensor<1x5x1200x300xf32>
    %6942 = stablehlo.exponential %6941 : tensor<1x5x1200x300xf32>
    %6943 = stablehlo.reduce(%6942 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %6944 = stablehlo.reshape %6943 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %6945 = stablehlo.broadcast_in_dim %6942, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %6946 = stablehlo.broadcast_in_dim %6944, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %6947 = stablehlo.divide %6945, %6946 : tensor<1x5x1200x300xf32>
    %6948 = stablehlo.convert %6947 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %6949 = stablehlo.reshape %6948 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %6950 = stablehlo.reshape %6927 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6951 = stablehlo.broadcast_in_dim %6950, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %6952 = stablehlo.dot_general %6949, %6951, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %6953 = stablehlo.reshape %6952 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %6954 = stablehlo.transpose %6953, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %6955 = stablehlo.reshape %6954 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %6956 = stablehlo.reshape %6955 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %6957 = stablehlo.convert %6956 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %6958 = stablehlo.dot_general %6957, %arg784, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %6959 = stablehlo.broadcast_in_dim %6958, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6960 = stablehlo.multiply %6959, %3065 : tensor<1200x320xf32>
    %6961 = stablehlo.broadcast_in_dim %6960, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %6962 = stablehlo.broadcast_in_dim %arg785, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %6963 = stablehlo.add %6961, %6962 : tensor<1200x320xf32>
    %6964 = stablehlo.convert %6963 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %6965 = stablehlo.reshape %6964 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %6966 = stablehlo.add %6965, %6810 : tensor<1x1200x320xbf16>
    %6967 = stablehlo.convert %6966 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %6968 = stablehlo.convert %6967 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %6969 = stablehlo.reduce(%6968 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6970 = stablehlo.reshape %6969 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6971 = stablehlo.broadcast_in_dim %6970, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6972 = stablehlo.divide %6971, %2987 : tensor<1x1200x1xf64>
    %6973 = stablehlo.broadcast_in_dim %6968, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %6974 = stablehlo.broadcast_in_dim %6972, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %6975 = stablehlo.subtract %6973, %6974 : tensor<1x1200x320xf64>
    %6976 = stablehlo.multiply %6975, %6975 : tensor<1x1200x320xf64>
    %6977 = stablehlo.reduce(%6976 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %6978 = stablehlo.reshape %6977 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %6979 = stablehlo.broadcast_in_dim %6978, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %6980 = stablehlo.divide %6979, %2987 : tensor<1x1200x1xf64>
    %6981 = stablehlo.convert %6980 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %6982 = stablehlo.reduce(%6967 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %6983 = stablehlo.reshape %6982 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %6984 = stablehlo.broadcast_in_dim %6983, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6985 = stablehlo.divide %6984, %3003 : tensor<1x1200x1xf32>
    %6986 = stablehlo.broadcast_in_dim %6981, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %6987 = stablehlo.add %6986, %3006 : tensor<1x1200x1xf32>
    %6988 = stablehlo.rsqrt %6987 : tensor<1x1200x1xf32>
    %6989 = stablehlo.broadcast_in_dim %6967, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6990 = stablehlo.broadcast_in_dim %6985, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6991 = stablehlo.subtract %6989, %6990 : tensor<1x1200x320xf32>
    %6992 = stablehlo.broadcast_in_dim %6991, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6993 = stablehlo.broadcast_in_dim %6988, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %6994 = stablehlo.multiply %6992, %6993 : tensor<1x1200x320xf32>
    %6995 = stablehlo.convert %arg309 : (tensor<320xbf16>) -> tensor<320xf32>
    %6996 = stablehlo.broadcast_in_dim %6994, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %6997 = stablehlo.broadcast_in_dim %6995, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %6998 = stablehlo.multiply %6996, %6997 : tensor<1x1200x320xf32>
    %6999 = stablehlo.convert %arg310 : (tensor<320xbf16>) -> tensor<320xf32>
    %7000 = stablehlo.broadcast_in_dim %6998, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7001 = stablehlo.broadcast_in_dim %6999, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7002 = stablehlo.add %7000, %7001 : tensor<1x1200x320xf32>
    %7003 = stablehlo.convert %7002 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7004 = stablehlo.reshape %7003 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7005 = stablehlo.convert %7004 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7006 = stablehlo.dot_general %7005, %arg786, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %7007 = stablehlo.broadcast_in_dim %7006, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7008 = stablehlo.multiply %7007, %3226 : tensor<1200x1280xf32>
    %7009 = stablehlo.broadcast_in_dim %7008, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7010 = stablehlo.broadcast_in_dim %arg787, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %7011 = stablehlo.add %7009, %7010 : tensor<1200x1280xf32>
    %7012 = stablehlo.convert %7011 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %7013 = stablehlo.reshape %7012 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %7014 = stablehlo.transpose %7013, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %7015 = stablehlo.reshape %7014 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %7016 = stablehlo.convolution(%7015, %arg311) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %7017 = stablehlo.reshape %arg312 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %7018 = stablehlo.broadcast_in_dim %7016, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %7019 = stablehlo.broadcast_in_dim %7017, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %7020 = stablehlo.add %7018, %7019 : tensor<1x1280x30x40xbf16>
    %7021 = stablehlo.reshape %7020 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %7022 = stablehlo.transpose %7021, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %7023 = stablehlo.multiply %7022, %cst_42 : tensor<1x1200x1280xbf16>
    %7024 = stablehlo.multiply %7022, %3243 : tensor<1x1200x1280xbf16>
    %7025 = stablehlo.convert %7024 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %7026 = stablehlo.clamp %cst_43, %7025, %cst_44 : tensor<1x1200x1280xf32>
    %7027 = stablehlo.multiply %7026, %7026 : tensor<1x1200x1280xf32>
    %7028 = stablehlo.multiply %cst_45, %7027 : tensor<1x1200x1280xf32>
    %7029 = stablehlo.add %7028, %cst_46 : tensor<1x1200x1280xf32>
    %7030 = stablehlo.multiply %7029, %7027 : tensor<1x1200x1280xf32>
    %7031 = stablehlo.add %7030, %cst_47 : tensor<1x1200x1280xf32>
    %7032 = stablehlo.multiply %7031, %7027 : tensor<1x1200x1280xf32>
    %7033 = stablehlo.add %7032, %cst_48 : tensor<1x1200x1280xf32>
    %7034 = stablehlo.multiply %7033, %7027 : tensor<1x1200x1280xf32>
    %7035 = stablehlo.add %7034, %cst_49 : tensor<1x1200x1280xf32>
    %7036 = stablehlo.multiply %7035, %7027 : tensor<1x1200x1280xf32>
    %7037 = stablehlo.add %7036, %cst_50 : tensor<1x1200x1280xf32>
    %7038 = stablehlo.multiply %7037, %7027 : tensor<1x1200x1280xf32>
    %7039 = stablehlo.add %7038, %cst_51 : tensor<1x1200x1280xf32>
    %7040 = stablehlo.multiply %cst_52, %7027 : tensor<1x1200x1280xf32>
    %7041 = stablehlo.add %7040, %cst_53 : tensor<1x1200x1280xf32>
    %7042 = stablehlo.multiply %7041, %7027 : tensor<1x1200x1280xf32>
    %7043 = stablehlo.add %7042, %cst_54 : tensor<1x1200x1280xf32>
    %7044 = stablehlo.multiply %7043, %7027 : tensor<1x1200x1280xf32>
    %7045 = stablehlo.add %7044, %cst_55 : tensor<1x1200x1280xf32>
    %7046 = stablehlo.multiply %7045, %7027 : tensor<1x1200x1280xf32>
    %7047 = stablehlo.add %7046, %cst_56 : tensor<1x1200x1280xf32>
    %7048 = stablehlo.multiply %7026, %7039 : tensor<1x1200x1280xf32>
    %7049 = stablehlo.divide %7048, %7047 : tensor<1x1200x1280xf32>
    %7050 = stablehlo.clamp %cst_57, %7049, %cst_58 : tensor<1x1200x1280xf32>
    %7051 = stablehlo.convert %7050 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %7052 = stablehlo.add %7051, %cst_40 : tensor<1x1200x1280xbf16>
    %7053 = stablehlo.multiply %7052, %7023 : tensor<1x1200x1280xbf16>
    %7054 = stablehlo.reshape %7053 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %7055 = stablehlo.dot_general %7054, %arg788, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %7056 = stablehlo.reshape %7055 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7057 = stablehlo.broadcast_in_dim %7056, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7058 = stablehlo.broadcast_in_dim %arg313, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %7059 = stablehlo.add %7057, %7058 : tensor<1x1200x320xbf16>
    %7060 = stablehlo.reshape %7059 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7061 = stablehlo.reshape %7060 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7062 = stablehlo.add %7061, %6966 : tensor<1x1200x320xbf16>
    %7063 = stablehlo.convert %7062 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7064 = stablehlo.convert %7063 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7065 = stablehlo.reduce(%7064 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7066 = stablehlo.reshape %7065 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7067 = stablehlo.broadcast_in_dim %7066, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7068 = stablehlo.divide %7067, %2987 : tensor<1x1200x1xf64>
    %7069 = stablehlo.broadcast_in_dim %7064, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7070 = stablehlo.broadcast_in_dim %7068, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7071 = stablehlo.subtract %7069, %7070 : tensor<1x1200x320xf64>
    %7072 = stablehlo.multiply %7071, %7071 : tensor<1x1200x320xf64>
    %7073 = stablehlo.reduce(%7072 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7074 = stablehlo.reshape %7073 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7075 = stablehlo.broadcast_in_dim %7074, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7076 = stablehlo.divide %7075, %2987 : tensor<1x1200x1xf64>
    %7077 = stablehlo.convert %7076 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7078 = stablehlo.reduce(%7063 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7079 = stablehlo.reshape %7078 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7080 = stablehlo.broadcast_in_dim %7079, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7081 = stablehlo.divide %7080, %3003 : tensor<1x1200x1xf32>
    %7082 = stablehlo.broadcast_in_dim %7077, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7083 = stablehlo.add %7082, %3006 : tensor<1x1200x1xf32>
    %7084 = stablehlo.rsqrt %7083 : tensor<1x1200x1xf32>
    %7085 = stablehlo.broadcast_in_dim %7063, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7086 = stablehlo.broadcast_in_dim %7081, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7087 = stablehlo.subtract %7085, %7086 : tensor<1x1200x320xf32>
    %7088 = stablehlo.broadcast_in_dim %7087, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7089 = stablehlo.broadcast_in_dim %7084, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7090 = stablehlo.multiply %7088, %7089 : tensor<1x1200x320xf32>
    %7091 = stablehlo.convert %arg314 : (tensor<320xbf16>) -> tensor<320xf32>
    %7092 = stablehlo.broadcast_in_dim %7090, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7093 = stablehlo.broadcast_in_dim %7091, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7094 = stablehlo.multiply %7092, %7093 : tensor<1x1200x320xf32>
    %7095 = stablehlo.convert %arg315 : (tensor<320xbf16>) -> tensor<320xf32>
    %7096 = stablehlo.broadcast_in_dim %7094, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7097 = stablehlo.broadcast_in_dim %7095, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7098 = stablehlo.add %7096, %7097 : tensor<1x1200x320xf32>
    %7099 = stablehlo.convert %7098 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7100 = stablehlo.reshape %7099 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7101 = stablehlo.convert %7100 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7102 = stablehlo.dot_general %7101, %arg789, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7103 = stablehlo.broadcast_in_dim %7102, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7104 = stablehlo.multiply %7103, %3065 : tensor<1200x320xf32>
    %7105 = stablehlo.broadcast_in_dim %7104, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7106 = stablehlo.broadcast_in_dim %arg790, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7107 = stablehlo.add %7105, %7106 : tensor<1200x320xf32>
    %7108 = stablehlo.convert %7107 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7109 = stablehlo.reshape %7108 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7110 = stablehlo.reshape %7109 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %7111 = stablehlo.transpose %7110, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7112 = stablehlo.transpose %7099, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %7113 = stablehlo.reshape %7112 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %7114 = stablehlo.convolution(%7113, %arg316) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %7115 = stablehlo.reshape %arg317 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %7116 = stablehlo.broadcast_in_dim %7114, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %7117 = stablehlo.broadcast_in_dim %7115, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %7118 = stablehlo.add %7116, %7117 : tensor<1x320x15x20xbf16>
    %7119 = stablehlo.reshape %7118 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %7120 = stablehlo.transpose %7119, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %7121 = stablehlo.convert %7120 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %7122 = stablehlo.convert %7121 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %7123 = stablehlo.reduce(%7122 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7124 = stablehlo.reshape %7123 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7125 = stablehlo.broadcast_in_dim %7124, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7126 = stablehlo.divide %7125, %3088 : tensor<1x300x1xf64>
    %7127 = stablehlo.broadcast_in_dim %7122, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %7128 = stablehlo.broadcast_in_dim %7126, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %7129 = stablehlo.subtract %7127, %7128 : tensor<1x300x320xf64>
    %7130 = stablehlo.multiply %7129, %7129 : tensor<1x300x320xf64>
    %7131 = stablehlo.reduce(%7130 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7132 = stablehlo.reshape %7131 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7133 = stablehlo.broadcast_in_dim %7132, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7134 = stablehlo.divide %7133, %3088 : tensor<1x300x1xf64>
    %7135 = stablehlo.convert %7134 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %7136 = stablehlo.reduce(%7121 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %7137 = stablehlo.reshape %7136 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %7138 = stablehlo.broadcast_in_dim %7137, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7139 = stablehlo.divide %7138, %3102 : tensor<1x300x1xf32>
    %7140 = stablehlo.broadcast_in_dim %7135, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7141 = stablehlo.add %7140, %136 : tensor<1x300x1xf32>
    %7142 = stablehlo.rsqrt %7141 : tensor<1x300x1xf32>
    %7143 = stablehlo.broadcast_in_dim %7121, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7144 = stablehlo.broadcast_in_dim %7139, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7145 = stablehlo.subtract %7143, %7144 : tensor<1x300x320xf32>
    %7146 = stablehlo.broadcast_in_dim %7145, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7147 = stablehlo.broadcast_in_dim %7142, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7148 = stablehlo.multiply %7146, %7147 : tensor<1x300x320xf32>
    %7149 = stablehlo.convert %arg318 : (tensor<320xbf16>) -> tensor<320xf32>
    %7150 = stablehlo.broadcast_in_dim %7148, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7151 = stablehlo.broadcast_in_dim %7149, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7152 = stablehlo.multiply %7150, %7151 : tensor<1x300x320xf32>
    %7153 = stablehlo.convert %arg319 : (tensor<320xbf16>) -> tensor<320xf32>
    %7154 = stablehlo.broadcast_in_dim %7152, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7155 = stablehlo.broadcast_in_dim %7153, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7156 = stablehlo.add %7154, %7155 : tensor<1x300x320xf32>
    %7157 = stablehlo.convert %7156 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %7158 = stablehlo.reshape %7157 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %7159 = stablehlo.convert %7158 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %7160 = stablehlo.dot_general %7159, %arg791, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7161 = stablehlo.broadcast_in_dim %7160, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7162 = stablehlo.multiply %7161, %3126 : tensor<300x320xf32>
    %7163 = stablehlo.broadcast_in_dim %7162, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7164 = stablehlo.broadcast_in_dim %arg792, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7165 = stablehlo.add %7163, %7164 : tensor<300x320xf32>
    %7166 = stablehlo.convert %7165 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7167 = stablehlo.reshape %7166 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7168 = stablehlo.reshape %7167 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7169 = stablehlo.transpose %7168, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7170 = stablehlo.dot_general %7159, %arg793, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7171 = stablehlo.broadcast_in_dim %7170, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7172 = stablehlo.multiply %7171, %3126 : tensor<300x320xf32>
    %7173 = stablehlo.broadcast_in_dim %7172, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7174 = stablehlo.broadcast_in_dim %arg794, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7175 = stablehlo.add %7173, %7174 : tensor<300x320xf32>
    %7176 = stablehlo.convert %7175 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7177 = stablehlo.reshape %7176 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7178 = stablehlo.reshape %7177 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7179 = stablehlo.transpose %7178, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7180 = stablehlo.transpose %7169, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %7181 = stablehlo.reshape %7111 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %7182 = stablehlo.reshape %7180 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7183 = stablehlo.broadcast_in_dim %7182, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7184 = stablehlo.dot_general %7181, %7183, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %7185 = stablehlo.reshape %7184 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7186 = stablehlo.broadcast_in_dim %7185, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7187 = stablehlo.divide %7186, %3152 : tensor<1x5x1200x300xbf16>
    %7188 = stablehlo.convert %7187 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %7189 = stablehlo.reduce(%7188 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7190 = stablehlo.reshape %7189 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7191 = stablehlo.broadcast_in_dim %7188, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7192 = stablehlo.broadcast_in_dim %7190, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7193 = stablehlo.subtract %7191, %7192 : tensor<1x5x1200x300xf32>
    %7194 = stablehlo.exponential %7193 : tensor<1x5x1200x300xf32>
    %7195 = stablehlo.reduce(%7194 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7196 = stablehlo.reshape %7195 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7197 = stablehlo.broadcast_in_dim %7194, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7198 = stablehlo.broadcast_in_dim %7196, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7199 = stablehlo.divide %7197, %7198 : tensor<1x5x1200x300xf32>
    %7200 = stablehlo.convert %7199 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %7201 = stablehlo.reshape %7200 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %7202 = stablehlo.reshape %7179 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7203 = stablehlo.broadcast_in_dim %7202, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7204 = stablehlo.dot_general %7201, %7203, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %7205 = stablehlo.reshape %7204 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7206 = stablehlo.transpose %7205, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %7207 = stablehlo.reshape %7206 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %7208 = stablehlo.reshape %7207 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7209 = stablehlo.convert %7208 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7210 = stablehlo.dot_general %7209, %arg795, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7211 = stablehlo.broadcast_in_dim %7210, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7212 = stablehlo.multiply %7211, %3065 : tensor<1200x320xf32>
    %7213 = stablehlo.broadcast_in_dim %7212, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7214 = stablehlo.broadcast_in_dim %arg796, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7215 = stablehlo.add %7213, %7214 : tensor<1200x320xf32>
    %7216 = stablehlo.convert %7215 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7217 = stablehlo.reshape %7216 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7218 = stablehlo.add %7217, %7062 : tensor<1x1200x320xbf16>
    %7219 = stablehlo.convert %7218 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7220 = stablehlo.convert %7219 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7221 = stablehlo.reduce(%7220 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7222 = stablehlo.reshape %7221 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7223 = stablehlo.broadcast_in_dim %7222, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7224 = stablehlo.divide %7223, %2987 : tensor<1x1200x1xf64>
    %7225 = stablehlo.broadcast_in_dim %7220, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7226 = stablehlo.broadcast_in_dim %7224, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7227 = stablehlo.subtract %7225, %7226 : tensor<1x1200x320xf64>
    %7228 = stablehlo.multiply %7227, %7227 : tensor<1x1200x320xf64>
    %7229 = stablehlo.reduce(%7228 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7230 = stablehlo.reshape %7229 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7231 = stablehlo.broadcast_in_dim %7230, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7232 = stablehlo.divide %7231, %2987 : tensor<1x1200x1xf64>
    %7233 = stablehlo.convert %7232 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7234 = stablehlo.reduce(%7219 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7235 = stablehlo.reshape %7234 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7236 = stablehlo.broadcast_in_dim %7235, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7237 = stablehlo.divide %7236, %3003 : tensor<1x1200x1xf32>
    %7238 = stablehlo.broadcast_in_dim %7233, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7239 = stablehlo.add %7238, %3006 : tensor<1x1200x1xf32>
    %7240 = stablehlo.rsqrt %7239 : tensor<1x1200x1xf32>
    %7241 = stablehlo.broadcast_in_dim %7219, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7242 = stablehlo.broadcast_in_dim %7237, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7243 = stablehlo.subtract %7241, %7242 : tensor<1x1200x320xf32>
    %7244 = stablehlo.broadcast_in_dim %7243, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7245 = stablehlo.broadcast_in_dim %7240, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7246 = stablehlo.multiply %7244, %7245 : tensor<1x1200x320xf32>
    %7247 = stablehlo.convert %arg320 : (tensor<320xbf16>) -> tensor<320xf32>
    %7248 = stablehlo.broadcast_in_dim %7246, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7249 = stablehlo.broadcast_in_dim %7247, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7250 = stablehlo.multiply %7248, %7249 : tensor<1x1200x320xf32>
    %7251 = stablehlo.convert %arg321 : (tensor<320xbf16>) -> tensor<320xf32>
    %7252 = stablehlo.broadcast_in_dim %7250, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7253 = stablehlo.broadcast_in_dim %7251, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7254 = stablehlo.add %7252, %7253 : tensor<1x1200x320xf32>
    %7255 = stablehlo.convert %7254 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7256 = stablehlo.reshape %7255 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7257 = stablehlo.convert %7256 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7258 = stablehlo.dot_general %7257, %arg797, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %7259 = stablehlo.broadcast_in_dim %7258, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7260 = stablehlo.multiply %7259, %3226 : tensor<1200x1280xf32>
    %7261 = stablehlo.broadcast_in_dim %7260, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7262 = stablehlo.broadcast_in_dim %arg798, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %7263 = stablehlo.add %7261, %7262 : tensor<1200x1280xf32>
    %7264 = stablehlo.convert %7263 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %7265 = stablehlo.reshape %7264 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %7266 = stablehlo.transpose %7265, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %7267 = stablehlo.reshape %7266 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %7268 = stablehlo.convolution(%7267, %arg322) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %7269 = stablehlo.reshape %arg323 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %7270 = stablehlo.broadcast_in_dim %7268, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %7271 = stablehlo.broadcast_in_dim %7269, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %7272 = stablehlo.add %7270, %7271 : tensor<1x1280x30x40xbf16>
    %7273 = stablehlo.reshape %7272 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %7274 = stablehlo.transpose %7273, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %7275 = stablehlo.multiply %7274, %cst_42 : tensor<1x1200x1280xbf16>
    %7276 = stablehlo.multiply %7274, %3243 : tensor<1x1200x1280xbf16>
    %7277 = stablehlo.convert %7276 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %7278 = stablehlo.clamp %cst_43, %7277, %cst_44 : tensor<1x1200x1280xf32>
    %7279 = stablehlo.multiply %7278, %7278 : tensor<1x1200x1280xf32>
    %7280 = stablehlo.multiply %cst_45, %7279 : tensor<1x1200x1280xf32>
    %7281 = stablehlo.add %7280, %cst_46 : tensor<1x1200x1280xf32>
    %7282 = stablehlo.multiply %7281, %7279 : tensor<1x1200x1280xf32>
    %7283 = stablehlo.add %7282, %cst_47 : tensor<1x1200x1280xf32>
    %7284 = stablehlo.multiply %7283, %7279 : tensor<1x1200x1280xf32>
    %7285 = stablehlo.add %7284, %cst_48 : tensor<1x1200x1280xf32>
    %7286 = stablehlo.multiply %7285, %7279 : tensor<1x1200x1280xf32>
    %7287 = stablehlo.add %7286, %cst_49 : tensor<1x1200x1280xf32>
    %7288 = stablehlo.multiply %7287, %7279 : tensor<1x1200x1280xf32>
    %7289 = stablehlo.add %7288, %cst_50 : tensor<1x1200x1280xf32>
    %7290 = stablehlo.multiply %7289, %7279 : tensor<1x1200x1280xf32>
    %7291 = stablehlo.add %7290, %cst_51 : tensor<1x1200x1280xf32>
    %7292 = stablehlo.multiply %cst_52, %7279 : tensor<1x1200x1280xf32>
    %7293 = stablehlo.add %7292, %cst_53 : tensor<1x1200x1280xf32>
    %7294 = stablehlo.multiply %7293, %7279 : tensor<1x1200x1280xf32>
    %7295 = stablehlo.add %7294, %cst_54 : tensor<1x1200x1280xf32>
    %7296 = stablehlo.multiply %7295, %7279 : tensor<1x1200x1280xf32>
    %7297 = stablehlo.add %7296, %cst_55 : tensor<1x1200x1280xf32>
    %7298 = stablehlo.multiply %7297, %7279 : tensor<1x1200x1280xf32>
    %7299 = stablehlo.add %7298, %cst_56 : tensor<1x1200x1280xf32>
    %7300 = stablehlo.multiply %7278, %7291 : tensor<1x1200x1280xf32>
    %7301 = stablehlo.divide %7300, %7299 : tensor<1x1200x1280xf32>
    %7302 = stablehlo.clamp %cst_57, %7301, %cst_58 : tensor<1x1200x1280xf32>
    %7303 = stablehlo.convert %7302 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %7304 = stablehlo.add %7303, %cst_40 : tensor<1x1200x1280xbf16>
    %7305 = stablehlo.multiply %7304, %7275 : tensor<1x1200x1280xbf16>
    %7306 = stablehlo.reshape %7305 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %7307 = stablehlo.dot_general %7306, %arg799, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %7308 = stablehlo.reshape %7307 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7309 = stablehlo.broadcast_in_dim %7308, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7310 = stablehlo.broadcast_in_dim %arg324, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %7311 = stablehlo.add %7309, %7310 : tensor<1x1200x320xbf16>
    %7312 = stablehlo.reshape %7311 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7313 = stablehlo.reshape %7312 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7314 = stablehlo.add %7313, %7218 : tensor<1x1200x320xbf16>
    %7315 = stablehlo.convert %7314 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7316 = stablehlo.convert %7315 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7317 = stablehlo.reduce(%7316 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7318 = stablehlo.reshape %7317 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7319 = stablehlo.broadcast_in_dim %7318, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7320 = stablehlo.divide %7319, %2987 : tensor<1x1200x1xf64>
    %7321 = stablehlo.broadcast_in_dim %7316, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7322 = stablehlo.broadcast_in_dim %7320, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7323 = stablehlo.subtract %7321, %7322 : tensor<1x1200x320xf64>
    %7324 = stablehlo.multiply %7323, %7323 : tensor<1x1200x320xf64>
    %7325 = stablehlo.reduce(%7324 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7326 = stablehlo.reshape %7325 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7327 = stablehlo.broadcast_in_dim %7326, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7328 = stablehlo.divide %7327, %2987 : tensor<1x1200x1xf64>
    %7329 = stablehlo.convert %7328 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7330 = stablehlo.reduce(%7315 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7331 = stablehlo.reshape %7330 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7332 = stablehlo.broadcast_in_dim %7331, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7333 = stablehlo.divide %7332, %3003 : tensor<1x1200x1xf32>
    %7334 = stablehlo.broadcast_in_dim %7329, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7335 = stablehlo.add %7334, %3006 : tensor<1x1200x1xf32>
    %7336 = stablehlo.rsqrt %7335 : tensor<1x1200x1xf32>
    %7337 = stablehlo.broadcast_in_dim %7315, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7338 = stablehlo.broadcast_in_dim %7333, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7339 = stablehlo.subtract %7337, %7338 : tensor<1x1200x320xf32>
    %7340 = stablehlo.broadcast_in_dim %7339, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7341 = stablehlo.broadcast_in_dim %7336, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7342 = stablehlo.multiply %7340, %7341 : tensor<1x1200x320xf32>
    %7343 = stablehlo.convert %arg325 : (tensor<320xbf16>) -> tensor<320xf32>
    %7344 = stablehlo.broadcast_in_dim %7342, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7345 = stablehlo.broadcast_in_dim %7343, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7346 = stablehlo.multiply %7344, %7345 : tensor<1x1200x320xf32>
    %7347 = stablehlo.convert %arg326 : (tensor<320xbf16>) -> tensor<320xf32>
    %7348 = stablehlo.broadcast_in_dim %7346, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7349 = stablehlo.broadcast_in_dim %7347, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7350 = stablehlo.add %7348, %7349 : tensor<1x1200x320xf32>
    %7351 = stablehlo.convert %7350 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7352 = stablehlo.reshape %7351 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7353 = stablehlo.convert %7352 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7354 = stablehlo.dot_general %7353, %arg800, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7355 = stablehlo.broadcast_in_dim %7354, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7356 = stablehlo.multiply %7355, %3065 : tensor<1200x320xf32>
    %7357 = stablehlo.broadcast_in_dim %7356, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7358 = stablehlo.broadcast_in_dim %arg801, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7359 = stablehlo.add %7357, %7358 : tensor<1200x320xf32>
    %7360 = stablehlo.convert %7359 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7361 = stablehlo.reshape %7360 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7362 = stablehlo.reshape %7361 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %7363 = stablehlo.transpose %7362, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7364 = stablehlo.transpose %7351, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %7365 = stablehlo.reshape %7364 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %7366 = stablehlo.convolution(%7365, %arg327) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %7367 = stablehlo.reshape %arg328 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %7368 = stablehlo.broadcast_in_dim %7366, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %7369 = stablehlo.broadcast_in_dim %7367, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %7370 = stablehlo.add %7368, %7369 : tensor<1x320x15x20xbf16>
    %7371 = stablehlo.reshape %7370 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %7372 = stablehlo.transpose %7371, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %7373 = stablehlo.convert %7372 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %7374 = stablehlo.convert %7373 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %7375 = stablehlo.reduce(%7374 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7376 = stablehlo.reshape %7375 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7377 = stablehlo.broadcast_in_dim %7376, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7378 = stablehlo.divide %7377, %3088 : tensor<1x300x1xf64>
    %7379 = stablehlo.broadcast_in_dim %7374, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %7380 = stablehlo.broadcast_in_dim %7378, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %7381 = stablehlo.subtract %7379, %7380 : tensor<1x300x320xf64>
    %7382 = stablehlo.multiply %7381, %7381 : tensor<1x300x320xf64>
    %7383 = stablehlo.reduce(%7382 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7384 = stablehlo.reshape %7383 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7385 = stablehlo.broadcast_in_dim %7384, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7386 = stablehlo.divide %7385, %3088 : tensor<1x300x1xf64>
    %7387 = stablehlo.convert %7386 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %7388 = stablehlo.reduce(%7373 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %7389 = stablehlo.reshape %7388 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %7390 = stablehlo.broadcast_in_dim %7389, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7391 = stablehlo.divide %7390, %3102 : tensor<1x300x1xf32>
    %7392 = stablehlo.broadcast_in_dim %7387, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7393 = stablehlo.add %7392, %136 : tensor<1x300x1xf32>
    %7394 = stablehlo.rsqrt %7393 : tensor<1x300x1xf32>
    %7395 = stablehlo.broadcast_in_dim %7373, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7396 = stablehlo.broadcast_in_dim %7391, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7397 = stablehlo.subtract %7395, %7396 : tensor<1x300x320xf32>
    %7398 = stablehlo.broadcast_in_dim %7397, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7399 = stablehlo.broadcast_in_dim %7394, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7400 = stablehlo.multiply %7398, %7399 : tensor<1x300x320xf32>
    %7401 = stablehlo.convert %arg329 : (tensor<320xbf16>) -> tensor<320xf32>
    %7402 = stablehlo.broadcast_in_dim %7400, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7403 = stablehlo.broadcast_in_dim %7401, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7404 = stablehlo.multiply %7402, %7403 : tensor<1x300x320xf32>
    %7405 = stablehlo.convert %arg330 : (tensor<320xbf16>) -> tensor<320xf32>
    %7406 = stablehlo.broadcast_in_dim %7404, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7407 = stablehlo.broadcast_in_dim %7405, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7408 = stablehlo.add %7406, %7407 : tensor<1x300x320xf32>
    %7409 = stablehlo.convert %7408 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %7410 = stablehlo.reshape %7409 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %7411 = stablehlo.convert %7410 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %7412 = stablehlo.dot_general %7411, %arg802, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7413 = stablehlo.broadcast_in_dim %7412, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7414 = stablehlo.multiply %7413, %3126 : tensor<300x320xf32>
    %7415 = stablehlo.broadcast_in_dim %7414, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7416 = stablehlo.broadcast_in_dim %arg803, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7417 = stablehlo.add %7415, %7416 : tensor<300x320xf32>
    %7418 = stablehlo.convert %7417 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7419 = stablehlo.reshape %7418 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7420 = stablehlo.reshape %7419 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7421 = stablehlo.transpose %7420, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7422 = stablehlo.dot_general %7411, %arg804, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7423 = stablehlo.broadcast_in_dim %7422, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7424 = stablehlo.multiply %7423, %3126 : tensor<300x320xf32>
    %7425 = stablehlo.broadcast_in_dim %7424, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7426 = stablehlo.broadcast_in_dim %arg805, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7427 = stablehlo.add %7425, %7426 : tensor<300x320xf32>
    %7428 = stablehlo.convert %7427 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7429 = stablehlo.reshape %7428 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7430 = stablehlo.reshape %7429 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7431 = stablehlo.transpose %7430, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7432 = stablehlo.transpose %7421, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %7433 = stablehlo.reshape %7363 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %7434 = stablehlo.reshape %7432 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7435 = stablehlo.broadcast_in_dim %7434, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7436 = stablehlo.dot_general %7433, %7435, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %7437 = stablehlo.reshape %7436 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7438 = stablehlo.broadcast_in_dim %7437, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7439 = stablehlo.divide %7438, %3152 : tensor<1x5x1200x300xbf16>
    %7440 = stablehlo.convert %7439 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %7441 = stablehlo.reduce(%7440 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7442 = stablehlo.reshape %7441 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7443 = stablehlo.broadcast_in_dim %7440, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7444 = stablehlo.broadcast_in_dim %7442, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7445 = stablehlo.subtract %7443, %7444 : tensor<1x5x1200x300xf32>
    %7446 = stablehlo.exponential %7445 : tensor<1x5x1200x300xf32>
    %7447 = stablehlo.reduce(%7446 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7448 = stablehlo.reshape %7447 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7449 = stablehlo.broadcast_in_dim %7446, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7450 = stablehlo.broadcast_in_dim %7448, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7451 = stablehlo.divide %7449, %7450 : tensor<1x5x1200x300xf32>
    %7452 = stablehlo.convert %7451 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %7453 = stablehlo.reshape %7452 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %7454 = stablehlo.reshape %7431 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7455 = stablehlo.broadcast_in_dim %7454, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7456 = stablehlo.dot_general %7453, %7455, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %7457 = stablehlo.reshape %7456 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7458 = stablehlo.transpose %7457, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %7459 = stablehlo.reshape %7458 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %7460 = stablehlo.reshape %7459 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7461 = stablehlo.convert %7460 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7462 = stablehlo.dot_general %7461, %arg806, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7463 = stablehlo.broadcast_in_dim %7462, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7464 = stablehlo.multiply %7463, %3065 : tensor<1200x320xf32>
    %7465 = stablehlo.broadcast_in_dim %7464, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7466 = stablehlo.broadcast_in_dim %arg807, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7467 = stablehlo.add %7465, %7466 : tensor<1200x320xf32>
    %7468 = stablehlo.convert %7467 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7469 = stablehlo.reshape %7468 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7470 = stablehlo.add %7469, %7314 : tensor<1x1200x320xbf16>
    %7471 = stablehlo.convert %7470 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7472 = stablehlo.convert %7471 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7473 = stablehlo.reduce(%7472 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7474 = stablehlo.reshape %7473 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7475 = stablehlo.broadcast_in_dim %7474, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7476 = stablehlo.divide %7475, %2987 : tensor<1x1200x1xf64>
    %7477 = stablehlo.broadcast_in_dim %7472, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7478 = stablehlo.broadcast_in_dim %7476, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7479 = stablehlo.subtract %7477, %7478 : tensor<1x1200x320xf64>
    %7480 = stablehlo.multiply %7479, %7479 : tensor<1x1200x320xf64>
    %7481 = stablehlo.reduce(%7480 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7482 = stablehlo.reshape %7481 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7483 = stablehlo.broadcast_in_dim %7482, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7484 = stablehlo.divide %7483, %2987 : tensor<1x1200x1xf64>
    %7485 = stablehlo.convert %7484 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7486 = stablehlo.reduce(%7471 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7487 = stablehlo.reshape %7486 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7488 = stablehlo.broadcast_in_dim %7487, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7489 = stablehlo.divide %7488, %3003 : tensor<1x1200x1xf32>
    %7490 = stablehlo.broadcast_in_dim %7485, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7491 = stablehlo.add %7490, %3006 : tensor<1x1200x1xf32>
    %7492 = stablehlo.rsqrt %7491 : tensor<1x1200x1xf32>
    %7493 = stablehlo.broadcast_in_dim %7471, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7494 = stablehlo.broadcast_in_dim %7489, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7495 = stablehlo.subtract %7493, %7494 : tensor<1x1200x320xf32>
    %7496 = stablehlo.broadcast_in_dim %7495, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7497 = stablehlo.broadcast_in_dim %7492, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7498 = stablehlo.multiply %7496, %7497 : tensor<1x1200x320xf32>
    %7499 = stablehlo.convert %arg331 : (tensor<320xbf16>) -> tensor<320xf32>
    %7500 = stablehlo.broadcast_in_dim %7498, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7501 = stablehlo.broadcast_in_dim %7499, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7502 = stablehlo.multiply %7500, %7501 : tensor<1x1200x320xf32>
    %7503 = stablehlo.convert %arg332 : (tensor<320xbf16>) -> tensor<320xf32>
    %7504 = stablehlo.broadcast_in_dim %7502, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7505 = stablehlo.broadcast_in_dim %7503, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7506 = stablehlo.add %7504, %7505 : tensor<1x1200x320xf32>
    %7507 = stablehlo.convert %7506 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7508 = stablehlo.reshape %7507 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7509 = stablehlo.convert %7508 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7510 = stablehlo.dot_general %7509, %arg808, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %7511 = stablehlo.broadcast_in_dim %7510, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7512 = stablehlo.multiply %7511, %3226 : tensor<1200x1280xf32>
    %7513 = stablehlo.broadcast_in_dim %7512, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7514 = stablehlo.broadcast_in_dim %arg809, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %7515 = stablehlo.add %7513, %7514 : tensor<1200x1280xf32>
    %7516 = stablehlo.convert %7515 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %7517 = stablehlo.reshape %7516 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %7518 = stablehlo.transpose %7517, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %7519 = stablehlo.reshape %7518 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %7520 = stablehlo.convolution(%7519, %arg333) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %7521 = stablehlo.reshape %arg334 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %7522 = stablehlo.broadcast_in_dim %7520, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %7523 = stablehlo.broadcast_in_dim %7521, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %7524 = stablehlo.add %7522, %7523 : tensor<1x1280x30x40xbf16>
    %7525 = stablehlo.reshape %7524 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %7526 = stablehlo.transpose %7525, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %7527 = stablehlo.multiply %7526, %cst_42 : tensor<1x1200x1280xbf16>
    %7528 = stablehlo.multiply %7526, %3243 : tensor<1x1200x1280xbf16>
    %7529 = stablehlo.convert %7528 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %7530 = stablehlo.clamp %cst_43, %7529, %cst_44 : tensor<1x1200x1280xf32>
    %7531 = stablehlo.multiply %7530, %7530 : tensor<1x1200x1280xf32>
    %7532 = stablehlo.multiply %cst_45, %7531 : tensor<1x1200x1280xf32>
    %7533 = stablehlo.add %7532, %cst_46 : tensor<1x1200x1280xf32>
    %7534 = stablehlo.multiply %7533, %7531 : tensor<1x1200x1280xf32>
    %7535 = stablehlo.add %7534, %cst_47 : tensor<1x1200x1280xf32>
    %7536 = stablehlo.multiply %7535, %7531 : tensor<1x1200x1280xf32>
    %7537 = stablehlo.add %7536, %cst_48 : tensor<1x1200x1280xf32>
    %7538 = stablehlo.multiply %7537, %7531 : tensor<1x1200x1280xf32>
    %7539 = stablehlo.add %7538, %cst_49 : tensor<1x1200x1280xf32>
    %7540 = stablehlo.multiply %7539, %7531 : tensor<1x1200x1280xf32>
    %7541 = stablehlo.add %7540, %cst_50 : tensor<1x1200x1280xf32>
    %7542 = stablehlo.multiply %7541, %7531 : tensor<1x1200x1280xf32>
    %7543 = stablehlo.add %7542, %cst_51 : tensor<1x1200x1280xf32>
    %7544 = stablehlo.multiply %cst_52, %7531 : tensor<1x1200x1280xf32>
    %7545 = stablehlo.add %7544, %cst_53 : tensor<1x1200x1280xf32>
    %7546 = stablehlo.multiply %7545, %7531 : tensor<1x1200x1280xf32>
    %7547 = stablehlo.add %7546, %cst_54 : tensor<1x1200x1280xf32>
    %7548 = stablehlo.multiply %7547, %7531 : tensor<1x1200x1280xf32>
    %7549 = stablehlo.add %7548, %cst_55 : tensor<1x1200x1280xf32>
    %7550 = stablehlo.multiply %7549, %7531 : tensor<1x1200x1280xf32>
    %7551 = stablehlo.add %7550, %cst_56 : tensor<1x1200x1280xf32>
    %7552 = stablehlo.multiply %7530, %7543 : tensor<1x1200x1280xf32>
    %7553 = stablehlo.divide %7552, %7551 : tensor<1x1200x1280xf32>
    %7554 = stablehlo.clamp %cst_57, %7553, %cst_58 : tensor<1x1200x1280xf32>
    %7555 = stablehlo.convert %7554 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %7556 = stablehlo.add %7555, %cst_40 : tensor<1x1200x1280xbf16>
    %7557 = stablehlo.multiply %7556, %7527 : tensor<1x1200x1280xbf16>
    %7558 = stablehlo.reshape %7557 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %7559 = stablehlo.dot_general %7558, %arg810, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %7560 = stablehlo.reshape %7559 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7561 = stablehlo.broadcast_in_dim %7560, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7562 = stablehlo.broadcast_in_dim %arg335, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %7563 = stablehlo.add %7561, %7562 : tensor<1x1200x320xbf16>
    %7564 = stablehlo.reshape %7563 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7565 = stablehlo.reshape %7564 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7566 = stablehlo.add %7565, %7470 : tensor<1x1200x320xbf16>
    %7567 = stablehlo.convert %7566 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7568 = stablehlo.convert %7567 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7569 = stablehlo.reduce(%7568 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7570 = stablehlo.reshape %7569 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7571 = stablehlo.broadcast_in_dim %7570, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7572 = stablehlo.divide %7571, %2987 : tensor<1x1200x1xf64>
    %7573 = stablehlo.broadcast_in_dim %7568, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7574 = stablehlo.broadcast_in_dim %7572, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7575 = stablehlo.subtract %7573, %7574 : tensor<1x1200x320xf64>
    %7576 = stablehlo.multiply %7575, %7575 : tensor<1x1200x320xf64>
    %7577 = stablehlo.reduce(%7576 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7578 = stablehlo.reshape %7577 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7579 = stablehlo.broadcast_in_dim %7578, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7580 = stablehlo.divide %7579, %2987 : tensor<1x1200x1xf64>
    %7581 = stablehlo.convert %7580 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7582 = stablehlo.reduce(%7567 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7583 = stablehlo.reshape %7582 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7584 = stablehlo.broadcast_in_dim %7583, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7585 = stablehlo.divide %7584, %3003 : tensor<1x1200x1xf32>
    %7586 = stablehlo.broadcast_in_dim %7581, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7587 = stablehlo.add %7586, %3006 : tensor<1x1200x1xf32>
    %7588 = stablehlo.rsqrt %7587 : tensor<1x1200x1xf32>
    %7589 = stablehlo.broadcast_in_dim %7567, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7590 = stablehlo.broadcast_in_dim %7585, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7591 = stablehlo.subtract %7589, %7590 : tensor<1x1200x320xf32>
    %7592 = stablehlo.broadcast_in_dim %7591, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7593 = stablehlo.broadcast_in_dim %7588, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7594 = stablehlo.multiply %7592, %7593 : tensor<1x1200x320xf32>
    %7595 = stablehlo.convert %arg336 : (tensor<320xbf16>) -> tensor<320xf32>
    %7596 = stablehlo.broadcast_in_dim %7594, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7597 = stablehlo.broadcast_in_dim %7595, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7598 = stablehlo.multiply %7596, %7597 : tensor<1x1200x320xf32>
    %7599 = stablehlo.convert %arg337 : (tensor<320xbf16>) -> tensor<320xf32>
    %7600 = stablehlo.broadcast_in_dim %7598, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7601 = stablehlo.broadcast_in_dim %7599, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7602 = stablehlo.add %7600, %7601 : tensor<1x1200x320xf32>
    %7603 = stablehlo.convert %7602 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7604 = stablehlo.reshape %7603 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7605 = stablehlo.convert %7604 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7606 = stablehlo.dot_general %7605, %arg811, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7607 = stablehlo.broadcast_in_dim %7606, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7608 = stablehlo.multiply %7607, %3065 : tensor<1200x320xf32>
    %7609 = stablehlo.broadcast_in_dim %7608, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7610 = stablehlo.broadcast_in_dim %arg812, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7611 = stablehlo.add %7609, %7610 : tensor<1200x320xf32>
    %7612 = stablehlo.convert %7611 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7613 = stablehlo.reshape %7612 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7614 = stablehlo.reshape %7613 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %7615 = stablehlo.transpose %7614, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7616 = stablehlo.transpose %7603, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %7617 = stablehlo.reshape %7616 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %7618 = stablehlo.convolution(%7617, %arg338) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %7619 = stablehlo.reshape %arg339 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %7620 = stablehlo.broadcast_in_dim %7618, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %7621 = stablehlo.broadcast_in_dim %7619, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %7622 = stablehlo.add %7620, %7621 : tensor<1x320x15x20xbf16>
    %7623 = stablehlo.reshape %7622 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %7624 = stablehlo.transpose %7623, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %7625 = stablehlo.convert %7624 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %7626 = stablehlo.convert %7625 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %7627 = stablehlo.reduce(%7626 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7628 = stablehlo.reshape %7627 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7629 = stablehlo.broadcast_in_dim %7628, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7630 = stablehlo.divide %7629, %3088 : tensor<1x300x1xf64>
    %7631 = stablehlo.broadcast_in_dim %7626, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %7632 = stablehlo.broadcast_in_dim %7630, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %7633 = stablehlo.subtract %7631, %7632 : tensor<1x300x320xf64>
    %7634 = stablehlo.multiply %7633, %7633 : tensor<1x300x320xf64>
    %7635 = stablehlo.reduce(%7634 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7636 = stablehlo.reshape %7635 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7637 = stablehlo.broadcast_in_dim %7636, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7638 = stablehlo.divide %7637, %3088 : tensor<1x300x1xf64>
    %7639 = stablehlo.convert %7638 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %7640 = stablehlo.reduce(%7625 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %7641 = stablehlo.reshape %7640 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %7642 = stablehlo.broadcast_in_dim %7641, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7643 = stablehlo.divide %7642, %3102 : tensor<1x300x1xf32>
    %7644 = stablehlo.broadcast_in_dim %7639, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7645 = stablehlo.add %7644, %136 : tensor<1x300x1xf32>
    %7646 = stablehlo.rsqrt %7645 : tensor<1x300x1xf32>
    %7647 = stablehlo.broadcast_in_dim %7625, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7648 = stablehlo.broadcast_in_dim %7643, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7649 = stablehlo.subtract %7647, %7648 : tensor<1x300x320xf32>
    %7650 = stablehlo.broadcast_in_dim %7649, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7651 = stablehlo.broadcast_in_dim %7646, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7652 = stablehlo.multiply %7650, %7651 : tensor<1x300x320xf32>
    %7653 = stablehlo.convert %arg340 : (tensor<320xbf16>) -> tensor<320xf32>
    %7654 = stablehlo.broadcast_in_dim %7652, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7655 = stablehlo.broadcast_in_dim %7653, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7656 = stablehlo.multiply %7654, %7655 : tensor<1x300x320xf32>
    %7657 = stablehlo.convert %arg341 : (tensor<320xbf16>) -> tensor<320xf32>
    %7658 = stablehlo.broadcast_in_dim %7656, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7659 = stablehlo.broadcast_in_dim %7657, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7660 = stablehlo.add %7658, %7659 : tensor<1x300x320xf32>
    %7661 = stablehlo.convert %7660 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %7662 = stablehlo.reshape %7661 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %7663 = stablehlo.convert %7662 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %7664 = stablehlo.dot_general %7663, %arg813, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7665 = stablehlo.broadcast_in_dim %7664, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7666 = stablehlo.multiply %7665, %3126 : tensor<300x320xf32>
    %7667 = stablehlo.broadcast_in_dim %7666, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7668 = stablehlo.broadcast_in_dim %arg814, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7669 = stablehlo.add %7667, %7668 : tensor<300x320xf32>
    %7670 = stablehlo.convert %7669 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7671 = stablehlo.reshape %7670 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7672 = stablehlo.reshape %7671 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7673 = stablehlo.transpose %7672, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7674 = stablehlo.dot_general %7663, %arg815, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7675 = stablehlo.broadcast_in_dim %7674, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7676 = stablehlo.multiply %7675, %3126 : tensor<300x320xf32>
    %7677 = stablehlo.broadcast_in_dim %7676, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7678 = stablehlo.broadcast_in_dim %arg816, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7679 = stablehlo.add %7677, %7678 : tensor<300x320xf32>
    %7680 = stablehlo.convert %7679 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7681 = stablehlo.reshape %7680 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7682 = stablehlo.reshape %7681 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7683 = stablehlo.transpose %7682, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7684 = stablehlo.transpose %7673, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %7685 = stablehlo.reshape %7615 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %7686 = stablehlo.reshape %7684 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7687 = stablehlo.broadcast_in_dim %7686, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7688 = stablehlo.dot_general %7685, %7687, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %7689 = stablehlo.reshape %7688 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7690 = stablehlo.broadcast_in_dim %7689, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7691 = stablehlo.divide %7690, %3152 : tensor<1x5x1200x300xbf16>
    %7692 = stablehlo.convert %7691 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %7693 = stablehlo.reduce(%7692 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7694 = stablehlo.reshape %7693 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7695 = stablehlo.broadcast_in_dim %7692, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7696 = stablehlo.broadcast_in_dim %7694, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7697 = stablehlo.subtract %7695, %7696 : tensor<1x5x1200x300xf32>
    %7698 = stablehlo.exponential %7697 : tensor<1x5x1200x300xf32>
    %7699 = stablehlo.reduce(%7698 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7700 = stablehlo.reshape %7699 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7701 = stablehlo.broadcast_in_dim %7698, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7702 = stablehlo.broadcast_in_dim %7700, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7703 = stablehlo.divide %7701, %7702 : tensor<1x5x1200x300xf32>
    %7704 = stablehlo.convert %7703 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %7705 = stablehlo.reshape %7704 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %7706 = stablehlo.reshape %7683 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7707 = stablehlo.broadcast_in_dim %7706, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7708 = stablehlo.dot_general %7705, %7707, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %7709 = stablehlo.reshape %7708 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7710 = stablehlo.transpose %7709, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %7711 = stablehlo.reshape %7710 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %7712 = stablehlo.reshape %7711 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7713 = stablehlo.convert %7712 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7714 = stablehlo.dot_general %7713, %arg817, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7715 = stablehlo.broadcast_in_dim %7714, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7716 = stablehlo.multiply %7715, %3065 : tensor<1200x320xf32>
    %7717 = stablehlo.broadcast_in_dim %7716, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7718 = stablehlo.broadcast_in_dim %arg818, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7719 = stablehlo.add %7717, %7718 : tensor<1200x320xf32>
    %7720 = stablehlo.convert %7719 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7721 = stablehlo.reshape %7720 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7722 = stablehlo.add %7721, %7566 : tensor<1x1200x320xbf16>
    %7723 = stablehlo.convert %7722 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7724 = stablehlo.convert %7723 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7725 = stablehlo.reduce(%7724 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7726 = stablehlo.reshape %7725 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7727 = stablehlo.broadcast_in_dim %7726, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7728 = stablehlo.divide %7727, %2987 : tensor<1x1200x1xf64>
    %7729 = stablehlo.broadcast_in_dim %7724, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7730 = stablehlo.broadcast_in_dim %7728, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7731 = stablehlo.subtract %7729, %7730 : tensor<1x1200x320xf64>
    %7732 = stablehlo.multiply %7731, %7731 : tensor<1x1200x320xf64>
    %7733 = stablehlo.reduce(%7732 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7734 = stablehlo.reshape %7733 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7735 = stablehlo.broadcast_in_dim %7734, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7736 = stablehlo.divide %7735, %2987 : tensor<1x1200x1xf64>
    %7737 = stablehlo.convert %7736 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7738 = stablehlo.reduce(%7723 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7739 = stablehlo.reshape %7738 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7740 = stablehlo.broadcast_in_dim %7739, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7741 = stablehlo.divide %7740, %3003 : tensor<1x1200x1xf32>
    %7742 = stablehlo.broadcast_in_dim %7737, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7743 = stablehlo.add %7742, %3006 : tensor<1x1200x1xf32>
    %7744 = stablehlo.rsqrt %7743 : tensor<1x1200x1xf32>
    %7745 = stablehlo.broadcast_in_dim %7723, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7746 = stablehlo.broadcast_in_dim %7741, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7747 = stablehlo.subtract %7745, %7746 : tensor<1x1200x320xf32>
    %7748 = stablehlo.broadcast_in_dim %7747, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7749 = stablehlo.broadcast_in_dim %7744, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7750 = stablehlo.multiply %7748, %7749 : tensor<1x1200x320xf32>
    %7751 = stablehlo.convert %arg342 : (tensor<320xbf16>) -> tensor<320xf32>
    %7752 = stablehlo.broadcast_in_dim %7750, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7753 = stablehlo.broadcast_in_dim %7751, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7754 = stablehlo.multiply %7752, %7753 : tensor<1x1200x320xf32>
    %7755 = stablehlo.convert %arg343 : (tensor<320xbf16>) -> tensor<320xf32>
    %7756 = stablehlo.broadcast_in_dim %7754, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7757 = stablehlo.broadcast_in_dim %7755, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7758 = stablehlo.add %7756, %7757 : tensor<1x1200x320xf32>
    %7759 = stablehlo.convert %7758 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7760 = stablehlo.reshape %7759 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7761 = stablehlo.convert %7760 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7762 = stablehlo.dot_general %7761, %arg819, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %7763 = stablehlo.broadcast_in_dim %7762, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7764 = stablehlo.multiply %7763, %3226 : tensor<1200x1280xf32>
    %7765 = stablehlo.broadcast_in_dim %7764, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %7766 = stablehlo.broadcast_in_dim %arg820, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %7767 = stablehlo.add %7765, %7766 : tensor<1200x1280xf32>
    %7768 = stablehlo.convert %7767 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %7769 = stablehlo.reshape %7768 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %7770 = stablehlo.transpose %7769, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %7771 = stablehlo.reshape %7770 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %7772 = stablehlo.convolution(%7771, %arg344) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %7773 = stablehlo.reshape %arg345 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %7774 = stablehlo.broadcast_in_dim %7772, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %7775 = stablehlo.broadcast_in_dim %7773, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %7776 = stablehlo.add %7774, %7775 : tensor<1x1280x30x40xbf16>
    %7777 = stablehlo.reshape %7776 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %7778 = stablehlo.transpose %7777, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %7779 = stablehlo.multiply %7778, %cst_42 : tensor<1x1200x1280xbf16>
    %7780 = stablehlo.multiply %7778, %3243 : tensor<1x1200x1280xbf16>
    %7781 = stablehlo.convert %7780 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %7782 = stablehlo.clamp %cst_43, %7781, %cst_44 : tensor<1x1200x1280xf32>
    %7783 = stablehlo.multiply %7782, %7782 : tensor<1x1200x1280xf32>
    %7784 = stablehlo.multiply %cst_45, %7783 : tensor<1x1200x1280xf32>
    %7785 = stablehlo.add %7784, %cst_46 : tensor<1x1200x1280xf32>
    %7786 = stablehlo.multiply %7785, %7783 : tensor<1x1200x1280xf32>
    %7787 = stablehlo.add %7786, %cst_47 : tensor<1x1200x1280xf32>
    %7788 = stablehlo.multiply %7787, %7783 : tensor<1x1200x1280xf32>
    %7789 = stablehlo.add %7788, %cst_48 : tensor<1x1200x1280xf32>
    %7790 = stablehlo.multiply %7789, %7783 : tensor<1x1200x1280xf32>
    %7791 = stablehlo.add %7790, %cst_49 : tensor<1x1200x1280xf32>
    %7792 = stablehlo.multiply %7791, %7783 : tensor<1x1200x1280xf32>
    %7793 = stablehlo.add %7792, %cst_50 : tensor<1x1200x1280xf32>
    %7794 = stablehlo.multiply %7793, %7783 : tensor<1x1200x1280xf32>
    %7795 = stablehlo.add %7794, %cst_51 : tensor<1x1200x1280xf32>
    %7796 = stablehlo.multiply %cst_52, %7783 : tensor<1x1200x1280xf32>
    %7797 = stablehlo.add %7796, %cst_53 : tensor<1x1200x1280xf32>
    %7798 = stablehlo.multiply %7797, %7783 : tensor<1x1200x1280xf32>
    %7799 = stablehlo.add %7798, %cst_54 : tensor<1x1200x1280xf32>
    %7800 = stablehlo.multiply %7799, %7783 : tensor<1x1200x1280xf32>
    %7801 = stablehlo.add %7800, %cst_55 : tensor<1x1200x1280xf32>
    %7802 = stablehlo.multiply %7801, %7783 : tensor<1x1200x1280xf32>
    %7803 = stablehlo.add %7802, %cst_56 : tensor<1x1200x1280xf32>
    %7804 = stablehlo.multiply %7782, %7795 : tensor<1x1200x1280xf32>
    %7805 = stablehlo.divide %7804, %7803 : tensor<1x1200x1280xf32>
    %7806 = stablehlo.clamp %cst_57, %7805, %cst_58 : tensor<1x1200x1280xf32>
    %7807 = stablehlo.convert %7806 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %7808 = stablehlo.add %7807, %cst_40 : tensor<1x1200x1280xbf16>
    %7809 = stablehlo.multiply %7808, %7779 : tensor<1x1200x1280xbf16>
    %7810 = stablehlo.reshape %7809 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %7811 = stablehlo.dot_general %7810, %arg821, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %7812 = stablehlo.reshape %7811 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7813 = stablehlo.broadcast_in_dim %7812, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7814 = stablehlo.broadcast_in_dim %arg346, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %7815 = stablehlo.add %7813, %7814 : tensor<1x1200x320xbf16>
    %7816 = stablehlo.reshape %7815 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7817 = stablehlo.reshape %7816 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7818 = stablehlo.add %7817, %7722 : tensor<1x1200x320xbf16>
    %7819 = stablehlo.convert %7818 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7820 = stablehlo.convert %7819 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7821 = stablehlo.reduce(%7820 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7822 = stablehlo.reshape %7821 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7823 = stablehlo.broadcast_in_dim %7822, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7824 = stablehlo.divide %7823, %2987 : tensor<1x1200x1xf64>
    %7825 = stablehlo.broadcast_in_dim %7820, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7826 = stablehlo.broadcast_in_dim %7824, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7827 = stablehlo.subtract %7825, %7826 : tensor<1x1200x320xf64>
    %7828 = stablehlo.multiply %7827, %7827 : tensor<1x1200x320xf64>
    %7829 = stablehlo.reduce(%7828 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7830 = stablehlo.reshape %7829 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7831 = stablehlo.broadcast_in_dim %7830, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7832 = stablehlo.divide %7831, %2987 : tensor<1x1200x1xf64>
    %7833 = stablehlo.convert %7832 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7834 = stablehlo.reduce(%7819 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7835 = stablehlo.reshape %7834 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7836 = stablehlo.broadcast_in_dim %7835, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7837 = stablehlo.divide %7836, %3003 : tensor<1x1200x1xf32>
    %7838 = stablehlo.broadcast_in_dim %7833, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7839 = stablehlo.add %7838, %3006 : tensor<1x1200x1xf32>
    %7840 = stablehlo.rsqrt %7839 : tensor<1x1200x1xf32>
    %7841 = stablehlo.broadcast_in_dim %7819, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7842 = stablehlo.broadcast_in_dim %7837, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7843 = stablehlo.subtract %7841, %7842 : tensor<1x1200x320xf32>
    %7844 = stablehlo.broadcast_in_dim %7843, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7845 = stablehlo.broadcast_in_dim %7840, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7846 = stablehlo.multiply %7844, %7845 : tensor<1x1200x320xf32>
    %7847 = stablehlo.convert %arg347 : (tensor<320xbf16>) -> tensor<320xf32>
    %7848 = stablehlo.broadcast_in_dim %7846, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7849 = stablehlo.broadcast_in_dim %7847, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7850 = stablehlo.multiply %7848, %7849 : tensor<1x1200x320xf32>
    %7851 = stablehlo.convert %arg348 : (tensor<320xbf16>) -> tensor<320xf32>
    %7852 = stablehlo.broadcast_in_dim %7850, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7853 = stablehlo.broadcast_in_dim %7851, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %7854 = stablehlo.add %7852, %7853 : tensor<1x1200x320xf32>
    %7855 = stablehlo.convert %7854 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %7856 = stablehlo.reshape %7855 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7857 = stablehlo.convert %7856 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7858 = stablehlo.dot_general %7857, %arg822, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7859 = stablehlo.broadcast_in_dim %7858, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7860 = stablehlo.multiply %7859, %3065 : tensor<1200x320xf32>
    %7861 = stablehlo.broadcast_in_dim %7860, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7862 = stablehlo.broadcast_in_dim %arg823, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7863 = stablehlo.add %7861, %7862 : tensor<1200x320xf32>
    %7864 = stablehlo.convert %7863 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7865 = stablehlo.reshape %7864 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7866 = stablehlo.reshape %7865 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %7867 = stablehlo.transpose %7866, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7868 = stablehlo.transpose %7855, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %7869 = stablehlo.reshape %7868 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %7870 = stablehlo.convolution(%7869, %arg349) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %7871 = stablehlo.reshape %arg350 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %7872 = stablehlo.broadcast_in_dim %7870, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %7873 = stablehlo.broadcast_in_dim %7871, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %7874 = stablehlo.add %7872, %7873 : tensor<1x320x15x20xbf16>
    %7875 = stablehlo.reshape %7874 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %7876 = stablehlo.transpose %7875, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %7877 = stablehlo.convert %7876 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %7878 = stablehlo.convert %7877 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %7879 = stablehlo.reduce(%7878 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7880 = stablehlo.reshape %7879 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7881 = stablehlo.broadcast_in_dim %7880, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7882 = stablehlo.divide %7881, %3088 : tensor<1x300x1xf64>
    %7883 = stablehlo.broadcast_in_dim %7878, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %7884 = stablehlo.broadcast_in_dim %7882, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %7885 = stablehlo.subtract %7883, %7884 : tensor<1x300x320xf64>
    %7886 = stablehlo.multiply %7885, %7885 : tensor<1x300x320xf64>
    %7887 = stablehlo.reduce(%7886 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %7888 = stablehlo.reshape %7887 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %7889 = stablehlo.broadcast_in_dim %7888, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %7890 = stablehlo.divide %7889, %3088 : tensor<1x300x1xf64>
    %7891 = stablehlo.convert %7890 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %7892 = stablehlo.reduce(%7877 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %7893 = stablehlo.reshape %7892 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %7894 = stablehlo.broadcast_in_dim %7893, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7895 = stablehlo.divide %7894, %3102 : tensor<1x300x1xf32>
    %7896 = stablehlo.broadcast_in_dim %7891, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %7897 = stablehlo.add %7896, %136 : tensor<1x300x1xf32>
    %7898 = stablehlo.rsqrt %7897 : tensor<1x300x1xf32>
    %7899 = stablehlo.broadcast_in_dim %7877, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7900 = stablehlo.broadcast_in_dim %7895, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7901 = stablehlo.subtract %7899, %7900 : tensor<1x300x320xf32>
    %7902 = stablehlo.broadcast_in_dim %7901, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7903 = stablehlo.broadcast_in_dim %7898, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %7904 = stablehlo.multiply %7902, %7903 : tensor<1x300x320xf32>
    %7905 = stablehlo.convert %arg351 : (tensor<320xbf16>) -> tensor<320xf32>
    %7906 = stablehlo.broadcast_in_dim %7904, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7907 = stablehlo.broadcast_in_dim %7905, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7908 = stablehlo.multiply %7906, %7907 : tensor<1x300x320xf32>
    %7909 = stablehlo.convert %arg352 : (tensor<320xbf16>) -> tensor<320xf32>
    %7910 = stablehlo.broadcast_in_dim %7908, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %7911 = stablehlo.broadcast_in_dim %7909, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %7912 = stablehlo.add %7910, %7911 : tensor<1x300x320xf32>
    %7913 = stablehlo.convert %7912 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %7914 = stablehlo.reshape %7913 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %7915 = stablehlo.convert %7914 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %7916 = stablehlo.dot_general %7915, %arg824, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7917 = stablehlo.broadcast_in_dim %7916, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7918 = stablehlo.multiply %7917, %3126 : tensor<300x320xf32>
    %7919 = stablehlo.broadcast_in_dim %7918, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7920 = stablehlo.broadcast_in_dim %arg825, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7921 = stablehlo.add %7919, %7920 : tensor<300x320xf32>
    %7922 = stablehlo.convert %7921 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7923 = stablehlo.reshape %7922 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7924 = stablehlo.reshape %7923 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7925 = stablehlo.transpose %7924, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7926 = stablehlo.dot_general %7915, %arg826, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %7927 = stablehlo.broadcast_in_dim %7926, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7928 = stablehlo.multiply %7927, %3126 : tensor<300x320xf32>
    %7929 = stablehlo.broadcast_in_dim %7928, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %7930 = stablehlo.broadcast_in_dim %arg827, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %7931 = stablehlo.add %7929, %7930 : tensor<300x320xf32>
    %7932 = stablehlo.convert %7931 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %7933 = stablehlo.reshape %7932 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %7934 = stablehlo.reshape %7933 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %7935 = stablehlo.transpose %7934, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %7936 = stablehlo.transpose %7925, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %7937 = stablehlo.reshape %7867 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %7938 = stablehlo.reshape %7936 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7939 = stablehlo.broadcast_in_dim %7938, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %7940 = stablehlo.dot_general %7937, %7939, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %7941 = stablehlo.reshape %7940 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7942 = stablehlo.broadcast_in_dim %7941, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %7943 = stablehlo.divide %7942, %3152 : tensor<1x5x1200x300xbf16>
    %7944 = stablehlo.convert %7943 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %7945 = stablehlo.reduce(%7944 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7946 = stablehlo.reshape %7945 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7947 = stablehlo.broadcast_in_dim %7944, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7948 = stablehlo.broadcast_in_dim %7946, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7949 = stablehlo.subtract %7947, %7948 : tensor<1x5x1200x300xf32>
    %7950 = stablehlo.exponential %7949 : tensor<1x5x1200x300xf32>
    %7951 = stablehlo.reduce(%7950 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %7952 = stablehlo.reshape %7951 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %7953 = stablehlo.broadcast_in_dim %7950, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %7954 = stablehlo.broadcast_in_dim %7952, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %7955 = stablehlo.divide %7953, %7954 : tensor<1x5x1200x300xf32>
    %7956 = stablehlo.convert %7955 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %7957 = stablehlo.reshape %7956 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %7958 = stablehlo.reshape %7935 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7959 = stablehlo.broadcast_in_dim %7958, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %7960 = stablehlo.dot_general %7957, %7959, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %7961 = stablehlo.reshape %7960 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %7962 = stablehlo.transpose %7961, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %7963 = stablehlo.reshape %7962 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %7964 = stablehlo.reshape %7963 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %7965 = stablehlo.convert %7964 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %7966 = stablehlo.dot_general %7965, %arg828, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %7967 = stablehlo.broadcast_in_dim %7966, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7968 = stablehlo.multiply %7967, %3065 : tensor<1200x320xf32>
    %7969 = stablehlo.broadcast_in_dim %7968, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %7970 = stablehlo.broadcast_in_dim %arg829, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %7971 = stablehlo.add %7969, %7970 : tensor<1200x320xf32>
    %7972 = stablehlo.convert %7971 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %7973 = stablehlo.reshape %7972 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %7974 = stablehlo.add %7973, %7818 : tensor<1x1200x320xbf16>
    %7975 = stablehlo.convert %7974 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %7976 = stablehlo.convert %7975 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %7977 = stablehlo.reduce(%7976 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7978 = stablehlo.reshape %7977 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7979 = stablehlo.broadcast_in_dim %7978, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7980 = stablehlo.divide %7979, %2987 : tensor<1x1200x1xf64>
    %7981 = stablehlo.broadcast_in_dim %7976, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %7982 = stablehlo.broadcast_in_dim %7980, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %7983 = stablehlo.subtract %7981, %7982 : tensor<1x1200x320xf64>
    %7984 = stablehlo.multiply %7983, %7983 : tensor<1x1200x320xf64>
    %7985 = stablehlo.reduce(%7984 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %7986 = stablehlo.reshape %7985 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %7987 = stablehlo.broadcast_in_dim %7986, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %7988 = stablehlo.divide %7987, %2987 : tensor<1x1200x1xf64>
    %7989 = stablehlo.convert %7988 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %7990 = stablehlo.reduce(%7975 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %7991 = stablehlo.reshape %7990 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %7992 = stablehlo.broadcast_in_dim %7991, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7993 = stablehlo.divide %7992, %3003 : tensor<1x1200x1xf32>
    %7994 = stablehlo.broadcast_in_dim %7989, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %7995 = stablehlo.add %7994, %3006 : tensor<1x1200x1xf32>
    %7996 = stablehlo.rsqrt %7995 : tensor<1x1200x1xf32>
    %7997 = stablehlo.broadcast_in_dim %7975, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %7998 = stablehlo.broadcast_in_dim %7993, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %7999 = stablehlo.subtract %7997, %7998 : tensor<1x1200x320xf32>
    %8000 = stablehlo.broadcast_in_dim %7999, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8001 = stablehlo.broadcast_in_dim %7996, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8002 = stablehlo.multiply %8000, %8001 : tensor<1x1200x320xf32>
    %8003 = stablehlo.convert %arg353 : (tensor<320xbf16>) -> tensor<320xf32>
    %8004 = stablehlo.broadcast_in_dim %8002, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8005 = stablehlo.broadcast_in_dim %8003, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8006 = stablehlo.multiply %8004, %8005 : tensor<1x1200x320xf32>
    %8007 = stablehlo.convert %arg354 : (tensor<320xbf16>) -> tensor<320xf32>
    %8008 = stablehlo.broadcast_in_dim %8006, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8009 = stablehlo.broadcast_in_dim %8007, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8010 = stablehlo.add %8008, %8009 : tensor<1x1200x320xf32>
    %8011 = stablehlo.convert %8010 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8012 = stablehlo.reshape %8011 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8013 = stablehlo.convert %8012 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8014 = stablehlo.dot_general %8013, %arg830, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %8015 = stablehlo.broadcast_in_dim %8014, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8016 = stablehlo.multiply %8015, %3226 : tensor<1200x1280xf32>
    %8017 = stablehlo.broadcast_in_dim %8016, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8018 = stablehlo.broadcast_in_dim %arg831, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %8019 = stablehlo.add %8017, %8018 : tensor<1200x1280xf32>
    %8020 = stablehlo.convert %8019 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %8021 = stablehlo.reshape %8020 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %8022 = stablehlo.transpose %8021, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %8023 = stablehlo.reshape %8022 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %8024 = stablehlo.convolution(%8023, %arg355) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %8025 = stablehlo.reshape %arg356 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %8026 = stablehlo.broadcast_in_dim %8024, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %8027 = stablehlo.broadcast_in_dim %8025, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %8028 = stablehlo.add %8026, %8027 : tensor<1x1280x30x40xbf16>
    %8029 = stablehlo.reshape %8028 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %8030 = stablehlo.transpose %8029, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %8031 = stablehlo.multiply %8030, %cst_42 : tensor<1x1200x1280xbf16>
    %8032 = stablehlo.multiply %8030, %3243 : tensor<1x1200x1280xbf16>
    %8033 = stablehlo.convert %8032 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %8034 = stablehlo.clamp %cst_43, %8033, %cst_44 : tensor<1x1200x1280xf32>
    %8035 = stablehlo.multiply %8034, %8034 : tensor<1x1200x1280xf32>
    %8036 = stablehlo.multiply %cst_45, %8035 : tensor<1x1200x1280xf32>
    %8037 = stablehlo.add %8036, %cst_46 : tensor<1x1200x1280xf32>
    %8038 = stablehlo.multiply %8037, %8035 : tensor<1x1200x1280xf32>
    %8039 = stablehlo.add %8038, %cst_47 : tensor<1x1200x1280xf32>
    %8040 = stablehlo.multiply %8039, %8035 : tensor<1x1200x1280xf32>
    %8041 = stablehlo.add %8040, %cst_48 : tensor<1x1200x1280xf32>
    %8042 = stablehlo.multiply %8041, %8035 : tensor<1x1200x1280xf32>
    %8043 = stablehlo.add %8042, %cst_49 : tensor<1x1200x1280xf32>
    %8044 = stablehlo.multiply %8043, %8035 : tensor<1x1200x1280xf32>
    %8045 = stablehlo.add %8044, %cst_50 : tensor<1x1200x1280xf32>
    %8046 = stablehlo.multiply %8045, %8035 : tensor<1x1200x1280xf32>
    %8047 = stablehlo.add %8046, %cst_51 : tensor<1x1200x1280xf32>
    %8048 = stablehlo.multiply %cst_52, %8035 : tensor<1x1200x1280xf32>
    %8049 = stablehlo.add %8048, %cst_53 : tensor<1x1200x1280xf32>
    %8050 = stablehlo.multiply %8049, %8035 : tensor<1x1200x1280xf32>
    %8051 = stablehlo.add %8050, %cst_54 : tensor<1x1200x1280xf32>
    %8052 = stablehlo.multiply %8051, %8035 : tensor<1x1200x1280xf32>
    %8053 = stablehlo.add %8052, %cst_55 : tensor<1x1200x1280xf32>
    %8054 = stablehlo.multiply %8053, %8035 : tensor<1x1200x1280xf32>
    %8055 = stablehlo.add %8054, %cst_56 : tensor<1x1200x1280xf32>
    %8056 = stablehlo.multiply %8034, %8047 : tensor<1x1200x1280xf32>
    %8057 = stablehlo.divide %8056, %8055 : tensor<1x1200x1280xf32>
    %8058 = stablehlo.clamp %cst_57, %8057, %cst_58 : tensor<1x1200x1280xf32>
    %8059 = stablehlo.convert %8058 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %8060 = stablehlo.add %8059, %cst_40 : tensor<1x1200x1280xbf16>
    %8061 = stablehlo.multiply %8060, %8031 : tensor<1x1200x1280xbf16>
    %8062 = stablehlo.reshape %8061 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %8063 = stablehlo.dot_general %8062, %arg832, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %8064 = stablehlo.reshape %8063 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8065 = stablehlo.broadcast_in_dim %8064, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8066 = stablehlo.broadcast_in_dim %arg357, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %8067 = stablehlo.add %8065, %8066 : tensor<1x1200x320xbf16>
    %8068 = stablehlo.reshape %8067 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8069 = stablehlo.reshape %8068 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8070 = stablehlo.add %8069, %7974 : tensor<1x1200x320xbf16>
    %8071 = stablehlo.convert %8070 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8072 = stablehlo.convert %8071 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8073 = stablehlo.reduce(%8072 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8074 = stablehlo.reshape %8073 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8075 = stablehlo.broadcast_in_dim %8074, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8076 = stablehlo.divide %8075, %2987 : tensor<1x1200x1xf64>
    %8077 = stablehlo.broadcast_in_dim %8072, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8078 = stablehlo.broadcast_in_dim %8076, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8079 = stablehlo.subtract %8077, %8078 : tensor<1x1200x320xf64>
    %8080 = stablehlo.multiply %8079, %8079 : tensor<1x1200x320xf64>
    %8081 = stablehlo.reduce(%8080 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8082 = stablehlo.reshape %8081 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8083 = stablehlo.broadcast_in_dim %8082, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8084 = stablehlo.divide %8083, %2987 : tensor<1x1200x1xf64>
    %8085 = stablehlo.convert %8084 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8086 = stablehlo.reduce(%8071 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8087 = stablehlo.reshape %8086 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8088 = stablehlo.broadcast_in_dim %8087, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8089 = stablehlo.divide %8088, %3003 : tensor<1x1200x1xf32>
    %8090 = stablehlo.broadcast_in_dim %8085, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8091 = stablehlo.add %8090, %3006 : tensor<1x1200x1xf32>
    %8092 = stablehlo.rsqrt %8091 : tensor<1x1200x1xf32>
    %8093 = stablehlo.broadcast_in_dim %8071, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8094 = stablehlo.broadcast_in_dim %8089, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8095 = stablehlo.subtract %8093, %8094 : tensor<1x1200x320xf32>
    %8096 = stablehlo.broadcast_in_dim %8095, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8097 = stablehlo.broadcast_in_dim %8092, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8098 = stablehlo.multiply %8096, %8097 : tensor<1x1200x320xf32>
    %8099 = stablehlo.convert %arg358 : (tensor<320xbf16>) -> tensor<320xf32>
    %8100 = stablehlo.broadcast_in_dim %8098, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8101 = stablehlo.broadcast_in_dim %8099, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8102 = stablehlo.multiply %8100, %8101 : tensor<1x1200x320xf32>
    %8103 = stablehlo.convert %arg359 : (tensor<320xbf16>) -> tensor<320xf32>
    %8104 = stablehlo.broadcast_in_dim %8102, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8105 = stablehlo.broadcast_in_dim %8103, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8106 = stablehlo.add %8104, %8105 : tensor<1x1200x320xf32>
    %8107 = stablehlo.convert %8106 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8108 = stablehlo.reshape %8107 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8109 = stablehlo.convert %8108 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8110 = stablehlo.dot_general %8109, %arg833, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8111 = stablehlo.broadcast_in_dim %8110, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8112 = stablehlo.multiply %8111, %3065 : tensor<1200x320xf32>
    %8113 = stablehlo.broadcast_in_dim %8112, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8114 = stablehlo.broadcast_in_dim %arg834, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8115 = stablehlo.add %8113, %8114 : tensor<1200x320xf32>
    %8116 = stablehlo.convert %8115 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8117 = stablehlo.reshape %8116 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8118 = stablehlo.reshape %8117 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %8119 = stablehlo.transpose %8118, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8120 = stablehlo.transpose %8107, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %8121 = stablehlo.reshape %8120 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %8122 = stablehlo.convolution(%8121, %arg360) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %8123 = stablehlo.reshape %arg361 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %8124 = stablehlo.broadcast_in_dim %8122, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %8125 = stablehlo.broadcast_in_dim %8123, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %8126 = stablehlo.add %8124, %8125 : tensor<1x320x15x20xbf16>
    %8127 = stablehlo.reshape %8126 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %8128 = stablehlo.transpose %8127, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %8129 = stablehlo.convert %8128 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %8130 = stablehlo.convert %8129 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %8131 = stablehlo.reduce(%8130 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8132 = stablehlo.reshape %8131 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8133 = stablehlo.broadcast_in_dim %8132, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8134 = stablehlo.divide %8133, %3088 : tensor<1x300x1xf64>
    %8135 = stablehlo.broadcast_in_dim %8130, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %8136 = stablehlo.broadcast_in_dim %8134, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %8137 = stablehlo.subtract %8135, %8136 : tensor<1x300x320xf64>
    %8138 = stablehlo.multiply %8137, %8137 : tensor<1x300x320xf64>
    %8139 = stablehlo.reduce(%8138 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8140 = stablehlo.reshape %8139 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8141 = stablehlo.broadcast_in_dim %8140, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8142 = stablehlo.divide %8141, %3088 : tensor<1x300x1xf64>
    %8143 = stablehlo.convert %8142 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %8144 = stablehlo.reduce(%8129 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %8145 = stablehlo.reshape %8144 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %8146 = stablehlo.broadcast_in_dim %8145, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8147 = stablehlo.divide %8146, %3102 : tensor<1x300x1xf32>
    %8148 = stablehlo.broadcast_in_dim %8143, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8149 = stablehlo.add %8148, %136 : tensor<1x300x1xf32>
    %8150 = stablehlo.rsqrt %8149 : tensor<1x300x1xf32>
    %8151 = stablehlo.broadcast_in_dim %8129, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8152 = stablehlo.broadcast_in_dim %8147, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8153 = stablehlo.subtract %8151, %8152 : tensor<1x300x320xf32>
    %8154 = stablehlo.broadcast_in_dim %8153, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8155 = stablehlo.broadcast_in_dim %8150, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8156 = stablehlo.multiply %8154, %8155 : tensor<1x300x320xf32>
    %8157 = stablehlo.convert %arg362 : (tensor<320xbf16>) -> tensor<320xf32>
    %8158 = stablehlo.broadcast_in_dim %8156, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8159 = stablehlo.broadcast_in_dim %8157, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8160 = stablehlo.multiply %8158, %8159 : tensor<1x300x320xf32>
    %8161 = stablehlo.convert %arg363 : (tensor<320xbf16>) -> tensor<320xf32>
    %8162 = stablehlo.broadcast_in_dim %8160, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8163 = stablehlo.broadcast_in_dim %8161, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8164 = stablehlo.add %8162, %8163 : tensor<1x300x320xf32>
    %8165 = stablehlo.convert %8164 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %8166 = stablehlo.reshape %8165 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %8167 = stablehlo.convert %8166 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %8168 = stablehlo.dot_general %8167, %arg835, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8169 = stablehlo.broadcast_in_dim %8168, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8170 = stablehlo.multiply %8169, %3126 : tensor<300x320xf32>
    %8171 = stablehlo.broadcast_in_dim %8170, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8172 = stablehlo.broadcast_in_dim %arg836, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8173 = stablehlo.add %8171, %8172 : tensor<300x320xf32>
    %8174 = stablehlo.convert %8173 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8175 = stablehlo.reshape %8174 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8176 = stablehlo.reshape %8175 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8177 = stablehlo.transpose %8176, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8178 = stablehlo.dot_general %8167, %arg837, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8179 = stablehlo.broadcast_in_dim %8178, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8180 = stablehlo.multiply %8179, %3126 : tensor<300x320xf32>
    %8181 = stablehlo.broadcast_in_dim %8180, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8182 = stablehlo.broadcast_in_dim %arg838, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8183 = stablehlo.add %8181, %8182 : tensor<300x320xf32>
    %8184 = stablehlo.convert %8183 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8185 = stablehlo.reshape %8184 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8186 = stablehlo.reshape %8185 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8187 = stablehlo.transpose %8186, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8188 = stablehlo.transpose %8177, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %8189 = stablehlo.reshape %8119 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %8190 = stablehlo.reshape %8188 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8191 = stablehlo.broadcast_in_dim %8190, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8192 = stablehlo.dot_general %8189, %8191, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %8193 = stablehlo.reshape %8192 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8194 = stablehlo.broadcast_in_dim %8193, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8195 = stablehlo.divide %8194, %3152 : tensor<1x5x1200x300xbf16>
    %8196 = stablehlo.convert %8195 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %8197 = stablehlo.reduce(%8196 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8198 = stablehlo.reshape %8197 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8199 = stablehlo.broadcast_in_dim %8196, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8200 = stablehlo.broadcast_in_dim %8198, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8201 = stablehlo.subtract %8199, %8200 : tensor<1x5x1200x300xf32>
    %8202 = stablehlo.exponential %8201 : tensor<1x5x1200x300xf32>
    %8203 = stablehlo.reduce(%8202 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8204 = stablehlo.reshape %8203 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8205 = stablehlo.broadcast_in_dim %8202, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8206 = stablehlo.broadcast_in_dim %8204, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8207 = stablehlo.divide %8205, %8206 : tensor<1x5x1200x300xf32>
    %8208 = stablehlo.convert %8207 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %8209 = stablehlo.reshape %8208 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %8210 = stablehlo.reshape %8187 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8211 = stablehlo.broadcast_in_dim %8210, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8212 = stablehlo.dot_general %8209, %8211, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %8213 = stablehlo.reshape %8212 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8214 = stablehlo.transpose %8213, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %8215 = stablehlo.reshape %8214 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %8216 = stablehlo.reshape %8215 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8217 = stablehlo.convert %8216 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8218 = stablehlo.dot_general %8217, %arg839, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8219 = stablehlo.broadcast_in_dim %8218, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8220 = stablehlo.multiply %8219, %3065 : tensor<1200x320xf32>
    %8221 = stablehlo.broadcast_in_dim %8220, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8222 = stablehlo.broadcast_in_dim %arg840, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8223 = stablehlo.add %8221, %8222 : tensor<1200x320xf32>
    %8224 = stablehlo.convert %8223 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8225 = stablehlo.reshape %8224 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8226 = stablehlo.add %8225, %8070 : tensor<1x1200x320xbf16>
    %8227 = stablehlo.convert %8226 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8228 = stablehlo.convert %8227 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8229 = stablehlo.reduce(%8228 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8230 = stablehlo.reshape %8229 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8231 = stablehlo.broadcast_in_dim %8230, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8232 = stablehlo.divide %8231, %2987 : tensor<1x1200x1xf64>
    %8233 = stablehlo.broadcast_in_dim %8228, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8234 = stablehlo.broadcast_in_dim %8232, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8235 = stablehlo.subtract %8233, %8234 : tensor<1x1200x320xf64>
    %8236 = stablehlo.multiply %8235, %8235 : tensor<1x1200x320xf64>
    %8237 = stablehlo.reduce(%8236 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8238 = stablehlo.reshape %8237 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8239 = stablehlo.broadcast_in_dim %8238, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8240 = stablehlo.divide %8239, %2987 : tensor<1x1200x1xf64>
    %8241 = stablehlo.convert %8240 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8242 = stablehlo.reduce(%8227 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8243 = stablehlo.reshape %8242 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8244 = stablehlo.broadcast_in_dim %8243, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8245 = stablehlo.divide %8244, %3003 : tensor<1x1200x1xf32>
    %8246 = stablehlo.broadcast_in_dim %8241, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8247 = stablehlo.add %8246, %3006 : tensor<1x1200x1xf32>
    %8248 = stablehlo.rsqrt %8247 : tensor<1x1200x1xf32>
    %8249 = stablehlo.broadcast_in_dim %8227, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8250 = stablehlo.broadcast_in_dim %8245, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8251 = stablehlo.subtract %8249, %8250 : tensor<1x1200x320xf32>
    %8252 = stablehlo.broadcast_in_dim %8251, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8253 = stablehlo.broadcast_in_dim %8248, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8254 = stablehlo.multiply %8252, %8253 : tensor<1x1200x320xf32>
    %8255 = stablehlo.convert %arg364 : (tensor<320xbf16>) -> tensor<320xf32>
    %8256 = stablehlo.broadcast_in_dim %8254, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8257 = stablehlo.broadcast_in_dim %8255, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8258 = stablehlo.multiply %8256, %8257 : tensor<1x1200x320xf32>
    %8259 = stablehlo.convert %arg365 : (tensor<320xbf16>) -> tensor<320xf32>
    %8260 = stablehlo.broadcast_in_dim %8258, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8261 = stablehlo.broadcast_in_dim %8259, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8262 = stablehlo.add %8260, %8261 : tensor<1x1200x320xf32>
    %8263 = stablehlo.convert %8262 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8264 = stablehlo.reshape %8263 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8265 = stablehlo.convert %8264 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8266 = stablehlo.dot_general %8265, %arg841, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %8267 = stablehlo.broadcast_in_dim %8266, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8268 = stablehlo.multiply %8267, %3226 : tensor<1200x1280xf32>
    %8269 = stablehlo.broadcast_in_dim %8268, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8270 = stablehlo.broadcast_in_dim %arg842, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %8271 = stablehlo.add %8269, %8270 : tensor<1200x1280xf32>
    %8272 = stablehlo.convert %8271 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %8273 = stablehlo.reshape %8272 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %8274 = stablehlo.transpose %8273, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %8275 = stablehlo.reshape %8274 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %8276 = stablehlo.convolution(%8275, %arg366) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %8277 = stablehlo.reshape %arg367 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %8278 = stablehlo.broadcast_in_dim %8276, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %8279 = stablehlo.broadcast_in_dim %8277, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %8280 = stablehlo.add %8278, %8279 : tensor<1x1280x30x40xbf16>
    %8281 = stablehlo.reshape %8280 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %8282 = stablehlo.transpose %8281, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %8283 = stablehlo.multiply %8282, %cst_42 : tensor<1x1200x1280xbf16>
    %8284 = stablehlo.multiply %8282, %3243 : tensor<1x1200x1280xbf16>
    %8285 = stablehlo.convert %8284 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %8286 = stablehlo.clamp %cst_43, %8285, %cst_44 : tensor<1x1200x1280xf32>
    %8287 = stablehlo.multiply %8286, %8286 : tensor<1x1200x1280xf32>
    %8288 = stablehlo.multiply %cst_45, %8287 : tensor<1x1200x1280xf32>
    %8289 = stablehlo.add %8288, %cst_46 : tensor<1x1200x1280xf32>
    %8290 = stablehlo.multiply %8289, %8287 : tensor<1x1200x1280xf32>
    %8291 = stablehlo.add %8290, %cst_47 : tensor<1x1200x1280xf32>
    %8292 = stablehlo.multiply %8291, %8287 : tensor<1x1200x1280xf32>
    %8293 = stablehlo.add %8292, %cst_48 : tensor<1x1200x1280xf32>
    %8294 = stablehlo.multiply %8293, %8287 : tensor<1x1200x1280xf32>
    %8295 = stablehlo.add %8294, %cst_49 : tensor<1x1200x1280xf32>
    %8296 = stablehlo.multiply %8295, %8287 : tensor<1x1200x1280xf32>
    %8297 = stablehlo.add %8296, %cst_50 : tensor<1x1200x1280xf32>
    %8298 = stablehlo.multiply %8297, %8287 : tensor<1x1200x1280xf32>
    %8299 = stablehlo.add %8298, %cst_51 : tensor<1x1200x1280xf32>
    %8300 = stablehlo.multiply %cst_52, %8287 : tensor<1x1200x1280xf32>
    %8301 = stablehlo.add %8300, %cst_53 : tensor<1x1200x1280xf32>
    %8302 = stablehlo.multiply %8301, %8287 : tensor<1x1200x1280xf32>
    %8303 = stablehlo.add %8302, %cst_54 : tensor<1x1200x1280xf32>
    %8304 = stablehlo.multiply %8303, %8287 : tensor<1x1200x1280xf32>
    %8305 = stablehlo.add %8304, %cst_55 : tensor<1x1200x1280xf32>
    %8306 = stablehlo.multiply %8305, %8287 : tensor<1x1200x1280xf32>
    %8307 = stablehlo.add %8306, %cst_56 : tensor<1x1200x1280xf32>
    %8308 = stablehlo.multiply %8286, %8299 : tensor<1x1200x1280xf32>
    %8309 = stablehlo.divide %8308, %8307 : tensor<1x1200x1280xf32>
    %8310 = stablehlo.clamp %cst_57, %8309, %cst_58 : tensor<1x1200x1280xf32>
    %8311 = stablehlo.convert %8310 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %8312 = stablehlo.add %8311, %cst_40 : tensor<1x1200x1280xbf16>
    %8313 = stablehlo.multiply %8312, %8283 : tensor<1x1200x1280xbf16>
    %8314 = stablehlo.reshape %8313 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %8315 = stablehlo.dot_general %8314, %arg843, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %8316 = stablehlo.reshape %8315 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8317 = stablehlo.broadcast_in_dim %8316, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8318 = stablehlo.broadcast_in_dim %arg368, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %8319 = stablehlo.add %8317, %8318 : tensor<1x1200x320xbf16>
    %8320 = stablehlo.reshape %8319 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8321 = stablehlo.reshape %8320 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8322 = stablehlo.add %8321, %8226 : tensor<1x1200x320xbf16>
    %8323 = stablehlo.convert %8322 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8324 = stablehlo.convert %8323 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8325 = stablehlo.reduce(%8324 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8326 = stablehlo.reshape %8325 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8327 = stablehlo.broadcast_in_dim %8326, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8328 = stablehlo.divide %8327, %2987 : tensor<1x1200x1xf64>
    %8329 = stablehlo.broadcast_in_dim %8324, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8330 = stablehlo.broadcast_in_dim %8328, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8331 = stablehlo.subtract %8329, %8330 : tensor<1x1200x320xf64>
    %8332 = stablehlo.multiply %8331, %8331 : tensor<1x1200x320xf64>
    %8333 = stablehlo.reduce(%8332 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8334 = stablehlo.reshape %8333 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8335 = stablehlo.broadcast_in_dim %8334, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8336 = stablehlo.divide %8335, %2987 : tensor<1x1200x1xf64>
    %8337 = stablehlo.convert %8336 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8338 = stablehlo.reduce(%8323 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8339 = stablehlo.reshape %8338 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8340 = stablehlo.broadcast_in_dim %8339, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8341 = stablehlo.divide %8340, %3003 : tensor<1x1200x1xf32>
    %8342 = stablehlo.broadcast_in_dim %8337, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8343 = stablehlo.add %8342, %3006 : tensor<1x1200x1xf32>
    %8344 = stablehlo.rsqrt %8343 : tensor<1x1200x1xf32>
    %8345 = stablehlo.broadcast_in_dim %8323, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8346 = stablehlo.broadcast_in_dim %8341, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8347 = stablehlo.subtract %8345, %8346 : tensor<1x1200x320xf32>
    %8348 = stablehlo.broadcast_in_dim %8347, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8349 = stablehlo.broadcast_in_dim %8344, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8350 = stablehlo.multiply %8348, %8349 : tensor<1x1200x320xf32>
    %8351 = stablehlo.convert %arg369 : (tensor<320xbf16>) -> tensor<320xf32>
    %8352 = stablehlo.broadcast_in_dim %8350, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8353 = stablehlo.broadcast_in_dim %8351, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8354 = stablehlo.multiply %8352, %8353 : tensor<1x1200x320xf32>
    %8355 = stablehlo.convert %arg370 : (tensor<320xbf16>) -> tensor<320xf32>
    %8356 = stablehlo.broadcast_in_dim %8354, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8357 = stablehlo.broadcast_in_dim %8355, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8358 = stablehlo.add %8356, %8357 : tensor<1x1200x320xf32>
    %8359 = stablehlo.convert %8358 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8360 = stablehlo.reshape %8359 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8361 = stablehlo.convert %8360 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8362 = stablehlo.dot_general %8361, %arg844, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8363 = stablehlo.broadcast_in_dim %8362, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8364 = stablehlo.multiply %8363, %3065 : tensor<1200x320xf32>
    %8365 = stablehlo.broadcast_in_dim %8364, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8366 = stablehlo.broadcast_in_dim %arg845, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8367 = stablehlo.add %8365, %8366 : tensor<1200x320xf32>
    %8368 = stablehlo.convert %8367 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8369 = stablehlo.reshape %8368 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8370 = stablehlo.reshape %8369 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %8371 = stablehlo.transpose %8370, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8372 = stablehlo.transpose %8359, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %8373 = stablehlo.reshape %8372 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %8374 = stablehlo.convolution(%8373, %arg371) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %8375 = stablehlo.reshape %arg372 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %8376 = stablehlo.broadcast_in_dim %8374, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %8377 = stablehlo.broadcast_in_dim %8375, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %8378 = stablehlo.add %8376, %8377 : tensor<1x320x15x20xbf16>
    %8379 = stablehlo.reshape %8378 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %8380 = stablehlo.transpose %8379, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %8381 = stablehlo.convert %8380 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %8382 = stablehlo.convert %8381 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %8383 = stablehlo.reduce(%8382 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8384 = stablehlo.reshape %8383 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8385 = stablehlo.broadcast_in_dim %8384, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8386 = stablehlo.divide %8385, %3088 : tensor<1x300x1xf64>
    %8387 = stablehlo.broadcast_in_dim %8382, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %8388 = stablehlo.broadcast_in_dim %8386, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %8389 = stablehlo.subtract %8387, %8388 : tensor<1x300x320xf64>
    %8390 = stablehlo.multiply %8389, %8389 : tensor<1x300x320xf64>
    %8391 = stablehlo.reduce(%8390 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8392 = stablehlo.reshape %8391 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8393 = stablehlo.broadcast_in_dim %8392, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8394 = stablehlo.divide %8393, %3088 : tensor<1x300x1xf64>
    %8395 = stablehlo.convert %8394 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %8396 = stablehlo.reduce(%8381 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %8397 = stablehlo.reshape %8396 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %8398 = stablehlo.broadcast_in_dim %8397, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8399 = stablehlo.divide %8398, %3102 : tensor<1x300x1xf32>
    %8400 = stablehlo.broadcast_in_dim %8395, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8401 = stablehlo.add %8400, %136 : tensor<1x300x1xf32>
    %8402 = stablehlo.rsqrt %8401 : tensor<1x300x1xf32>
    %8403 = stablehlo.broadcast_in_dim %8381, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8404 = stablehlo.broadcast_in_dim %8399, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8405 = stablehlo.subtract %8403, %8404 : tensor<1x300x320xf32>
    %8406 = stablehlo.broadcast_in_dim %8405, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8407 = stablehlo.broadcast_in_dim %8402, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8408 = stablehlo.multiply %8406, %8407 : tensor<1x300x320xf32>
    %8409 = stablehlo.convert %arg373 : (tensor<320xbf16>) -> tensor<320xf32>
    %8410 = stablehlo.broadcast_in_dim %8408, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8411 = stablehlo.broadcast_in_dim %8409, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8412 = stablehlo.multiply %8410, %8411 : tensor<1x300x320xf32>
    %8413 = stablehlo.convert %arg374 : (tensor<320xbf16>) -> tensor<320xf32>
    %8414 = stablehlo.broadcast_in_dim %8412, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8415 = stablehlo.broadcast_in_dim %8413, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8416 = stablehlo.add %8414, %8415 : tensor<1x300x320xf32>
    %8417 = stablehlo.convert %8416 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %8418 = stablehlo.reshape %8417 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %8419 = stablehlo.convert %8418 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %8420 = stablehlo.dot_general %8419, %arg846, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8421 = stablehlo.broadcast_in_dim %8420, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8422 = stablehlo.multiply %8421, %3126 : tensor<300x320xf32>
    %8423 = stablehlo.broadcast_in_dim %8422, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8424 = stablehlo.broadcast_in_dim %arg847, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8425 = stablehlo.add %8423, %8424 : tensor<300x320xf32>
    %8426 = stablehlo.convert %8425 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8427 = stablehlo.reshape %8426 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8428 = stablehlo.reshape %8427 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8429 = stablehlo.transpose %8428, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8430 = stablehlo.dot_general %8419, %arg848, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8431 = stablehlo.broadcast_in_dim %8430, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8432 = stablehlo.multiply %8431, %3126 : tensor<300x320xf32>
    %8433 = stablehlo.broadcast_in_dim %8432, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8434 = stablehlo.broadcast_in_dim %arg849, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8435 = stablehlo.add %8433, %8434 : tensor<300x320xf32>
    %8436 = stablehlo.convert %8435 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8437 = stablehlo.reshape %8436 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8438 = stablehlo.reshape %8437 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8439 = stablehlo.transpose %8438, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8440 = stablehlo.transpose %8429, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %8441 = stablehlo.reshape %8371 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %8442 = stablehlo.reshape %8440 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8443 = stablehlo.broadcast_in_dim %8442, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8444 = stablehlo.dot_general %8441, %8443, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %8445 = stablehlo.reshape %8444 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8446 = stablehlo.broadcast_in_dim %8445, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8447 = stablehlo.divide %8446, %3152 : tensor<1x5x1200x300xbf16>
    %8448 = stablehlo.convert %8447 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %8449 = stablehlo.reduce(%8448 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8450 = stablehlo.reshape %8449 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8451 = stablehlo.broadcast_in_dim %8448, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8452 = stablehlo.broadcast_in_dim %8450, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8453 = stablehlo.subtract %8451, %8452 : tensor<1x5x1200x300xf32>
    %8454 = stablehlo.exponential %8453 : tensor<1x5x1200x300xf32>
    %8455 = stablehlo.reduce(%8454 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8456 = stablehlo.reshape %8455 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8457 = stablehlo.broadcast_in_dim %8454, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8458 = stablehlo.broadcast_in_dim %8456, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8459 = stablehlo.divide %8457, %8458 : tensor<1x5x1200x300xf32>
    %8460 = stablehlo.convert %8459 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %8461 = stablehlo.reshape %8460 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %8462 = stablehlo.reshape %8439 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8463 = stablehlo.broadcast_in_dim %8462, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8464 = stablehlo.dot_general %8461, %8463, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %8465 = stablehlo.reshape %8464 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8466 = stablehlo.transpose %8465, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %8467 = stablehlo.reshape %8466 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %8468 = stablehlo.reshape %8467 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8469 = stablehlo.convert %8468 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8470 = stablehlo.dot_general %8469, %arg850, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8471 = stablehlo.broadcast_in_dim %8470, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8472 = stablehlo.multiply %8471, %3065 : tensor<1200x320xf32>
    %8473 = stablehlo.broadcast_in_dim %8472, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8474 = stablehlo.broadcast_in_dim %arg851, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8475 = stablehlo.add %8473, %8474 : tensor<1200x320xf32>
    %8476 = stablehlo.convert %8475 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8477 = stablehlo.reshape %8476 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8478 = stablehlo.add %8477, %8322 : tensor<1x1200x320xbf16>
    %8479 = stablehlo.convert %8478 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8480 = stablehlo.convert %8479 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8481 = stablehlo.reduce(%8480 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8482 = stablehlo.reshape %8481 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8483 = stablehlo.broadcast_in_dim %8482, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8484 = stablehlo.divide %8483, %2987 : tensor<1x1200x1xf64>
    %8485 = stablehlo.broadcast_in_dim %8480, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8486 = stablehlo.broadcast_in_dim %8484, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8487 = stablehlo.subtract %8485, %8486 : tensor<1x1200x320xf64>
    %8488 = stablehlo.multiply %8487, %8487 : tensor<1x1200x320xf64>
    %8489 = stablehlo.reduce(%8488 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8490 = stablehlo.reshape %8489 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8491 = stablehlo.broadcast_in_dim %8490, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8492 = stablehlo.divide %8491, %2987 : tensor<1x1200x1xf64>
    %8493 = stablehlo.convert %8492 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8494 = stablehlo.reduce(%8479 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8495 = stablehlo.reshape %8494 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8496 = stablehlo.broadcast_in_dim %8495, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8497 = stablehlo.divide %8496, %3003 : tensor<1x1200x1xf32>
    %8498 = stablehlo.broadcast_in_dim %8493, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8499 = stablehlo.add %8498, %3006 : tensor<1x1200x1xf32>
    %8500 = stablehlo.rsqrt %8499 : tensor<1x1200x1xf32>
    %8501 = stablehlo.broadcast_in_dim %8479, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8502 = stablehlo.broadcast_in_dim %8497, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8503 = stablehlo.subtract %8501, %8502 : tensor<1x1200x320xf32>
    %8504 = stablehlo.broadcast_in_dim %8503, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8505 = stablehlo.broadcast_in_dim %8500, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8506 = stablehlo.multiply %8504, %8505 : tensor<1x1200x320xf32>
    %8507 = stablehlo.convert %arg375 : (tensor<320xbf16>) -> tensor<320xf32>
    %8508 = stablehlo.broadcast_in_dim %8506, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8509 = stablehlo.broadcast_in_dim %8507, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8510 = stablehlo.multiply %8508, %8509 : tensor<1x1200x320xf32>
    %8511 = stablehlo.convert %arg376 : (tensor<320xbf16>) -> tensor<320xf32>
    %8512 = stablehlo.broadcast_in_dim %8510, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8513 = stablehlo.broadcast_in_dim %8511, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8514 = stablehlo.add %8512, %8513 : tensor<1x1200x320xf32>
    %8515 = stablehlo.convert %8514 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8516 = stablehlo.reshape %8515 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8517 = stablehlo.convert %8516 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8518 = stablehlo.dot_general %8517, %arg852, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %8519 = stablehlo.broadcast_in_dim %8518, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8520 = stablehlo.multiply %8519, %3226 : tensor<1200x1280xf32>
    %8521 = stablehlo.broadcast_in_dim %8520, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8522 = stablehlo.broadcast_in_dim %arg853, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %8523 = stablehlo.add %8521, %8522 : tensor<1200x1280xf32>
    %8524 = stablehlo.convert %8523 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %8525 = stablehlo.reshape %8524 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %8526 = stablehlo.transpose %8525, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %8527 = stablehlo.reshape %8526 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %8528 = stablehlo.convolution(%8527, %arg377) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %8529 = stablehlo.reshape %arg378 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %8530 = stablehlo.broadcast_in_dim %8528, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %8531 = stablehlo.broadcast_in_dim %8529, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %8532 = stablehlo.add %8530, %8531 : tensor<1x1280x30x40xbf16>
    %8533 = stablehlo.reshape %8532 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %8534 = stablehlo.transpose %8533, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %8535 = stablehlo.multiply %8534, %cst_42 : tensor<1x1200x1280xbf16>
    %8536 = stablehlo.multiply %8534, %3243 : tensor<1x1200x1280xbf16>
    %8537 = stablehlo.convert %8536 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %8538 = stablehlo.clamp %cst_43, %8537, %cst_44 : tensor<1x1200x1280xf32>
    %8539 = stablehlo.multiply %8538, %8538 : tensor<1x1200x1280xf32>
    %8540 = stablehlo.multiply %cst_45, %8539 : tensor<1x1200x1280xf32>
    %8541 = stablehlo.add %8540, %cst_46 : tensor<1x1200x1280xf32>
    %8542 = stablehlo.multiply %8541, %8539 : tensor<1x1200x1280xf32>
    %8543 = stablehlo.add %8542, %cst_47 : tensor<1x1200x1280xf32>
    %8544 = stablehlo.multiply %8543, %8539 : tensor<1x1200x1280xf32>
    %8545 = stablehlo.add %8544, %cst_48 : tensor<1x1200x1280xf32>
    %8546 = stablehlo.multiply %8545, %8539 : tensor<1x1200x1280xf32>
    %8547 = stablehlo.add %8546, %cst_49 : tensor<1x1200x1280xf32>
    %8548 = stablehlo.multiply %8547, %8539 : tensor<1x1200x1280xf32>
    %8549 = stablehlo.add %8548, %cst_50 : tensor<1x1200x1280xf32>
    %8550 = stablehlo.multiply %8549, %8539 : tensor<1x1200x1280xf32>
    %8551 = stablehlo.add %8550, %cst_51 : tensor<1x1200x1280xf32>
    %8552 = stablehlo.multiply %cst_52, %8539 : tensor<1x1200x1280xf32>
    %8553 = stablehlo.add %8552, %cst_53 : tensor<1x1200x1280xf32>
    %8554 = stablehlo.multiply %8553, %8539 : tensor<1x1200x1280xf32>
    %8555 = stablehlo.add %8554, %cst_54 : tensor<1x1200x1280xf32>
    %8556 = stablehlo.multiply %8555, %8539 : tensor<1x1200x1280xf32>
    %8557 = stablehlo.add %8556, %cst_55 : tensor<1x1200x1280xf32>
    %8558 = stablehlo.multiply %8557, %8539 : tensor<1x1200x1280xf32>
    %8559 = stablehlo.add %8558, %cst_56 : tensor<1x1200x1280xf32>
    %8560 = stablehlo.multiply %8538, %8551 : tensor<1x1200x1280xf32>
    %8561 = stablehlo.divide %8560, %8559 : tensor<1x1200x1280xf32>
    %8562 = stablehlo.clamp %cst_57, %8561, %cst_58 : tensor<1x1200x1280xf32>
    %8563 = stablehlo.convert %8562 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %8564 = stablehlo.add %8563, %cst_40 : tensor<1x1200x1280xbf16>
    %8565 = stablehlo.multiply %8564, %8535 : tensor<1x1200x1280xbf16>
    %8566 = stablehlo.reshape %8565 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %8567 = stablehlo.dot_general %8566, %arg854, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %8568 = stablehlo.reshape %8567 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8569 = stablehlo.broadcast_in_dim %8568, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8570 = stablehlo.broadcast_in_dim %arg379, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %8571 = stablehlo.add %8569, %8570 : tensor<1x1200x320xbf16>
    %8572 = stablehlo.reshape %8571 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8573 = stablehlo.reshape %8572 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8574 = stablehlo.add %8573, %8478 : tensor<1x1200x320xbf16>
    %8575 = stablehlo.convert %8574 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8576 = stablehlo.convert %8575 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8577 = stablehlo.reduce(%8576 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8578 = stablehlo.reshape %8577 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8579 = stablehlo.broadcast_in_dim %8578, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8580 = stablehlo.divide %8579, %2987 : tensor<1x1200x1xf64>
    %8581 = stablehlo.broadcast_in_dim %8576, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8582 = stablehlo.broadcast_in_dim %8580, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8583 = stablehlo.subtract %8581, %8582 : tensor<1x1200x320xf64>
    %8584 = stablehlo.multiply %8583, %8583 : tensor<1x1200x320xf64>
    %8585 = stablehlo.reduce(%8584 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8586 = stablehlo.reshape %8585 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8587 = stablehlo.broadcast_in_dim %8586, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8588 = stablehlo.divide %8587, %2987 : tensor<1x1200x1xf64>
    %8589 = stablehlo.convert %8588 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8590 = stablehlo.reduce(%8575 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8591 = stablehlo.reshape %8590 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8592 = stablehlo.broadcast_in_dim %8591, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8593 = stablehlo.divide %8592, %3003 : tensor<1x1200x1xf32>
    %8594 = stablehlo.broadcast_in_dim %8589, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8595 = stablehlo.add %8594, %3006 : tensor<1x1200x1xf32>
    %8596 = stablehlo.rsqrt %8595 : tensor<1x1200x1xf32>
    %8597 = stablehlo.broadcast_in_dim %8575, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8598 = stablehlo.broadcast_in_dim %8593, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8599 = stablehlo.subtract %8597, %8598 : tensor<1x1200x320xf32>
    %8600 = stablehlo.broadcast_in_dim %8599, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8601 = stablehlo.broadcast_in_dim %8596, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8602 = stablehlo.multiply %8600, %8601 : tensor<1x1200x320xf32>
    %8603 = stablehlo.convert %arg380 : (tensor<320xbf16>) -> tensor<320xf32>
    %8604 = stablehlo.broadcast_in_dim %8602, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8605 = stablehlo.broadcast_in_dim %8603, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8606 = stablehlo.multiply %8604, %8605 : tensor<1x1200x320xf32>
    %8607 = stablehlo.convert %arg381 : (tensor<320xbf16>) -> tensor<320xf32>
    %8608 = stablehlo.broadcast_in_dim %8606, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8609 = stablehlo.broadcast_in_dim %8607, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8610 = stablehlo.add %8608, %8609 : tensor<1x1200x320xf32>
    %8611 = stablehlo.convert %8610 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8612 = stablehlo.reshape %8611 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8613 = stablehlo.convert %8612 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8614 = stablehlo.dot_general %8613, %arg855, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8615 = stablehlo.broadcast_in_dim %8614, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8616 = stablehlo.multiply %8615, %3065 : tensor<1200x320xf32>
    %8617 = stablehlo.broadcast_in_dim %8616, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8618 = stablehlo.broadcast_in_dim %arg856, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8619 = stablehlo.add %8617, %8618 : tensor<1200x320xf32>
    %8620 = stablehlo.convert %8619 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8621 = stablehlo.reshape %8620 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8622 = stablehlo.reshape %8621 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %8623 = stablehlo.transpose %8622, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8624 = stablehlo.transpose %8611, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %8625 = stablehlo.reshape %8624 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %8626 = stablehlo.convolution(%8625, %arg382) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %8627 = stablehlo.reshape %arg383 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %8628 = stablehlo.broadcast_in_dim %8626, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %8629 = stablehlo.broadcast_in_dim %8627, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %8630 = stablehlo.add %8628, %8629 : tensor<1x320x15x20xbf16>
    %8631 = stablehlo.reshape %8630 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %8632 = stablehlo.transpose %8631, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %8633 = stablehlo.convert %8632 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %8634 = stablehlo.convert %8633 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %8635 = stablehlo.reduce(%8634 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8636 = stablehlo.reshape %8635 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8637 = stablehlo.broadcast_in_dim %8636, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8638 = stablehlo.divide %8637, %3088 : tensor<1x300x1xf64>
    %8639 = stablehlo.broadcast_in_dim %8634, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %8640 = stablehlo.broadcast_in_dim %8638, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %8641 = stablehlo.subtract %8639, %8640 : tensor<1x300x320xf64>
    %8642 = stablehlo.multiply %8641, %8641 : tensor<1x300x320xf64>
    %8643 = stablehlo.reduce(%8642 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8644 = stablehlo.reshape %8643 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8645 = stablehlo.broadcast_in_dim %8644, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8646 = stablehlo.divide %8645, %3088 : tensor<1x300x1xf64>
    %8647 = stablehlo.convert %8646 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %8648 = stablehlo.reduce(%8633 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %8649 = stablehlo.reshape %8648 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %8650 = stablehlo.broadcast_in_dim %8649, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8651 = stablehlo.divide %8650, %3102 : tensor<1x300x1xf32>
    %8652 = stablehlo.broadcast_in_dim %8647, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8653 = stablehlo.add %8652, %136 : tensor<1x300x1xf32>
    %8654 = stablehlo.rsqrt %8653 : tensor<1x300x1xf32>
    %8655 = stablehlo.broadcast_in_dim %8633, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8656 = stablehlo.broadcast_in_dim %8651, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8657 = stablehlo.subtract %8655, %8656 : tensor<1x300x320xf32>
    %8658 = stablehlo.broadcast_in_dim %8657, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8659 = stablehlo.broadcast_in_dim %8654, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8660 = stablehlo.multiply %8658, %8659 : tensor<1x300x320xf32>
    %8661 = stablehlo.convert %arg384 : (tensor<320xbf16>) -> tensor<320xf32>
    %8662 = stablehlo.broadcast_in_dim %8660, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8663 = stablehlo.broadcast_in_dim %8661, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8664 = stablehlo.multiply %8662, %8663 : tensor<1x300x320xf32>
    %8665 = stablehlo.convert %arg385 : (tensor<320xbf16>) -> tensor<320xf32>
    %8666 = stablehlo.broadcast_in_dim %8664, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8667 = stablehlo.broadcast_in_dim %8665, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8668 = stablehlo.add %8666, %8667 : tensor<1x300x320xf32>
    %8669 = stablehlo.convert %8668 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %8670 = stablehlo.reshape %8669 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %8671 = stablehlo.convert %8670 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %8672 = stablehlo.dot_general %8671, %arg857, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8673 = stablehlo.broadcast_in_dim %8672, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8674 = stablehlo.multiply %8673, %3126 : tensor<300x320xf32>
    %8675 = stablehlo.broadcast_in_dim %8674, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8676 = stablehlo.broadcast_in_dim %arg858, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8677 = stablehlo.add %8675, %8676 : tensor<300x320xf32>
    %8678 = stablehlo.convert %8677 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8679 = stablehlo.reshape %8678 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8680 = stablehlo.reshape %8679 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8681 = stablehlo.transpose %8680, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8682 = stablehlo.dot_general %8671, %arg859, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8683 = stablehlo.broadcast_in_dim %8682, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8684 = stablehlo.multiply %8683, %3126 : tensor<300x320xf32>
    %8685 = stablehlo.broadcast_in_dim %8684, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8686 = stablehlo.broadcast_in_dim %arg860, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8687 = stablehlo.add %8685, %8686 : tensor<300x320xf32>
    %8688 = stablehlo.convert %8687 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8689 = stablehlo.reshape %8688 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8690 = stablehlo.reshape %8689 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8691 = stablehlo.transpose %8690, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8692 = stablehlo.transpose %8681, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %8693 = stablehlo.reshape %8623 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %8694 = stablehlo.reshape %8692 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8695 = stablehlo.broadcast_in_dim %8694, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8696 = stablehlo.dot_general %8693, %8695, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %8697 = stablehlo.reshape %8696 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8698 = stablehlo.broadcast_in_dim %8697, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8699 = stablehlo.divide %8698, %3152 : tensor<1x5x1200x300xbf16>
    %8700 = stablehlo.convert %8699 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %8701 = stablehlo.reduce(%8700 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8702 = stablehlo.reshape %8701 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8703 = stablehlo.broadcast_in_dim %8700, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8704 = stablehlo.broadcast_in_dim %8702, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8705 = stablehlo.subtract %8703, %8704 : tensor<1x5x1200x300xf32>
    %8706 = stablehlo.exponential %8705 : tensor<1x5x1200x300xf32>
    %8707 = stablehlo.reduce(%8706 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8708 = stablehlo.reshape %8707 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8709 = stablehlo.broadcast_in_dim %8706, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8710 = stablehlo.broadcast_in_dim %8708, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8711 = stablehlo.divide %8709, %8710 : tensor<1x5x1200x300xf32>
    %8712 = stablehlo.convert %8711 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %8713 = stablehlo.reshape %8712 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %8714 = stablehlo.reshape %8691 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8715 = stablehlo.broadcast_in_dim %8714, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8716 = stablehlo.dot_general %8713, %8715, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %8717 = stablehlo.reshape %8716 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8718 = stablehlo.transpose %8717, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %8719 = stablehlo.reshape %8718 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %8720 = stablehlo.reshape %8719 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8721 = stablehlo.convert %8720 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8722 = stablehlo.dot_general %8721, %arg861, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8723 = stablehlo.broadcast_in_dim %8722, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8724 = stablehlo.multiply %8723, %3065 : tensor<1200x320xf32>
    %8725 = stablehlo.broadcast_in_dim %8724, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8726 = stablehlo.broadcast_in_dim %arg862, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8727 = stablehlo.add %8725, %8726 : tensor<1200x320xf32>
    %8728 = stablehlo.convert %8727 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8729 = stablehlo.reshape %8728 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8730 = stablehlo.add %8729, %8574 : tensor<1x1200x320xbf16>
    %8731 = stablehlo.convert %8730 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8732 = stablehlo.convert %8731 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8733 = stablehlo.reduce(%8732 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8734 = stablehlo.reshape %8733 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8735 = stablehlo.broadcast_in_dim %8734, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8736 = stablehlo.divide %8735, %2987 : tensor<1x1200x1xf64>
    %8737 = stablehlo.broadcast_in_dim %8732, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8738 = stablehlo.broadcast_in_dim %8736, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8739 = stablehlo.subtract %8737, %8738 : tensor<1x1200x320xf64>
    %8740 = stablehlo.multiply %8739, %8739 : tensor<1x1200x320xf64>
    %8741 = stablehlo.reduce(%8740 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8742 = stablehlo.reshape %8741 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8743 = stablehlo.broadcast_in_dim %8742, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8744 = stablehlo.divide %8743, %2987 : tensor<1x1200x1xf64>
    %8745 = stablehlo.convert %8744 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8746 = stablehlo.reduce(%8731 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8747 = stablehlo.reshape %8746 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8748 = stablehlo.broadcast_in_dim %8747, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8749 = stablehlo.divide %8748, %3003 : tensor<1x1200x1xf32>
    %8750 = stablehlo.broadcast_in_dim %8745, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8751 = stablehlo.add %8750, %3006 : tensor<1x1200x1xf32>
    %8752 = stablehlo.rsqrt %8751 : tensor<1x1200x1xf32>
    %8753 = stablehlo.broadcast_in_dim %8731, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8754 = stablehlo.broadcast_in_dim %8749, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8755 = stablehlo.subtract %8753, %8754 : tensor<1x1200x320xf32>
    %8756 = stablehlo.broadcast_in_dim %8755, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8757 = stablehlo.broadcast_in_dim %8752, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8758 = stablehlo.multiply %8756, %8757 : tensor<1x1200x320xf32>
    %8759 = stablehlo.convert %arg386 : (tensor<320xbf16>) -> tensor<320xf32>
    %8760 = stablehlo.broadcast_in_dim %8758, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8761 = stablehlo.broadcast_in_dim %8759, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8762 = stablehlo.multiply %8760, %8761 : tensor<1x1200x320xf32>
    %8763 = stablehlo.convert %arg387 : (tensor<320xbf16>) -> tensor<320xf32>
    %8764 = stablehlo.broadcast_in_dim %8762, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8765 = stablehlo.broadcast_in_dim %8763, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8766 = stablehlo.add %8764, %8765 : tensor<1x1200x320xf32>
    %8767 = stablehlo.convert %8766 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8768 = stablehlo.reshape %8767 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8769 = stablehlo.convert %8768 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8770 = stablehlo.dot_general %8769, %arg863, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %8771 = stablehlo.broadcast_in_dim %8770, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8772 = stablehlo.multiply %8771, %3226 : tensor<1200x1280xf32>
    %8773 = stablehlo.broadcast_in_dim %8772, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %8774 = stablehlo.broadcast_in_dim %arg864, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %8775 = stablehlo.add %8773, %8774 : tensor<1200x1280xf32>
    %8776 = stablehlo.convert %8775 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %8777 = stablehlo.reshape %8776 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %8778 = stablehlo.transpose %8777, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %8779 = stablehlo.reshape %8778 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %8780 = stablehlo.convolution(%8779, %arg388) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %8781 = stablehlo.reshape %arg389 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %8782 = stablehlo.broadcast_in_dim %8780, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %8783 = stablehlo.broadcast_in_dim %8781, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %8784 = stablehlo.add %8782, %8783 : tensor<1x1280x30x40xbf16>
    %8785 = stablehlo.reshape %8784 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %8786 = stablehlo.transpose %8785, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %8787 = stablehlo.multiply %8786, %cst_42 : tensor<1x1200x1280xbf16>
    %8788 = stablehlo.multiply %8786, %3243 : tensor<1x1200x1280xbf16>
    %8789 = stablehlo.convert %8788 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %8790 = stablehlo.clamp %cst_43, %8789, %cst_44 : tensor<1x1200x1280xf32>
    %8791 = stablehlo.multiply %8790, %8790 : tensor<1x1200x1280xf32>
    %8792 = stablehlo.multiply %cst_45, %8791 : tensor<1x1200x1280xf32>
    %8793 = stablehlo.add %8792, %cst_46 : tensor<1x1200x1280xf32>
    %8794 = stablehlo.multiply %8793, %8791 : tensor<1x1200x1280xf32>
    %8795 = stablehlo.add %8794, %cst_47 : tensor<1x1200x1280xf32>
    %8796 = stablehlo.multiply %8795, %8791 : tensor<1x1200x1280xf32>
    %8797 = stablehlo.add %8796, %cst_48 : tensor<1x1200x1280xf32>
    %8798 = stablehlo.multiply %8797, %8791 : tensor<1x1200x1280xf32>
    %8799 = stablehlo.add %8798, %cst_49 : tensor<1x1200x1280xf32>
    %8800 = stablehlo.multiply %8799, %8791 : tensor<1x1200x1280xf32>
    %8801 = stablehlo.add %8800, %cst_50 : tensor<1x1200x1280xf32>
    %8802 = stablehlo.multiply %8801, %8791 : tensor<1x1200x1280xf32>
    %8803 = stablehlo.add %8802, %cst_51 : tensor<1x1200x1280xf32>
    %8804 = stablehlo.multiply %cst_52, %8791 : tensor<1x1200x1280xf32>
    %8805 = stablehlo.add %8804, %cst_53 : tensor<1x1200x1280xf32>
    %8806 = stablehlo.multiply %8805, %8791 : tensor<1x1200x1280xf32>
    %8807 = stablehlo.add %8806, %cst_54 : tensor<1x1200x1280xf32>
    %8808 = stablehlo.multiply %8807, %8791 : tensor<1x1200x1280xf32>
    %8809 = stablehlo.add %8808, %cst_55 : tensor<1x1200x1280xf32>
    %8810 = stablehlo.multiply %8809, %8791 : tensor<1x1200x1280xf32>
    %8811 = stablehlo.add %8810, %cst_56 : tensor<1x1200x1280xf32>
    %8812 = stablehlo.multiply %8790, %8803 : tensor<1x1200x1280xf32>
    %8813 = stablehlo.divide %8812, %8811 : tensor<1x1200x1280xf32>
    %8814 = stablehlo.clamp %cst_57, %8813, %cst_58 : tensor<1x1200x1280xf32>
    %8815 = stablehlo.convert %8814 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %8816 = stablehlo.add %8815, %cst_40 : tensor<1x1200x1280xbf16>
    %8817 = stablehlo.multiply %8816, %8787 : tensor<1x1200x1280xbf16>
    %8818 = stablehlo.reshape %8817 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %8819 = stablehlo.dot_general %8818, %arg865, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %8820 = stablehlo.reshape %8819 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8821 = stablehlo.broadcast_in_dim %8820, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8822 = stablehlo.broadcast_in_dim %arg390, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %8823 = stablehlo.add %8821, %8822 : tensor<1x1200x320xbf16>
    %8824 = stablehlo.reshape %8823 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8825 = stablehlo.reshape %8824 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8826 = stablehlo.add %8825, %8730 : tensor<1x1200x320xbf16>
    %8827 = stablehlo.convert %8826 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8828 = stablehlo.convert %8827 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8829 = stablehlo.reduce(%8828 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8830 = stablehlo.reshape %8829 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8831 = stablehlo.broadcast_in_dim %8830, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8832 = stablehlo.divide %8831, %2987 : tensor<1x1200x1xf64>
    %8833 = stablehlo.broadcast_in_dim %8828, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8834 = stablehlo.broadcast_in_dim %8832, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8835 = stablehlo.subtract %8833, %8834 : tensor<1x1200x320xf64>
    %8836 = stablehlo.multiply %8835, %8835 : tensor<1x1200x320xf64>
    %8837 = stablehlo.reduce(%8836 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8838 = stablehlo.reshape %8837 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8839 = stablehlo.broadcast_in_dim %8838, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8840 = stablehlo.divide %8839, %2987 : tensor<1x1200x1xf64>
    %8841 = stablehlo.convert %8840 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8842 = stablehlo.reduce(%8827 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8843 = stablehlo.reshape %8842 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %8844 = stablehlo.broadcast_in_dim %8843, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8845 = stablehlo.divide %8844, %3003 : tensor<1x1200x1xf32>
    %8846 = stablehlo.broadcast_in_dim %8841, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %8847 = stablehlo.add %8846, %3006 : tensor<1x1200x1xf32>
    %8848 = stablehlo.rsqrt %8847 : tensor<1x1200x1xf32>
    %8849 = stablehlo.broadcast_in_dim %8827, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8850 = stablehlo.broadcast_in_dim %8845, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8851 = stablehlo.subtract %8849, %8850 : tensor<1x1200x320xf32>
    %8852 = stablehlo.broadcast_in_dim %8851, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8853 = stablehlo.broadcast_in_dim %8848, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %8854 = stablehlo.multiply %8852, %8853 : tensor<1x1200x320xf32>
    %8855 = stablehlo.convert %arg391 : (tensor<320xbf16>) -> tensor<320xf32>
    %8856 = stablehlo.broadcast_in_dim %8854, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8857 = stablehlo.broadcast_in_dim %8855, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8858 = stablehlo.multiply %8856, %8857 : tensor<1x1200x320xf32>
    %8859 = stablehlo.convert %arg392 : (tensor<320xbf16>) -> tensor<320xf32>
    %8860 = stablehlo.broadcast_in_dim %8858, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %8861 = stablehlo.broadcast_in_dim %8859, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %8862 = stablehlo.add %8860, %8861 : tensor<1x1200x320xf32>
    %8863 = stablehlo.convert %8862 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %8864 = stablehlo.reshape %8863 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8865 = stablehlo.convert %8864 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8866 = stablehlo.dot_general %8865, %arg866, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8867 = stablehlo.broadcast_in_dim %8866, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8868 = stablehlo.multiply %8867, %3065 : tensor<1200x320xf32>
    %8869 = stablehlo.broadcast_in_dim %8868, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8870 = stablehlo.broadcast_in_dim %arg867, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8871 = stablehlo.add %8869, %8870 : tensor<1200x320xf32>
    %8872 = stablehlo.convert %8871 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8873 = stablehlo.reshape %8872 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8874 = stablehlo.reshape %8873 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %8875 = stablehlo.transpose %8874, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8876 = stablehlo.transpose %8863, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %8877 = stablehlo.reshape %8876 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %8878 = stablehlo.convolution(%8877, %arg393) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %8879 = stablehlo.reshape %arg394 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %8880 = stablehlo.broadcast_in_dim %8878, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %8881 = stablehlo.broadcast_in_dim %8879, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %8882 = stablehlo.add %8880, %8881 : tensor<1x320x15x20xbf16>
    %8883 = stablehlo.reshape %8882 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %8884 = stablehlo.transpose %8883, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %8885 = stablehlo.convert %8884 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %8886 = stablehlo.convert %8885 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %8887 = stablehlo.reduce(%8886 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8888 = stablehlo.reshape %8887 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8889 = stablehlo.broadcast_in_dim %8888, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8890 = stablehlo.divide %8889, %3088 : tensor<1x300x1xf64>
    %8891 = stablehlo.broadcast_in_dim %8886, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %8892 = stablehlo.broadcast_in_dim %8890, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %8893 = stablehlo.subtract %8891, %8892 : tensor<1x300x320xf64>
    %8894 = stablehlo.multiply %8893, %8893 : tensor<1x300x320xf64>
    %8895 = stablehlo.reduce(%8894 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %8896 = stablehlo.reshape %8895 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %8897 = stablehlo.broadcast_in_dim %8896, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %8898 = stablehlo.divide %8897, %3088 : tensor<1x300x1xf64>
    %8899 = stablehlo.convert %8898 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %8900 = stablehlo.reduce(%8885 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %8901 = stablehlo.reshape %8900 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %8902 = stablehlo.broadcast_in_dim %8901, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8903 = stablehlo.divide %8902, %3102 : tensor<1x300x1xf32>
    %8904 = stablehlo.broadcast_in_dim %8899, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %8905 = stablehlo.add %8904, %136 : tensor<1x300x1xf32>
    %8906 = stablehlo.rsqrt %8905 : tensor<1x300x1xf32>
    %8907 = stablehlo.broadcast_in_dim %8885, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8908 = stablehlo.broadcast_in_dim %8903, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8909 = stablehlo.subtract %8907, %8908 : tensor<1x300x320xf32>
    %8910 = stablehlo.broadcast_in_dim %8909, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8911 = stablehlo.broadcast_in_dim %8906, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %8912 = stablehlo.multiply %8910, %8911 : tensor<1x300x320xf32>
    %8913 = stablehlo.convert %arg395 : (tensor<320xbf16>) -> tensor<320xf32>
    %8914 = stablehlo.broadcast_in_dim %8912, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8915 = stablehlo.broadcast_in_dim %8913, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8916 = stablehlo.multiply %8914, %8915 : tensor<1x300x320xf32>
    %8917 = stablehlo.convert %arg396 : (tensor<320xbf16>) -> tensor<320xf32>
    %8918 = stablehlo.broadcast_in_dim %8916, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %8919 = stablehlo.broadcast_in_dim %8917, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %8920 = stablehlo.add %8918, %8919 : tensor<1x300x320xf32>
    %8921 = stablehlo.convert %8920 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %8922 = stablehlo.reshape %8921 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %8923 = stablehlo.convert %8922 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %8924 = stablehlo.dot_general %8923, %arg868, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8925 = stablehlo.broadcast_in_dim %8924, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8926 = stablehlo.multiply %8925, %3126 : tensor<300x320xf32>
    %8927 = stablehlo.broadcast_in_dim %8926, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8928 = stablehlo.broadcast_in_dim %arg869, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8929 = stablehlo.add %8927, %8928 : tensor<300x320xf32>
    %8930 = stablehlo.convert %8929 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8931 = stablehlo.reshape %8930 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8932 = stablehlo.reshape %8931 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8933 = stablehlo.transpose %8932, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8934 = stablehlo.dot_general %8923, %arg870, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %8935 = stablehlo.broadcast_in_dim %8934, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8936 = stablehlo.multiply %8935, %3126 : tensor<300x320xf32>
    %8937 = stablehlo.broadcast_in_dim %8936, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %8938 = stablehlo.broadcast_in_dim %arg871, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %8939 = stablehlo.add %8937, %8938 : tensor<300x320xf32>
    %8940 = stablehlo.convert %8939 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %8941 = stablehlo.reshape %8940 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %8942 = stablehlo.reshape %8941 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %8943 = stablehlo.transpose %8942, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %8944 = stablehlo.transpose %8933, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %8945 = stablehlo.reshape %8875 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %8946 = stablehlo.reshape %8944 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8947 = stablehlo.broadcast_in_dim %8946, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %8948 = stablehlo.dot_general %8945, %8947, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %8949 = stablehlo.reshape %8948 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8950 = stablehlo.broadcast_in_dim %8949, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %8951 = stablehlo.divide %8950, %3152 : tensor<1x5x1200x300xbf16>
    %8952 = stablehlo.convert %8951 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %8953 = stablehlo.reduce(%8952 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8954 = stablehlo.reshape %8953 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8955 = stablehlo.broadcast_in_dim %8952, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8956 = stablehlo.broadcast_in_dim %8954, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8957 = stablehlo.subtract %8955, %8956 : tensor<1x5x1200x300xf32>
    %8958 = stablehlo.exponential %8957 : tensor<1x5x1200x300xf32>
    %8959 = stablehlo.reduce(%8958 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %8960 = stablehlo.reshape %8959 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %8961 = stablehlo.broadcast_in_dim %8958, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %8962 = stablehlo.broadcast_in_dim %8960, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %8963 = stablehlo.divide %8961, %8962 : tensor<1x5x1200x300xf32>
    %8964 = stablehlo.convert %8963 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %8965 = stablehlo.reshape %8964 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %8966 = stablehlo.reshape %8943 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8967 = stablehlo.broadcast_in_dim %8966, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %8968 = stablehlo.dot_general %8965, %8967, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %8969 = stablehlo.reshape %8968 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %8970 = stablehlo.transpose %8969, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %8971 = stablehlo.reshape %8970 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %8972 = stablehlo.reshape %8971 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %8973 = stablehlo.convert %8972 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %8974 = stablehlo.dot_general %8973, %arg872, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %8975 = stablehlo.broadcast_in_dim %8974, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8976 = stablehlo.multiply %8975, %3065 : tensor<1200x320xf32>
    %8977 = stablehlo.broadcast_in_dim %8976, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %8978 = stablehlo.broadcast_in_dim %arg873, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %8979 = stablehlo.add %8977, %8978 : tensor<1200x320xf32>
    %8980 = stablehlo.convert %8979 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %8981 = stablehlo.reshape %8980 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %8982 = stablehlo.add %8981, %8826 : tensor<1x1200x320xbf16>
    %8983 = stablehlo.convert %8982 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %8984 = stablehlo.convert %8983 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %8985 = stablehlo.reduce(%8984 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8986 = stablehlo.reshape %8985 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8987 = stablehlo.broadcast_in_dim %8986, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8988 = stablehlo.divide %8987, %2987 : tensor<1x1200x1xf64>
    %8989 = stablehlo.broadcast_in_dim %8984, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %8990 = stablehlo.broadcast_in_dim %8988, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %8991 = stablehlo.subtract %8989, %8990 : tensor<1x1200x320xf64>
    %8992 = stablehlo.multiply %8991, %8991 : tensor<1x1200x320xf64>
    %8993 = stablehlo.reduce(%8992 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %8994 = stablehlo.reshape %8993 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %8995 = stablehlo.broadcast_in_dim %8994, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %8996 = stablehlo.divide %8995, %2987 : tensor<1x1200x1xf64>
    %8997 = stablehlo.convert %8996 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %8998 = stablehlo.reduce(%8983 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %8999 = stablehlo.reshape %8998 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9000 = stablehlo.broadcast_in_dim %8999, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9001 = stablehlo.divide %9000, %3003 : tensor<1x1200x1xf32>
    %9002 = stablehlo.broadcast_in_dim %8997, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9003 = stablehlo.add %9002, %3006 : tensor<1x1200x1xf32>
    %9004 = stablehlo.rsqrt %9003 : tensor<1x1200x1xf32>
    %9005 = stablehlo.broadcast_in_dim %8983, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9006 = stablehlo.broadcast_in_dim %9001, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9007 = stablehlo.subtract %9005, %9006 : tensor<1x1200x320xf32>
    %9008 = stablehlo.broadcast_in_dim %9007, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9009 = stablehlo.broadcast_in_dim %9004, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9010 = stablehlo.multiply %9008, %9009 : tensor<1x1200x320xf32>
    %9011 = stablehlo.convert %arg397 : (tensor<320xbf16>) -> tensor<320xf32>
    %9012 = stablehlo.broadcast_in_dim %9010, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9013 = stablehlo.broadcast_in_dim %9011, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9014 = stablehlo.multiply %9012, %9013 : tensor<1x1200x320xf32>
    %9015 = stablehlo.convert %arg398 : (tensor<320xbf16>) -> tensor<320xf32>
    %9016 = stablehlo.broadcast_in_dim %9014, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9017 = stablehlo.broadcast_in_dim %9015, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9018 = stablehlo.add %9016, %9017 : tensor<1x1200x320xf32>
    %9019 = stablehlo.convert %9018 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9020 = stablehlo.reshape %9019 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9021 = stablehlo.convert %9020 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9022 = stablehlo.dot_general %9021, %arg874, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %9023 = stablehlo.broadcast_in_dim %9022, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9024 = stablehlo.multiply %9023, %3226 : tensor<1200x1280xf32>
    %9025 = stablehlo.broadcast_in_dim %9024, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9026 = stablehlo.broadcast_in_dim %arg875, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %9027 = stablehlo.add %9025, %9026 : tensor<1200x1280xf32>
    %9028 = stablehlo.convert %9027 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %9029 = stablehlo.reshape %9028 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %9030 = stablehlo.transpose %9029, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %9031 = stablehlo.reshape %9030 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %9032 = stablehlo.convolution(%9031, %arg399) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %9033 = stablehlo.reshape %arg400 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %9034 = stablehlo.broadcast_in_dim %9032, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %9035 = stablehlo.broadcast_in_dim %9033, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %9036 = stablehlo.add %9034, %9035 : tensor<1x1280x30x40xbf16>
    %9037 = stablehlo.reshape %9036 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %9038 = stablehlo.transpose %9037, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %9039 = stablehlo.multiply %9038, %cst_42 : tensor<1x1200x1280xbf16>
    %9040 = stablehlo.multiply %9038, %3243 : tensor<1x1200x1280xbf16>
    %9041 = stablehlo.convert %9040 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %9042 = stablehlo.clamp %cst_43, %9041, %cst_44 : tensor<1x1200x1280xf32>
    %9043 = stablehlo.multiply %9042, %9042 : tensor<1x1200x1280xf32>
    %9044 = stablehlo.multiply %cst_45, %9043 : tensor<1x1200x1280xf32>
    %9045 = stablehlo.add %9044, %cst_46 : tensor<1x1200x1280xf32>
    %9046 = stablehlo.multiply %9045, %9043 : tensor<1x1200x1280xf32>
    %9047 = stablehlo.add %9046, %cst_47 : tensor<1x1200x1280xf32>
    %9048 = stablehlo.multiply %9047, %9043 : tensor<1x1200x1280xf32>
    %9049 = stablehlo.add %9048, %cst_48 : tensor<1x1200x1280xf32>
    %9050 = stablehlo.multiply %9049, %9043 : tensor<1x1200x1280xf32>
    %9051 = stablehlo.add %9050, %cst_49 : tensor<1x1200x1280xf32>
    %9052 = stablehlo.multiply %9051, %9043 : tensor<1x1200x1280xf32>
    %9053 = stablehlo.add %9052, %cst_50 : tensor<1x1200x1280xf32>
    %9054 = stablehlo.multiply %9053, %9043 : tensor<1x1200x1280xf32>
    %9055 = stablehlo.add %9054, %cst_51 : tensor<1x1200x1280xf32>
    %9056 = stablehlo.multiply %cst_52, %9043 : tensor<1x1200x1280xf32>
    %9057 = stablehlo.add %9056, %cst_53 : tensor<1x1200x1280xf32>
    %9058 = stablehlo.multiply %9057, %9043 : tensor<1x1200x1280xf32>
    %9059 = stablehlo.add %9058, %cst_54 : tensor<1x1200x1280xf32>
    %9060 = stablehlo.multiply %9059, %9043 : tensor<1x1200x1280xf32>
    %9061 = stablehlo.add %9060, %cst_55 : tensor<1x1200x1280xf32>
    %9062 = stablehlo.multiply %9061, %9043 : tensor<1x1200x1280xf32>
    %9063 = stablehlo.add %9062, %cst_56 : tensor<1x1200x1280xf32>
    %9064 = stablehlo.multiply %9042, %9055 : tensor<1x1200x1280xf32>
    %9065 = stablehlo.divide %9064, %9063 : tensor<1x1200x1280xf32>
    %9066 = stablehlo.clamp %cst_57, %9065, %cst_58 : tensor<1x1200x1280xf32>
    %9067 = stablehlo.convert %9066 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %9068 = stablehlo.add %9067, %cst_40 : tensor<1x1200x1280xbf16>
    %9069 = stablehlo.multiply %9068, %9039 : tensor<1x1200x1280xbf16>
    %9070 = stablehlo.reshape %9069 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %9071 = stablehlo.dot_general %9070, %arg876, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %9072 = stablehlo.reshape %9071 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9073 = stablehlo.broadcast_in_dim %9072, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9074 = stablehlo.broadcast_in_dim %arg401, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %9075 = stablehlo.add %9073, %9074 : tensor<1x1200x320xbf16>
    %9076 = stablehlo.reshape %9075 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9077 = stablehlo.reshape %9076 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9078 = stablehlo.add %9077, %8982 : tensor<1x1200x320xbf16>
    %9079 = stablehlo.convert %9078 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9080 = stablehlo.convert %9079 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9081 = stablehlo.reduce(%9080 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9082 = stablehlo.reshape %9081 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9083 = stablehlo.broadcast_in_dim %9082, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9084 = stablehlo.divide %9083, %2987 : tensor<1x1200x1xf64>
    %9085 = stablehlo.broadcast_in_dim %9080, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9086 = stablehlo.broadcast_in_dim %9084, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9087 = stablehlo.subtract %9085, %9086 : tensor<1x1200x320xf64>
    %9088 = stablehlo.multiply %9087, %9087 : tensor<1x1200x320xf64>
    %9089 = stablehlo.reduce(%9088 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9090 = stablehlo.reshape %9089 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9091 = stablehlo.broadcast_in_dim %9090, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9092 = stablehlo.divide %9091, %2987 : tensor<1x1200x1xf64>
    %9093 = stablehlo.convert %9092 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9094 = stablehlo.reduce(%9079 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9095 = stablehlo.reshape %9094 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9096 = stablehlo.broadcast_in_dim %9095, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9097 = stablehlo.divide %9096, %3003 : tensor<1x1200x1xf32>
    %9098 = stablehlo.broadcast_in_dim %9093, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9099 = stablehlo.add %9098, %3006 : tensor<1x1200x1xf32>
    %9100 = stablehlo.rsqrt %9099 : tensor<1x1200x1xf32>
    %9101 = stablehlo.broadcast_in_dim %9079, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9102 = stablehlo.broadcast_in_dim %9097, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9103 = stablehlo.subtract %9101, %9102 : tensor<1x1200x320xf32>
    %9104 = stablehlo.broadcast_in_dim %9103, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9105 = stablehlo.broadcast_in_dim %9100, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9106 = stablehlo.multiply %9104, %9105 : tensor<1x1200x320xf32>
    %9107 = stablehlo.convert %arg402 : (tensor<320xbf16>) -> tensor<320xf32>
    %9108 = stablehlo.broadcast_in_dim %9106, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9109 = stablehlo.broadcast_in_dim %9107, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9110 = stablehlo.multiply %9108, %9109 : tensor<1x1200x320xf32>
    %9111 = stablehlo.convert %arg403 : (tensor<320xbf16>) -> tensor<320xf32>
    %9112 = stablehlo.broadcast_in_dim %9110, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9113 = stablehlo.broadcast_in_dim %9111, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9114 = stablehlo.add %9112, %9113 : tensor<1x1200x320xf32>
    %9115 = stablehlo.convert %9114 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9116 = stablehlo.reshape %9115 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9117 = stablehlo.convert %9116 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9118 = stablehlo.dot_general %9117, %arg877, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %9119 = stablehlo.broadcast_in_dim %9118, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9120 = stablehlo.multiply %9119, %3065 : tensor<1200x320xf32>
    %9121 = stablehlo.broadcast_in_dim %9120, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9122 = stablehlo.broadcast_in_dim %arg878, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %9123 = stablehlo.add %9121, %9122 : tensor<1200x320xf32>
    %9124 = stablehlo.convert %9123 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %9125 = stablehlo.reshape %9124 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9126 = stablehlo.reshape %9125 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %9127 = stablehlo.transpose %9126, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %9128 = stablehlo.transpose %9115, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %9129 = stablehlo.reshape %9128 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %9130 = stablehlo.convolution(%9129, %arg404) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %9131 = stablehlo.reshape %arg405 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %9132 = stablehlo.broadcast_in_dim %9130, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %9133 = stablehlo.broadcast_in_dim %9131, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %9134 = stablehlo.add %9132, %9133 : tensor<1x320x15x20xbf16>
    %9135 = stablehlo.reshape %9134 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %9136 = stablehlo.transpose %9135, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %9137 = stablehlo.convert %9136 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %9138 = stablehlo.convert %9137 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %9139 = stablehlo.reduce(%9138 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9140 = stablehlo.reshape %9139 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9141 = stablehlo.broadcast_in_dim %9140, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9142 = stablehlo.divide %9141, %3088 : tensor<1x300x1xf64>
    %9143 = stablehlo.broadcast_in_dim %9138, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %9144 = stablehlo.broadcast_in_dim %9142, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %9145 = stablehlo.subtract %9143, %9144 : tensor<1x300x320xf64>
    %9146 = stablehlo.multiply %9145, %9145 : tensor<1x300x320xf64>
    %9147 = stablehlo.reduce(%9146 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9148 = stablehlo.reshape %9147 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9149 = stablehlo.broadcast_in_dim %9148, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9150 = stablehlo.divide %9149, %3088 : tensor<1x300x1xf64>
    %9151 = stablehlo.convert %9150 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %9152 = stablehlo.reduce(%9137 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %9153 = stablehlo.reshape %9152 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %9154 = stablehlo.broadcast_in_dim %9153, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9155 = stablehlo.divide %9154, %3102 : tensor<1x300x1xf32>
    %9156 = stablehlo.broadcast_in_dim %9151, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9157 = stablehlo.add %9156, %136 : tensor<1x300x1xf32>
    %9158 = stablehlo.rsqrt %9157 : tensor<1x300x1xf32>
    %9159 = stablehlo.broadcast_in_dim %9137, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9160 = stablehlo.broadcast_in_dim %9155, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %9161 = stablehlo.subtract %9159, %9160 : tensor<1x300x320xf32>
    %9162 = stablehlo.broadcast_in_dim %9161, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9163 = stablehlo.broadcast_in_dim %9158, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %9164 = stablehlo.multiply %9162, %9163 : tensor<1x300x320xf32>
    %9165 = stablehlo.convert %arg406 : (tensor<320xbf16>) -> tensor<320xf32>
    %9166 = stablehlo.broadcast_in_dim %9164, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9167 = stablehlo.broadcast_in_dim %9165, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %9168 = stablehlo.multiply %9166, %9167 : tensor<1x300x320xf32>
    %9169 = stablehlo.convert %arg407 : (tensor<320xbf16>) -> tensor<320xf32>
    %9170 = stablehlo.broadcast_in_dim %9168, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9171 = stablehlo.broadcast_in_dim %9169, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %9172 = stablehlo.add %9170, %9171 : tensor<1x300x320xf32>
    %9173 = stablehlo.convert %9172 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %9174 = stablehlo.reshape %9173 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %9175 = stablehlo.convert %9174 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %9176 = stablehlo.dot_general %9175, %arg879, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %9177 = stablehlo.broadcast_in_dim %9176, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9178 = stablehlo.multiply %9177, %3126 : tensor<300x320xf32>
    %9179 = stablehlo.broadcast_in_dim %9178, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9180 = stablehlo.broadcast_in_dim %arg880, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %9181 = stablehlo.add %9179, %9180 : tensor<300x320xf32>
    %9182 = stablehlo.convert %9181 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %9183 = stablehlo.reshape %9182 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %9184 = stablehlo.reshape %9183 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %9185 = stablehlo.transpose %9184, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %9186 = stablehlo.dot_general %9175, %arg881, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %9187 = stablehlo.broadcast_in_dim %9186, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9188 = stablehlo.multiply %9187, %3126 : tensor<300x320xf32>
    %9189 = stablehlo.broadcast_in_dim %9188, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9190 = stablehlo.broadcast_in_dim %arg882, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %9191 = stablehlo.add %9189, %9190 : tensor<300x320xf32>
    %9192 = stablehlo.convert %9191 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %9193 = stablehlo.reshape %9192 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %9194 = stablehlo.reshape %9193 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %9195 = stablehlo.transpose %9194, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %9196 = stablehlo.transpose %9185, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %9197 = stablehlo.reshape %9127 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %9198 = stablehlo.reshape %9196 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %9199 = stablehlo.broadcast_in_dim %9198, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %9200 = stablehlo.dot_general %9197, %9199, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %9201 = stablehlo.reshape %9200 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %9202 = stablehlo.broadcast_in_dim %9201, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %9203 = stablehlo.divide %9202, %3152 : tensor<1x5x1200x300xbf16>
    %9204 = stablehlo.convert %9203 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %9205 = stablehlo.reduce(%9204 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %9206 = stablehlo.reshape %9205 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %9207 = stablehlo.broadcast_in_dim %9204, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %9208 = stablehlo.broadcast_in_dim %9206, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %9209 = stablehlo.subtract %9207, %9208 : tensor<1x5x1200x300xf32>
    %9210 = stablehlo.exponential %9209 : tensor<1x5x1200x300xf32>
    %9211 = stablehlo.reduce(%9210 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %9212 = stablehlo.reshape %9211 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %9213 = stablehlo.broadcast_in_dim %9210, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %9214 = stablehlo.broadcast_in_dim %9212, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %9215 = stablehlo.divide %9213, %9214 : tensor<1x5x1200x300xf32>
    %9216 = stablehlo.convert %9215 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %9217 = stablehlo.reshape %9216 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %9218 = stablehlo.reshape %9195 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %9219 = stablehlo.broadcast_in_dim %9218, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %9220 = stablehlo.dot_general %9217, %9219, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %9221 = stablehlo.reshape %9220 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %9222 = stablehlo.transpose %9221, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %9223 = stablehlo.reshape %9222 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %9224 = stablehlo.reshape %9223 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9225 = stablehlo.convert %9224 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9226 = stablehlo.dot_general %9225, %arg883, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %9227 = stablehlo.broadcast_in_dim %9226, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9228 = stablehlo.multiply %9227, %3065 : tensor<1200x320xf32>
    %9229 = stablehlo.broadcast_in_dim %9228, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9230 = stablehlo.broadcast_in_dim %arg884, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %9231 = stablehlo.add %9229, %9230 : tensor<1200x320xf32>
    %9232 = stablehlo.convert %9231 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %9233 = stablehlo.reshape %9232 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9234 = stablehlo.add %9233, %9078 : tensor<1x1200x320xbf16>
    %9235 = stablehlo.convert %9234 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9236 = stablehlo.convert %9235 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9237 = stablehlo.reduce(%9236 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9238 = stablehlo.reshape %9237 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9239 = stablehlo.broadcast_in_dim %9238, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9240 = stablehlo.divide %9239, %2987 : tensor<1x1200x1xf64>
    %9241 = stablehlo.broadcast_in_dim %9236, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9242 = stablehlo.broadcast_in_dim %9240, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9243 = stablehlo.subtract %9241, %9242 : tensor<1x1200x320xf64>
    %9244 = stablehlo.multiply %9243, %9243 : tensor<1x1200x320xf64>
    %9245 = stablehlo.reduce(%9244 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9246 = stablehlo.reshape %9245 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9247 = stablehlo.broadcast_in_dim %9246, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9248 = stablehlo.divide %9247, %2987 : tensor<1x1200x1xf64>
    %9249 = stablehlo.convert %9248 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9250 = stablehlo.reduce(%9235 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9251 = stablehlo.reshape %9250 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9252 = stablehlo.broadcast_in_dim %9251, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9253 = stablehlo.divide %9252, %3003 : tensor<1x1200x1xf32>
    %9254 = stablehlo.broadcast_in_dim %9249, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9255 = stablehlo.add %9254, %3006 : tensor<1x1200x1xf32>
    %9256 = stablehlo.rsqrt %9255 : tensor<1x1200x1xf32>
    %9257 = stablehlo.broadcast_in_dim %9235, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9258 = stablehlo.broadcast_in_dim %9253, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9259 = stablehlo.subtract %9257, %9258 : tensor<1x1200x320xf32>
    %9260 = stablehlo.broadcast_in_dim %9259, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9261 = stablehlo.broadcast_in_dim %9256, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9262 = stablehlo.multiply %9260, %9261 : tensor<1x1200x320xf32>
    %9263 = stablehlo.convert %arg408 : (tensor<320xbf16>) -> tensor<320xf32>
    %9264 = stablehlo.broadcast_in_dim %9262, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9265 = stablehlo.broadcast_in_dim %9263, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9266 = stablehlo.multiply %9264, %9265 : tensor<1x1200x320xf32>
    %9267 = stablehlo.convert %arg409 : (tensor<320xbf16>) -> tensor<320xf32>
    %9268 = stablehlo.broadcast_in_dim %9266, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9269 = stablehlo.broadcast_in_dim %9267, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9270 = stablehlo.add %9268, %9269 : tensor<1x1200x320xf32>
    %9271 = stablehlo.convert %9270 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9272 = stablehlo.reshape %9271 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9273 = stablehlo.convert %9272 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9274 = stablehlo.dot_general %9273, %arg885, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %9275 = stablehlo.broadcast_in_dim %9274, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9276 = stablehlo.multiply %9275, %3226 : tensor<1200x1280xf32>
    %9277 = stablehlo.broadcast_in_dim %9276, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9278 = stablehlo.broadcast_in_dim %arg886, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %9279 = stablehlo.add %9277, %9278 : tensor<1200x1280xf32>
    %9280 = stablehlo.convert %9279 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %9281 = stablehlo.reshape %9280 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %9282 = stablehlo.transpose %9281, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %9283 = stablehlo.reshape %9282 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %9284 = stablehlo.convolution(%9283, %arg410) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %9285 = stablehlo.reshape %arg411 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %9286 = stablehlo.broadcast_in_dim %9284, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %9287 = stablehlo.broadcast_in_dim %9285, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %9288 = stablehlo.add %9286, %9287 : tensor<1x1280x30x40xbf16>
    %9289 = stablehlo.reshape %9288 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %9290 = stablehlo.transpose %9289, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %9291 = stablehlo.multiply %9290, %cst_42 : tensor<1x1200x1280xbf16>
    %9292 = stablehlo.multiply %9290, %3243 : tensor<1x1200x1280xbf16>
    %9293 = stablehlo.convert %9292 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %9294 = stablehlo.clamp %cst_43, %9293, %cst_44 : tensor<1x1200x1280xf32>
    %9295 = stablehlo.multiply %9294, %9294 : tensor<1x1200x1280xf32>
    %9296 = stablehlo.multiply %cst_45, %9295 : tensor<1x1200x1280xf32>
    %9297 = stablehlo.add %9296, %cst_46 : tensor<1x1200x1280xf32>
    %9298 = stablehlo.multiply %9297, %9295 : tensor<1x1200x1280xf32>
    %9299 = stablehlo.add %9298, %cst_47 : tensor<1x1200x1280xf32>
    %9300 = stablehlo.multiply %9299, %9295 : tensor<1x1200x1280xf32>
    %9301 = stablehlo.add %9300, %cst_48 : tensor<1x1200x1280xf32>
    %9302 = stablehlo.multiply %9301, %9295 : tensor<1x1200x1280xf32>
    %9303 = stablehlo.add %9302, %cst_49 : tensor<1x1200x1280xf32>
    %9304 = stablehlo.multiply %9303, %9295 : tensor<1x1200x1280xf32>
    %9305 = stablehlo.add %9304, %cst_50 : tensor<1x1200x1280xf32>
    %9306 = stablehlo.multiply %9305, %9295 : tensor<1x1200x1280xf32>
    %9307 = stablehlo.add %9306, %cst_51 : tensor<1x1200x1280xf32>
    %9308 = stablehlo.multiply %cst_52, %9295 : tensor<1x1200x1280xf32>
    %9309 = stablehlo.add %9308, %cst_53 : tensor<1x1200x1280xf32>
    %9310 = stablehlo.multiply %9309, %9295 : tensor<1x1200x1280xf32>
    %9311 = stablehlo.add %9310, %cst_54 : tensor<1x1200x1280xf32>
    %9312 = stablehlo.multiply %9311, %9295 : tensor<1x1200x1280xf32>
    %9313 = stablehlo.add %9312, %cst_55 : tensor<1x1200x1280xf32>
    %9314 = stablehlo.multiply %9313, %9295 : tensor<1x1200x1280xf32>
    %9315 = stablehlo.add %9314, %cst_56 : tensor<1x1200x1280xf32>
    %9316 = stablehlo.multiply %9294, %9307 : tensor<1x1200x1280xf32>
    %9317 = stablehlo.divide %9316, %9315 : tensor<1x1200x1280xf32>
    %9318 = stablehlo.clamp %cst_57, %9317, %cst_58 : tensor<1x1200x1280xf32>
    %9319 = stablehlo.convert %9318 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %9320 = stablehlo.add %9319, %cst_40 : tensor<1x1200x1280xbf16>
    %9321 = stablehlo.multiply %9320, %9291 : tensor<1x1200x1280xbf16>
    %9322 = stablehlo.reshape %9321 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %9323 = stablehlo.dot_general %9322, %arg887, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %9324 = stablehlo.reshape %9323 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9325 = stablehlo.broadcast_in_dim %9324, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9326 = stablehlo.broadcast_in_dim %arg412, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %9327 = stablehlo.add %9325, %9326 : tensor<1x1200x320xbf16>
    %9328 = stablehlo.reshape %9327 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9329 = stablehlo.reshape %9328 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9330 = stablehlo.add %9329, %9234 : tensor<1x1200x320xbf16>
    %9331 = stablehlo.convert %9330 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9332 = stablehlo.convert %9331 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9333 = stablehlo.reduce(%9332 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9334 = stablehlo.reshape %9333 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9335 = stablehlo.broadcast_in_dim %9334, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9336 = stablehlo.divide %9335, %2987 : tensor<1x1200x1xf64>
    %9337 = stablehlo.broadcast_in_dim %9332, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9338 = stablehlo.broadcast_in_dim %9336, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9339 = stablehlo.subtract %9337, %9338 : tensor<1x1200x320xf64>
    %9340 = stablehlo.multiply %9339, %9339 : tensor<1x1200x320xf64>
    %9341 = stablehlo.reduce(%9340 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9342 = stablehlo.reshape %9341 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9343 = stablehlo.broadcast_in_dim %9342, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9344 = stablehlo.divide %9343, %2987 : tensor<1x1200x1xf64>
    %9345 = stablehlo.convert %9344 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9346 = stablehlo.reduce(%9331 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9347 = stablehlo.reshape %9346 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9348 = stablehlo.broadcast_in_dim %9347, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9349 = stablehlo.divide %9348, %3003 : tensor<1x1200x1xf32>
    %9350 = stablehlo.broadcast_in_dim %9345, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9351 = stablehlo.add %9350, %3006 : tensor<1x1200x1xf32>
    %9352 = stablehlo.rsqrt %9351 : tensor<1x1200x1xf32>
    %9353 = stablehlo.broadcast_in_dim %9331, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9354 = stablehlo.broadcast_in_dim %9349, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9355 = stablehlo.subtract %9353, %9354 : tensor<1x1200x320xf32>
    %9356 = stablehlo.broadcast_in_dim %9355, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9357 = stablehlo.broadcast_in_dim %9352, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9358 = stablehlo.multiply %9356, %9357 : tensor<1x1200x320xf32>
    %9359 = stablehlo.convert %arg413 : (tensor<320xbf16>) -> tensor<320xf32>
    %9360 = stablehlo.broadcast_in_dim %9358, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9361 = stablehlo.broadcast_in_dim %9359, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9362 = stablehlo.multiply %9360, %9361 : tensor<1x1200x320xf32>
    %9363 = stablehlo.convert %arg414 : (tensor<320xbf16>) -> tensor<320xf32>
    %9364 = stablehlo.broadcast_in_dim %9362, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9365 = stablehlo.broadcast_in_dim %9363, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9366 = stablehlo.add %9364, %9365 : tensor<1x1200x320xf32>
    %9367 = stablehlo.convert %9366 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9368 = stablehlo.reshape %9367 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9369 = stablehlo.convert %9368 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9370 = stablehlo.dot_general %9369, %arg888, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %9371 = stablehlo.broadcast_in_dim %9370, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9372 = stablehlo.multiply %9371, %3065 : tensor<1200x320xf32>
    %9373 = stablehlo.broadcast_in_dim %9372, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9374 = stablehlo.broadcast_in_dim %arg889, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %9375 = stablehlo.add %9373, %9374 : tensor<1200x320xf32>
    %9376 = stablehlo.convert %9375 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %9377 = stablehlo.reshape %9376 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9378 = stablehlo.reshape %9377 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %9379 = stablehlo.transpose %9378, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %9380 = stablehlo.transpose %9367, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %9381 = stablehlo.reshape %9380 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %9382 = stablehlo.convolution(%9381, %arg415) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %9383 = stablehlo.reshape %arg416 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %9384 = stablehlo.broadcast_in_dim %9382, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %9385 = stablehlo.broadcast_in_dim %9383, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %9386 = stablehlo.add %9384, %9385 : tensor<1x320x15x20xbf16>
    %9387 = stablehlo.reshape %9386 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %9388 = stablehlo.transpose %9387, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %9389 = stablehlo.convert %9388 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %9390 = stablehlo.convert %9389 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %9391 = stablehlo.reduce(%9390 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9392 = stablehlo.reshape %9391 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9393 = stablehlo.broadcast_in_dim %9392, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9394 = stablehlo.divide %9393, %3088 : tensor<1x300x1xf64>
    %9395 = stablehlo.broadcast_in_dim %9390, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %9396 = stablehlo.broadcast_in_dim %9394, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %9397 = stablehlo.subtract %9395, %9396 : tensor<1x300x320xf64>
    %9398 = stablehlo.multiply %9397, %9397 : tensor<1x300x320xf64>
    %9399 = stablehlo.reduce(%9398 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9400 = stablehlo.reshape %9399 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9401 = stablehlo.broadcast_in_dim %9400, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9402 = stablehlo.divide %9401, %3088 : tensor<1x300x1xf64>
    %9403 = stablehlo.convert %9402 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %9404 = stablehlo.reduce(%9389 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %9405 = stablehlo.reshape %9404 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %9406 = stablehlo.broadcast_in_dim %9405, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9407 = stablehlo.divide %9406, %3102 : tensor<1x300x1xf32>
    %9408 = stablehlo.broadcast_in_dim %9403, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9409 = stablehlo.add %9408, %136 : tensor<1x300x1xf32>
    %9410 = stablehlo.rsqrt %9409 : tensor<1x300x1xf32>
    %9411 = stablehlo.broadcast_in_dim %9389, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9412 = stablehlo.broadcast_in_dim %9407, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %9413 = stablehlo.subtract %9411, %9412 : tensor<1x300x320xf32>
    %9414 = stablehlo.broadcast_in_dim %9413, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9415 = stablehlo.broadcast_in_dim %9410, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %9416 = stablehlo.multiply %9414, %9415 : tensor<1x300x320xf32>
    %9417 = stablehlo.convert %arg417 : (tensor<320xbf16>) -> tensor<320xf32>
    %9418 = stablehlo.broadcast_in_dim %9416, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9419 = stablehlo.broadcast_in_dim %9417, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %9420 = stablehlo.multiply %9418, %9419 : tensor<1x300x320xf32>
    %9421 = stablehlo.convert %arg418 : (tensor<320xbf16>) -> tensor<320xf32>
    %9422 = stablehlo.broadcast_in_dim %9420, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9423 = stablehlo.broadcast_in_dim %9421, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %9424 = stablehlo.add %9422, %9423 : tensor<1x300x320xf32>
    %9425 = stablehlo.convert %9424 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %9426 = stablehlo.reshape %9425 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %9427 = stablehlo.convert %9426 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %9428 = stablehlo.dot_general %9427, %arg890, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %9429 = stablehlo.broadcast_in_dim %9428, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9430 = stablehlo.multiply %9429, %3126 : tensor<300x320xf32>
    %9431 = stablehlo.broadcast_in_dim %9430, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9432 = stablehlo.broadcast_in_dim %arg891, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %9433 = stablehlo.add %9431, %9432 : tensor<300x320xf32>
    %9434 = stablehlo.convert %9433 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %9435 = stablehlo.reshape %9434 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %9436 = stablehlo.reshape %9435 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %9437 = stablehlo.transpose %9436, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %9438 = stablehlo.dot_general %9427, %arg892, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %9439 = stablehlo.broadcast_in_dim %9438, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9440 = stablehlo.multiply %9439, %3126 : tensor<300x320xf32>
    %9441 = stablehlo.broadcast_in_dim %9440, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9442 = stablehlo.broadcast_in_dim %arg893, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %9443 = stablehlo.add %9441, %9442 : tensor<300x320xf32>
    %9444 = stablehlo.convert %9443 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %9445 = stablehlo.reshape %9444 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %9446 = stablehlo.reshape %9445 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %9447 = stablehlo.transpose %9446, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %9448 = stablehlo.transpose %9437, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %9449 = stablehlo.reshape %9379 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %9450 = stablehlo.reshape %9448 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %9451 = stablehlo.broadcast_in_dim %9450, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %9452 = stablehlo.dot_general %9449, %9451, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %9453 = stablehlo.reshape %9452 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %9454 = stablehlo.broadcast_in_dim %9453, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %9455 = stablehlo.divide %9454, %3152 : tensor<1x5x1200x300xbf16>
    %9456 = stablehlo.convert %9455 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %9457 = stablehlo.reduce(%9456 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %9458 = stablehlo.reshape %9457 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %9459 = stablehlo.broadcast_in_dim %9456, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %9460 = stablehlo.broadcast_in_dim %9458, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %9461 = stablehlo.subtract %9459, %9460 : tensor<1x5x1200x300xf32>
    %9462 = stablehlo.exponential %9461 : tensor<1x5x1200x300xf32>
    %9463 = stablehlo.reduce(%9462 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %9464 = stablehlo.reshape %9463 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %9465 = stablehlo.broadcast_in_dim %9462, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %9466 = stablehlo.broadcast_in_dim %9464, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %9467 = stablehlo.divide %9465, %9466 : tensor<1x5x1200x300xf32>
    %9468 = stablehlo.convert %9467 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %9469 = stablehlo.reshape %9468 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %9470 = stablehlo.reshape %9447 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %9471 = stablehlo.broadcast_in_dim %9470, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %9472 = stablehlo.dot_general %9469, %9471, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %9473 = stablehlo.reshape %9472 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %9474 = stablehlo.transpose %9473, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %9475 = stablehlo.reshape %9474 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %9476 = stablehlo.reshape %9475 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9477 = stablehlo.convert %9476 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9478 = stablehlo.dot_general %9477, %arg894, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %9479 = stablehlo.broadcast_in_dim %9478, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9480 = stablehlo.multiply %9479, %3065 : tensor<1200x320xf32>
    %9481 = stablehlo.broadcast_in_dim %9480, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9482 = stablehlo.broadcast_in_dim %arg895, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %9483 = stablehlo.add %9481, %9482 : tensor<1200x320xf32>
    %9484 = stablehlo.convert %9483 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %9485 = stablehlo.reshape %9484 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9486 = stablehlo.add %9485, %9330 : tensor<1x1200x320xbf16>
    %9487 = stablehlo.convert %9486 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9488 = stablehlo.convert %9487 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9489 = stablehlo.reduce(%9488 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9490 = stablehlo.reshape %9489 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9491 = stablehlo.broadcast_in_dim %9490, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9492 = stablehlo.divide %9491, %2987 : tensor<1x1200x1xf64>
    %9493 = stablehlo.broadcast_in_dim %9488, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9494 = stablehlo.broadcast_in_dim %9492, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9495 = stablehlo.subtract %9493, %9494 : tensor<1x1200x320xf64>
    %9496 = stablehlo.multiply %9495, %9495 : tensor<1x1200x320xf64>
    %9497 = stablehlo.reduce(%9496 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9498 = stablehlo.reshape %9497 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9499 = stablehlo.broadcast_in_dim %9498, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9500 = stablehlo.divide %9499, %2987 : tensor<1x1200x1xf64>
    %9501 = stablehlo.convert %9500 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9502 = stablehlo.reduce(%9487 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9503 = stablehlo.reshape %9502 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9504 = stablehlo.broadcast_in_dim %9503, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9505 = stablehlo.divide %9504, %3003 : tensor<1x1200x1xf32>
    %9506 = stablehlo.broadcast_in_dim %9501, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9507 = stablehlo.add %9506, %3006 : tensor<1x1200x1xf32>
    %9508 = stablehlo.rsqrt %9507 : tensor<1x1200x1xf32>
    %9509 = stablehlo.broadcast_in_dim %9487, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9510 = stablehlo.broadcast_in_dim %9505, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9511 = stablehlo.subtract %9509, %9510 : tensor<1x1200x320xf32>
    %9512 = stablehlo.broadcast_in_dim %9511, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9513 = stablehlo.broadcast_in_dim %9508, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9514 = stablehlo.multiply %9512, %9513 : tensor<1x1200x320xf32>
    %9515 = stablehlo.convert %arg419 : (tensor<320xbf16>) -> tensor<320xf32>
    %9516 = stablehlo.broadcast_in_dim %9514, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9517 = stablehlo.broadcast_in_dim %9515, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9518 = stablehlo.multiply %9516, %9517 : tensor<1x1200x320xf32>
    %9519 = stablehlo.convert %arg420 : (tensor<320xbf16>) -> tensor<320xf32>
    %9520 = stablehlo.broadcast_in_dim %9518, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9521 = stablehlo.broadcast_in_dim %9519, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9522 = stablehlo.add %9520, %9521 : tensor<1x1200x320xf32>
    %9523 = stablehlo.convert %9522 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9524 = stablehlo.reshape %9523 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9525 = stablehlo.convert %9524 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9526 = stablehlo.dot_general %9525, %arg896, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %9527 = stablehlo.broadcast_in_dim %9526, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9528 = stablehlo.multiply %9527, %3226 : tensor<1200x1280xf32>
    %9529 = stablehlo.broadcast_in_dim %9528, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9530 = stablehlo.broadcast_in_dim %arg897, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %9531 = stablehlo.add %9529, %9530 : tensor<1200x1280xf32>
    %9532 = stablehlo.convert %9531 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %9533 = stablehlo.reshape %9532 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %9534 = stablehlo.transpose %9533, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %9535 = stablehlo.reshape %9534 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %9536 = stablehlo.convolution(%9535, %arg421) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %9537 = stablehlo.reshape %arg422 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %9538 = stablehlo.broadcast_in_dim %9536, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %9539 = stablehlo.broadcast_in_dim %9537, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %9540 = stablehlo.add %9538, %9539 : tensor<1x1280x30x40xbf16>
    %9541 = stablehlo.reshape %9540 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %9542 = stablehlo.transpose %9541, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %9543 = stablehlo.multiply %9542, %cst_42 : tensor<1x1200x1280xbf16>
    %9544 = stablehlo.multiply %9542, %3243 : tensor<1x1200x1280xbf16>
    %9545 = stablehlo.convert %9544 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %9546 = stablehlo.clamp %cst_43, %9545, %cst_44 : tensor<1x1200x1280xf32>
    %9547 = stablehlo.multiply %9546, %9546 : tensor<1x1200x1280xf32>
    %9548 = stablehlo.multiply %cst_45, %9547 : tensor<1x1200x1280xf32>
    %9549 = stablehlo.add %9548, %cst_46 : tensor<1x1200x1280xf32>
    %9550 = stablehlo.multiply %9549, %9547 : tensor<1x1200x1280xf32>
    %9551 = stablehlo.add %9550, %cst_47 : tensor<1x1200x1280xf32>
    %9552 = stablehlo.multiply %9551, %9547 : tensor<1x1200x1280xf32>
    %9553 = stablehlo.add %9552, %cst_48 : tensor<1x1200x1280xf32>
    %9554 = stablehlo.multiply %9553, %9547 : tensor<1x1200x1280xf32>
    %9555 = stablehlo.add %9554, %cst_49 : tensor<1x1200x1280xf32>
    %9556 = stablehlo.multiply %9555, %9547 : tensor<1x1200x1280xf32>
    %9557 = stablehlo.add %9556, %cst_50 : tensor<1x1200x1280xf32>
    %9558 = stablehlo.multiply %9557, %9547 : tensor<1x1200x1280xf32>
    %9559 = stablehlo.add %9558, %cst_51 : tensor<1x1200x1280xf32>
    %9560 = stablehlo.multiply %cst_52, %9547 : tensor<1x1200x1280xf32>
    %9561 = stablehlo.add %9560, %cst_53 : tensor<1x1200x1280xf32>
    %9562 = stablehlo.multiply %9561, %9547 : tensor<1x1200x1280xf32>
    %9563 = stablehlo.add %9562, %cst_54 : tensor<1x1200x1280xf32>
    %9564 = stablehlo.multiply %9563, %9547 : tensor<1x1200x1280xf32>
    %9565 = stablehlo.add %9564, %cst_55 : tensor<1x1200x1280xf32>
    %9566 = stablehlo.multiply %9565, %9547 : tensor<1x1200x1280xf32>
    %9567 = stablehlo.add %9566, %cst_56 : tensor<1x1200x1280xf32>
    %9568 = stablehlo.multiply %9546, %9559 : tensor<1x1200x1280xf32>
    %9569 = stablehlo.divide %9568, %9567 : tensor<1x1200x1280xf32>
    %9570 = stablehlo.clamp %cst_57, %9569, %cst_58 : tensor<1x1200x1280xf32>
    %9571 = stablehlo.convert %9570 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %9572 = stablehlo.add %9571, %cst_40 : tensor<1x1200x1280xbf16>
    %9573 = stablehlo.multiply %9572, %9543 : tensor<1x1200x1280xbf16>
    %9574 = stablehlo.reshape %9573 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %9575 = stablehlo.dot_general %9574, %arg898, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %9576 = stablehlo.reshape %9575 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9577 = stablehlo.broadcast_in_dim %9576, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9578 = stablehlo.broadcast_in_dim %arg423, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %9579 = stablehlo.add %9577, %9578 : tensor<1x1200x320xbf16>
    %9580 = stablehlo.reshape %9579 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9581 = stablehlo.reshape %9580 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9582 = stablehlo.add %9581, %9486 : tensor<1x1200x320xbf16>
    %9583 = stablehlo.convert %9582 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9584 = stablehlo.convert %9583 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9585 = stablehlo.reduce(%9584 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9586 = stablehlo.reshape %9585 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9587 = stablehlo.broadcast_in_dim %9586, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9588 = stablehlo.divide %9587, %2987 : tensor<1x1200x1xf64>
    %9589 = stablehlo.broadcast_in_dim %9584, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9590 = stablehlo.broadcast_in_dim %9588, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9591 = stablehlo.subtract %9589, %9590 : tensor<1x1200x320xf64>
    %9592 = stablehlo.multiply %9591, %9591 : tensor<1x1200x320xf64>
    %9593 = stablehlo.reduce(%9592 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9594 = stablehlo.reshape %9593 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9595 = stablehlo.broadcast_in_dim %9594, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9596 = stablehlo.divide %9595, %2987 : tensor<1x1200x1xf64>
    %9597 = stablehlo.convert %9596 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9598 = stablehlo.reduce(%9583 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9599 = stablehlo.reshape %9598 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9600 = stablehlo.broadcast_in_dim %9599, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9601 = stablehlo.divide %9600, %3003 : tensor<1x1200x1xf32>
    %9602 = stablehlo.broadcast_in_dim %9597, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9603 = stablehlo.add %9602, %3006 : tensor<1x1200x1xf32>
    %9604 = stablehlo.rsqrt %9603 : tensor<1x1200x1xf32>
    %9605 = stablehlo.broadcast_in_dim %9583, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9606 = stablehlo.broadcast_in_dim %9601, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9607 = stablehlo.subtract %9605, %9606 : tensor<1x1200x320xf32>
    %9608 = stablehlo.broadcast_in_dim %9607, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9609 = stablehlo.broadcast_in_dim %9604, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9610 = stablehlo.multiply %9608, %9609 : tensor<1x1200x320xf32>
    %9611 = stablehlo.convert %arg424 : (tensor<320xbf16>) -> tensor<320xf32>
    %9612 = stablehlo.broadcast_in_dim %9610, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9613 = stablehlo.broadcast_in_dim %9611, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9614 = stablehlo.multiply %9612, %9613 : tensor<1x1200x320xf32>
    %9615 = stablehlo.convert %arg425 : (tensor<320xbf16>) -> tensor<320xf32>
    %9616 = stablehlo.broadcast_in_dim %9614, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9617 = stablehlo.broadcast_in_dim %9615, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9618 = stablehlo.add %9616, %9617 : tensor<1x1200x320xf32>
    %9619 = stablehlo.convert %9618 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9620 = stablehlo.reshape %9619 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9621 = stablehlo.convert %9620 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9622 = stablehlo.dot_general %9621, %arg899, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %9623 = stablehlo.broadcast_in_dim %9622, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9624 = stablehlo.multiply %9623, %3065 : tensor<1200x320xf32>
    %9625 = stablehlo.broadcast_in_dim %9624, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9626 = stablehlo.broadcast_in_dim %arg900, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %9627 = stablehlo.add %9625, %9626 : tensor<1200x320xf32>
    %9628 = stablehlo.convert %9627 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %9629 = stablehlo.reshape %9628 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9630 = stablehlo.reshape %9629 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x5x64xbf16>
    %9631 = stablehlo.transpose %9630, dims = [0, 2, 1, 3] : (tensor<1x1200x5x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %9632 = stablehlo.transpose %9619, dims = [0, 2, 1] : (tensor<1x1200x320xbf16>) -> tensor<1x320x1200xbf16>
    %9633 = stablehlo.reshape %9632 : (tensor<1x320x1200xbf16>) -> tensor<1x320x30x40xbf16>
    %9634 = stablehlo.convolution(%9633, %arg426) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<320x320x2x2xbf16>) -> tensor<1x320x15x20xbf16>
    %9635 = stablehlo.reshape %arg427 : (tensor<320xbf16>) -> tensor<320x1x1xbf16>
    %9636 = stablehlo.broadcast_in_dim %9634, dims = [0, 1, 2, 3] : (tensor<1x320x15x20xbf16>) -> tensor<1x320x15x20xbf16>
    %9637 = stablehlo.broadcast_in_dim %9635, dims = [1, 2, 3] : (tensor<320x1x1xbf16>) -> tensor<1x320x15x20xbf16>
    %9638 = stablehlo.add %9636, %9637 : tensor<1x320x15x20xbf16>
    %9639 = stablehlo.reshape %9638 : (tensor<1x320x15x20xbf16>) -> tensor<1x320x300xbf16>
    %9640 = stablehlo.transpose %9639, dims = [0, 2, 1] : (tensor<1x320x300xbf16>) -> tensor<1x300x320xbf16>
    %9641 = stablehlo.convert %9640 : (tensor<1x300x320xbf16>) -> tensor<1x300x320xf32>
    %9642 = stablehlo.convert %9641 : (tensor<1x300x320xf32>) -> tensor<1x300x320xf64>
    %9643 = stablehlo.reduce(%9642 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9644 = stablehlo.reshape %9643 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9645 = stablehlo.broadcast_in_dim %9644, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9646 = stablehlo.divide %9645, %3088 : tensor<1x300x1xf64>
    %9647 = stablehlo.broadcast_in_dim %9642, dims = [0, 1, 2] : (tensor<1x300x320xf64>) -> tensor<1x300x320xf64>
    %9648 = stablehlo.broadcast_in_dim %9646, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x320xf64>
    %9649 = stablehlo.subtract %9647, %9648 : tensor<1x300x320xf64>
    %9650 = stablehlo.multiply %9649, %9649 : tensor<1x300x320xf64>
    %9651 = stablehlo.reduce(%9650 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9652 = stablehlo.reshape %9651 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9653 = stablehlo.broadcast_in_dim %9652, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9654 = stablehlo.divide %9653, %3088 : tensor<1x300x1xf64>
    %9655 = stablehlo.convert %9654 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %9656 = stablehlo.reduce(%9641 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x320xf32>, tensor<f32>) -> tensor<1x300xf32>
    %9657 = stablehlo.reshape %9656 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %9658 = stablehlo.broadcast_in_dim %9657, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9659 = stablehlo.divide %9658, %3102 : tensor<1x300x1xf32>
    %9660 = stablehlo.broadcast_in_dim %9655, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9661 = stablehlo.add %9660, %136 : tensor<1x300x1xf32>
    %9662 = stablehlo.rsqrt %9661 : tensor<1x300x1xf32>
    %9663 = stablehlo.broadcast_in_dim %9641, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9664 = stablehlo.broadcast_in_dim %9659, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %9665 = stablehlo.subtract %9663, %9664 : tensor<1x300x320xf32>
    %9666 = stablehlo.broadcast_in_dim %9665, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9667 = stablehlo.broadcast_in_dim %9662, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x320xf32>
    %9668 = stablehlo.multiply %9666, %9667 : tensor<1x300x320xf32>
    %9669 = stablehlo.convert %arg428 : (tensor<320xbf16>) -> tensor<320xf32>
    %9670 = stablehlo.broadcast_in_dim %9668, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9671 = stablehlo.broadcast_in_dim %9669, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %9672 = stablehlo.multiply %9670, %9671 : tensor<1x300x320xf32>
    %9673 = stablehlo.convert %arg429 : (tensor<320xbf16>) -> tensor<320xf32>
    %9674 = stablehlo.broadcast_in_dim %9672, dims = [0, 1, 2] : (tensor<1x300x320xf32>) -> tensor<1x300x320xf32>
    %9675 = stablehlo.broadcast_in_dim %9673, dims = [2] : (tensor<320xf32>) -> tensor<1x300x320xf32>
    %9676 = stablehlo.add %9674, %9675 : tensor<1x300x320xf32>
    %9677 = stablehlo.convert %9676 : (tensor<1x300x320xf32>) -> tensor<1x300x320xbf16>
    %9678 = stablehlo.reshape %9677 : (tensor<1x300x320xbf16>) -> tensor<300x320xbf16>
    %9679 = stablehlo.convert %9678 : (tensor<300x320xbf16>) -> tensor<300x320xf32>
    %9680 = stablehlo.dot_general %9679, %arg901, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %9681 = stablehlo.broadcast_in_dim %9680, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9682 = stablehlo.multiply %9681, %3126 : tensor<300x320xf32>
    %9683 = stablehlo.broadcast_in_dim %9682, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9684 = stablehlo.broadcast_in_dim %arg902, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %9685 = stablehlo.add %9683, %9684 : tensor<300x320xf32>
    %9686 = stablehlo.convert %9685 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %9687 = stablehlo.reshape %9686 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %9688 = stablehlo.reshape %9687 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %9689 = stablehlo.transpose %9688, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %9690 = stablehlo.dot_general %9679, %arg903, contracting_dims = [1] x [0] : (tensor<300x320xf32>, tensor<320x320xf32>) -> tensor<300x320xf32>
    %9691 = stablehlo.broadcast_in_dim %9690, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9692 = stablehlo.multiply %9691, %3126 : tensor<300x320xf32>
    %9693 = stablehlo.broadcast_in_dim %9692, dims = [0, 1] : (tensor<300x320xf32>) -> tensor<300x320xf32>
    %9694 = stablehlo.broadcast_in_dim %arg904, dims = [1] : (tensor<320xf32>) -> tensor<300x320xf32>
    %9695 = stablehlo.add %9693, %9694 : tensor<300x320xf32>
    %9696 = stablehlo.convert %9695 : (tensor<300x320xf32>) -> tensor<300x320xbf16>
    %9697 = stablehlo.reshape %9696 : (tensor<300x320xbf16>) -> tensor<1x300x320xbf16>
    %9698 = stablehlo.reshape %9697 : (tensor<1x300x320xbf16>) -> tensor<1x300x5x64xbf16>
    %9699 = stablehlo.transpose %9698, dims = [0, 2, 1, 3] : (tensor<1x300x5x64xbf16>) -> tensor<1x5x300x64xbf16>
    %9700 = stablehlo.transpose %9689, dims = [0, 1, 3, 2] : (tensor<1x5x300x64xbf16>) -> tensor<1x5x64x300xbf16>
    %9701 = stablehlo.reshape %9631 : (tensor<1x5x1200x64xbf16>) -> tensor<5x1200x64xbf16>
    %9702 = stablehlo.reshape %9700 : (tensor<1x5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %9703 = stablehlo.broadcast_in_dim %9702, dims = [0, 1, 2] : (tensor<5x64x300xbf16>) -> tensor<5x64x300xbf16>
    %9704 = stablehlo.dot_general %9701, %9703, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x64xbf16>, tensor<5x64x300xbf16>) -> tensor<5x1200x300xbf16>
    %9705 = stablehlo.reshape %9704 : (tensor<5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %9706 = stablehlo.broadcast_in_dim %9705, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xbf16>
    %9707 = stablehlo.divide %9706, %3152 : tensor<1x5x1200x300xbf16>
    %9708 = stablehlo.convert %9707 : (tensor<1x5x1200x300xbf16>) -> tensor<1x5x1200x300xf32>
    %9709 = stablehlo.reduce(%9708 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %9710 = stablehlo.reshape %9709 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %9711 = stablehlo.broadcast_in_dim %9708, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %9712 = stablehlo.broadcast_in_dim %9710, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %9713 = stablehlo.subtract %9711, %9712 : tensor<1x5x1200x300xf32>
    %9714 = stablehlo.exponential %9713 : tensor<1x5x1200x300xf32>
    %9715 = stablehlo.reduce(%9714 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x5x1200x300xf32>, tensor<f32>) -> tensor<1x5x1200xf32>
    %9716 = stablehlo.reshape %9715 : (tensor<1x5x1200xf32>) -> tensor<1x5x1200x1xf32>
    %9717 = stablehlo.broadcast_in_dim %9714, dims = [0, 1, 2, 3] : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xf32>
    %9718 = stablehlo.broadcast_in_dim %9716, dims = [0, 1, 2, 3] : (tensor<1x5x1200x1xf32>) -> tensor<1x5x1200x300xf32>
    %9719 = stablehlo.divide %9717, %9718 : tensor<1x5x1200x300xf32>
    %9720 = stablehlo.convert %9719 : (tensor<1x5x1200x300xf32>) -> tensor<1x5x1200x300xbf16>
    %9721 = stablehlo.reshape %9720 : (tensor<1x5x1200x300xbf16>) -> tensor<5x1200x300xbf16>
    %9722 = stablehlo.reshape %9699 : (tensor<1x5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %9723 = stablehlo.broadcast_in_dim %9722, dims = [0, 1, 2] : (tensor<5x300x64xbf16>) -> tensor<5x300x64xbf16>
    %9724 = stablehlo.dot_general %9721, %9723, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<5x1200x300xbf16>, tensor<5x300x64xbf16>) -> tensor<5x1200x64xbf16>
    %9725 = stablehlo.reshape %9724 : (tensor<5x1200x64xbf16>) -> tensor<1x5x1200x64xbf16>
    %9726 = stablehlo.transpose %9725, dims = [0, 2, 1, 3] : (tensor<1x5x1200x64xbf16>) -> tensor<1x1200x5x64xbf16>
    %9727 = stablehlo.reshape %9726 : (tensor<1x1200x5x64xbf16>) -> tensor<1x1200x320xbf16>
    %9728 = stablehlo.reshape %9727 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9729 = stablehlo.convert %9728 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9730 = stablehlo.dot_general %9729, %arg905, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x320xf32>) -> tensor<1200x320xf32>
    %9731 = stablehlo.broadcast_in_dim %9730, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9732 = stablehlo.multiply %9731, %3065 : tensor<1200x320xf32>
    %9733 = stablehlo.broadcast_in_dim %9732, dims = [0, 1] : (tensor<1200x320xf32>) -> tensor<1200x320xf32>
    %9734 = stablehlo.broadcast_in_dim %arg906, dims = [1] : (tensor<320xf32>) -> tensor<1200x320xf32>
    %9735 = stablehlo.add %9733, %9734 : tensor<1200x320xf32>
    %9736 = stablehlo.convert %9735 : (tensor<1200x320xf32>) -> tensor<1200x320xbf16>
    %9737 = stablehlo.reshape %9736 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9738 = stablehlo.add %9737, %9582 : tensor<1x1200x320xbf16>
    %9739 = stablehlo.convert %9738 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9740 = stablehlo.convert %9739 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9741 = stablehlo.reduce(%9740 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9742 = stablehlo.reshape %9741 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9743 = stablehlo.broadcast_in_dim %9742, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9744 = stablehlo.divide %9743, %2987 : tensor<1x1200x1xf64>
    %9745 = stablehlo.broadcast_in_dim %9740, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9746 = stablehlo.broadcast_in_dim %9744, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9747 = stablehlo.subtract %9745, %9746 : tensor<1x1200x320xf64>
    %9748 = stablehlo.multiply %9747, %9747 : tensor<1x1200x320xf64>
    %9749 = stablehlo.reduce(%9748 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9750 = stablehlo.reshape %9749 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9751 = stablehlo.broadcast_in_dim %9750, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9752 = stablehlo.divide %9751, %2987 : tensor<1x1200x1xf64>
    %9753 = stablehlo.convert %9752 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9754 = stablehlo.reduce(%9739 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9755 = stablehlo.reshape %9754 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9756 = stablehlo.broadcast_in_dim %9755, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9757 = stablehlo.divide %9756, %3003 : tensor<1x1200x1xf32>
    %9758 = stablehlo.broadcast_in_dim %9753, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9759 = stablehlo.add %9758, %3006 : tensor<1x1200x1xf32>
    %9760 = stablehlo.rsqrt %9759 : tensor<1x1200x1xf32>
    %9761 = stablehlo.broadcast_in_dim %9739, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9762 = stablehlo.broadcast_in_dim %9757, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9763 = stablehlo.subtract %9761, %9762 : tensor<1x1200x320xf32>
    %9764 = stablehlo.broadcast_in_dim %9763, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9765 = stablehlo.broadcast_in_dim %9760, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9766 = stablehlo.multiply %9764, %9765 : tensor<1x1200x320xf32>
    %9767 = stablehlo.convert %arg430 : (tensor<320xbf16>) -> tensor<320xf32>
    %9768 = stablehlo.broadcast_in_dim %9766, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9769 = stablehlo.broadcast_in_dim %9767, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9770 = stablehlo.multiply %9768, %9769 : tensor<1x1200x320xf32>
    %9771 = stablehlo.convert %arg431 : (tensor<320xbf16>) -> tensor<320xf32>
    %9772 = stablehlo.broadcast_in_dim %9770, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9773 = stablehlo.broadcast_in_dim %9771, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9774 = stablehlo.add %9772, %9773 : tensor<1x1200x320xf32>
    %9775 = stablehlo.convert %9774 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9776 = stablehlo.reshape %9775 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9777 = stablehlo.convert %9776 : (tensor<1200x320xbf16>) -> tensor<1200x320xf32>
    %9778 = stablehlo.dot_general %9777, %arg907, contracting_dims = [1] x [0] : (tensor<1200x320xf32>, tensor<320x1280xf32>) -> tensor<1200x1280xf32>
    %9779 = stablehlo.broadcast_in_dim %9778, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9780 = stablehlo.multiply %9779, %3226 : tensor<1200x1280xf32>
    %9781 = stablehlo.broadcast_in_dim %9780, dims = [0, 1] : (tensor<1200x1280xf32>) -> tensor<1200x1280xf32>
    %9782 = stablehlo.broadcast_in_dim %arg908, dims = [1] : (tensor<1280xf32>) -> tensor<1200x1280xf32>
    %9783 = stablehlo.add %9781, %9782 : tensor<1200x1280xf32>
    %9784 = stablehlo.convert %9783 : (tensor<1200x1280xf32>) -> tensor<1200x1280xbf16>
    %9785 = stablehlo.reshape %9784 : (tensor<1200x1280xbf16>) -> tensor<1x1200x1280xbf16>
    %9786 = stablehlo.transpose %9785, dims = [0, 2, 1] : (tensor<1x1200x1280xbf16>) -> tensor<1x1280x1200xbf16>
    %9787 = stablehlo.reshape %9786 : (tensor<1x1280x1200xbf16>) -> tensor<1x1280x30x40xbf16>
    %9788 = stablehlo.convolution(%9787, %arg432) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1280 : i64} : (tensor<1x1280x30x40xbf16>, tensor<1280x1x3x3xbf16>) -> tensor<1x1280x30x40xbf16>
    %9789 = stablehlo.reshape %arg433 : (tensor<1280xbf16>) -> tensor<1280x1x1xbf16>
    %9790 = stablehlo.broadcast_in_dim %9788, dims = [0, 1, 2, 3] : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x30x40xbf16>
    %9791 = stablehlo.broadcast_in_dim %9789, dims = [1, 2, 3] : (tensor<1280x1x1xbf16>) -> tensor<1x1280x30x40xbf16>
    %9792 = stablehlo.add %9790, %9791 : tensor<1x1280x30x40xbf16>
    %9793 = stablehlo.reshape %9792 : (tensor<1x1280x30x40xbf16>) -> tensor<1x1280x1200xbf16>
    %9794 = stablehlo.transpose %9793, dims = [0, 2, 1] : (tensor<1x1280x1200xbf16>) -> tensor<1x1200x1280xbf16>
    %9795 = stablehlo.multiply %9794, %cst_42 : tensor<1x1200x1280xbf16>
    %9796 = stablehlo.multiply %9794, %3243 : tensor<1x1200x1280xbf16>
    %9797 = stablehlo.convert %9796 : (tensor<1x1200x1280xbf16>) -> tensor<1x1200x1280xf32>
    %9798 = stablehlo.clamp %cst_43, %9797, %cst_44 : tensor<1x1200x1280xf32>
    %9799 = stablehlo.multiply %9798, %9798 : tensor<1x1200x1280xf32>
    %9800 = stablehlo.multiply %cst_45, %9799 : tensor<1x1200x1280xf32>
    %9801 = stablehlo.add %9800, %cst_46 : tensor<1x1200x1280xf32>
    %9802 = stablehlo.multiply %9801, %9799 : tensor<1x1200x1280xf32>
    %9803 = stablehlo.add %9802, %cst_47 : tensor<1x1200x1280xf32>
    %9804 = stablehlo.multiply %9803, %9799 : tensor<1x1200x1280xf32>
    %9805 = stablehlo.add %9804, %cst_48 : tensor<1x1200x1280xf32>
    %9806 = stablehlo.multiply %9805, %9799 : tensor<1x1200x1280xf32>
    %9807 = stablehlo.add %9806, %cst_49 : tensor<1x1200x1280xf32>
    %9808 = stablehlo.multiply %9807, %9799 : tensor<1x1200x1280xf32>
    %9809 = stablehlo.add %9808, %cst_50 : tensor<1x1200x1280xf32>
    %9810 = stablehlo.multiply %9809, %9799 : tensor<1x1200x1280xf32>
    %9811 = stablehlo.add %9810, %cst_51 : tensor<1x1200x1280xf32>
    %9812 = stablehlo.multiply %cst_52, %9799 : tensor<1x1200x1280xf32>
    %9813 = stablehlo.add %9812, %cst_53 : tensor<1x1200x1280xf32>
    %9814 = stablehlo.multiply %9813, %9799 : tensor<1x1200x1280xf32>
    %9815 = stablehlo.add %9814, %cst_54 : tensor<1x1200x1280xf32>
    %9816 = stablehlo.multiply %9815, %9799 : tensor<1x1200x1280xf32>
    %9817 = stablehlo.add %9816, %cst_55 : tensor<1x1200x1280xf32>
    %9818 = stablehlo.multiply %9817, %9799 : tensor<1x1200x1280xf32>
    %9819 = stablehlo.add %9818, %cst_56 : tensor<1x1200x1280xf32>
    %9820 = stablehlo.multiply %9798, %9811 : tensor<1x1200x1280xf32>
    %9821 = stablehlo.divide %9820, %9819 : tensor<1x1200x1280xf32>
    %9822 = stablehlo.clamp %cst_57, %9821, %cst_58 : tensor<1x1200x1280xf32>
    %9823 = stablehlo.convert %9822 : (tensor<1x1200x1280xf32>) -> tensor<1x1200x1280xbf16>
    %9824 = stablehlo.add %9823, %cst_40 : tensor<1x1200x1280xbf16>
    %9825 = stablehlo.multiply %9824, %9795 : tensor<1x1200x1280xbf16>
    %9826 = stablehlo.reshape %9825 : (tensor<1x1200x1280xbf16>) -> tensor<1200x1280xbf16>
    %9827 = stablehlo.dot_general %9826, %arg909, contracting_dims = [1] x [0] : (tensor<1200x1280xbf16>, tensor<1280x320xbf16>) -> tensor<1200x320xbf16>
    %9828 = stablehlo.reshape %9827 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9829 = stablehlo.broadcast_in_dim %9828, dims = [0, 1, 2] : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9830 = stablehlo.broadcast_in_dim %arg434, dims = [2] : (tensor<320xbf16>) -> tensor<1x1200x320xbf16>
    %9831 = stablehlo.add %9829, %9830 : tensor<1x1200x320xbf16>
    %9832 = stablehlo.reshape %9831 : (tensor<1x1200x320xbf16>) -> tensor<1200x320xbf16>
    %9833 = stablehlo.reshape %9832 : (tensor<1200x320xbf16>) -> tensor<1x1200x320xbf16>
    %9834 = stablehlo.add %9833, %9738 : tensor<1x1200x320xbf16>
    %9835 = stablehlo.convert %9834 : (tensor<1x1200x320xbf16>) -> tensor<1x1200x320xf32>
    %9836 = stablehlo.convert %9835 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf64>
    %9837 = stablehlo.reduce(%9836 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9838 = stablehlo.reshape %9837 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9839 = stablehlo.broadcast_in_dim %9838, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9840 = stablehlo.divide %9839, %2987 : tensor<1x1200x1xf64>
    %9841 = stablehlo.broadcast_in_dim %9836, dims = [0, 1, 2] : (tensor<1x1200x320xf64>) -> tensor<1x1200x320xf64>
    %9842 = stablehlo.broadcast_in_dim %9840, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x320xf64>
    %9843 = stablehlo.subtract %9841, %9842 : tensor<1x1200x320xf64>
    %9844 = stablehlo.multiply %9843, %9843 : tensor<1x1200x320xf64>
    %9845 = stablehlo.reduce(%9844 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf64>, tensor<f64>) -> tensor<1x1200xf64>
    %9846 = stablehlo.reshape %9845 : (tensor<1x1200xf64>) -> tensor<1x1200x1xf64>
    %9847 = stablehlo.broadcast_in_dim %9846, dims = [0, 1, 2] : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf64>
    %9848 = stablehlo.divide %9847, %2987 : tensor<1x1200x1xf64>
    %9849 = stablehlo.convert %9848 : (tensor<1x1200x1xf64>) -> tensor<1x1200x1xf32>
    %9850 = stablehlo.reduce(%9835 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x1200x320xf32>, tensor<f32>) -> tensor<1x1200xf32>
    %9851 = stablehlo.reshape %9850 : (tensor<1x1200xf32>) -> tensor<1x1200x1xf32>
    %9852 = stablehlo.broadcast_in_dim %9851, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9853 = stablehlo.divide %9852, %3003 : tensor<1x1200x1xf32>
    %9854 = stablehlo.broadcast_in_dim %9849, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x1xf32>
    %9855 = stablehlo.add %9854, %3006 : tensor<1x1200x1xf32>
    %9856 = stablehlo.rsqrt %9855 : tensor<1x1200x1xf32>
    %9857 = stablehlo.broadcast_in_dim %9835, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9858 = stablehlo.broadcast_in_dim %9853, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9859 = stablehlo.subtract %9857, %9858 : tensor<1x1200x320xf32>
    %9860 = stablehlo.broadcast_in_dim %9859, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9861 = stablehlo.broadcast_in_dim %9856, dims = [0, 1, 2] : (tensor<1x1200x1xf32>) -> tensor<1x1200x320xf32>
    %9862 = stablehlo.multiply %9860, %9861 : tensor<1x1200x320xf32>
    %9863 = stablehlo.convert %arg435 : (tensor<320xbf16>) -> tensor<320xf32>
    %9864 = stablehlo.broadcast_in_dim %9862, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9865 = stablehlo.broadcast_in_dim %9863, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9866 = stablehlo.multiply %9864, %9865 : tensor<1x1200x320xf32>
    %9867 = stablehlo.convert %arg436 : (tensor<320xbf16>) -> tensor<320xf32>
    %9868 = stablehlo.broadcast_in_dim %9866, dims = [0, 1, 2] : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xf32>
    %9869 = stablehlo.broadcast_in_dim %9867, dims = [2] : (tensor<320xf32>) -> tensor<1x1200x320xf32>
    %9870 = stablehlo.add %9868, %9869 : tensor<1x1200x320xf32>
    %9871 = stablehlo.convert %9870 : (tensor<1x1200x320xf32>) -> tensor<1x1200x320xbf16>
    %9872 = stablehlo.reshape %9871 : (tensor<1x1200x320xbf16>) -> tensor<1x30x40x320xbf16>
    %9873 = stablehlo.transpose %9872, dims = [0, 3, 1, 2] : (tensor<1x30x40x320xbf16>) -> tensor<1x320x30x40xbf16>
    %9874 = stablehlo.convolution(%9873, %arg437) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [2, 2], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<512x320x3x3xbf16>) -> tensor<1x512x15x20xbf16>
    %9875 = stablehlo.reshape %arg438 : (tensor<512xbf16>) -> tensor<512x1x1xbf16>
    %9876 = stablehlo.broadcast_in_dim %9874, dims = [0, 1, 2, 3] : (tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16>
    %9877 = stablehlo.broadcast_in_dim %9875, dims = [1, 2, 3] : (tensor<512x1x1xbf16>) -> tensor<1x512x15x20xbf16>
    %9878 = stablehlo.add %9876, %9877 : tensor<1x512x15x20xbf16>
    %9879 = stablehlo.reshape %9878 : (tensor<1x512x15x20xbf16>) -> tensor<1x512x300xbf16>
    %9880 = stablehlo.transpose %9879, dims = [0, 2, 1] : (tensor<1x512x300xbf16>) -> tensor<1x300x512xbf16>
    %9881 = stablehlo.convert %9880 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %9882 = stablehlo.convert %9881 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %9883 = stablehlo.reduce(%9882 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9884 = stablehlo.reshape %9883 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9885 = stablehlo.convert %cst_91 : (tensor<1xi64>) -> tensor<1xf64>
    %9886 = stablehlo.reshape %9885 : (tensor<1xf64>) -> tensor<f64>
    %9887 = stablehlo.broadcast_in_dim %9884, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9888 = stablehlo.broadcast_in_dim %9886, dims = [] : (tensor<f64>) -> tensor<1x300x1xf64>
    %9889 = stablehlo.divide %9887, %9888 : tensor<1x300x1xf64>
    %9890 = stablehlo.broadcast_in_dim %9882, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %9891 = stablehlo.broadcast_in_dim %9889, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %9892 = stablehlo.subtract %9890, %9891 : tensor<1x300x512xf64>
    %9893 = stablehlo.multiply %9892, %9892 : tensor<1x300x512xf64>
    %9894 = stablehlo.reduce(%9893 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9895 = stablehlo.reshape %9894 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9896 = stablehlo.broadcast_in_dim %9895, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9897 = stablehlo.divide %9896, %9888 : tensor<1x300x1xf64>
    %9898 = stablehlo.convert %9897 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %9899 = stablehlo.reduce(%9881 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %9900 = stablehlo.reshape %9899 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %9901 = stablehlo.convert %cst_91 : (tensor<1xi64>) -> tensor<1xf32>
    %9902 = stablehlo.reshape %9901 : (tensor<1xf32>) -> tensor<f32>
    %9903 = stablehlo.broadcast_in_dim %9900, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9904 = stablehlo.broadcast_in_dim %9902, dims = [] : (tensor<f32>) -> tensor<1x300x1xf32>
    %9905 = stablehlo.divide %9903, %9904 : tensor<1x300x1xf32>
    %9906 = stablehlo.broadcast_in_dim %9898, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9907 = stablehlo.add %9906, %136 : tensor<1x300x1xf32>
    %9908 = stablehlo.rsqrt %9907 : tensor<1x300x1xf32>
    %9909 = stablehlo.broadcast_in_dim %9881, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9910 = stablehlo.broadcast_in_dim %9905, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %9911 = stablehlo.subtract %9909, %9910 : tensor<1x300x512xf32>
    %9912 = stablehlo.broadcast_in_dim %9911, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9913 = stablehlo.broadcast_in_dim %9908, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %9914 = stablehlo.multiply %9912, %9913 : tensor<1x300x512xf32>
    %9915 = stablehlo.convert %arg439 : (tensor<512xbf16>) -> tensor<512xf32>
    %9916 = stablehlo.broadcast_in_dim %9914, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9917 = stablehlo.broadcast_in_dim %9915, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %9918 = stablehlo.multiply %9916, %9917 : tensor<1x300x512xf32>
    %9919 = stablehlo.convert %arg440 : (tensor<512xbf16>) -> tensor<512xf32>
    %9920 = stablehlo.broadcast_in_dim %9918, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9921 = stablehlo.broadcast_in_dim %9919, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %9922 = stablehlo.add %9920, %9921 : tensor<1x300x512xf32>
    %9923 = stablehlo.convert %9922 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %9924 = stablehlo.convert %9923 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %9925 = stablehlo.convert %9924 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %9926 = stablehlo.reduce(%9925 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9927 = stablehlo.reshape %9926 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9928 = stablehlo.broadcast_in_dim %9927, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9929 = stablehlo.divide %9928, %9888 : tensor<1x300x1xf64>
    %9930 = stablehlo.broadcast_in_dim %9925, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %9931 = stablehlo.broadcast_in_dim %9929, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %9932 = stablehlo.subtract %9930, %9931 : tensor<1x300x512xf64>
    %9933 = stablehlo.multiply %9932, %9932 : tensor<1x300x512xf64>
    %9934 = stablehlo.reduce(%9933 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %9935 = stablehlo.reshape %9934 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %9936 = stablehlo.broadcast_in_dim %9935, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %9937 = stablehlo.divide %9936, %9888 : tensor<1x300x1xf64>
    %9938 = stablehlo.convert %9937 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %9939 = stablehlo.reduce(%9924 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %9940 = stablehlo.reshape %9939 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %9941 = stablehlo.broadcast_in_dim %9940, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9942 = stablehlo.divide %9941, %9904 : tensor<1x300x1xf32>
    %9943 = stablehlo.broadcast_in_dim %9938, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %9944 = stablehlo.add %9943, %136 : tensor<1x300x1xf32>
    %9945 = stablehlo.rsqrt %9944 : tensor<1x300x1xf32>
    %9946 = stablehlo.broadcast_in_dim %9924, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9947 = stablehlo.broadcast_in_dim %9942, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %9948 = stablehlo.subtract %9946, %9947 : tensor<1x300x512xf32>
    %9949 = stablehlo.broadcast_in_dim %9948, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9950 = stablehlo.broadcast_in_dim %9945, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %9951 = stablehlo.multiply %9949, %9950 : tensor<1x300x512xf32>
    %9952 = stablehlo.convert %arg441 : (tensor<512xbf16>) -> tensor<512xf32>
    %9953 = stablehlo.broadcast_in_dim %9951, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9954 = stablehlo.broadcast_in_dim %9952, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %9955 = stablehlo.multiply %9953, %9954 : tensor<1x300x512xf32>
    %9956 = stablehlo.convert %arg442 : (tensor<512xbf16>) -> tensor<512xf32>
    %9957 = stablehlo.broadcast_in_dim %9955, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %9958 = stablehlo.broadcast_in_dim %9956, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %9959 = stablehlo.add %9957, %9958 : tensor<1x300x512xf32>
    %9960 = stablehlo.convert %9959 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %9961 = stablehlo.reshape %9960 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %9962 = stablehlo.convert %9961 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %9963 = stablehlo.dot_general %9962, %arg910, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %9964 = stablehlo.broadcast_in_dim %9963, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %9965 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<300x512xf32>
    %9966 = stablehlo.multiply %9964, %9965 : tensor<300x512xf32>
    %9967 = stablehlo.broadcast_in_dim %9966, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %9968 = stablehlo.broadcast_in_dim %arg911, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %9969 = stablehlo.add %9967, %9968 : tensor<300x512xf32>
    %9970 = stablehlo.convert %9969 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %9971 = stablehlo.reshape %9970 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %9972 = stablehlo.reshape %9971 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %9973 = stablehlo.transpose %9972, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %9974 = stablehlo.dot_general %9962, %arg912, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %9975 = stablehlo.broadcast_in_dim %9974, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %9976 = stablehlo.multiply %9975, %9965 : tensor<300x512xf32>
    %9977 = stablehlo.broadcast_in_dim %9976, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %9978 = stablehlo.broadcast_in_dim %arg913, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %9979 = stablehlo.add %9977, %9978 : tensor<300x512xf32>
    %9980 = stablehlo.convert %9979 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %9981 = stablehlo.reshape %9980 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %9982 = stablehlo.reshape %9981 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %9983 = stablehlo.transpose %9982, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %9984 = stablehlo.dot_general %9962, %arg914, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %9985 = stablehlo.broadcast_in_dim %9984, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %9986 = stablehlo.multiply %9985, %9965 : tensor<300x512xf32>
    %9987 = stablehlo.broadcast_in_dim %9986, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %9988 = stablehlo.broadcast_in_dim %arg915, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %9989 = stablehlo.add %9987, %9988 : tensor<300x512xf32>
    %9990 = stablehlo.convert %9989 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %9991 = stablehlo.reshape %9990 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %9992 = stablehlo.reshape %9991 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %9993 = stablehlo.transpose %9992, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %9994 = stablehlo.transpose %9983, dims = [0, 1, 3, 2] : (tensor<1x8x300x64xbf16>) -> tensor<1x8x64x300xbf16>
    %9995 = stablehlo.reshape %9973 : (tensor<1x8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %9996 = stablehlo.reshape %9994 : (tensor<1x8x64x300xbf16>) -> tensor<8x64x300xbf16>
    %9997 = stablehlo.broadcast_in_dim %9996, dims = [0, 1, 2] : (tensor<8x64x300xbf16>) -> tensor<8x64x300xbf16>
    %9998 = stablehlo.dot_general %9995, %9997, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<8x300x64xbf16>, tensor<8x64x300xbf16>) -> tensor<8x300x300xbf16>
    %9999 = stablehlo.reshape %9998 : (tensor<8x300x300xbf16>) -> tensor<1x8x300x300xbf16>
    %10000 = stablehlo.broadcast_in_dim %9999, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xbf16>) -> tensor<1x8x300x300xbf16>
    %10001 = stablehlo.broadcast_in_dim %184, dims = [] : (tensor<bf16>) -> tensor<1x8x300x300xbf16>
    %10002 = stablehlo.divide %10000, %10001 : tensor<1x8x300x300xbf16>
    %10003 = stablehlo.convert %10002 : (tensor<1x8x300x300xbf16>) -> tensor<1x8x300x300xf32>
    %10004 = stablehlo.reduce(%10003 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x8x300x300xf32>, tensor<f32>) -> tensor<1x8x300xf32>
    %10005 = stablehlo.reshape %10004 : (tensor<1x8x300xf32>) -> tensor<1x8x300x1xf32>
    %10006 = stablehlo.broadcast_in_dim %10003, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xf32>
    %10007 = stablehlo.broadcast_in_dim %10005, dims = [0, 1, 2, 3] : (tensor<1x8x300x1xf32>) -> tensor<1x8x300x300xf32>
    %10008 = stablehlo.subtract %10006, %10007 : tensor<1x8x300x300xf32>
    %10009 = stablehlo.exponential %10008 : tensor<1x8x300x300xf32>
    %10010 = stablehlo.reduce(%10009 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x8x300x300xf32>, tensor<f32>) -> tensor<1x8x300xf32>
    %10011 = stablehlo.reshape %10010 : (tensor<1x8x300xf32>) -> tensor<1x8x300x1xf32>
    %10012 = stablehlo.broadcast_in_dim %10009, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xf32>
    %10013 = stablehlo.broadcast_in_dim %10011, dims = [0, 1, 2, 3] : (tensor<1x8x300x1xf32>) -> tensor<1x8x300x300xf32>
    %10014 = stablehlo.divide %10012, %10013 : tensor<1x8x300x300xf32>
    %10015 = stablehlo.convert %10014 : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xbf16>
    %10016 = stablehlo.reshape %10015 : (tensor<1x8x300x300xbf16>) -> tensor<8x300x300xbf16>
    %10017 = stablehlo.reshape %9993 : (tensor<1x8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10018 = stablehlo.broadcast_in_dim %10017, dims = [0, 1, 2] : (tensor<8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10019 = stablehlo.dot_general %10016, %10018, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<8x300x300xbf16>, tensor<8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10020 = stablehlo.reshape %10019 : (tensor<8x300x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10021 = stablehlo.transpose %10020, dims = [0, 2, 1, 3] : (tensor<1x8x300x64xbf16>) -> tensor<1x300x8x64xbf16>
    %10022 = stablehlo.reshape %10021 : (tensor<1x300x8x64xbf16>) -> tensor<1x300x512xbf16>
    %10023 = stablehlo.reshape %10022 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10024 = stablehlo.convert %10023 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10025 = stablehlo.dot_general %10024, %arg916, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10026 = stablehlo.broadcast_in_dim %10025, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10027 = stablehlo.multiply %10026, %9965 : tensor<300x512xf32>
    %10028 = stablehlo.broadcast_in_dim %10027, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10029 = stablehlo.broadcast_in_dim %arg917, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10030 = stablehlo.add %10028, %10029 : tensor<300x512xf32>
    %10031 = stablehlo.convert %10030 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10032 = stablehlo.reshape %10031 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10033 = stablehlo.add %10032, %9923 : tensor<1x300x512xbf16>
    %10034 = stablehlo.convert %10033 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %10035 = stablehlo.convert %10034 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %10036 = stablehlo.reduce(%10035 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10037 = stablehlo.reshape %10036 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10038 = stablehlo.broadcast_in_dim %10037, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10039 = stablehlo.divide %10038, %9888 : tensor<1x300x1xf64>
    %10040 = stablehlo.broadcast_in_dim %10035, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %10041 = stablehlo.broadcast_in_dim %10039, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %10042 = stablehlo.subtract %10040, %10041 : tensor<1x300x512xf64>
    %10043 = stablehlo.multiply %10042, %10042 : tensor<1x300x512xf64>
    %10044 = stablehlo.reduce(%10043 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10045 = stablehlo.reshape %10044 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10046 = stablehlo.broadcast_in_dim %10045, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10047 = stablehlo.divide %10046, %9888 : tensor<1x300x1xf64>
    %10048 = stablehlo.convert %10047 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %10049 = stablehlo.reduce(%10034 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %10050 = stablehlo.reshape %10049 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %10051 = stablehlo.broadcast_in_dim %10050, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10052 = stablehlo.divide %10051, %9904 : tensor<1x300x1xf32>
    %10053 = stablehlo.broadcast_in_dim %10048, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10054 = stablehlo.add %10053, %136 : tensor<1x300x1xf32>
    %10055 = stablehlo.rsqrt %10054 : tensor<1x300x1xf32>
    %10056 = stablehlo.broadcast_in_dim %10034, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10057 = stablehlo.broadcast_in_dim %10052, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10058 = stablehlo.subtract %10056, %10057 : tensor<1x300x512xf32>
    %10059 = stablehlo.broadcast_in_dim %10058, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10060 = stablehlo.broadcast_in_dim %10055, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10061 = stablehlo.multiply %10059, %10060 : tensor<1x300x512xf32>
    %10062 = stablehlo.convert %arg443 : (tensor<512xbf16>) -> tensor<512xf32>
    %10063 = stablehlo.broadcast_in_dim %10061, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10064 = stablehlo.broadcast_in_dim %10062, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10065 = stablehlo.multiply %10063, %10064 : tensor<1x300x512xf32>
    %10066 = stablehlo.convert %arg444 : (tensor<512xbf16>) -> tensor<512xf32>
    %10067 = stablehlo.broadcast_in_dim %10065, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10068 = stablehlo.broadcast_in_dim %10066, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10069 = stablehlo.add %10067, %10068 : tensor<1x300x512xf32>
    %10070 = stablehlo.convert %10069 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %10071 = stablehlo.reshape %10070 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10072 = stablehlo.convert %10071 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10073 = stablehlo.dot_general %10072, %arg918, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x2048xf32>) -> tensor<300x2048xf32>
    %10074 = stablehlo.broadcast_in_dim %10073, dims = [0, 1] : (tensor<300x2048xf32>) -> tensor<300x2048xf32>
    %10075 = stablehlo.broadcast_in_dim %94, dims = [] : (tensor<f32>) -> tensor<300x2048xf32>
    %10076 = stablehlo.multiply %10074, %10075 : tensor<300x2048xf32>
    %10077 = stablehlo.broadcast_in_dim %10076, dims = [0, 1] : (tensor<300x2048xf32>) -> tensor<300x2048xf32>
    %10078 = stablehlo.broadcast_in_dim %arg919, dims = [1] : (tensor<2048xf32>) -> tensor<300x2048xf32>
    %10079 = stablehlo.add %10077, %10078 : tensor<300x2048xf32>
    %10080 = stablehlo.convert %10079 : (tensor<300x2048xf32>) -> tensor<300x2048xbf16>
    %10081 = stablehlo.reshape %10080 : (tensor<300x2048xbf16>) -> tensor<1x300x2048xbf16>
    %10082 = stablehlo.transpose %10081, dims = [0, 2, 1] : (tensor<1x300x2048xbf16>) -> tensor<1x2048x300xbf16>
    %10083 = stablehlo.reshape %10082 : (tensor<1x2048x300xbf16>) -> tensor<1x2048x15x20xbf16>
    %10084 = stablehlo.convolution(%10083, %arg445) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 2048 : i64} : (tensor<1x2048x15x20xbf16>, tensor<2048x1x3x3xbf16>) -> tensor<1x2048x15x20xbf16>
    %10085 = stablehlo.reshape %arg446 : (tensor<2048xbf16>) -> tensor<2048x1x1xbf16>
    %10086 = stablehlo.broadcast_in_dim %10084, dims = [0, 1, 2, 3] : (tensor<1x2048x15x20xbf16>) -> tensor<1x2048x15x20xbf16>
    %10087 = stablehlo.broadcast_in_dim %10085, dims = [1, 2, 3] : (tensor<2048x1x1xbf16>) -> tensor<1x2048x15x20xbf16>
    %10088 = stablehlo.add %10086, %10087 : tensor<1x2048x15x20xbf16>
    %10089 = stablehlo.reshape %10088 : (tensor<1x2048x15x20xbf16>) -> tensor<1x2048x300xbf16>
    %10090 = stablehlo.transpose %10089, dims = [0, 2, 1] : (tensor<1x2048x300xbf16>) -> tensor<1x300x2048xbf16>
    %10091 = stablehlo.multiply %10090, %cst_61 : tensor<1x300x2048xbf16>
    %10092 = stablehlo.rsqrt %cst_60 : tensor<1x300x2048xbf16>
    %10093 = stablehlo.multiply %10090, %10092 : tensor<1x300x2048xbf16>
    %10094 = stablehlo.convert %10093 : (tensor<1x300x2048xbf16>) -> tensor<1x300x2048xf32>
    %10095 = stablehlo.clamp %cst_62, %10094, %cst_63 : tensor<1x300x2048xf32>
    %10096 = stablehlo.multiply %10095, %10095 : tensor<1x300x2048xf32>
    %10097 = stablehlo.multiply %cst_64, %10096 : tensor<1x300x2048xf32>
    %10098 = stablehlo.add %10097, %cst_65 : tensor<1x300x2048xf32>
    %10099 = stablehlo.multiply %10098, %10096 : tensor<1x300x2048xf32>
    %10100 = stablehlo.add %10099, %cst_66 : tensor<1x300x2048xf32>
    %10101 = stablehlo.multiply %10100, %10096 : tensor<1x300x2048xf32>
    %10102 = stablehlo.add %10101, %cst_67 : tensor<1x300x2048xf32>
    %10103 = stablehlo.multiply %10102, %10096 : tensor<1x300x2048xf32>
    %10104 = stablehlo.add %10103, %cst_68 : tensor<1x300x2048xf32>
    %10105 = stablehlo.multiply %10104, %10096 : tensor<1x300x2048xf32>
    %10106 = stablehlo.add %10105, %cst_69 : tensor<1x300x2048xf32>
    %10107 = stablehlo.multiply %10106, %10096 : tensor<1x300x2048xf32>
    %10108 = stablehlo.add %10107, %cst_70 : tensor<1x300x2048xf32>
    %10109 = stablehlo.multiply %cst_71, %10096 : tensor<1x300x2048xf32>
    %10110 = stablehlo.add %10109, %cst_72 : tensor<1x300x2048xf32>
    %10111 = stablehlo.multiply %10110, %10096 : tensor<1x300x2048xf32>
    %10112 = stablehlo.add %10111, %cst_73 : tensor<1x300x2048xf32>
    %10113 = stablehlo.multiply %10112, %10096 : tensor<1x300x2048xf32>
    %10114 = stablehlo.add %10113, %cst_74 : tensor<1x300x2048xf32>
    %10115 = stablehlo.multiply %10114, %10096 : tensor<1x300x2048xf32>
    %10116 = stablehlo.add %10115, %cst_75 : tensor<1x300x2048xf32>
    %10117 = stablehlo.multiply %10095, %10108 : tensor<1x300x2048xf32>
    %10118 = stablehlo.divide %10117, %10116 : tensor<1x300x2048xf32>
    %10119 = stablehlo.clamp %cst_76, %10118, %cst_77 : tensor<1x300x2048xf32>
    %10120 = stablehlo.convert %10119 : (tensor<1x300x2048xf32>) -> tensor<1x300x2048xbf16>
    %10121 = stablehlo.add %10120, %cst_59 : tensor<1x300x2048xbf16>
    %10122 = stablehlo.multiply %10121, %10091 : tensor<1x300x2048xbf16>
    %10123 = stablehlo.reshape %10122 : (tensor<1x300x2048xbf16>) -> tensor<300x2048xbf16>
    %10124 = stablehlo.dot_general %10123, %arg920, contracting_dims = [1] x [0] : (tensor<300x2048xbf16>, tensor<2048x512xbf16>) -> tensor<300x512xbf16>
    %10125 = stablehlo.reshape %10124 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10126 = stablehlo.broadcast_in_dim %10125, dims = [0, 1, 2] : (tensor<1x300x512xbf16>) -> tensor<1x300x512xbf16>
    %10127 = stablehlo.broadcast_in_dim %arg447, dims = [2] : (tensor<512xbf16>) -> tensor<1x300x512xbf16>
    %10128 = stablehlo.add %10126, %10127 : tensor<1x300x512xbf16>
    %10129 = stablehlo.reshape %10128 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10130 = stablehlo.reshape %10129 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10131 = stablehlo.add %10130, %10033 : tensor<1x300x512xbf16>
    %10132 = stablehlo.convert %10131 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %10133 = stablehlo.convert %10132 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %10134 = stablehlo.reduce(%10133 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10135 = stablehlo.reshape %10134 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10136 = stablehlo.broadcast_in_dim %10135, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10137 = stablehlo.divide %10136, %9888 : tensor<1x300x1xf64>
    %10138 = stablehlo.broadcast_in_dim %10133, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %10139 = stablehlo.broadcast_in_dim %10137, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %10140 = stablehlo.subtract %10138, %10139 : tensor<1x300x512xf64>
    %10141 = stablehlo.multiply %10140, %10140 : tensor<1x300x512xf64>
    %10142 = stablehlo.reduce(%10141 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10143 = stablehlo.reshape %10142 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10144 = stablehlo.broadcast_in_dim %10143, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10145 = stablehlo.divide %10144, %9888 : tensor<1x300x1xf64>
    %10146 = stablehlo.convert %10145 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %10147 = stablehlo.reduce(%10132 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %10148 = stablehlo.reshape %10147 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %10149 = stablehlo.broadcast_in_dim %10148, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10150 = stablehlo.divide %10149, %9904 : tensor<1x300x1xf32>
    %10151 = stablehlo.broadcast_in_dim %10146, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10152 = stablehlo.add %10151, %136 : tensor<1x300x1xf32>
    %10153 = stablehlo.rsqrt %10152 : tensor<1x300x1xf32>
    %10154 = stablehlo.broadcast_in_dim %10132, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10155 = stablehlo.broadcast_in_dim %10150, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10156 = stablehlo.subtract %10154, %10155 : tensor<1x300x512xf32>
    %10157 = stablehlo.broadcast_in_dim %10156, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10158 = stablehlo.broadcast_in_dim %10153, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10159 = stablehlo.multiply %10157, %10158 : tensor<1x300x512xf32>
    %10160 = stablehlo.convert %arg448 : (tensor<512xbf16>) -> tensor<512xf32>
    %10161 = stablehlo.broadcast_in_dim %10159, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10162 = stablehlo.broadcast_in_dim %10160, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10163 = stablehlo.multiply %10161, %10162 : tensor<1x300x512xf32>
    %10164 = stablehlo.convert %arg449 : (tensor<512xbf16>) -> tensor<512xf32>
    %10165 = stablehlo.broadcast_in_dim %10163, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10166 = stablehlo.broadcast_in_dim %10164, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10167 = stablehlo.add %10165, %10166 : tensor<1x300x512xf32>
    %10168 = stablehlo.convert %10167 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %10169 = stablehlo.reshape %10168 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10170 = stablehlo.convert %10169 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10171 = stablehlo.dot_general %10170, %arg921, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10172 = stablehlo.broadcast_in_dim %10171, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10173 = stablehlo.multiply %10172, %9965 : tensor<300x512xf32>
    %10174 = stablehlo.broadcast_in_dim %10173, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10175 = stablehlo.broadcast_in_dim %arg922, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10176 = stablehlo.add %10174, %10175 : tensor<300x512xf32>
    %10177 = stablehlo.convert %10176 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10178 = stablehlo.reshape %10177 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10179 = stablehlo.reshape %10178 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %10180 = stablehlo.transpose %10179, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10181 = stablehlo.dot_general %10170, %arg923, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10182 = stablehlo.broadcast_in_dim %10181, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10183 = stablehlo.multiply %10182, %9965 : tensor<300x512xf32>
    %10184 = stablehlo.broadcast_in_dim %10183, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10185 = stablehlo.broadcast_in_dim %arg924, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10186 = stablehlo.add %10184, %10185 : tensor<300x512xf32>
    %10187 = stablehlo.convert %10186 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10188 = stablehlo.reshape %10187 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10189 = stablehlo.reshape %10188 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %10190 = stablehlo.transpose %10189, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10191 = stablehlo.dot_general %10170, %arg925, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10192 = stablehlo.broadcast_in_dim %10191, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10193 = stablehlo.multiply %10192, %9965 : tensor<300x512xf32>
    %10194 = stablehlo.broadcast_in_dim %10193, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10195 = stablehlo.broadcast_in_dim %arg926, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10196 = stablehlo.add %10194, %10195 : tensor<300x512xf32>
    %10197 = stablehlo.convert %10196 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10198 = stablehlo.reshape %10197 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10199 = stablehlo.reshape %10198 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %10200 = stablehlo.transpose %10199, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10201 = stablehlo.transpose %10190, dims = [0, 1, 3, 2] : (tensor<1x8x300x64xbf16>) -> tensor<1x8x64x300xbf16>
    %10202 = stablehlo.reshape %10180 : (tensor<1x8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10203 = stablehlo.reshape %10201 : (tensor<1x8x64x300xbf16>) -> tensor<8x64x300xbf16>
    %10204 = stablehlo.broadcast_in_dim %10203, dims = [0, 1, 2] : (tensor<8x64x300xbf16>) -> tensor<8x64x300xbf16>
    %10205 = stablehlo.dot_general %10202, %10204, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<8x300x64xbf16>, tensor<8x64x300xbf16>) -> tensor<8x300x300xbf16>
    %10206 = stablehlo.reshape %10205 : (tensor<8x300x300xbf16>) -> tensor<1x8x300x300xbf16>
    %10207 = stablehlo.broadcast_in_dim %10206, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xbf16>) -> tensor<1x8x300x300xbf16>
    %10208 = stablehlo.divide %10207, %10001 : tensor<1x8x300x300xbf16>
    %10209 = stablehlo.convert %10208 : (tensor<1x8x300x300xbf16>) -> tensor<1x8x300x300xf32>
    %10210 = stablehlo.reduce(%10209 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x8x300x300xf32>, tensor<f32>) -> tensor<1x8x300xf32>
    %10211 = stablehlo.reshape %10210 : (tensor<1x8x300xf32>) -> tensor<1x8x300x1xf32>
    %10212 = stablehlo.broadcast_in_dim %10209, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xf32>
    %10213 = stablehlo.broadcast_in_dim %10211, dims = [0, 1, 2, 3] : (tensor<1x8x300x1xf32>) -> tensor<1x8x300x300xf32>
    %10214 = stablehlo.subtract %10212, %10213 : tensor<1x8x300x300xf32>
    %10215 = stablehlo.exponential %10214 : tensor<1x8x300x300xf32>
    %10216 = stablehlo.reduce(%10215 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x8x300x300xf32>, tensor<f32>) -> tensor<1x8x300xf32>
    %10217 = stablehlo.reshape %10216 : (tensor<1x8x300xf32>) -> tensor<1x8x300x1xf32>
    %10218 = stablehlo.broadcast_in_dim %10215, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xf32>
    %10219 = stablehlo.broadcast_in_dim %10217, dims = [0, 1, 2, 3] : (tensor<1x8x300x1xf32>) -> tensor<1x8x300x300xf32>
    %10220 = stablehlo.divide %10218, %10219 : tensor<1x8x300x300xf32>
    %10221 = stablehlo.convert %10220 : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xbf16>
    %10222 = stablehlo.reshape %10221 : (tensor<1x8x300x300xbf16>) -> tensor<8x300x300xbf16>
    %10223 = stablehlo.reshape %10200 : (tensor<1x8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10224 = stablehlo.broadcast_in_dim %10223, dims = [0, 1, 2] : (tensor<8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10225 = stablehlo.dot_general %10222, %10224, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<8x300x300xbf16>, tensor<8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10226 = stablehlo.reshape %10225 : (tensor<8x300x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10227 = stablehlo.transpose %10226, dims = [0, 2, 1, 3] : (tensor<1x8x300x64xbf16>) -> tensor<1x300x8x64xbf16>
    %10228 = stablehlo.reshape %10227 : (tensor<1x300x8x64xbf16>) -> tensor<1x300x512xbf16>
    %10229 = stablehlo.reshape %10228 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10230 = stablehlo.convert %10229 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10231 = stablehlo.dot_general %10230, %arg927, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10232 = stablehlo.broadcast_in_dim %10231, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10233 = stablehlo.multiply %10232, %9965 : tensor<300x512xf32>
    %10234 = stablehlo.broadcast_in_dim %10233, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10235 = stablehlo.broadcast_in_dim %arg928, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10236 = stablehlo.add %10234, %10235 : tensor<300x512xf32>
    %10237 = stablehlo.convert %10236 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10238 = stablehlo.reshape %10237 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10239 = stablehlo.add %10238, %10131 : tensor<1x300x512xbf16>
    %10240 = stablehlo.convert %10239 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %10241 = stablehlo.convert %10240 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %10242 = stablehlo.reduce(%10241 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10243 = stablehlo.reshape %10242 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10244 = stablehlo.broadcast_in_dim %10243, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10245 = stablehlo.divide %10244, %9888 : tensor<1x300x1xf64>
    %10246 = stablehlo.broadcast_in_dim %10241, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %10247 = stablehlo.broadcast_in_dim %10245, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %10248 = stablehlo.subtract %10246, %10247 : tensor<1x300x512xf64>
    %10249 = stablehlo.multiply %10248, %10248 : tensor<1x300x512xf64>
    %10250 = stablehlo.reduce(%10249 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10251 = stablehlo.reshape %10250 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10252 = stablehlo.broadcast_in_dim %10251, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10253 = stablehlo.divide %10252, %9888 : tensor<1x300x1xf64>
    %10254 = stablehlo.convert %10253 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %10255 = stablehlo.reduce(%10240 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %10256 = stablehlo.reshape %10255 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %10257 = stablehlo.broadcast_in_dim %10256, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10258 = stablehlo.divide %10257, %9904 : tensor<1x300x1xf32>
    %10259 = stablehlo.broadcast_in_dim %10254, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10260 = stablehlo.add %10259, %136 : tensor<1x300x1xf32>
    %10261 = stablehlo.rsqrt %10260 : tensor<1x300x1xf32>
    %10262 = stablehlo.broadcast_in_dim %10240, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10263 = stablehlo.broadcast_in_dim %10258, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10264 = stablehlo.subtract %10262, %10263 : tensor<1x300x512xf32>
    %10265 = stablehlo.broadcast_in_dim %10264, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10266 = stablehlo.broadcast_in_dim %10261, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10267 = stablehlo.multiply %10265, %10266 : tensor<1x300x512xf32>
    %10268 = stablehlo.convert %arg450 : (tensor<512xbf16>) -> tensor<512xf32>
    %10269 = stablehlo.broadcast_in_dim %10267, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10270 = stablehlo.broadcast_in_dim %10268, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10271 = stablehlo.multiply %10269, %10270 : tensor<1x300x512xf32>
    %10272 = stablehlo.convert %arg451 : (tensor<512xbf16>) -> tensor<512xf32>
    %10273 = stablehlo.broadcast_in_dim %10271, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10274 = stablehlo.broadcast_in_dim %10272, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10275 = stablehlo.add %10273, %10274 : tensor<1x300x512xf32>
    %10276 = stablehlo.convert %10275 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %10277 = stablehlo.reshape %10276 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10278 = stablehlo.convert %10277 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10279 = stablehlo.dot_general %10278, %arg929, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x2048xf32>) -> tensor<300x2048xf32>
    %10280 = stablehlo.broadcast_in_dim %10279, dims = [0, 1] : (tensor<300x2048xf32>) -> tensor<300x2048xf32>
    %10281 = stablehlo.multiply %10280, %10075 : tensor<300x2048xf32>
    %10282 = stablehlo.broadcast_in_dim %10281, dims = [0, 1] : (tensor<300x2048xf32>) -> tensor<300x2048xf32>
    %10283 = stablehlo.broadcast_in_dim %arg930, dims = [1] : (tensor<2048xf32>) -> tensor<300x2048xf32>
    %10284 = stablehlo.add %10282, %10283 : tensor<300x2048xf32>
    %10285 = stablehlo.convert %10284 : (tensor<300x2048xf32>) -> tensor<300x2048xbf16>
    %10286 = stablehlo.reshape %10285 : (tensor<300x2048xbf16>) -> tensor<1x300x2048xbf16>
    %10287 = stablehlo.transpose %10286, dims = [0, 2, 1] : (tensor<1x300x2048xbf16>) -> tensor<1x2048x300xbf16>
    %10288 = stablehlo.reshape %10287 : (tensor<1x2048x300xbf16>) -> tensor<1x2048x15x20xbf16>
    %10289 = stablehlo.convolution(%10288, %arg452) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 2048 : i64} : (tensor<1x2048x15x20xbf16>, tensor<2048x1x3x3xbf16>) -> tensor<1x2048x15x20xbf16>
    %10290 = stablehlo.reshape %arg453 : (tensor<2048xbf16>) -> tensor<2048x1x1xbf16>
    %10291 = stablehlo.broadcast_in_dim %10289, dims = [0, 1, 2, 3] : (tensor<1x2048x15x20xbf16>) -> tensor<1x2048x15x20xbf16>
    %10292 = stablehlo.broadcast_in_dim %10290, dims = [1, 2, 3] : (tensor<2048x1x1xbf16>) -> tensor<1x2048x15x20xbf16>
    %10293 = stablehlo.add %10291, %10292 : tensor<1x2048x15x20xbf16>
    %10294 = stablehlo.reshape %10293 : (tensor<1x2048x15x20xbf16>) -> tensor<1x2048x300xbf16>
    %10295 = stablehlo.transpose %10294, dims = [0, 2, 1] : (tensor<1x2048x300xbf16>) -> tensor<1x300x2048xbf16>
    %10296 = stablehlo.multiply %10295, %cst_61 : tensor<1x300x2048xbf16>
    %10297 = stablehlo.multiply %10295, %10092 : tensor<1x300x2048xbf16>
    %10298 = stablehlo.convert %10297 : (tensor<1x300x2048xbf16>) -> tensor<1x300x2048xf32>
    %10299 = stablehlo.clamp %cst_62, %10298, %cst_63 : tensor<1x300x2048xf32>
    %10300 = stablehlo.multiply %10299, %10299 : tensor<1x300x2048xf32>
    %10301 = stablehlo.multiply %cst_64, %10300 : tensor<1x300x2048xf32>
    %10302 = stablehlo.add %10301, %cst_65 : tensor<1x300x2048xf32>
    %10303 = stablehlo.multiply %10302, %10300 : tensor<1x300x2048xf32>
    %10304 = stablehlo.add %10303, %cst_66 : tensor<1x300x2048xf32>
    %10305 = stablehlo.multiply %10304, %10300 : tensor<1x300x2048xf32>
    %10306 = stablehlo.add %10305, %cst_67 : tensor<1x300x2048xf32>
    %10307 = stablehlo.multiply %10306, %10300 : tensor<1x300x2048xf32>
    %10308 = stablehlo.add %10307, %cst_68 : tensor<1x300x2048xf32>
    %10309 = stablehlo.multiply %10308, %10300 : tensor<1x300x2048xf32>
    %10310 = stablehlo.add %10309, %cst_69 : tensor<1x300x2048xf32>
    %10311 = stablehlo.multiply %10310, %10300 : tensor<1x300x2048xf32>
    %10312 = stablehlo.add %10311, %cst_70 : tensor<1x300x2048xf32>
    %10313 = stablehlo.multiply %cst_71, %10300 : tensor<1x300x2048xf32>
    %10314 = stablehlo.add %10313, %cst_72 : tensor<1x300x2048xf32>
    %10315 = stablehlo.multiply %10314, %10300 : tensor<1x300x2048xf32>
    %10316 = stablehlo.add %10315, %cst_73 : tensor<1x300x2048xf32>
    %10317 = stablehlo.multiply %10316, %10300 : tensor<1x300x2048xf32>
    %10318 = stablehlo.add %10317, %cst_74 : tensor<1x300x2048xf32>
    %10319 = stablehlo.multiply %10318, %10300 : tensor<1x300x2048xf32>
    %10320 = stablehlo.add %10319, %cst_75 : tensor<1x300x2048xf32>
    %10321 = stablehlo.multiply %10299, %10312 : tensor<1x300x2048xf32>
    %10322 = stablehlo.divide %10321, %10320 : tensor<1x300x2048xf32>
    %10323 = stablehlo.clamp %cst_76, %10322, %cst_77 : tensor<1x300x2048xf32>
    %10324 = stablehlo.convert %10323 : (tensor<1x300x2048xf32>) -> tensor<1x300x2048xbf16>
    %10325 = stablehlo.add %10324, %cst_59 : tensor<1x300x2048xbf16>
    %10326 = stablehlo.multiply %10325, %10296 : tensor<1x300x2048xbf16>
    %10327 = stablehlo.reshape %10326 : (tensor<1x300x2048xbf16>) -> tensor<300x2048xbf16>
    %10328 = stablehlo.dot_general %10327, %arg931, contracting_dims = [1] x [0] : (tensor<300x2048xbf16>, tensor<2048x512xbf16>) -> tensor<300x512xbf16>
    %10329 = stablehlo.reshape %10328 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10330 = stablehlo.broadcast_in_dim %10329, dims = [0, 1, 2] : (tensor<1x300x512xbf16>) -> tensor<1x300x512xbf16>
    %10331 = stablehlo.broadcast_in_dim %arg454, dims = [2] : (tensor<512xbf16>) -> tensor<1x300x512xbf16>
    %10332 = stablehlo.add %10330, %10331 : tensor<1x300x512xbf16>
    %10333 = stablehlo.reshape %10332 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10334 = stablehlo.reshape %10333 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10335 = stablehlo.add %10334, %10239 : tensor<1x300x512xbf16>
    %10336 = stablehlo.convert %10335 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %10337 = stablehlo.convert %10336 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %10338 = stablehlo.reduce(%10337 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10339 = stablehlo.reshape %10338 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10340 = stablehlo.broadcast_in_dim %10339, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10341 = stablehlo.divide %10340, %9888 : tensor<1x300x1xf64>
    %10342 = stablehlo.broadcast_in_dim %10337, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %10343 = stablehlo.broadcast_in_dim %10341, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %10344 = stablehlo.subtract %10342, %10343 : tensor<1x300x512xf64>
    %10345 = stablehlo.multiply %10344, %10344 : tensor<1x300x512xf64>
    %10346 = stablehlo.reduce(%10345 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10347 = stablehlo.reshape %10346 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10348 = stablehlo.broadcast_in_dim %10347, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10349 = stablehlo.divide %10348, %9888 : tensor<1x300x1xf64>
    %10350 = stablehlo.convert %10349 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %10351 = stablehlo.reduce(%10336 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %10352 = stablehlo.reshape %10351 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %10353 = stablehlo.broadcast_in_dim %10352, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10354 = stablehlo.divide %10353, %9904 : tensor<1x300x1xf32>
    %10355 = stablehlo.broadcast_in_dim %10350, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10356 = stablehlo.add %10355, %136 : tensor<1x300x1xf32>
    %10357 = stablehlo.rsqrt %10356 : tensor<1x300x1xf32>
    %10358 = stablehlo.broadcast_in_dim %10336, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10359 = stablehlo.broadcast_in_dim %10354, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10360 = stablehlo.subtract %10358, %10359 : tensor<1x300x512xf32>
    %10361 = stablehlo.broadcast_in_dim %10360, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10362 = stablehlo.broadcast_in_dim %10357, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10363 = stablehlo.multiply %10361, %10362 : tensor<1x300x512xf32>
    %10364 = stablehlo.convert %arg455 : (tensor<512xbf16>) -> tensor<512xf32>
    %10365 = stablehlo.broadcast_in_dim %10363, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10366 = stablehlo.broadcast_in_dim %10364, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10367 = stablehlo.multiply %10365, %10366 : tensor<1x300x512xf32>
    %10368 = stablehlo.convert %arg456 : (tensor<512xbf16>) -> tensor<512xf32>
    %10369 = stablehlo.broadcast_in_dim %10367, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10370 = stablehlo.broadcast_in_dim %10368, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10371 = stablehlo.add %10369, %10370 : tensor<1x300x512xf32>
    %10372 = stablehlo.convert %10371 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %10373 = stablehlo.reshape %10372 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10374 = stablehlo.convert %10373 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10375 = stablehlo.dot_general %10374, %arg932, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10376 = stablehlo.broadcast_in_dim %10375, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10377 = stablehlo.multiply %10376, %9965 : tensor<300x512xf32>
    %10378 = stablehlo.broadcast_in_dim %10377, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10379 = stablehlo.broadcast_in_dim %arg933, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10380 = stablehlo.add %10378, %10379 : tensor<300x512xf32>
    %10381 = stablehlo.convert %10380 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10382 = stablehlo.reshape %10381 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10383 = stablehlo.reshape %10382 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %10384 = stablehlo.transpose %10383, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10385 = stablehlo.dot_general %10374, %arg934, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10386 = stablehlo.broadcast_in_dim %10385, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10387 = stablehlo.multiply %10386, %9965 : tensor<300x512xf32>
    %10388 = stablehlo.broadcast_in_dim %10387, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10389 = stablehlo.broadcast_in_dim %arg935, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10390 = stablehlo.add %10388, %10389 : tensor<300x512xf32>
    %10391 = stablehlo.convert %10390 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10392 = stablehlo.reshape %10391 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10393 = stablehlo.reshape %10392 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %10394 = stablehlo.transpose %10393, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10395 = stablehlo.dot_general %10374, %arg936, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10396 = stablehlo.broadcast_in_dim %10395, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10397 = stablehlo.multiply %10396, %9965 : tensor<300x512xf32>
    %10398 = stablehlo.broadcast_in_dim %10397, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10399 = stablehlo.broadcast_in_dim %arg937, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10400 = stablehlo.add %10398, %10399 : tensor<300x512xf32>
    %10401 = stablehlo.convert %10400 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10402 = stablehlo.reshape %10401 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10403 = stablehlo.reshape %10402 : (tensor<1x300x512xbf16>) -> tensor<1x300x8x64xbf16>
    %10404 = stablehlo.transpose %10403, dims = [0, 2, 1, 3] : (tensor<1x300x8x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10405 = stablehlo.transpose %10394, dims = [0, 1, 3, 2] : (tensor<1x8x300x64xbf16>) -> tensor<1x8x64x300xbf16>
    %10406 = stablehlo.reshape %10384 : (tensor<1x8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10407 = stablehlo.reshape %10405 : (tensor<1x8x64x300xbf16>) -> tensor<8x64x300xbf16>
    %10408 = stablehlo.broadcast_in_dim %10407, dims = [0, 1, 2] : (tensor<8x64x300xbf16>) -> tensor<8x64x300xbf16>
    %10409 = stablehlo.dot_general %10406, %10408, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<8x300x64xbf16>, tensor<8x64x300xbf16>) -> tensor<8x300x300xbf16>
    %10410 = stablehlo.reshape %10409 : (tensor<8x300x300xbf16>) -> tensor<1x8x300x300xbf16>
    %10411 = stablehlo.broadcast_in_dim %10410, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xbf16>) -> tensor<1x8x300x300xbf16>
    %10412 = stablehlo.divide %10411, %10001 : tensor<1x8x300x300xbf16>
    %10413 = stablehlo.convert %10412 : (tensor<1x8x300x300xbf16>) -> tensor<1x8x300x300xf32>
    %10414 = stablehlo.reduce(%10413 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x8x300x300xf32>, tensor<f32>) -> tensor<1x8x300xf32>
    %10415 = stablehlo.reshape %10414 : (tensor<1x8x300xf32>) -> tensor<1x8x300x1xf32>
    %10416 = stablehlo.broadcast_in_dim %10413, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xf32>
    %10417 = stablehlo.broadcast_in_dim %10415, dims = [0, 1, 2, 3] : (tensor<1x8x300x1xf32>) -> tensor<1x8x300x300xf32>
    %10418 = stablehlo.subtract %10416, %10417 : tensor<1x8x300x300xf32>
    %10419 = stablehlo.exponential %10418 : tensor<1x8x300x300xf32>
    %10420 = stablehlo.reduce(%10419 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x8x300x300xf32>, tensor<f32>) -> tensor<1x8x300xf32>
    %10421 = stablehlo.reshape %10420 : (tensor<1x8x300xf32>) -> tensor<1x8x300x1xf32>
    %10422 = stablehlo.broadcast_in_dim %10419, dims = [0, 1, 2, 3] : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xf32>
    %10423 = stablehlo.broadcast_in_dim %10421, dims = [0, 1, 2, 3] : (tensor<1x8x300x1xf32>) -> tensor<1x8x300x300xf32>
    %10424 = stablehlo.divide %10422, %10423 : tensor<1x8x300x300xf32>
    %10425 = stablehlo.convert %10424 : (tensor<1x8x300x300xf32>) -> tensor<1x8x300x300xbf16>
    %10426 = stablehlo.reshape %10425 : (tensor<1x8x300x300xbf16>) -> tensor<8x300x300xbf16>
    %10427 = stablehlo.reshape %10404 : (tensor<1x8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10428 = stablehlo.broadcast_in_dim %10427, dims = [0, 1, 2] : (tensor<8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10429 = stablehlo.dot_general %10426, %10428, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<8x300x300xbf16>, tensor<8x300x64xbf16>) -> tensor<8x300x64xbf16>
    %10430 = stablehlo.reshape %10429 : (tensor<8x300x64xbf16>) -> tensor<1x8x300x64xbf16>
    %10431 = stablehlo.transpose %10430, dims = [0, 2, 1, 3] : (tensor<1x8x300x64xbf16>) -> tensor<1x300x8x64xbf16>
    %10432 = stablehlo.reshape %10431 : (tensor<1x300x8x64xbf16>) -> tensor<1x300x512xbf16>
    %10433 = stablehlo.reshape %10432 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10434 = stablehlo.convert %10433 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10435 = stablehlo.dot_general %10434, %arg938, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x512xf32>) -> tensor<300x512xf32>
    %10436 = stablehlo.broadcast_in_dim %10435, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10437 = stablehlo.multiply %10436, %9965 : tensor<300x512xf32>
    %10438 = stablehlo.broadcast_in_dim %10437, dims = [0, 1] : (tensor<300x512xf32>) -> tensor<300x512xf32>
    %10439 = stablehlo.broadcast_in_dim %arg939, dims = [1] : (tensor<512xf32>) -> tensor<300x512xf32>
    %10440 = stablehlo.add %10438, %10439 : tensor<300x512xf32>
    %10441 = stablehlo.convert %10440 : (tensor<300x512xf32>) -> tensor<300x512xbf16>
    %10442 = stablehlo.reshape %10441 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10443 = stablehlo.add %10442, %10335 : tensor<1x300x512xbf16>
    %10444 = stablehlo.convert %10443 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %10445 = stablehlo.convert %10444 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %10446 = stablehlo.reduce(%10445 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10447 = stablehlo.reshape %10446 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10448 = stablehlo.broadcast_in_dim %10447, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10449 = stablehlo.divide %10448, %9888 : tensor<1x300x1xf64>
    %10450 = stablehlo.broadcast_in_dim %10445, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %10451 = stablehlo.broadcast_in_dim %10449, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %10452 = stablehlo.subtract %10450, %10451 : tensor<1x300x512xf64>
    %10453 = stablehlo.multiply %10452, %10452 : tensor<1x300x512xf64>
    %10454 = stablehlo.reduce(%10453 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10455 = stablehlo.reshape %10454 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10456 = stablehlo.broadcast_in_dim %10455, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10457 = stablehlo.divide %10456, %9888 : tensor<1x300x1xf64>
    %10458 = stablehlo.convert %10457 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %10459 = stablehlo.reduce(%10444 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %10460 = stablehlo.reshape %10459 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %10461 = stablehlo.broadcast_in_dim %10460, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10462 = stablehlo.divide %10461, %9904 : tensor<1x300x1xf32>
    %10463 = stablehlo.broadcast_in_dim %10458, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10464 = stablehlo.add %10463, %136 : tensor<1x300x1xf32>
    %10465 = stablehlo.rsqrt %10464 : tensor<1x300x1xf32>
    %10466 = stablehlo.broadcast_in_dim %10444, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10467 = stablehlo.broadcast_in_dim %10462, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10468 = stablehlo.subtract %10466, %10467 : tensor<1x300x512xf32>
    %10469 = stablehlo.broadcast_in_dim %10468, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10470 = stablehlo.broadcast_in_dim %10465, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10471 = stablehlo.multiply %10469, %10470 : tensor<1x300x512xf32>
    %10472 = stablehlo.convert %arg457 : (tensor<512xbf16>) -> tensor<512xf32>
    %10473 = stablehlo.broadcast_in_dim %10471, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10474 = stablehlo.broadcast_in_dim %10472, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10475 = stablehlo.multiply %10473, %10474 : tensor<1x300x512xf32>
    %10476 = stablehlo.convert %arg458 : (tensor<512xbf16>) -> tensor<512xf32>
    %10477 = stablehlo.broadcast_in_dim %10475, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10478 = stablehlo.broadcast_in_dim %10476, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10479 = stablehlo.add %10477, %10478 : tensor<1x300x512xf32>
    %10480 = stablehlo.convert %10479 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %10481 = stablehlo.reshape %10480 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10482 = stablehlo.convert %10481 : (tensor<300x512xbf16>) -> tensor<300x512xf32>
    %10483 = stablehlo.dot_general %10482, %arg940, contracting_dims = [1] x [0] : (tensor<300x512xf32>, tensor<512x2048xf32>) -> tensor<300x2048xf32>
    %10484 = stablehlo.broadcast_in_dim %10483, dims = [0, 1] : (tensor<300x2048xf32>) -> tensor<300x2048xf32>
    %10485 = stablehlo.multiply %10484, %10075 : tensor<300x2048xf32>
    %10486 = stablehlo.broadcast_in_dim %10485, dims = [0, 1] : (tensor<300x2048xf32>) -> tensor<300x2048xf32>
    %10487 = stablehlo.broadcast_in_dim %arg941, dims = [1] : (tensor<2048xf32>) -> tensor<300x2048xf32>
    %10488 = stablehlo.add %10486, %10487 : tensor<300x2048xf32>
    %10489 = stablehlo.convert %10488 : (tensor<300x2048xf32>) -> tensor<300x2048xbf16>
    %10490 = stablehlo.reshape %10489 : (tensor<300x2048xbf16>) -> tensor<1x300x2048xbf16>
    %10491 = stablehlo.transpose %10490, dims = [0, 2, 1] : (tensor<1x300x2048xbf16>) -> tensor<1x2048x300xbf16>
    %10492 = stablehlo.reshape %10491 : (tensor<1x2048x300xbf16>) -> tensor<1x2048x15x20xbf16>
    %10493 = stablehlo.convolution(%10492, %arg459) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 2048 : i64} : (tensor<1x2048x15x20xbf16>, tensor<2048x1x3x3xbf16>) -> tensor<1x2048x15x20xbf16>
    %10494 = stablehlo.reshape %arg460 : (tensor<2048xbf16>) -> tensor<2048x1x1xbf16>
    %10495 = stablehlo.broadcast_in_dim %10493, dims = [0, 1, 2, 3] : (tensor<1x2048x15x20xbf16>) -> tensor<1x2048x15x20xbf16>
    %10496 = stablehlo.broadcast_in_dim %10494, dims = [1, 2, 3] : (tensor<2048x1x1xbf16>) -> tensor<1x2048x15x20xbf16>
    %10497 = stablehlo.add %10495, %10496 : tensor<1x2048x15x20xbf16>
    %10498 = stablehlo.reshape %10497 : (tensor<1x2048x15x20xbf16>) -> tensor<1x2048x300xbf16>
    %10499 = stablehlo.transpose %10498, dims = [0, 2, 1] : (tensor<1x2048x300xbf16>) -> tensor<1x300x2048xbf16>
    %10500 = stablehlo.multiply %10499, %cst_61 : tensor<1x300x2048xbf16>
    %10501 = stablehlo.multiply %10499, %10092 : tensor<1x300x2048xbf16>
    %10502 = stablehlo.convert %10501 : (tensor<1x300x2048xbf16>) -> tensor<1x300x2048xf32>
    %10503 = stablehlo.clamp %cst_62, %10502, %cst_63 : tensor<1x300x2048xf32>
    %10504 = stablehlo.multiply %10503, %10503 : tensor<1x300x2048xf32>
    %10505 = stablehlo.multiply %cst_64, %10504 : tensor<1x300x2048xf32>
    %10506 = stablehlo.add %10505, %cst_65 : tensor<1x300x2048xf32>
    %10507 = stablehlo.multiply %10506, %10504 : tensor<1x300x2048xf32>
    %10508 = stablehlo.add %10507, %cst_66 : tensor<1x300x2048xf32>
    %10509 = stablehlo.multiply %10508, %10504 : tensor<1x300x2048xf32>
    %10510 = stablehlo.add %10509, %cst_67 : tensor<1x300x2048xf32>
    %10511 = stablehlo.multiply %10510, %10504 : tensor<1x300x2048xf32>
    %10512 = stablehlo.add %10511, %cst_68 : tensor<1x300x2048xf32>
    %10513 = stablehlo.multiply %10512, %10504 : tensor<1x300x2048xf32>
    %10514 = stablehlo.add %10513, %cst_69 : tensor<1x300x2048xf32>
    %10515 = stablehlo.multiply %10514, %10504 : tensor<1x300x2048xf32>
    %10516 = stablehlo.add %10515, %cst_70 : tensor<1x300x2048xf32>
    %10517 = stablehlo.multiply %cst_71, %10504 : tensor<1x300x2048xf32>
    %10518 = stablehlo.add %10517, %cst_72 : tensor<1x300x2048xf32>
    %10519 = stablehlo.multiply %10518, %10504 : tensor<1x300x2048xf32>
    %10520 = stablehlo.add %10519, %cst_73 : tensor<1x300x2048xf32>
    %10521 = stablehlo.multiply %10520, %10504 : tensor<1x300x2048xf32>
    %10522 = stablehlo.add %10521, %cst_74 : tensor<1x300x2048xf32>
    %10523 = stablehlo.multiply %10522, %10504 : tensor<1x300x2048xf32>
    %10524 = stablehlo.add %10523, %cst_75 : tensor<1x300x2048xf32>
    %10525 = stablehlo.multiply %10503, %10516 : tensor<1x300x2048xf32>
    %10526 = stablehlo.divide %10525, %10524 : tensor<1x300x2048xf32>
    %10527 = stablehlo.clamp %cst_76, %10526, %cst_77 : tensor<1x300x2048xf32>
    %10528 = stablehlo.convert %10527 : (tensor<1x300x2048xf32>) -> tensor<1x300x2048xbf16>
    %10529 = stablehlo.add %10528, %cst_59 : tensor<1x300x2048xbf16>
    %10530 = stablehlo.multiply %10529, %10500 : tensor<1x300x2048xbf16>
    %10531 = stablehlo.reshape %10530 : (tensor<1x300x2048xbf16>) -> tensor<300x2048xbf16>
    %10532 = stablehlo.dot_general %10531, %arg942, contracting_dims = [1] x [0] : (tensor<300x2048xbf16>, tensor<2048x512xbf16>) -> tensor<300x512xbf16>
    %10533 = stablehlo.reshape %10532 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10534 = stablehlo.broadcast_in_dim %10533, dims = [0, 1, 2] : (tensor<1x300x512xbf16>) -> tensor<1x300x512xbf16>
    %10535 = stablehlo.broadcast_in_dim %arg461, dims = [2] : (tensor<512xbf16>) -> tensor<1x300x512xbf16>
    %10536 = stablehlo.add %10534, %10535 : tensor<1x300x512xbf16>
    %10537 = stablehlo.reshape %10536 : (tensor<1x300x512xbf16>) -> tensor<300x512xbf16>
    %10538 = stablehlo.reshape %10537 : (tensor<300x512xbf16>) -> tensor<1x300x512xbf16>
    %10539 = stablehlo.add %10538, %10443 : tensor<1x300x512xbf16>
    %10540 = stablehlo.convert %10539 : (tensor<1x300x512xbf16>) -> tensor<1x300x512xf32>
    %10541 = stablehlo.convert %10540 : (tensor<1x300x512xf32>) -> tensor<1x300x512xf64>
    %10542 = stablehlo.reduce(%10541 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10543 = stablehlo.reshape %10542 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10544 = stablehlo.broadcast_in_dim %10543, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10545 = stablehlo.divide %10544, %9888 : tensor<1x300x1xf64>
    %10546 = stablehlo.broadcast_in_dim %10541, dims = [0, 1, 2] : (tensor<1x300x512xf64>) -> tensor<1x300x512xf64>
    %10547 = stablehlo.broadcast_in_dim %10545, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x512xf64>
    %10548 = stablehlo.subtract %10546, %10547 : tensor<1x300x512xf64>
    %10549 = stablehlo.multiply %10548, %10548 : tensor<1x300x512xf64>
    %10550 = stablehlo.reduce(%10549 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf64>, tensor<f64>) -> tensor<1x300xf64>
    %10551 = stablehlo.reshape %10550 : (tensor<1x300xf64>) -> tensor<1x300x1xf64>
    %10552 = stablehlo.broadcast_in_dim %10551, dims = [0, 1, 2] : (tensor<1x300x1xf64>) -> tensor<1x300x1xf64>
    %10553 = stablehlo.divide %10552, %9888 : tensor<1x300x1xf64>
    %10554 = stablehlo.convert %10553 : (tensor<1x300x1xf64>) -> tensor<1x300x1xf32>
    %10555 = stablehlo.reduce(%10540 init: %cst_0) applies stablehlo.add across dimensions = [2] : (tensor<1x300x512xf32>, tensor<f32>) -> tensor<1x300xf32>
    %10556 = stablehlo.reshape %10555 : (tensor<1x300xf32>) -> tensor<1x300x1xf32>
    %10557 = stablehlo.broadcast_in_dim %10556, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10558 = stablehlo.divide %10557, %9904 : tensor<1x300x1xf32>
    %10559 = stablehlo.broadcast_in_dim %10554, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x1xf32>
    %10560 = stablehlo.add %10559, %136 : tensor<1x300x1xf32>
    %10561 = stablehlo.rsqrt %10560 : tensor<1x300x1xf32>
    %10562 = stablehlo.broadcast_in_dim %10540, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10563 = stablehlo.broadcast_in_dim %10558, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10564 = stablehlo.subtract %10562, %10563 : tensor<1x300x512xf32>
    %10565 = stablehlo.broadcast_in_dim %10564, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10566 = stablehlo.broadcast_in_dim %10561, dims = [0, 1, 2] : (tensor<1x300x1xf32>) -> tensor<1x300x512xf32>
    %10567 = stablehlo.multiply %10565, %10566 : tensor<1x300x512xf32>
    %10568 = stablehlo.convert %arg462 : (tensor<512xbf16>) -> tensor<512xf32>
    %10569 = stablehlo.broadcast_in_dim %10567, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10570 = stablehlo.broadcast_in_dim %10568, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10571 = stablehlo.multiply %10569, %10570 : tensor<1x300x512xf32>
    %10572 = stablehlo.convert %arg463 : (tensor<512xbf16>) -> tensor<512xf32>
    %10573 = stablehlo.broadcast_in_dim %10571, dims = [0, 1, 2] : (tensor<1x300x512xf32>) -> tensor<1x300x512xf32>
    %10574 = stablehlo.broadcast_in_dim %10572, dims = [2] : (tensor<512xf32>) -> tensor<1x300x512xf32>
    %10575 = stablehlo.add %10573, %10574 : tensor<1x300x512xf32>
    %10576 = stablehlo.convert %10575 : (tensor<1x300x512xf32>) -> tensor<1x300x512xbf16>
    %10577 = stablehlo.reshape %10576 : (tensor<1x300x512xbf16>) -> tensor<1x15x20x512xbf16>
    %10578 = stablehlo.transpose %10577, dims = [0, 3, 1, 2] : (tensor<1x15x20x512xbf16>) -> tensor<1x512x15x20xbf16>
    %10579 = stablehlo.convolution(%10578, %arg464) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x512x15x20xbf16>, tensor<64x512x1x1xbf16>) -> tensor<1x64x15x20xbf16>
    %10580 = stablehlo.reshape %arg465 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10581 = stablehlo.broadcast_in_dim %10579, dims = [0, 1, 2, 3] : (tensor<1x64x15x20xbf16>) -> tensor<1x64x15x20xbf16>
    %10582 = stablehlo.broadcast_in_dim %10580, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x15x20xbf16>
    %10583 = stablehlo.add %10581, %10582 : tensor<1x64x15x20xbf16>
    %10584 = stablehlo.transpose %10583, dims = [0, 1, 3, 2] : (tensor<1x64x15x20xbf16>) -> tensor<1x64x20x15xbf16>
    %10585 = stablehlo.reshape %10584 : (tensor<1x64x20x15xbf16>) -> tensor<64x20x15xbf16>
    %10586 = stablehlo.broadcast_in_dim %arg943, dims = [0, 1, 2] : (tensor<64x15x30xbf16>) -> tensor<64x15x30xbf16>
    %10587 = stablehlo.dot_general %10585, %10586, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x20x15xbf16>, tensor<64x15x30xbf16>) -> tensor<64x20x30xbf16>
    %10588 = stablehlo.reshape %10587 : (tensor<64x20x30xbf16>) -> tensor<1x64x20x30xbf16>
    %10589 = stablehlo.transpose %10588, dims = [0, 1, 3, 2] : (tensor<1x64x20x30xbf16>) -> tensor<1x64x30x20xbf16>
    %10590 = stablehlo.reshape %10589 : (tensor<1x64x30x20xbf16>) -> tensor<64x30x20xbf16>
    %10591 = stablehlo.broadcast_in_dim %arg944, dims = [0, 1, 2] : (tensor<64x20x40xbf16>) -> tensor<64x20x40xbf16>
    %10592 = stablehlo.dot_general %10590, %10591, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x30x20xbf16>, tensor<64x20x40xbf16>) -> tensor<64x30x40xbf16>
    %10593 = stablehlo.reshape %10592 : (tensor<64x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10594 = stablehlo.convolution(%9873, %arg466) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x320x30x40xbf16>, tensor<64x320x1x1xbf16>) -> tensor<1x64x30x40xbf16>
    %10595 = stablehlo.reshape %arg467 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10596 = stablehlo.broadcast_in_dim %10594, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10597 = stablehlo.broadcast_in_dim %10595, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x30x40xbf16>
    %10598 = stablehlo.add %10596, %10597 : tensor<1x64x30x40xbf16>
    %10599 = stablehlo.concatenate %10598, %10593, dim = 1 : (tensor<1x64x30x40xbf16>, tensor<1x64x30x40xbf16>) -> tensor<1x128x30x40xbf16>
    %10600 = stablehlo.convolution(%10599, %arg468) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x30x40xbf16>, tensor<64x128x3x3xbf16>) -> tensor<1x64x30x40xbf16>
    %10601 = stablehlo.reshape %arg469 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10602 = stablehlo.broadcast_in_dim %10600, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10603 = stablehlo.broadcast_in_dim %10601, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x30x40xbf16>
    %10604 = stablehlo.add %10602, %10603 : tensor<1x64x30x40xbf16>
    %10605 = stablehlo.convert %10604 : (tensor<1x64x30x40xbf16>) -> tensor<1x64x30x40xf32>
    %10606 = stablehlo.broadcast_in_dim %10605, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xf32>) -> tensor<1x64x30x40xf32>
    %10607 = stablehlo.broadcast_in_dim %arg945, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x30x40xf32>
    %10608 = stablehlo.subtract %10606, %10607 : tensor<1x64x30x40xf32>
    %10609 = stablehlo.broadcast_in_dim %10608, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xf32>) -> tensor<1x64x30x40xf32>
    %10610 = stablehlo.broadcast_in_dim %arg946, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x30x40xf32>
    %10611 = stablehlo.multiply %10609, %10610 : tensor<1x64x30x40xf32>
    %10612 = stablehlo.convert %arg947 : (tensor<64x1x1xbf16>) -> tensor<64x1x1xf32>
    %10613 = stablehlo.broadcast_in_dim %10611, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xf32>) -> tensor<1x64x30x40xf32>
    %10614 = stablehlo.broadcast_in_dim %10612, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x30x40xf32>
    %10615 = stablehlo.multiply %10613, %10614 : tensor<1x64x30x40xf32>
    %10616 = stablehlo.convert %arg948 : (tensor<64x1x1xbf16>) -> tensor<64x1x1xf32>
    %10617 = stablehlo.broadcast_in_dim %10615, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xf32>) -> tensor<1x64x30x40xf32>
    %10618 = stablehlo.broadcast_in_dim %10616, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x30x40xf32>
    %10619 = stablehlo.add %10617, %10618 : tensor<1x64x30x40xf32>
    %10620 = stablehlo.convert %10619 : (tensor<1x64x30x40xf32>) -> tensor<1x64x30x40xbf16>
    %10621 = stablehlo.maximum %10620, %cst_78 : tensor<1x64x30x40xbf16>
    %10622 = stablehlo.convolution(%10621, %arg470) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x30x40xbf16>, tensor<32x64x3x3xbf16>) -> tensor<1x32x30x40xbf16>
    %10623 = stablehlo.reshape %arg471 : (tensor<32xbf16>) -> tensor<32x1x1xbf16>
    %10624 = stablehlo.broadcast_in_dim %10622, dims = [0, 1, 2, 3] : (tensor<1x32x30x40xbf16>) -> tensor<1x32x30x40xbf16>
    %10625 = stablehlo.broadcast_in_dim %10623, dims = [1, 2, 3] : (tensor<32x1x1xbf16>) -> tensor<1x32x30x40xbf16>
    %10626 = stablehlo.add %10624, %10625 : tensor<1x32x30x40xbf16>
    %10627 = stablehlo.convert %10626 : (tensor<1x32x30x40xbf16>) -> tensor<1x32x30x40xf32>
    %10628 = stablehlo.broadcast_in_dim %10627, dims = [0, 1, 2, 3] : (tensor<1x32x30x40xf32>) -> tensor<1x32x30x40xf32>
    %10629 = stablehlo.broadcast_in_dim %arg949, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x30x40xf32>
    %10630 = stablehlo.subtract %10628, %10629 : tensor<1x32x30x40xf32>
    %10631 = stablehlo.broadcast_in_dim %10630, dims = [0, 1, 2, 3] : (tensor<1x32x30x40xf32>) -> tensor<1x32x30x40xf32>
    %10632 = stablehlo.broadcast_in_dim %arg950, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x30x40xf32>
    %10633 = stablehlo.multiply %10631, %10632 : tensor<1x32x30x40xf32>
    %10634 = stablehlo.convert %arg951 : (tensor<32x1x1xbf16>) -> tensor<32x1x1xf32>
    %10635 = stablehlo.broadcast_in_dim %10633, dims = [0, 1, 2, 3] : (tensor<1x32x30x40xf32>) -> tensor<1x32x30x40xf32>
    %10636 = stablehlo.broadcast_in_dim %10634, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x30x40xf32>
    %10637 = stablehlo.multiply %10635, %10636 : tensor<1x32x30x40xf32>
    %10638 = stablehlo.convert %arg952 : (tensor<32x1x1xbf16>) -> tensor<32x1x1xf32>
    %10639 = stablehlo.broadcast_in_dim %10637, dims = [0, 1, 2, 3] : (tensor<1x32x30x40xf32>) -> tensor<1x32x30x40xf32>
    %10640 = stablehlo.broadcast_in_dim %10638, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x30x40xf32>
    %10641 = stablehlo.add %10639, %10640 : tensor<1x32x30x40xf32>
    %10642 = stablehlo.convert %10641 : (tensor<1x32x30x40xf32>) -> tensor<1x32x30x40xbf16>
    %10643 = stablehlo.maximum %10642, %cst_79 : tensor<1x32x30x40xbf16>
    %10644 = stablehlo.convolution(%10643, %arg472) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x32x30x40xbf16>, tensor<2x32x3x3xbf16>) -> tensor<1x2x30x40xbf16>
    %10645 = stablehlo.reshape %arg473 : (tensor<2xbf16>) -> tensor<2x1x1xbf16>
    %10646 = stablehlo.broadcast_in_dim %10644, dims = [0, 1, 2, 3] : (tensor<1x2x30x40xbf16>) -> tensor<1x2x30x40xbf16>
    %10647 = stablehlo.broadcast_in_dim %10645, dims = [1, 2, 3] : (tensor<2x1x1xbf16>) -> tensor<1x2x30x40xbf16>
    %10648 = stablehlo.add %10646, %10647 : tensor<1x2x30x40xbf16>
    %10649 = stablehlo.logistic %10648 : tensor<1x2x30x40xbf16>
    %10650 = stablehlo.slice %10649 [0:1, 0:1, 0:30, 0:40] : (tensor<1x2x30x40xbf16>) -> tensor<1x1x30x40xbf16>
    %10651 = stablehlo.reshape %10650 : (tensor<1x1x30x40xbf16>) -> tensor<1x30x40xbf16>
    %10652 = stablehlo.reshape %10651 : (tensor<1x30x40xbf16>) -> tensor<1x1x30x40xbf16>
    %10653 = stablehlo.broadcast_in_dim %10598, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10654 = stablehlo.broadcast_in_dim %10652, dims = [0, 1, 2, 3] : (tensor<1x1x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10655 = stablehlo.multiply %10653, %10654 : tensor<1x64x30x40xbf16>
    %10656 = stablehlo.slice %10649 [0:1, 1:2, 0:30, 0:40] : (tensor<1x2x30x40xbf16>) -> tensor<1x1x30x40xbf16>
    %10657 = stablehlo.reshape %10656 : (tensor<1x1x30x40xbf16>) -> tensor<1x30x40xbf16>
    %10658 = stablehlo.reshape %10657 : (tensor<1x30x40xbf16>) -> tensor<1x1x30x40xbf16>
    %10659 = stablehlo.broadcast_in_dim %10593, dims = [0, 1, 2, 3] : (tensor<1x64x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10660 = stablehlo.broadcast_in_dim %10658, dims = [0, 1, 2, 3] : (tensor<1x1x30x40xbf16>) -> tensor<1x64x30x40xbf16>
    %10661 = stablehlo.multiply %10659, %10660 : tensor<1x64x30x40xbf16>
    %10662 = stablehlo.add %10655, %10661 : tensor<1x64x30x40xbf16>
    %10663 = stablehlo.transpose %10662, dims = [0, 1, 3, 2] : (tensor<1x64x30x40xbf16>) -> tensor<1x64x40x30xbf16>
    %10664 = stablehlo.reshape %10663 : (tensor<1x64x40x30xbf16>) -> tensor<64x40x30xbf16>
    %10665 = stablehlo.broadcast_in_dim %arg953, dims = [0, 1, 2] : (tensor<64x30x60xbf16>) -> tensor<64x30x60xbf16>
    %10666 = stablehlo.dot_general %10664, %10665, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x40x30xbf16>, tensor<64x30x60xbf16>) -> tensor<64x40x60xbf16>
    %10667 = stablehlo.reshape %10666 : (tensor<64x40x60xbf16>) -> tensor<1x64x40x60xbf16>
    %10668 = stablehlo.transpose %10667, dims = [0, 1, 3, 2] : (tensor<1x64x40x60xbf16>) -> tensor<1x64x60x40xbf16>
    %10669 = stablehlo.reshape %10668 : (tensor<1x64x60x40xbf16>) -> tensor<64x60x40xbf16>
    %10670 = stablehlo.broadcast_in_dim %arg954, dims = [0, 1, 2] : (tensor<64x40x80xbf16>) -> tensor<64x40x80xbf16>
    %10671 = stablehlo.dot_general %10669, %10670, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x60x40xbf16>, tensor<64x40x80xbf16>) -> tensor<64x60x80xbf16>
    %10672 = stablehlo.reshape %10671 : (tensor<64x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10673 = stablehlo.convolution(%2972, %arg474) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[0, 0], [0, 0]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<64x128x1x1xbf16>) -> tensor<1x64x60x80xbf16>
    %10674 = stablehlo.reshape %arg475 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10675 = stablehlo.broadcast_in_dim %10673, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10676 = stablehlo.broadcast_in_dim %10674, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x60x80xbf16>
    %10677 = stablehlo.add %10675, %10676 : tensor<1x64x60x80xbf16>
    %10678 = stablehlo.concatenate %10677, %10672, dim = 1 : (tensor<1x64x60x80xbf16>, tensor<1x64x60x80xbf16>) -> tensor<1x128x60x80xbf16>
    %10679 = stablehlo.convolution(%10678, %arg476) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x60x80xbf16>, tensor<64x128x3x3xbf16>) -> tensor<1x64x60x80xbf16>
    %10680 = stablehlo.reshape %arg477 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10681 = stablehlo.broadcast_in_dim %10679, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10682 = stablehlo.broadcast_in_dim %10680, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x60x80xbf16>
    %10683 = stablehlo.add %10681, %10682 : tensor<1x64x60x80xbf16>
    %10684 = stablehlo.convert %10683 : (tensor<1x64x60x80xbf16>) -> tensor<1x64x60x80xf32>
    %10685 = stablehlo.broadcast_in_dim %10684, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xf32>) -> tensor<1x64x60x80xf32>
    %10686 = stablehlo.broadcast_in_dim %arg955, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x60x80xf32>
    %10687 = stablehlo.subtract %10685, %10686 : tensor<1x64x60x80xf32>
    %10688 = stablehlo.broadcast_in_dim %10687, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xf32>) -> tensor<1x64x60x80xf32>
    %10689 = stablehlo.broadcast_in_dim %arg956, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x60x80xf32>
    %10690 = stablehlo.multiply %10688, %10689 : tensor<1x64x60x80xf32>
    %10691 = stablehlo.convert %arg957 : (tensor<64x1x1xbf16>) -> tensor<64x1x1xf32>
    %10692 = stablehlo.broadcast_in_dim %10690, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xf32>) -> tensor<1x64x60x80xf32>
    %10693 = stablehlo.broadcast_in_dim %10691, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x60x80xf32>
    %10694 = stablehlo.multiply %10692, %10693 : tensor<1x64x60x80xf32>
    %10695 = stablehlo.convert %arg958 : (tensor<64x1x1xbf16>) -> tensor<64x1x1xf32>
    %10696 = stablehlo.broadcast_in_dim %10694, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xf32>) -> tensor<1x64x60x80xf32>
    %10697 = stablehlo.broadcast_in_dim %10695, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x60x80xf32>
    %10698 = stablehlo.add %10696, %10697 : tensor<1x64x60x80xf32>
    %10699 = stablehlo.convert %10698 : (tensor<1x64x60x80xf32>) -> tensor<1x64x60x80xbf16>
    %10700 = stablehlo.maximum %10699, %cst_80 : tensor<1x64x60x80xbf16>
    %10701 = stablehlo.convolution(%10700, %arg478) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x60x80xbf16>, tensor<32x64x3x3xbf16>) -> tensor<1x32x60x80xbf16>
    %10702 = stablehlo.reshape %arg479 : (tensor<32xbf16>) -> tensor<32x1x1xbf16>
    %10703 = stablehlo.broadcast_in_dim %10701, dims = [0, 1, 2, 3] : (tensor<1x32x60x80xbf16>) -> tensor<1x32x60x80xbf16>
    %10704 = stablehlo.broadcast_in_dim %10702, dims = [1, 2, 3] : (tensor<32x1x1xbf16>) -> tensor<1x32x60x80xbf16>
    %10705 = stablehlo.add %10703, %10704 : tensor<1x32x60x80xbf16>
    %10706 = stablehlo.convert %10705 : (tensor<1x32x60x80xbf16>) -> tensor<1x32x60x80xf32>
    %10707 = stablehlo.broadcast_in_dim %10706, dims = [0, 1, 2, 3] : (tensor<1x32x60x80xf32>) -> tensor<1x32x60x80xf32>
    %10708 = stablehlo.broadcast_in_dim %arg959, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x60x80xf32>
    %10709 = stablehlo.subtract %10707, %10708 : tensor<1x32x60x80xf32>
    %10710 = stablehlo.broadcast_in_dim %10709, dims = [0, 1, 2, 3] : (tensor<1x32x60x80xf32>) -> tensor<1x32x60x80xf32>
    %10711 = stablehlo.broadcast_in_dim %arg960, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x60x80xf32>
    %10712 = stablehlo.multiply %10710, %10711 : tensor<1x32x60x80xf32>
    %10713 = stablehlo.convert %arg961 : (tensor<32x1x1xbf16>) -> tensor<32x1x1xf32>
    %10714 = stablehlo.broadcast_in_dim %10712, dims = [0, 1, 2, 3] : (tensor<1x32x60x80xf32>) -> tensor<1x32x60x80xf32>
    %10715 = stablehlo.broadcast_in_dim %10713, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x60x80xf32>
    %10716 = stablehlo.multiply %10714, %10715 : tensor<1x32x60x80xf32>
    %10717 = stablehlo.convert %arg962 : (tensor<32x1x1xbf16>) -> tensor<32x1x1xf32>
    %10718 = stablehlo.broadcast_in_dim %10716, dims = [0, 1, 2, 3] : (tensor<1x32x60x80xf32>) -> tensor<1x32x60x80xf32>
    %10719 = stablehlo.broadcast_in_dim %10717, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x60x80xf32>
    %10720 = stablehlo.add %10718, %10719 : tensor<1x32x60x80xf32>
    %10721 = stablehlo.convert %10720 : (tensor<1x32x60x80xf32>) -> tensor<1x32x60x80xbf16>
    %10722 = stablehlo.maximum %10721, %cst_81 : tensor<1x32x60x80xbf16>
    %10723 = stablehlo.convolution(%10722, %arg480) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x32x60x80xbf16>, tensor<2x32x3x3xbf16>) -> tensor<1x2x60x80xbf16>
    %10724 = stablehlo.reshape %arg481 : (tensor<2xbf16>) -> tensor<2x1x1xbf16>
    %10725 = stablehlo.broadcast_in_dim %10723, dims = [0, 1, 2, 3] : (tensor<1x2x60x80xbf16>) -> tensor<1x2x60x80xbf16>
    %10726 = stablehlo.broadcast_in_dim %10724, dims = [1, 2, 3] : (tensor<2x1x1xbf16>) -> tensor<1x2x60x80xbf16>
    %10727 = stablehlo.add %10725, %10726 : tensor<1x2x60x80xbf16>
    %10728 = stablehlo.logistic %10727 : tensor<1x2x60x80xbf16>
    %10729 = stablehlo.slice %10728 [0:1, 0:1, 0:60, 0:80] : (tensor<1x2x60x80xbf16>) -> tensor<1x1x60x80xbf16>
    %10730 = stablehlo.reshape %10729 : (tensor<1x1x60x80xbf16>) -> tensor<1x60x80xbf16>
    %10731 = stablehlo.reshape %10730 : (tensor<1x60x80xbf16>) -> tensor<1x1x60x80xbf16>
    %10732 = stablehlo.broadcast_in_dim %10677, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10733 = stablehlo.broadcast_in_dim %10731, dims = [0, 1, 2, 3] : (tensor<1x1x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10734 = stablehlo.multiply %10732, %10733 : tensor<1x64x60x80xbf16>
    %10735 = stablehlo.slice %10728 [0:1, 1:2, 0:60, 0:80] : (tensor<1x2x60x80xbf16>) -> tensor<1x1x60x80xbf16>
    %10736 = stablehlo.reshape %10735 : (tensor<1x1x60x80xbf16>) -> tensor<1x60x80xbf16>
    %10737 = stablehlo.reshape %10736 : (tensor<1x60x80xbf16>) -> tensor<1x1x60x80xbf16>
    %10738 = stablehlo.broadcast_in_dim %10672, dims = [0, 1, 2, 3] : (tensor<1x64x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10739 = stablehlo.broadcast_in_dim %10737, dims = [0, 1, 2, 3] : (tensor<1x1x60x80xbf16>) -> tensor<1x64x60x80xbf16>
    %10740 = stablehlo.multiply %10738, %10739 : tensor<1x64x60x80xbf16>
    %10741 = stablehlo.add %10734, %10740 : tensor<1x64x60x80xbf16>
    %10742 = stablehlo.transpose %10741, dims = [0, 1, 3, 2] : (tensor<1x64x60x80xbf16>) -> tensor<1x64x80x60xbf16>
    %10743 = stablehlo.reshape %10742 : (tensor<1x64x80x60xbf16>) -> tensor<64x80x60xbf16>
    %10744 = stablehlo.broadcast_in_dim %arg963, dims = [0, 1, 2] : (tensor<64x60x120xbf16>) -> tensor<64x60x120xbf16>
    %10745 = stablehlo.dot_general %10743, %10744, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x80x60xbf16>, tensor<64x60x120xbf16>) -> tensor<64x80x120xbf16>
    %10746 = stablehlo.reshape %10745 : (tensor<64x80x120xbf16>) -> tensor<1x64x80x120xbf16>
    %10747 = stablehlo.transpose %10746, dims = [0, 1, 3, 2] : (tensor<1x64x80x120xbf16>) -> tensor<1x64x120x80xbf16>
    %10748 = stablehlo.reshape %10747 : (tensor<1x64x120x80xbf16>) -> tensor<64x120x80xbf16>
    %10749 = stablehlo.broadcast_in_dim %arg964, dims = [0, 1, 2] : (tensor<64x80x160xbf16>) -> tensor<64x80x160xbf16>
    %10750 = stablehlo.dot_general %10748, %10749, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x120x80xbf16>, tensor<64x80x160xbf16>) -> tensor<64x120x160xbf16>
    %10751 = stablehlo.reshape %10750 : (tensor<64x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %10752 = stablehlo.concatenate %859, %10751, dim = 1 : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x128x120x160xbf16>
    %10753 = stablehlo.convolution(%10752, %arg482) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x128x120x160xbf16>, tensor<64x128x3x3xbf16>) -> tensor<1x64x120x160xbf16>
    %10754 = stablehlo.reshape %arg483 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10755 = stablehlo.broadcast_in_dim %10753, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %10756 = stablehlo.broadcast_in_dim %10754, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x120x160xbf16>
    %10757 = stablehlo.add %10755, %10756 : tensor<1x64x120x160xbf16>
    %10758 = stablehlo.convert %10757 : (tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xf32>
    %10759 = stablehlo.broadcast_in_dim %10758, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xf32>) -> tensor<1x64x120x160xf32>
    %10760 = stablehlo.broadcast_in_dim %arg965, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x120x160xf32>
    %10761 = stablehlo.subtract %10759, %10760 : tensor<1x64x120x160xf32>
    %10762 = stablehlo.broadcast_in_dim %10761, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xf32>) -> tensor<1x64x120x160xf32>
    %10763 = stablehlo.broadcast_in_dim %arg966, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x120x160xf32>
    %10764 = stablehlo.multiply %10762, %10763 : tensor<1x64x120x160xf32>
    %10765 = stablehlo.convert %arg967 : (tensor<64x1x1xbf16>) -> tensor<64x1x1xf32>
    %10766 = stablehlo.broadcast_in_dim %10764, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xf32>) -> tensor<1x64x120x160xf32>
    %10767 = stablehlo.broadcast_in_dim %10765, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x120x160xf32>
    %10768 = stablehlo.multiply %10766, %10767 : tensor<1x64x120x160xf32>
    %10769 = stablehlo.convert %arg968 : (tensor<64x1x1xbf16>) -> tensor<64x1x1xf32>
    %10770 = stablehlo.broadcast_in_dim %10768, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xf32>) -> tensor<1x64x120x160xf32>
    %10771 = stablehlo.broadcast_in_dim %10769, dims = [1, 2, 3] : (tensor<64x1x1xf32>) -> tensor<1x64x120x160xf32>
    %10772 = stablehlo.add %10770, %10771 : tensor<1x64x120x160xf32>
    %10773 = stablehlo.convert %10772 : (tensor<1x64x120x160xf32>) -> tensor<1x64x120x160xbf16>
    %10774 = stablehlo.maximum %10773, %cst_82 : tensor<1x64x120x160xbf16>
    %10775 = stablehlo.convolution(%10774, %arg484) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x120x160xbf16>, tensor<32x64x3x3xbf16>) -> tensor<1x32x120x160xbf16>
    %10776 = stablehlo.reshape %arg485 : (tensor<32xbf16>) -> tensor<32x1x1xbf16>
    %10777 = stablehlo.broadcast_in_dim %10775, dims = [0, 1, 2, 3] : (tensor<1x32x120x160xbf16>) -> tensor<1x32x120x160xbf16>
    %10778 = stablehlo.broadcast_in_dim %10776, dims = [1, 2, 3] : (tensor<32x1x1xbf16>) -> tensor<1x32x120x160xbf16>
    %10779 = stablehlo.add %10777, %10778 : tensor<1x32x120x160xbf16>
    %10780 = stablehlo.convert %10779 : (tensor<1x32x120x160xbf16>) -> tensor<1x32x120x160xf32>
    %10781 = stablehlo.broadcast_in_dim %10780, dims = [0, 1, 2, 3] : (tensor<1x32x120x160xf32>) -> tensor<1x32x120x160xf32>
    %10782 = stablehlo.broadcast_in_dim %arg969, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x120x160xf32>
    %10783 = stablehlo.subtract %10781, %10782 : tensor<1x32x120x160xf32>
    %10784 = stablehlo.broadcast_in_dim %10783, dims = [0, 1, 2, 3] : (tensor<1x32x120x160xf32>) -> tensor<1x32x120x160xf32>
    %10785 = stablehlo.broadcast_in_dim %arg970, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x120x160xf32>
    %10786 = stablehlo.multiply %10784, %10785 : tensor<1x32x120x160xf32>
    %10787 = stablehlo.convert %arg971 : (tensor<32x1x1xbf16>) -> tensor<32x1x1xf32>
    %10788 = stablehlo.broadcast_in_dim %10786, dims = [0, 1, 2, 3] : (tensor<1x32x120x160xf32>) -> tensor<1x32x120x160xf32>
    %10789 = stablehlo.broadcast_in_dim %10787, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x120x160xf32>
    %10790 = stablehlo.multiply %10788, %10789 : tensor<1x32x120x160xf32>
    %10791 = stablehlo.convert %arg972 : (tensor<32x1x1xbf16>) -> tensor<32x1x1xf32>
    %10792 = stablehlo.broadcast_in_dim %10790, dims = [0, 1, 2, 3] : (tensor<1x32x120x160xf32>) -> tensor<1x32x120x160xf32>
    %10793 = stablehlo.broadcast_in_dim %10791, dims = [1, 2, 3] : (tensor<32x1x1xf32>) -> tensor<1x32x120x160xf32>
    %10794 = stablehlo.add %10792, %10793 : tensor<1x32x120x160xf32>
    %10795 = stablehlo.convert %10794 : (tensor<1x32x120x160xf32>) -> tensor<1x32x120x160xbf16>
    %10796 = stablehlo.maximum %10795, %cst_83 : tensor<1x32x120x160xbf16>
    %10797 = stablehlo.convolution(%10796, %arg486) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x32x120x160xbf16>, tensor<2x32x3x3xbf16>) -> tensor<1x2x120x160xbf16>
    %10798 = stablehlo.reshape %arg487 : (tensor<2xbf16>) -> tensor<2x1x1xbf16>
    %10799 = stablehlo.broadcast_in_dim %10797, dims = [0, 1, 2, 3] : (tensor<1x2x120x160xbf16>) -> tensor<1x2x120x160xbf16>
    %10800 = stablehlo.broadcast_in_dim %10798, dims = [1, 2, 3] : (tensor<2x1x1xbf16>) -> tensor<1x2x120x160xbf16>
    %10801 = stablehlo.add %10799, %10800 : tensor<1x2x120x160xbf16>
    %10802 = stablehlo.logistic %10801 : tensor<1x2x120x160xbf16>
    %10803 = stablehlo.slice %10802 [0:1, 0:1, 0:120, 0:160] : (tensor<1x2x120x160xbf16>) -> tensor<1x1x120x160xbf16>
    %10804 = stablehlo.reshape %10803 : (tensor<1x1x120x160xbf16>) -> tensor<1x120x160xbf16>
    %10805 = stablehlo.reshape %10804 : (tensor<1x120x160xbf16>) -> tensor<1x1x120x160xbf16>
    %10806 = stablehlo.broadcast_in_dim %859, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %10807 = stablehlo.broadcast_in_dim %10805, dims = [0, 1, 2, 3] : (tensor<1x1x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %10808 = stablehlo.multiply %10806, %10807 : tensor<1x64x120x160xbf16>
    %10809 = stablehlo.slice %10802 [0:1, 1:2, 0:120, 0:160] : (tensor<1x2x120x160xbf16>) -> tensor<1x1x120x160xbf16>
    %10810 = stablehlo.reshape %10809 : (tensor<1x1x120x160xbf16>) -> tensor<1x120x160xbf16>
    %10811 = stablehlo.reshape %10810 : (tensor<1x120x160xbf16>) -> tensor<1x1x120x160xbf16>
    %10812 = stablehlo.broadcast_in_dim %10751, dims = [0, 1, 2, 3] : (tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %10813 = stablehlo.broadcast_in_dim %10811, dims = [0, 1, 2, 3] : (tensor<1x1x120x160xbf16>) -> tensor<1x64x120x160xbf16>
    %10814 = stablehlo.multiply %10812, %10813 : tensor<1x64x120x160xbf16>
    %10815 = stablehlo.add %10808, %10814 : tensor<1x64x120x160xbf16>
    %10816 = stablehlo.transpose %10815, dims = [0, 1, 3, 2] : (tensor<1x64x120x160xbf16>) -> tensor<1x64x160x120xbf16>
    %10817 = stablehlo.reshape %10816 : (tensor<1x64x160x120xbf16>) -> tensor<64x160x120xbf16>
    %10818 = stablehlo.broadcast_in_dim %arg973, dims = [0, 1, 2] : (tensor<64x120x240xbf16>) -> tensor<64x120x240xbf16>
    %10819 = stablehlo.dot_general %10817, %10818, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x160x120xbf16>, tensor<64x120x240xbf16>) -> tensor<64x160x240xbf16>
    %10820 = stablehlo.reshape %10819 : (tensor<64x160x240xbf16>) -> tensor<1x64x160x240xbf16>
    %10821 = stablehlo.transpose %10820, dims = [0, 1, 3, 2] : (tensor<1x64x160x240xbf16>) -> tensor<1x64x240x160xbf16>
    %10822 = stablehlo.reshape %10821 : (tensor<1x64x240x160xbf16>) -> tensor<64x240x160xbf16>
    %10823 = stablehlo.broadcast_in_dim %arg974, dims = [0, 1, 2] : (tensor<64x160x320xbf16>) -> tensor<64x160x320xbf16>
    %10824 = stablehlo.dot_general %10822, %10823, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x240x160xbf16>, tensor<64x160x320xbf16>) -> tensor<64x240x320xbf16>
    %10825 = stablehlo.reshape %10824 : (tensor<64x240x320xbf16>) -> tensor<1x64x240x320xbf16>
    %10826 = stablehlo.transpose %10825, dims = [0, 1, 3, 2] : (tensor<1x64x240x320xbf16>) -> tensor<1x64x320x240xbf16>
    %10827 = stablehlo.reshape %10826 : (tensor<1x64x320x240xbf16>) -> tensor<64x320x240xbf16>
    %10828 = stablehlo.broadcast_in_dim %arg975, dims = [0, 1, 2] : (tensor<64x240x480xbf16>) -> tensor<64x240x480xbf16>
    %10829 = stablehlo.dot_general %10827, %10828, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x320x240xbf16>, tensor<64x240x480xbf16>) -> tensor<64x320x480xbf16>
    %10830 = stablehlo.reshape %10829 : (tensor<64x320x480xbf16>) -> tensor<1x64x320x480xbf16>
    %10831 = stablehlo.transpose %10830, dims = [0, 1, 3, 2] : (tensor<1x64x320x480xbf16>) -> tensor<1x64x480x320xbf16>
    %10832 = stablehlo.reshape %10831 : (tensor<1x64x480x320xbf16>) -> tensor<64x480x320xbf16>
    %10833 = stablehlo.broadcast_in_dim %arg976, dims = [0, 1, 2] : (tensor<64x320x640xbf16>) -> tensor<64x320x640xbf16>
    %10834 = stablehlo.dot_general %10832, %10833, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<64x480x320xbf16>, tensor<64x320x640xbf16>) -> tensor<64x480x640xbf16>
    %10835 = stablehlo.reshape %10834 : (tensor<64x480x640xbf16>) -> tensor<1x64x480x640xbf16>
    %10836 = stablehlo.convolution(%10835, %arg488) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x480x640xbf16>, tensor<64x64x3x3xbf16>) -> tensor<1x64x480x640xbf16>
    %10837 = stablehlo.reshape %arg489 : (tensor<64xbf16>) -> tensor<64x1x1xbf16>
    %10838 = stablehlo.broadcast_in_dim %10836, dims = [0, 1, 2, 3] : (tensor<1x64x480x640xbf16>) -> tensor<1x64x480x640xbf16>
    %10839 = stablehlo.broadcast_in_dim %10837, dims = [1, 2, 3] : (tensor<64x1x1xbf16>) -> tensor<1x64x480x640xbf16>
    %10840 = stablehlo.add %10838, %10839 : tensor<1x64x480x640xbf16>
    %10841 = stablehlo.maximum %10840, %cst_84 : tensor<1x64x480x640xbf16>
    %10842 = stablehlo.convolution(%10841, %arg490) dim_numbers = [b, f, 0, 1]x[o, i, 0, 1]->[b, f, 0, 1], window = {stride = [1, 1], pad = [[1, 1], [1, 1]], rhs_dilate = [1, 1]} {batch_group_count = 1 : i64, feature_group_count = 1 : i64} : (tensor<1x64x480x640xbf16>, tensor<1x64x3x3xbf16>) -> tensor<1x1x480x640xbf16>
    %10843 = stablehlo.reshape %arg491 : (tensor<1xbf16>) -> tensor<1x1x1xbf16>
    %10844 = stablehlo.broadcast_in_dim %10842, dims = [0, 1, 2, 3] : (tensor<1x1x480x640xbf16>) -> tensor<1x1x480x640xbf16>
    %10845 = stablehlo.broadcast_in_dim %10843, dims = [1, 2, 3] : (tensor<1x1x1xbf16>) -> tensor<1x1x480x640xbf16>
    %10846 = stablehlo.add %10844, %10845 : tensor<1x1x480x640xbf16>
    %10847 = stablehlo.logistic %10846 : tensor<1x1x480x640xbf16>
    %10848 = stablehlo.convert %cst_92 : (tensor<1xi64>) -> tensor<1xbf16>
    %10849 = stablehlo.reshape %10848 : (tensor<1xbf16>) -> tensor<bf16>
    %10850 = stablehlo.broadcast_in_dim %10847, dims = [0, 1, 2, 3] : (tensor<1x1x480x640xbf16>) -> tensor<1x1x480x640xbf16>
    %10851 = stablehlo.broadcast_in_dim %10849, dims = [] : (tensor<bf16>) -> tensor<1x1x480x640xbf16>
    %10852 = stablehlo.multiply %10850, %10851 : tensor<1x1x480x640xbf16>
    %10853 = stablehlo.reshape %10852 : (tensor<1x1x480x640xbf16>) -> tensor<1x480x640xbf16>
    return %10853 : tensor<1x480x640xbf16>
  }
}
