name: Run Tests

on:
  workflow_dispatch:
  workflow_call:
  workflow_run:
    workflows: [Build]
    types: [completed]

jobs:
  tests:
    timeout-minutes: 120
    strategy:
      fail-fast: false
      matrix:
        build: [
          {runs-on: wormhole_b0, name: "run"},
        ]

    runs-on:
      - ${{ matrix.build.runs-on }}

    container:
      image: ghcr.io/tenstorrent/tt-torch/tt-torch-ci-ubuntu-22-04:latest
      options: --user root --device /dev/tenstorrent/0 --shm-size=2gb
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /mnt/dockercache:/mnt/dockercache

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive
        lfs: true

    - name: Set reusable strings
      id: strings
      shell: bash
      env:
        job-name: "${{ github.job }} (${{ matrix.build.runs-on }}, ${{ matrix.build.name }})"
      run: |
        echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
        echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"
        echo "install-output-dir=$(pwd)/install" >> "$GITHUB_OUTPUT"

        # Github job context unfortunately doesn't contain job_id, this is the workaround how to fetch it using GH API
        echo "Expected job name: ${{ env.job-name }}"
        JOB_ID=$(curl -s -H "Authorization: token ${{ secrets.GH_TOKEN }}" \
          "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/${{ github.run_attempt }}/jobs" | \
          jq -r '.jobs[] | select(.name | contains("${{ env.job-name }}")) | .id ')
        echo "Current job id: $JOB_ID"

        echo "job-id=$JOB_ID" >> "$GITHUB_OUTPUT"
        echo "test_report_path_torch=report_torch_$JOB_ID.xml" >> "$GITHUB_OUTPUT"
        echo "test_report_path_models=report_models_$JOB_ID.xml" >> "$GITHUB_OUTPUT"
        echo "test_report_path_onnx=report_onnx_$JOB_ID.xml" >> "$GITHUB_OUTPUT"

    - name: Git safe dir
      run: git config --global --add safe.directory ${{ steps.strings.outputs.work-dir }}

    - name: Use build artifacts
      uses: actions/download-artifact@v4
      with:
        name: install-artifacts
        path: ${{ steps.strings.outputs.install-output-dir }}

    - name: 'Untar install directory'
      shell: bash
      working-directory: ${{ steps.strings.outputs.install-output-dir }}
      run: tar xvf artifact.tar

    - name: make tt-metal and env directories
      shell: bash
      working-directory: ${{ steps.strings.outputs.install-output-dir }}
      run: |
        mkdir -p ${{ steps.strings.outputs.work-dir }}/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
        mkdir -p ${{ steps.strings.outputs.work-dir }}/env

    - name: copy tt-metal and env dirs
      shell: bash
      working-directory: ${{ steps.strings.outputs.install-output-dir }}
      run: |
        cp -r ${{ steps.strings.outputs.install-output-dir }}/tt-metal/* ${{ steps.strings.outputs.work-dir }}/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
        cp -r ${{ steps.strings.outputs.install-output-dir }}/env/* ${{ steps.strings.outputs.work-dir }}/env

    - name: Run PyTorch Unit tests
      shell: bash
      run: |
        source env/activate
        export LD_LIBRARY_PATH="/opt/ttmlir-toolchain/lib/:${{ steps.strings.outputs.install-output-dir }}/lib:${{ steps.strings.outputs.build-output-dir }}/lib:./lib/:${LD_LIBRARY_PATH}"
        pytest -v tests/torch \
           --junit-xml=${{ steps.strings.outputs.test_report_path_torch }}

    - name: Upload Test Report Torch
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: test-reports-torch-${{ matrix.build.runs-on }}-${{ matrix.build.name }}
        path: ${{ steps.strings.outputs.test_report_path_torch }}

    - name: Run Supported Models
      env:
        HF_HOME: /mnt/dockercache/huggingface
        HF_HUB_DISABLE_PROGRESS_BARS: 1
      shell: bash
      run: |
        source env/activate
        export LD_LIBRARY_PATH="/opt/ttmlir-toolchain/lib/:${{ steps.strings.outputs.install-output-dir }}/lib:${{ steps.strings.outputs.build-output-dir }}/lib:./lib/:${LD_LIBRARY_PATH}"
        pytest -v \
                  tests/models/autoencoder_linear/test_autoencoder_linear.py::test_autoencoder_linear[full-eval] \
                  tests/models/distilbert/test_distilbert.py::test_distilbert[full-distilbert-base-uncased-eval] \
                  tests/models/mlpmixer/test_mlpmixer.py::test_mlpmixer[full-eval] \
                  tests/models/mnist/test_mnist.py::test_mnist_train[full-eval] \
                  tests/models/MobileNetV2/test_MobileNetV2.py::test_MobileNetV2[full-eval] \
                  tests/models/openpose/test_openpose_v2.py::test_openpose_v2[full-eval] \
                  tests/models/perceiver_io/test_perceiver_io.py::test_perceiver_io[full-eval] \
                  tests/models/resnet/test_resnet.py::test_resnet[full-eval] \
                  tests/models/resnet50/test_resnet50.py::test_resnet[full-eval] \
                  tests/models/yolov3/test_yolov3.py::test_yolov3[full-eval] \
                  tests/models/albert/test_albert_masked_lm.py::test_albert_masked_lm[full-albert/albert-xxlarge-v2-eval] \
                  tests/models/llama/test_llama.py::test_llama[full-eval] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-mobilenet_v2] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-mobilenet_v3_small] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-mobilenet_v3_large] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnet18] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnet34] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnet50] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnet101] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnet152] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnext50_32x4d] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnext101_32x8d] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-resnext101_64x4d] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-wide_resnet50_2] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-wide_resnet101_2] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_400mf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_800mf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_1_6gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_3_2gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_8gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_16gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_y_32gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_400mf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_800mf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_1_6gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_3_2gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_8gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_16gf] \
                  tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[full-regnet_x_32gf] \
           --junit-xml=${{ steps.strings.outputs.test_report_path_models }}
    - name: Upload Test Report Models
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: test-reports-models-${{ matrix.build.runs-on }}-${{ matrix.build.name }}
        path: ${{ steps.strings.outputs.test_report_path_models }}

    - name: Run ONNX Unit tests
      shell: bash
      run: |
        source env/activate
        export LD_LIBRARY_PATH="/opt/ttmlir-toolchain/lib/:${{ steps.strings.outputs.install-output-dir }}/lib:${{ steps.strings.outputs.build-output-dir }}/lib:./lib/:${LD_LIBRARY_PATH}"
        pytest -v tests/onnx \
            --junit-xml=${{ steps.strings.outputs.test_report_path_onnx }}

    - name: Upload Test Report Onnx
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: test-reports-onnx-${{ matrix.build.runs-on }}-${{ matrix.build.name }}
        path: ${{ steps.strings.outputs.test_report_path_onnx }}
