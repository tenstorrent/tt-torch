name: Run Model Tests

on:
  workflow_dispatch:
  workflow_call:
  workflow_run:
    workflows: [Build]
    types: [completed]

jobs:
  tests:
    timeout-minutes: 600
    strategy:
      fail-fast: false
      matrix:
        build: [
          {
            runs-on: n150, name: "run1", tests: "
              tests/models/MobileNetV2/test_MobileNetV2.py::test_MobileNetV2
              tests/models/Qwen/test_qwen2_casual_lm.py::test_qwen2_casual_lm
              tests/models/Qwen/test_qwen2_token_classification.py::test_qwen2_token_classification
              tests/models/RMBG/test_RMBG.py::test_RMBG
              tests/models/albert/test_albert_masked_lm.py::test_albert_masked_lm
              tests/models/albert/test_albert_question_answering.py::test_albert_question_answering
              tests/models/albert/test_albert_sequence_classification.py::test_albert_sequence_classification
              tests/models/albert/test_albert_token_classification.py::test_albert_token_classification
              tests/models/clip/test_clip.py::test_clip
              tests/models/codegen/test_codegen.py::test_codegen
              tests/models/flan_t5/test_flan_t5.py::test_flan_t5
              tests/models/glpn_kitti/test_glpn_kitti.py::test_glpn_kitti
              tests/models/mgp-str-base/test_mgp_str_base.py::test_mgp_str_base
              tests/models/mlpmixer/test_mlpmixer.py::test_mlpmixer
              tests/models/mnist/test_mnist.py::test_mnist_train
              tests/models/musicgen_small/test_musicgen_small.py::test_musicgen_small
              tests/models/resnet/test_resnet.py::test_resnet
              tests/models/resnet50/test_resnet50.py::test_resnet
              tests/models/segformer/test_segformer.py::test_segformer
              tests/models/stable_diffusion/test_stable_diffusion.py::test_stable_diffusion
              tests/models/stable_diffusion/test_stable_diffusion_v2.py::test_stable_diffusion_v2
              tests/models/unet_carvana/test_unet_carvana.py::test_unet_carvana
              tests/models/vilt/test_vilt.py::test_vilt
              tests/models/yolos/test_yolos.py::test_yolos
              "
          },
          {
            runs-on: n150, name: "run2", tests: "
              tests/models/autoencoder_conv/test_autoencoder_conv.py::test_autoencoder_conv
              tests/models/autoencoder_conv/test_autoencoder_conv_v2.py::test_autoencoder_conv_v2
              tests/models/autoencoder_linear/test_autoencoder_linear.py::test_autoencoder_linear
              tests/models/beit/test_beit_image_classification.py::test_beit_image_classification
              tests/models/bert/test_bert.py::test_bert
              tests/models/bloom/test_bloom.py::test_bloom
              tests/models/deit/test_deit.py::test_deit
              tests/models/detr/test_detr.py::test_detr
              tests/models/distilbert/test_distilbert.py::test_distilbert
              tests/models/dpr/test_dpr.py::test_dpr
              tests/models/gpt2/test_gpt2.py::test_gpt2
              tests/models/hand_landmark/test_hand_landmark.py::test_hand_landmark
              tests/models/hardnet/test_hardnet.py::test_hardnet
              tests/models/llama/test_llama.py::test_llama
              tests/models/mobilenet_ssd/test_mobilenet_ssd.py::test_mobilenet_ssd
              tests/models/openpose/test_openpose.py::test_openpose
              tests/models/openpose/test_openpose_v2.py::test_openpose_v2
              tests/models/opt/test_opt.py::test_opt
              tests/models/perceiver_io/test_perceiver_io.py::test_perceiver_io
              tests/models/roberta/test_roberta.py::test_roberta
              tests/models/segment_anything/test_segment_anything.py::test_segment_anything
              tests/models/speecht5_tts/test_speecht5_tts.py::test_speecht5_tts
              tests/models/squeeze_bert/test_squeeze_bert.py::test_squeeze_bert
              tests/models/t5/test_t5.py::test_t5
              tests/models/timm/test_timm_image_classification.py::test_timm_image_classification
              tests/models/unet/test_unet.py::test_unet
              tests/models/unet_brain/test_unet_brain.py::test_unet_brain
              tests/models/whisper/test_whisper.py::test_whisper
              tests/models/xglm/test_xglm.py::test_xglm
              tests/models/yolov3/test_yolov3.py::test_yolov3
              tests/models/yolov5/test_yolov5.py::test_yolov5
              "
          },
          {
            runs-on: n150, name: "run3", tests: "\
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-googlenet]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-densenet201]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-mobilenet_v2]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-mobilenet_v3_large]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-resnet152]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-resnext101_64x4d]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-vgg19]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-vgg19_bn]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-vit_h_14]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-wide_resnet101_2]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-regnet_y_32gf]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-regnet_x_32gf]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-swin_b]
              tests/models/torchvision/test_torchvision_image_classification.py::test_torchvision_image_classification[op_by_op-swin_v2_b]
              tests/models/torchvision/test_torchvision_object_detection.py::test_torchvision_object_detection
              tests/models/gpt_neo/test_gpt_neo.py::test_gpt_neo
              tests/models/falcon/test_falcon.py::test_falcon
              "
          },
        ]
    runs-on:
      - ${{ matrix.build.runs-on }}

    container:
      image: ghcr.io/tenstorrent/tt-torch/tt-torch-ci-ubuntu-22-04:latest
      options: --user root --device /dev/tenstorrent/0 --shm-size=4gb
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive
        lfs: true

    - name: Set reusable strings
      id: strings
      shell: bash
      env:
        job-name: "${{ github.job }} (${{ matrix.build.runs-on }}, ${{ matrix.build.name }}"
      run: |
        echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
        echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"
        echo "install-output-dir=$(pwd)/install" >> "$GITHUB_OUTPUT"
        echo "test-output-dir=$(pwd)/results/models/tests/" >> "$GITHUB_OUTPUT"
        # Github job context unfortunately doesn't contain job_id, this is the workaround how to fetch it using GH API
        echo "Expected job name: ${{ env.job-name }}"
        JOB_ID=$(curl -s -H "Authorization: token ${{ secrets.GH_TOKEN }}" \
          "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/${{ github.run_attempt }}/jobs" | \
          jq -r '.jobs[] | select(.name | contains("${{ env.job-name }}")) | .id ')
        echo "Current job id: $JOB_ID"
        echo "job-id=$JOB_ID" >> "$GITHUB_OUTPUT"

    - name: Git safe dir
      run: git config --global --add safe.directory ${{ steps.strings.outputs.work-dir }}

    - name: Use build artifacts
      uses: actions/download-artifact@v4
      with:
        name: install-artifacts
        path: ${{ steps.strings.outputs.install-output-dir }}

    - name: 'Untar install directory'
      shell: bash
      working-directory: ${{ steps.strings.outputs.install-output-dir }}
      run: tar xvf artifact.tar

    - name: make directories
      shell: bash
      working-directory: ${{ steps.strings.outputs.install-output-dir }}
      run: |
        mkdir -p ${{ steps.strings.outputs.work-dir }}/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
        mkdir -p ${{ steps.strings.outputs.work-dir }}/env

    - name: copy tt-metal and env dirs
      shell: bash
      working-directory: ${{ steps.strings.outputs.install-output-dir }}
      run: |
        cp -r ${{ steps.strings.outputs.install-output-dir }}/tt-metal/* ${{ steps.strings.outputs.work-dir }}/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
        cp -r ${{ steps.strings.outputs.install-output-dir }}/env/* ${{ steps.strings.outputs.work-dir }}/env

    - name: Run Model Tests
      shell: bash
      run: |
        source env/activate
        export LD_LIBRARY_PATH="/opt/ttmlir-toolchain/lib/:${{ steps.strings.outputs.install-output-dir }}/lib:${{ steps.strings.outputs.build-output-dir }}/lib:./lib/:${LD_LIBRARY_PATH}"

        # Make sure we don't stop on first failure
        set +e

        tests_list=$(echo "${{ matrix.build.tests }}" | xargs -n1 echo)
        total_tests=$(echo "$tests_list" | wc -l)

        failures=0
        counter=0

        for test_case in $tests_list; do
          counter=$((counter + 1))

          pytest_log="test_${counter}.log"

          pytest -svv "$test_case" --op_by_op > "$pytest_log" 2>&1
          exit_code=$?

          echo "====== BEGIN LOG: $test_case ======" >> full_job_output.log
          cat "$pytest_log" >> full_job_output.log
          echo "====== END LOG: $test_case ========" >> full_job_output.log
          echo >> full_job_output.log
          rm "$pytest_log"

          if [ $exit_code -eq 0 ]; then
            echo "[ $counter / $total_tests ] $test_case PASSED"
          else
            echo "[ $counter / $total_tests ] $test_case FAILED"
            failures=$((failures + 1))
          fi
        done


        # If any test failed, exit nonzero to mark the job as failed
        if [ $failures -ne 0 ]; then
          echo "Total failures: $failures"
          exit 1
        fi

    - name: Tar results
      if: success() || failure()
      shell: bash
      working-directory: ${{ steps.strings.outputs.test-output-dir }}
      run: |
        tar cvf ${{ matrix.build.name }}_${{ steps.strings.outputs.job-id }}.tar .

    - name: Upload test folder to archive
      if: success() || failure()
      uses: actions/upload-artifact@v4
      with:
        name: test-reports-${{ matrix.build.name }}.tar
        path: ${{ steps.strings.outputs.test-output-dir }}/${{ matrix.build.name }}_${{ steps.strings.outputs.job-id }}.tar

    - name: Upload full logs
      if: success() || failure()
      uses: actions/upload-artifact@v4
      with:
        name: full-logs-${{ matrix.build.name }}
        path: full_job_output.log
