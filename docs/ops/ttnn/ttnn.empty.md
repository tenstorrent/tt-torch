# ttnn.empty

| Name | Input Shapes | Input Layouts | Attributes | Output Shapes | Output Layouts | Runs on TTNN | PCC | ATOL |
|------|--------------|---------------|------------|---------------|----------------|--------------|-----|------|
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x32x32> | tensor<[1,1,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1> | tensor<[1,32,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x4>>> <br> shape: #ttnn.shape<1x32x32x128> | tensor<[1,32,32,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 8.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x32x32x32> | tensor<[1,32,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x32x4096> | tensor<[1,32,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x32> | tensor<[1,64,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<32x32x32> | tensor<[32,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 11.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x4>>> <br> shape: #ttnn.shape<32x32x128> | tensor<[32,32,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 1.21 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x32x128> | tensor<[1,32,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x4>>> <br> shape: #ttnn.shape<1x32x32x128> | tensor<[1,32,32,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x32x128> | tensor<[1,32,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<32x32> | tensor<[32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x32x32> | tensor<[1,1,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1> | tensor<[1,32,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<32x4096> | tensor<[32,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 5.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x344>>> <br> shape: #ttnn.shape<32x11008> | tensor<[32,11008,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 3.73 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<32x4096> | tensor<[32,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 5.47 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1000>>> <br> shape: #ttnn.shape<32x32000> | tensor<[32,32000,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 31.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x4>>> <br> shape: #ttnn.shape<1x32x32x128> | tensor<[1,32,32,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x32x128x32> | tensor<[1,32,128,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x32> | tensor<[32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x32x128> | tensor<[1,32,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x32x4096> | tensor<[1,32,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x32x4096> | tensor<[1,32,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x4>>> <br> shape: #ttnn.shape<1x32x32x128> | tensor<[1,32,32,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 8.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x344>>> <br> shape: #ttnn.shape<1x32x11008> | tensor<[1,32,11008,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x2>>> <br> shape: #ttnn.shape<1x32x32x64> | tensor<[1,32,32,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 6.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1> | tensor<[1,32,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x344>>> <br> shape: #ttnn.shape<1x32x11008> | tensor<[1,32,11008,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x2>>> <br> shape: #ttnn.shape<1x32x32x64> | tensor<[1,32,32,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 8.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x2>>> <br> shape: #ttnn.shape<1x32x32x64> | tensor<[1,32,32,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 6.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x32x32> | tensor<[1,1,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x7x768> | tensor<[1,7,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<7> | tensor<[7,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x7x1> | tensor<[1,7,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x7x768> | tensor<[1,7,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x72>>> <br> shape: #ttnn.shape<7x2304> | tensor<[7,2304,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x12x7x7> | tensor<[1,12,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<7x768> | tensor<[7,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<7x3072> | tensor<[7,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<12x7x7> | tensor<[12,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 12.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<12x7x64> | tensor<[12,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.19 | 1.67 |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<7x7> | tensor<[7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 105195241472.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x7> | tensor<[1,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x72>>> <br> shape: #ttnn.shape<7x2304> | tensor<[7,2304,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<7x768> | tensor<[7,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<7x3072> | tensor<[7,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<7x768> | tensor<[7,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<7x2> | tensor<[7,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.56 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<1x12x7x64> | tensor<[1,12,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x7> | tensor<[1,12,64,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x7x768> | tensor<[1,7,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x72>>> <br> shape: #ttnn.shape<7x2304> | tensor<[7,2304,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x72>>> <br> shape: #ttnn.shape<2304> | tensor<[2304,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<7x768> | tensor<[7,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<7x3072> | tensor<[7,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x7x1> | tensor<[1,7,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x7> | tensor<[1,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x7x768> | tensor<[1,7,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x7x3072> | tensor<[1,7,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<7x7> | tensor<[7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x7> | tensor<[1,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.87 | 0.99 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.98 | 0.54 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.82 | 4.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.96 | 0.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 26.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.37 | 6.07 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.88 | 0.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<162x1>>> <br> shape: #ttnn.shape<1x185x28x28> | tensor<[1,185,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x1>>> <br> shape: #ttnn.shape<1x1x12544x32> | tensor<[1,1,12544,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x1>>> <br> shape: #ttnn.shape<1x1x12544x32> | tensor<[1,1,12544,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.41 | 10.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x2>>> <br> shape: #ttnn.shape<1x1x12544x64> | tensor<[1,1,12544,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.83 | 62.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x2>>> <br> shape: #ttnn.shape<1x1x3136x64> | tensor<[1,1,3136,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.43 | 11.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x4>>> <br> shape: #ttnn.shape<1x1x3136x128> | tensor<[1,1,3136,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.33 | 21.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x4>>> <br> shape: #ttnn.shape<1x1x3136x128> | tensor<[1,1,3136,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x4>>> <br> shape: #ttnn.shape<1x1x3136x128> | tensor<[1,1,3136,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x8>>> <br> shape: #ttnn.shape<1x1x784x256> | tensor<[1,1,784,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 18.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x8>>> <br> shape: #ttnn.shape<1x1x784x256> | tensor<[1,1,784,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x8>>> <br> shape: #ttnn.shape<1x1x784x256> | tensor<[1,1,784,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x19> | tensor<[1,1,784,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<17x1>>> <br> shape: #ttnn.shape<1x19x28x28> | tensor<[1,19,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x38> | tensor<[1,1,784,38,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 0.90 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<34x1>>> <br> shape: #ttnn.shape<1x38x28x28> | tensor<[1,38,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 0.90 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.51 | 2.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.51 | 2.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 3.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 3.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.47 | 1.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.47 | 1.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x19> | tensor<[1,1,784,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<17x1>>> <br> shape: #ttnn.shape<1x19x28x28> | tensor<[1,19,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x38> | tensor<[1,1,784,38,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.14 | 1.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<34x1>>> <br> shape: #ttnn.shape<1x38x28x28> | tensor<[1,38,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.14 | 1.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x1>>> <br> shape: #ttnn.shape<1x57x28x28> | tensor<[1,57,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 1.10 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 12.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 12.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 4.58 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 4.58 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<256x512> | tensor<[256,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x256x512> | tensor<[1,256,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x256x512> | tensor<[1,256,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x16>>> <br> shape: #ttnn.shape<1x1024x512> | tensor<[1,1024,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x16>>> <br> shape: #ttnn.shape<1x1024x512> | tensor<[1,1024,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<256x512> | tensor<[256,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 4.07 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<256x512> | tensor<[256,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 1.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 0.84 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<256x512> | tensor<[256,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x256x512> | tensor<[1,256,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<230x29>>> <br> shape: #ttnn.shape<8x920x920> | tensor<[8,920,920,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<230x1>>> <br> shape: #ttnn.shape<8x920x1> | tensor<[8,920,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<8x100x100> | tensor<[8,100,100,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<8x100x1> | tensor<[8,100,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x29>>> <br> shape: #ttnn.shape<8x100x920> | tensor<[8,100,920,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<8x100x1> | tensor<[8,100,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x20>>> <br> shape: #ttnn.shape<1x64x360x640> | tensor<[1,64,360,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.51 | 0.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x10>>> <br> shape: #ttnn.shape<1x64x180x320> | tensor<[1,64,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 0.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1x1> | tensor<[1,256,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x10>>> <br> shape: #ttnn.shape<1x256x180x320> | tensor<[1,256,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.73 | 0.70 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x10>>> <br> shape: #ttnn.shape<1x256x180x320> | tensor<[1,256,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x10>>> <br> shape: #ttnn.shape<1x128x180x320> | tensor<[1,128,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.79 | 0.74 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x5>>> <br> shape: #ttnn.shape<1x128x90x160> | tensor<[1,128,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.7 | 0.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x512x1x1> | tensor<[1,512,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x5>>> <br> shape: #ttnn.shape<1x512x90x160> | tensor<[1,512,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.47 | 0.86 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x5>>> <br> shape: #ttnn.shape<1x512x90x160> | tensor<[1,512,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x5>>> <br> shape: #ttnn.shape<1x256x90x160> | tensor<[1,256,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.57 | 0.87 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x3>>> <br> shape: #ttnn.shape<1x256x45x80> | tensor<[1,256,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.66 | 0.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1x1> | tensor<[1,1024,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x3>>> <br> shape: #ttnn.shape<1x1024x45x80> | tensor<[1,1024,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.51 | 1.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x3>>> <br> shape: #ttnn.shape<1x1024x45x80> | tensor<[1,1024,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.87 | 2.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x3>>> <br> shape: #ttnn.shape<1x512x45x80> | tensor<[1,512,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.55 | 1.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<368x2>>> <br> shape: #ttnn.shape<1x512x23x40> | tensor<[1,512,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 0.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1x1> | tensor<[1,2048,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1472x2>>> <br> shape: #ttnn.shape<1x2048x23x40> | tensor<[1,2048,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1472x2>>> <br> shape: #ttnn.shape<1x2048x23x40> | tensor<[1,2048,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 8.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<23> | tensor<[23,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x40> | tensor<[1,1,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x23x1> | tensor<[1,23,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.38 | 9.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x256> | tensor<[920,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x1>>> <br> shape: #ttnn.shape<920x1x1> | tensor<[920,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x64>>> <br> shape: #ttnn.shape<920x2048> | tensor<[920,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x1x256> | tensor<[100,1,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x256> | tensor<[100,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x1x1> | tensor<[100,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x1x256> | tensor<[100,1,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x64>>> <br> shape: #ttnn.shape<100x2048> | tensor<[100,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x3>>> <br> shape: #ttnn.shape<6x1x100x92> | tensor<[6,1,100,92,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x8>>> <br> shape: #ttnn.shape<6x1x100x256> | tensor<[6,1,100,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x1>>> <br> shape: #ttnn.shape<6x1x100x4> | tensor<[6,1,100,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 16.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<230x29>>> <br> shape: #ttnn.shape<8x920x920> | tensor<[8,920,920,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x29>>> <br> shape: #ttnn.shape<8x100x920> | tensor<[8,100,920,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x23x40> | tensor<[1,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<230x1>>> <br> shape: #ttnn.shape<8x920x32> | tensor<[8,920,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<8x100x100> | tensor<[8,100,100,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 31.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<8x100x32> | tensor<[8,100,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 0.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<8x100x32> | tensor<[8,100,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 25.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x3>>> <br> shape: #ttnn.shape<6x100x92> | tensor<[6,100,92,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 48.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x8>>> <br> shape: #ttnn.shape<6x100x256> | tensor<[6,100,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<1x23x40x256> | tensor<[1,23,40,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7200x2>>> <br> shape: #ttnn.shape<1x1x230400x64> | tensor<[1,1,230400,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1800x2>>> <br> shape: #ttnn.shape<1x1x57600x64> | tensor<[1,1,57600,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1800x2>>> <br> shape: #ttnn.shape<1x1x57600x64> | tensor<[1,1,57600,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1800x8>>> <br> shape: #ttnn.shape<1x1x57600x256> | tensor<[1,1,57600,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1800x4>>> <br> shape: #ttnn.shape<1x1x57600x128> | tensor<[1,1,57600,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<450x4>>> <br> shape: #ttnn.shape<1x1x14400x128> | tensor<[1,1,14400,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<450x16>>> <br> shape: #ttnn.shape<1x1x14400x512> | tensor<[1,1,14400,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<450x16>>> <br> shape: #ttnn.shape<1x1x14400x512> | tensor<[1,1,14400,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<450x4>>> <br> shape: #ttnn.shape<1x1x14400x128> | tensor<[1,1,14400,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<450x8>>> <br> shape: #ttnn.shape<1x1x14400x256> | tensor<[1,1,14400,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<113x8>>> <br> shape: #ttnn.shape<1x1x3600x256> | tensor<[1,1,3600,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<113x32>>> <br> shape: #ttnn.shape<1x1x3600x1024> | tensor<[1,1,3600,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.95 | 0.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<113x32>>> <br> shape: #ttnn.shape<1x1x3600x1024> | tensor<[1,1,3600,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<113x8>>> <br> shape: #ttnn.shape<1x1x3600x256> | tensor<[1,1,3600,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.96 | 1.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<113x8>>> <br> shape: #ttnn.shape<1x1x3600x256> | tensor<[1,1,3600,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.95 | 0.84 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<113x16>>> <br> shape: #ttnn.shape<1x1x3600x512> | tensor<[1,1,3600,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.81 | 0.87 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x16>>> <br> shape: #ttnn.shape<1x1x920x512> | tensor<[1,1,920,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.78 | 0.70 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x64>>> <br> shape: #ttnn.shape<1x1x920x2048> | tensor<[1,1,920,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.44 | 0.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x64>>> <br> shape: #ttnn.shape<1x1x920x2048> | tensor<[1,1,920,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.82 | 0.43 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x16>>> <br> shape: #ttnn.shape<1x1x920x512> | tensor<[1,1,920,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.24 | 3.70 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x16>>> <br> shape: #ttnn.shape<1x1x920x512> | tensor<[1,1,920,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 0.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<1x1x920x256> | tensor<[1,1,920,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 7.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<184x2>>> <br> shape: #ttnn.shape<1x256x23x40> | tensor<[1,256,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 7.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x2>>> <br> shape: #ttnn.shape<1x23x40x64> | tensor<[1,23,40,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 2.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x23x40> | tensor<[1,23,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x23x40> | tensor<[1,23,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x256> | tensor<[920,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 2.93 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x64>>> <br> shape: #ttnn.shape<920x2048> | tensor<[920,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 12.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x256> | tensor<[920,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 7.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x256> | tensor<[100,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 7.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x64>>> <br> shape: #ttnn.shape<100x2048> | tensor<[100,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 9.96 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x256> | tensor<[100,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.1 | 10.72 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x8>>> <br> shape: #ttnn.shape<600x256> | tensor<[600,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 33.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x1>>> <br> shape: #ttnn.shape<600x4> | tensor<[600,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 13.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.19 | 0.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x20>>> <br> shape: #ttnn.shape<1x64x360x640> | tensor<[1,64,360,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 1.27 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x10>>> <br> shape: #ttnn.shape<1x64x180x320> | tensor<[1,64,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.29 | 1.15 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1x1> | tensor<[1,256,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 5.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x10>>> <br> shape: #ttnn.shape<1x256x180x320> | tensor<[1,256,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.23 | 1.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 2.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x10>>> <br> shape: #ttnn.shape<1x128x180x320> | tensor<[1,128,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 1.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x5>>> <br> shape: #ttnn.shape<1x128x90x160> | tensor<[1,128,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 1.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x512x1x1> | tensor<[1,512,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.07 | 5.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x5>>> <br> shape: #ttnn.shape<1x512x90x160> | tensor<[1,512,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 1.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x5>>> <br> shape: #ttnn.shape<1x256x90x160> | tensor<[1,256,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 47660691512487140583616282624.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x3>>> <br> shape: #ttnn.shape<1x256x45x80> | tensor<[1,256,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.23 | 0.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1x1> | tensor<[1,1024,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 4.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x3>>> <br> shape: #ttnn.shape<1x1024x45x80> | tensor<[1,1024,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.19 | 1.57 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x3>>> <br> shape: #ttnn.shape<1x512x45x80> | tensor<[1,512,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 1.18 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<368x2>>> <br> shape: #ttnn.shape<1x512x23x40> | tensor<[1,512,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 0.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1x1> | tensor<[1,2048,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 29741476405687492656222682973772709888.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1472x2>>> <br> shape: #ttnn.shape<1x2048x23x40> | tensor<[1,2048,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<23> | tensor<[23,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x23x40> | tensor<[1,23,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<230x1>>> <br> shape: #ttnn.shape<8x920x32> | tensor<[8,920,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x256> | tensor<[920,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x64>>> <br> shape: #ttnn.shape<920x2048> | tensor<[920,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x256> | tensor<[100,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<8x100x32> | tensor<[8,100,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<100x1x256> | tensor<[100,1,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x64>>> <br> shape: #ttnn.shape<100x2048> | tensor<[100,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x20>>> <br> shape: #ttnn.shape<1x64x360x640> | tensor<[1,64,360,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x10>>> <br> shape: #ttnn.shape<1x64x180x320> | tensor<[1,64,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x10>>> <br> shape: #ttnn.shape<1x256x180x320> | tensor<[1,256,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x10>>> <br> shape: #ttnn.shape<1x128x180x320> | tensor<[1,128,180,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x5>>> <br> shape: #ttnn.shape<1x128x90x160> | tensor<[1,128,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x5>>> <br> shape: #ttnn.shape<1x512x90x160> | tensor<[1,512,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x5>>> <br> shape: #ttnn.shape<1x256x90x160> | tensor<[1,256,90,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<360x3>>> <br> shape: #ttnn.shape<1x256x45x80> | tensor<[1,256,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1440x3>>> <br> shape: #ttnn.shape<1x1024x45x80> | tensor<[1,1024,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<720x3>>> <br> shape: #ttnn.shape<1x512x45x80> | tensor<[1,512,45,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<368x2>>> <br> shape: #ttnn.shape<1x512x23x40> | tensor<[1,512,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1472x2>>> <br> shape: #ttnn.shape<1x2048x23x40> | tensor<[1,2048,23,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x64>>> <br> shape: #ttnn.shape<920x1x2048> | tensor<[920,1,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x64>>> <br> shape: #ttnn.shape<100x1x2048> | tensor<[100,1,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x8>>> <br> shape: #ttnn.shape<6x1x100x256> | tensor<[6,1,100,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1x1> | tensor<[1,256,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.34 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x512x1x1> | tensor<[1,512,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1x1> | tensor<[1,1024,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1x1> | tensor<[1,2048,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x1>>> <br> shape: #ttnn.shape<920x1x1> | tensor<[920,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x1x1> | tensor<[100,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x1x100x4> | tensor<[1,1,100,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 3.20 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<1x1x100x92> | tensor<[1,1,100,92,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<68x40>>> <br> shape: #ttnn.shape<1x3x720x1280> | tensor<[1,3,720,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x1>>> <br> shape: #ttnn.shape<6x1x100x4> | tensor<[6,1,100,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.11 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x2>>> <br> shape: #ttnn.shape<1x23x40x64> | tensor<[1,23,40,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.19 | 1.87 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x40> | tensor<[1,1,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x23x1> | tensor<[1,23,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x2>>> <br> shape: #ttnn.shape<1x23x40x64> | tensor<[1,23,40,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x2>>> <br> shape: #ttnn.shape<1x23x40x64> | tensor<[1,23,40,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1840x1>>> <br> shape: #ttnn.shape<1x23x40x64x2> | tensor<[1,23,40,64,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x8>>> <br> shape: #ttnn.shape<6x100x1x256> | tensor<[6,100,1,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.16 | 0.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1x1> | tensor<[1,256,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 0.70 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.12 | 0.74 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x512x1x1> | tensor<[1,512,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 142139126502390906331022337012400128.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1x1> | tensor<[1,1024,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 1.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1x1> | tensor<[1,2048,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 1.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x1x1> | tensor<[100,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x29>>> <br> shape: #ttnn.shape<1x920> | tensor<[1,920,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<68x40>>> <br> shape: #ttnn.shape<1x3x720x1280> | tensor<[1,3,720,1280,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6> | tensor<[6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6> | tensor<[1,6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x6x1024> | tensor<[1,6,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<6x1024> | tensor<[6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x16x6x6> | tensor<[1,16,6,6,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.48 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1> | tensor<[1,6,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x6x1024> | tensor<[1,6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<6x4096> | tensor<[6,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<6x1024> | tensor<[6,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<16x6x6> | tensor<[16,6,6,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.07 | 6.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<16x6x64> | tensor<[16,6,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x7> | tensor<[1,7,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<6x6> | tensor<[6,6,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 36425226944095543472969424710926336.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6> | tensor<[1,6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6> | tensor<[1,6,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<6x1024> | tensor<[6,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 1.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<6x1024> | tensor<[6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 1.82 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<6x4096> | tensor<[6,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 8.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<6x1024> | tensor<[6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 19.36 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<6x512> | tensor<[6,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 36.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1571>>> <br> shape: #ttnn.shape<6x50272> | tensor<[6,50272,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 44.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<1x16x6x64> | tensor<[1,16,6,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x16x64x6> | tensor<[1,16,64,6,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<6x1024> | tensor<[6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x6x1024> | tensor<[1,6,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x6x1024> | tensor<[1,6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<6x4096> | tensor<[6,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<6x4096> | tensor<[6,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1> | tensor<[1,6,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x6x6> | tensor<[1,1,6,6,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6> | tensor<[6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6> | tensor<[1,6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x6x1024> | tensor<[1,6,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6> | tensor<[1,6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6x6> | tensor<[6,6,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x6x6> | tensor<[1,1,6,6,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<320x1> | tensor<[320,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x10>>> <br> shape: #ttnn.shape<1x3x320x320> | tensor<[1,3,320,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x5>>> <br> shape: #ttnn.shape<1x16x160x160> | tensor<[1,16,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x5>>> <br> shape: #ttnn.shape<1x64x160x160> | tensor<[1,64,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x3>>> <br> shape: #ttnn.shape<1x64x80x80> | tensor<[1,64,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x24x80x80> | tensor<[1,24,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<72> | tensor<[72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<180x3>>> <br> shape: #ttnn.shape<1x72x80x80> | tensor<[1,72,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x24x80x80> | tensor<[1,24,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<90x2>>> <br> shape: #ttnn.shape<1x72x40x40> | tensor<[1,72,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x2>>> <br> shape: #ttnn.shape<1x40x40x40> | tensor<[1,40,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x2>>> <br> shape: #ttnn.shape<1x120x40x40> | tensor<[1,120,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x2>>> <br> shape: #ttnn.shape<1x240x40x40> | tensor<[1,240,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x240x20x20> | tensor<[1,240,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x1>>> <br> shape: #ttnn.shape<1x80x20x20> | tensor<[1,80,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<200> | tensor<[200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<125x1>>> <br> shape: #ttnn.shape<1x200x20x20> | tensor<[1,200,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<184> | tensor<[184,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<115x1>>> <br> shape: #ttnn.shape<1x184x20x20> | tensor<[1,184,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x1>>> <br> shape: #ttnn.shape<1x480x20x20> | tensor<[1,480,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<112> | tensor<[112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x1>>> <br> shape: #ttnn.shape<1x112x20x20> | tensor<[1,112,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x21>>> <br> shape: #ttnn.shape<672> | tensor<[672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<420x1>>> <br> shape: #ttnn.shape<1x672x20x20> | tensor<[1,672,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x672x10x10> | tensor<[1,672,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x80x10x10> | tensor<[1,80,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x480x10x10> | tensor<[1,480,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x256x10x10> | tensor<[1,256,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1x256x5x5> | tensor<[1,256,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x512x5x5> | tensor<[1,512,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x1>>> <br> shape: #ttnn.shape<1x128x5x5> | tensor<[1,128,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<12x1>>> <br> shape: #ttnn.shape<1x128x3x3> | tensor<[1,128,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x256x3x3> | tensor<[1,256,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x128x2x2> | tensor<[1,128,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x256x2x2> | tensor<[1,256,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x64x2x2> | tensor<[1,64,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20> | tensor<[20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10> | tensor<[10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<5> | tensor<[5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3> | tensor<[3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.35 | 0.86 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x102>>> <br> shape: #ttnn.shape<3234> | tensor<[3234,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.11 | 365.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<1x3234x4> | tensor<[1,3234,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x3>>> <br> shape: #ttnn.shape<1x3234x91> | tensor<[1,3234,91,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<75x1>>> <br> shape: #ttnn.shape<2400x4> | tensor<[2400,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x1>>> <br> shape: #ttnn.shape<600x4> | tensor<[600,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<150x4> | tensor<[150,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<54x4> | tensor<[54,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24x4> | tensor<[24,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6x4> | tensor<[6,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x4> | tensor<[3234,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x4> | tensor<[3234,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<320x1> | tensor<[320,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6x2> | tensor<[6,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<800x1>>> <br> shape: #ttnn.shape<1x1x25600x16> | tensor<[1,1,25600,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<800x1>>> <br> shape: #ttnn.shape<1x1x25600x16> | tensor<[1,1,25600,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<800x1>>> <br> shape: #ttnn.shape<1x1x25600x16> | tensor<[1,1,25600,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<800x2>>> <br> shape: #ttnn.shape<1x1x25600x64> | tensor<[1,1,25600,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<200x2>>> <br> shape: #ttnn.shape<1x1x6400x64> | tensor<[1,1,6400,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<200x1>>> <br> shape: #ttnn.shape<1x1x6400x24> | tensor<[1,1,6400,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.68 | 7.57 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<200x3>>> <br> shape: #ttnn.shape<1x1x6400x72> | tensor<[1,1,6400,72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<200x3>>> <br> shape: #ttnn.shape<1x1x6400x72> | tensor<[1,1,6400,72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<200x1>>> <br> shape: #ttnn.shape<1x1x6400x24> | tensor<[1,1,6400,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x3>>> <br> shape: #ttnn.shape<1x1x1600x72> | tensor<[1,1,1600,72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x24> | tensor<[1,1,1,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x24x1x1> | tensor<[1,24,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<1x1x1x72> | tensor<[1,1,1,72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x72x1x1> | tensor<[1,72,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x2>>> <br> shape: #ttnn.shape<1x1x1600x40> | tensor<[1,1,1600,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x4>>> <br> shape: #ttnn.shape<1x1x1600x120> | tensor<[1,1,1600,120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x4>>> <br> shape: #ttnn.shape<1x1x1600x120> | tensor<[1,1,1600,120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x32> | tensor<[1,1,1,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x1x120> | tensor<[1,1,1,120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x120x1x1> | tensor<[1,120,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x2>>> <br> shape: #ttnn.shape<1x1x1600x40> | tensor<[1,1,1600,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x8>>> <br> shape: #ttnn.shape<1x1x1600x240> | tensor<[1,1,1600,240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x8>>> <br> shape: #ttnn.shape<1x1x400x240> | tensor<[1,1,400,240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x3>>> <br> shape: #ttnn.shape<1x1x400x80> | tensor<[1,1,400,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x7>>> <br> shape: #ttnn.shape<1x1x400x200> | tensor<[1,1,400,200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x7>>> <br> shape: #ttnn.shape<1x1x400x200> | tensor<[1,1,400,200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x3>>> <br> shape: #ttnn.shape<1x1x400x80> | tensor<[1,1,400,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x6>>> <br> shape: #ttnn.shape<1x1x400x184> | tensor<[1,1,400,184,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x6>>> <br> shape: #ttnn.shape<1x1x400x184> | tensor<[1,1,400,184,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x15>>> <br> shape: #ttnn.shape<1x1x400x480> | tensor<[1,1,400,480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x15>>> <br> shape: #ttnn.shape<1x1x400x480> | tensor<[1,1,400,480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x1x120> | tensor<[1,1,1,120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x120x1x1> | tensor<[1,120,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<1x1x1x480> | tensor<[1,1,1,480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<1x480x1x1> | tensor<[1,480,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x4>>> <br> shape: #ttnn.shape<1x1x400x112> | tensor<[1,1,400,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x21>>> <br> shape: #ttnn.shape<1x1x400x672> | tensor<[1,1,400,672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x21>>> <br> shape: #ttnn.shape<1x1x400x672> | tensor<[1,1,400,672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<1x1x1x168> | tensor<[1,1,1,168,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<1x168x1x1> | tensor<[1,168,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x21>>> <br> shape: #ttnn.shape<1x1x1x672> | tensor<[1,1,1,672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<21x1>>> <br> shape: #ttnn.shape<1x672x1x1> | tensor<[1,672,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x21>>> <br> shape: #ttnn.shape<1x1x100x672> | tensor<[1,1,100,672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<1x1x100x80> | tensor<[1,1,100,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x15>>> <br> shape: #ttnn.shape<1x1x100x480> | tensor<[1,1,100,480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x15>>> <br> shape: #ttnn.shape<1x1x100x480> | tensor<[1,1,100,480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x8>>> <br> shape: #ttnn.shape<1x1x100x256> | tensor<[1,1,100,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x1x25x256> | tensor<[1,1,25,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 60160.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x25x512> | tensor<[1,1,25,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x25x128> | tensor<[1,1,25,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x9x128> | tensor<[1,1,9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x1x9x256> | tensor<[1,1,9,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x9x128> | tensor<[1,1,9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x4x128> | tensor<[1,1,4,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x1x4x256> | tensor<[1,1,4,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x4x64> | tensor<[1,1,4,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x1x64> | tensor<[1,1,1,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x1x128> | tensor<[1,1,1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x1>>> <br> shape: #ttnn.shape<1x1x400x24> | tensor<[1,1,400,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<1x24x20x20> | tensor<[1,24,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x15>>> <br> shape: #ttnn.shape<1x1x100x480> | tensor<[1,1,100,480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x1x100x24> | tensor<[1,1,100,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x24x10x10> | tensor<[1,24,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x25x512> | tensor<[1,1,25,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x25x24> | tensor<[1,1,25,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x24x5x5> | tensor<[1,24,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x1x9x256> | tensor<[1,1,9,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x24> | tensor<[1,1,9,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x24x3x3> | tensor<[1,24,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x1x4x256> | tensor<[1,1,4,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x4x24> | tensor<[1,1,4,24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x24x2x2> | tensor<[1,24,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x1x1x128> | tensor<[1,1,1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x18>>> <br> shape: #ttnn.shape<1x1x400x546> | tensor<[1,1,400,546,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<342x1>>> <br> shape: #ttnn.shape<1x546x20x20> | tensor<[1,546,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x18>>> <br> shape: #ttnn.shape<1x1x100x546> | tensor<[1,1,100,546,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.35 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<171x1>>> <br> shape: #ttnn.shape<1x546x10x10> | tensor<[1,546,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.35 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<1x1x25x546> | tensor<[1,1,25,546,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x546x5x5> | tensor<[1,546,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<1x1x9x546> | tensor<[1,1,9,546,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<52x1>>> <br> shape: #ttnn.shape<1x546x3x3> | tensor<[1,546,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<1x1x4x546> | tensor<[1,1,4,546,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x546x2x2> | tensor<[1,546,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<1x1x1x546> | tensor<[1,1,1,546,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x546x1x1> | tensor<[1,546,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x10>>> <br> shape: #ttnn.shape<3x320x320> | tensor<[3,320,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20> | tensor<[20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10> | tensor<[10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<5> | tensor<[5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3> | tensor<[3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x72x1x1> | tensor<[1,72,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x120x1x1> | tensor<[1,120,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<1x480x1x1> | tensor<[1,480,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<21x1>>> <br> shape: #ttnn.shape<1x672x1x1> | tensor<[1,672,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x5>>> <br> shape: #ttnn.shape<1x16x160x160> | tensor<[1,16,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x2>>> <br> shape: #ttnn.shape<1x240x40x40> | tensor<[1,240,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x240x20x20> | tensor<[1,240,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<125x1>>> <br> shape: #ttnn.shape<1x200x20x20> | tensor<[1,200,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<115x1>>> <br> shape: #ttnn.shape<1x184x20x20> | tensor<[1,184,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x1>>> <br> shape: #ttnn.shape<1x480x20x20> | tensor<[1,480,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<420x1>>> <br> shape: #ttnn.shape<1x672x20x20> | tensor<[1,672,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x672x10x10> | tensor<[1,672,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x480x10x10> | tensor<[1,480,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x256x10x10> | tensor<[1,256,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1x256x5x5> | tensor<[1,256,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x512x5x5> | tensor<[1,512,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x1>>> <br> shape: #ttnn.shape<1x128x5x5> | tensor<[1,128,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<12x1>>> <br> shape: #ttnn.shape<1x128x3x3> | tensor<[1,128,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x256x3x3> | tensor<[1,256,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x128x2x2> | tensor<[1,128,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x256x2x2> | tensor<[1,256,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x64x2x2> | tensor<[1,64,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<420x1>>> <br> shape: #ttnn.shape<1x672x20x20> | tensor<[1,672,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x480x10x10> | tensor<[1,480,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x72x1x1> | tensor<[1,72,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x120x1x1> | tensor<[1,120,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<1x480x1x1> | tensor<[1,480,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<21x1>>> <br> shape: #ttnn.shape<1x672x1x1> | tensor<[1,672,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<21x1>>> <br> shape: #ttnn.shape<1x672x1x1> | tensor<[1,672,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<1x480x1x1> | tensor<[1,480,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x5>>> <br> shape: #ttnn.shape<1x16x160x160> | tensor<[1,16,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x5>>> <br> shape: #ttnn.shape<1x64x160x160> | tensor<[1,64,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x3>>> <br> shape: #ttnn.shape<1x64x80x80> | tensor<[1,64,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x24x80x80> | tensor<[1,24,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<72> | tensor<[72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<180x3>>> <br> shape: #ttnn.shape<1x72x80x80> | tensor<[1,72,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x2>>> <br> shape: #ttnn.shape<1x40x40x40> | tensor<[1,40,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x2>>> <br> shape: #ttnn.shape<1x120x40x40> | tensor<[1,120,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x2>>> <br> shape: #ttnn.shape<1x240x40x40> | tensor<[1,240,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x240x20x20> | tensor<[1,240,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<50x1>>> <br> shape: #ttnn.shape<1x80x20x20> | tensor<[1,80,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<200> | tensor<[200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<125x1>>> <br> shape: #ttnn.shape<1x200x20x20> | tensor<[1,200,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<184> | tensor<[184,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<115x1>>> <br> shape: #ttnn.shape<1x184x20x20> | tensor<[1,184,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x1>>> <br> shape: #ttnn.shape<1x480x20x20> | tensor<[1,480,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<112> | tensor<[112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x1>>> <br> shape: #ttnn.shape<1x112x20x20> | tensor<[1,112,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x21>>> <br> shape: #ttnn.shape<672> | tensor<[672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<420x1>>> <br> shape: #ttnn.shape<1x672x20x20> | tensor<[1,672,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x672x10x10> | tensor<[1,672,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x80x10x10> | tensor<[1,80,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x480x10x10> | tensor<[1,480,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x256x10x10> | tensor<[1,256,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1x256x5x5> | tensor<[1,256,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x512x5x5> | tensor<[1,512,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x1>>> <br> shape: #ttnn.shape<1x128x5x5> | tensor<[1,128,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<12x1>>> <br> shape: #ttnn.shape<1x128x3x3> | tensor<[1,128,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x256x3x3> | tensor<[1,256,3,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x256x2x2> | tensor<[1,256,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x64x2x2> | tensor<[1,64,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.54 | 293.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x102>>> <br> shape: #ttnn.shape<3234> | tensor<[3234,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<72> | tensor<[72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<200> | tensor<[200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<184> | tensor<[184,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<112> | tensor<[112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x21>>> <br> shape: #ttnn.shape<672> | tensor<[672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x5>>> <br> shape: #ttnn.shape<1x16x160x160> | tensor<[1,16,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x5>>> <br> shape: #ttnn.shape<1x64x160x160> | tensor<[1,64,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x3>>> <br> shape: #ttnn.shape<1x64x80x80> | tensor<[1,64,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<180x3>>> <br> shape: #ttnn.shape<1x72x80x80> | tensor<[1,72,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<90x2>>> <br> shape: #ttnn.shape<1x72x40x40> | tensor<[1,72,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x24x1x1> | tensor<[1,24,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x2>>> <br> shape: #ttnn.shape<1x120x40x40> | tensor<[1,120,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x120x1x1> | tensor<[1,120,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<1x168x1x1> | tensor<[1,168,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 0.86 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<72> | tensor<[72,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<200> | tensor<[200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<184> | tensor<[184,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<112> | tensor<[112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x21>>> <br> shape: #ttnn.shape<672> | tensor<[672,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<13x1>>> <br> shape: #ttnn.shape<400x12> | tensor<[400,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x12> | tensor<[100,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<25x12> | tensor<[25,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<9x12> | tensor<[9,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<4x12> | tensor<[4,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1x4> | tensor<[3234,1,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<203x1>>> <br> shape: #ttnn.shape<3234x2x2> | tensor<[3234,2,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x10>>> <br> shape: #ttnn.shape<3x320x320> | tensor<[3,320,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3x1x1> | tensor<[3,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 319.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<320x1> | tensor<[320,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 319.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16x1x1> | tensor<[16,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x5>>> <br> shape: #ttnn.shape<1x64x160x160> | tensor<[1,64,160,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x3>>> <br> shape: #ttnn.shape<1x64x80x80> | tensor<[1,64,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24x1x1> | tensor<[24,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<180x3>>> <br> shape: #ttnn.shape<1x72x80x80> | tensor<[1,72,80,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<72x1x1> | tensor<[72,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<90x2>>> <br> shape: #ttnn.shape<1x72x40x40> | tensor<[1,72,40,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<72x1x1> | tensor<[72,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<40x1x1> | tensor<[40,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<120x1x1> | tensor<[120,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<240x1x1> | tensor<[240,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x240x20x20> | tensor<[1,240,20,20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<80x1x1> | tensor<[80,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<200x1x1> | tensor<[200,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<184x1x1> | tensor<[184,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<480x1x1> | tensor<[480,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<112x1x1> | tensor<[112,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<21x1>>> <br> shape: #ttnn.shape<672x1x1> | tensor<[672,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x2> | tensor<[3234,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.32 | 0.86 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x102>>> <br> shape: #ttnn.shape<3234> | tensor<[3234,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 548.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<3234x1> | tensor<[3234,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.36 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x256x1024> | tensor<[1,256,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x256x1024> | tensor<[1,256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x16x256x256> | tensor<[1,16,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x128>>> <br> shape: #ttnn.shape<256x4096> | tensor<[256,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x2> | tensor<[256,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<16x256x256> | tensor<[16,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<16x256x64> | tensor<[16,256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 4.98 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x128>>> <br> shape: #ttnn.shape<1x256x4096> | tensor<[1,256,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x128>>> <br> shape: #ttnn.shape<1x256x4096> | tensor<[1,256,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 8.82 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x128>>> <br> shape: #ttnn.shape<256x4096> | tensor<[256,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 39.35 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x2> | tensor<[256,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.57 | 10.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x16x256x64> | tensor<[1,16,256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x16x64x256> | tensor<[1,16,64,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x256x1024> | tensor<[1,256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x256x1024> | tensor<[1,256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x128>>> <br> shape: #ttnn.shape<256x4096> | tensor<[256,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x2> | tensor<[256,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x256> | tensor<[1,256,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.44 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x45> | tensor<[1,45,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x45> | tensor<[1,45,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<45> | tensor<[45,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x45> | tensor<[1,45,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x45> | tensor<[1,45,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x12x10x10> | tensor<[1,12,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<10x3072> | tensor<[10,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7813>>> <br> shape: #ttnn.shape<10x250002> | tensor<[10,250002,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<12x10x10> | tensor<[12,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 18.36 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<12x10x64> | tensor<[12,10,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 4.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x10x3072> | tensor<[1,10,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x10x3072> | tensor<[1,10,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 6.22 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<10x3072> | tensor<[10,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 30.29 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 45.35 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7813>>> <br> shape: #ttnn.shape<10x250002> | tensor<[10,250002,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 95.33 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<1x12x10x64> | tensor<[1,12,10,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x10> | tensor<[1,12,64,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<10x3072> | tensor<[10,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7813>>> <br> shape: #ttnn.shape<10x250002> | tensor<[10,250002,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7813>>> <br> shape: #ttnn.shape<250002> | tensor<[250002,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x10x10> | tensor<[1,1,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x10x10> | tensor<[1,1,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1x1280> | tensor<[1,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131009.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<1x320> | tensor<[1,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x4096x1> | tensor<[1,4096,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x4096x320> | tensor<[1,4096,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<4096x320> | tensor<[4096,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x4096x320> | tensor<[1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.61 | 2.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x80>>> <br> shape: #ttnn.shape<4096x2560> | tensor<[4096,2560,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x320x32x32> | tensor<[1,320,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 131008.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<1x640> | tensor<[1,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.76 | 8.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1> | tensor<[1,1024,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.53 | 8.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x160>>> <br> shape: #ttnn.shape<1024x5120> | tensor<[1024,5120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x640x16x16> | tensor<[1,640,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.47 | 2.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.65 | 10.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.56 | 12.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x320>>> <br> shape: #ttnn.shape<256x10240> | tensor<[256,10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 0.83 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1> | tensor<[1,64,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x64x1280> | tensor<[1,64,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<64x1280> | tensor<[64,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x64x1280> | tensor<[1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.56 | 13.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x320>>> <br> shape: #ttnn.shape<64x10240> | tensor<[64,10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x2560x8x8> | tensor<[1,2560,8,8,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.46 | 2.43 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x2560x16x16> | tensor<[1,2560,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131008.22 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x1920x16x16> | tensor<[1,1920,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.88 | 1.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x1>>> <br> shape: #ttnn.shape<1x1920x32x32> | tensor<[1,1920,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 131007.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x1280x32x32> | tensor<[1,1280,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131008.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x960x32x32> | tensor<[1,960,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.56 | 0.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x2>>> <br> shape: #ttnn.shape<1x960x64x64> | tensor<[1,960,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 131008.33 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x2>>> <br> shape: #ttnn.shape<1x640x64x64> | tensor<[1,640,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.7 | 1.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x128>>> <br> shape: #ttnn.shape<8x4096x4096> | tensor<[8,4096,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 17.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x2>>> <br> shape: #ttnn.shape<8x4096x40> | tensor<[8,4096,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.34 | 1.77 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x1>>> <br> shape: #ttnn.shape<8x4096x9> | tensor<[8,4096,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 16.99 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x2>>> <br> shape: #ttnn.shape<8x4096x40> | tensor<[8,4096,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 3.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x32>>> <br> shape: #ttnn.shape<8x1024x1024> | tensor<[8,1024,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 11.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x3>>> <br> shape: #ttnn.shape<8x1024x80> | tensor<[8,1024,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.31 | 1.72 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<8x1024x9> | tensor<[8,1024,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 17.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x3>>> <br> shape: #ttnn.shape<8x1024x80> | tensor<[8,1024,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.1 | 7.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<8x256x256> | tensor<[8,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 9.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x5>>> <br> shape: #ttnn.shape<8x256x160> | tensor<[8,256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.22 | 2.10 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<8x256x9> | tensor<[8,256,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 10.76 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x5>>> <br> shape: #ttnn.shape<8x256x160> | tensor<[8,256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 3.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<8x64x64> | tensor<[8,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 6.43 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x5>>> <br> shape: #ttnn.shape<8x64x160> | tensor<[8,64,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.34 | 1.80 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<8x64x9> | tensor<[8,64,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 9.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x5>>> <br> shape: #ttnn.shape<8x64x160> | tensor<[8,64,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.13 | 5.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<1x320> | tensor<[1,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x2560x8x8> | tensor<[1,2560,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x2560x16x16> | tensor<[1,2560,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x1920x16x16> | tensor<[1,1920,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x1>>> <br> shape: #ttnn.shape<1x1920x32x32> | tensor<[1,1920,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x1280x32x32> | tensor<[1,1280,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x960x32x32> | tensor<[1,960,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x2>>> <br> shape: #ttnn.shape<1x960x64x64> | tensor<[1,960,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x2>>> <br> shape: #ttnn.shape<1x640x64x64> | tensor<[1,640,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x10>>> <br> shape: #ttnn.shape<1x1x1024x320> | tensor<[1,1,1024,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x320x32x32> | tensor<[1,320,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.22 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.22 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x20>>> <br> shape: #ttnn.shape<1x1x256x640> | tensor<[1,1,256,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x640x16x16> | tensor<[1,640,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.78 | 22.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.78 | 22.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.52 | 3.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.52 | 3.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 7.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 7.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.53 | 9.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.53 | 9.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x1x64x1280> | tensor<[1,1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 21.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 21.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x1x64x1280> | tensor<[1,1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 109661309652255559514564082473128427520.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 109661309652255559514564082473128427520.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x1x64x1280> | tensor<[1,1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 114978221635395223006179310714249805824.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 114978221635395223006179310714249805824.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x1x64x1280> | tensor<[1,1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.12 | 16.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.12 | 16.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x1x64x1280> | tensor<[1,1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 14.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 14.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.59 | 29.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.59 | 29.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 13.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 13.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.82 | 44.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.82 | 44.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x1x256x1280> | tensor<[1,1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 17.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.5 | 17.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x40>>> <br> shape: #ttnn.shape<1x1x1024x1280> | tensor<[1,1,1024,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 14.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x1280x32x32> | tensor<[1,1280,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 14.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 2.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 2.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.46 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.46 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x20>>> <br> shape: #ttnn.shape<1x1x4096x640> | tensor<[1,1,4096,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x2>>> <br> shape: #ttnn.shape<1x640x64x64> | tensor<[1,640,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x1x4096x320> | tensor<[1,1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x1x4096x4> | tensor<[1,1,4096,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<1x4x64x64> | tensor<[1,4,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<1x160> | tensor<[1,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x4096x320> | tensor<[1,4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x64x1280> | tensor<[1,64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x40>>> <br> shape: #ttnn.shape<1x4096x1280> | tensor<[1,4096,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x40>>> <br> shape: #ttnn.shape<1x4096x1280> | tensor<[1,4096,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x80>>> <br> shape: #ttnn.shape<1x1024x2560> | tensor<[1,1024,2560,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x80>>> <br> shape: #ttnn.shape<1x1024x2560> | tensor<[1,1024,2560,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x160>>> <br> shape: #ttnn.shape<1x256x5120> | tensor<[1,256,5120,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x160>>> <br> shape: #ttnn.shape<1x256x5120> | tensor<[1,256,5120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x160>>> <br> shape: #ttnn.shape<1x64x5120> | tensor<[1,64,5120,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x160>>> <br> shape: #ttnn.shape<1x64x5120> | tensor<[1,64,5120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1x1280> | tensor<[1,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 8.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1x1280> | tensor<[1,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 3.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<1x320> | tensor<[1,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 3.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<4096x320> | tensor<[4096,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 4.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<9x320> | tensor<[9,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 12.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x80>>> <br> shape: #ttnn.shape<4096x2560> | tensor<[4096,2560,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 7.64 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<4096x320> | tensor<[4096,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.12 | 1.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<1x640> | tensor<[1,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 8.35 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 5.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<9x640> | tensor<[9,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 12.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x160>>> <br> shape: #ttnn.shape<1024x5120> | tensor<[1024,5120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 3.96 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 3.98 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 3.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<9x1280> | tensor<[9,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 13.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x320>>> <br> shape: #ttnn.shape<256x10240> | tensor<[256,10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 6.96 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<64x1280> | tensor<[64,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 2.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x320>>> <br> shape: #ttnn.shape<64x10240> | tensor<[64,10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 8.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<64x1280> | tensor<[64,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 5.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x2>>> <br> shape: #ttnn.shape<1x8x4096x40> | tensor<[1,8,4096,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x128>>> <br> shape: #ttnn.shape<1x8x40x4096> | tensor<[1,8,40,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x8x40x9> | tensor<[1,8,40,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x3>>> <br> shape: #ttnn.shape<1x8x1024x80> | tensor<[1,8,1024,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x32>>> <br> shape: #ttnn.shape<1x8x80x1024> | tensor<[1,8,80,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x1>>> <br> shape: #ttnn.shape<1x8x80x9> | tensor<[1,8,80,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x5>>> <br> shape: #ttnn.shape<1x8x256x160> | tensor<[1,8,256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x8>>> <br> shape: #ttnn.shape<1x8x160x256> | tensor<[1,8,160,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1x8x160x9> | tensor<[1,8,160,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x5>>> <br> shape: #ttnn.shape<1x8x64x160> | tensor<[1,8,64,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x2>>> <br> shape: #ttnn.shape<1x8x160x64> | tensor<[1,8,160,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<1x160> | tensor<[1,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1x1280> | tensor<[1,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x128>>> <br> shape: #ttnn.shape<1x32x10x4096> | tensor<[1,32,10,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.37 | 131009.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<1x320> | tensor<[1,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<1x4096x320> | tensor<[1,4096,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x10>>> <br> shape: #ttnn.shape<4096x320> | tensor<[4096,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x80>>> <br> shape: #ttnn.shape<4096x2560> | tensor<[4096,2560,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x80>>> <br> shape: #ttnn.shape<2560> | tensor<[2560,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x40>>> <br> shape: #ttnn.shape<1x4096x1280> | tensor<[1,4096,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.34 | 5.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x32>>> <br> shape: #ttnn.shape<1x32x10x1024> | tensor<[1,32,10,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x320x32x32> | tensor<[1,320,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.2 | 1.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<1x640> | tensor<[1,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x32>>> <br> shape: #ttnn.shape<1x32x20x1024> | tensor<[1,32,20,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.52 | 6.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x160>>> <br> shape: #ttnn.shape<1024x5120> | tensor<[1024,5120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x160>>> <br> shape: #ttnn.shape<5120> | tensor<[5120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x80>>> <br> shape: #ttnn.shape<1x1024x2560> | tensor<[1,1024,2560,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 14.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x8>>> <br> shape: #ttnn.shape<1x32x20x256> | tensor<[1,32,20,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x640x16x16> | tensor<[1,640,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 12.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x8>>> <br> shape: #ttnn.shape<1x32x40x256> | tensor<[1,32,40,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 6.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x320>>> <br> shape: #ttnn.shape<256x10240> | tensor<[256,10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x320>>> <br> shape: #ttnn.shape<10240> | tensor<[10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x160>>> <br> shape: #ttnn.shape<1x256x5120> | tensor<[1,256,5120,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 25.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x2>>> <br> shape: #ttnn.shape<1x32x40x64> | tensor<[1,32,40,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.31 | 2.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x64x1280> | tensor<[1,64,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<64x1280> | tensor<[64,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x320>>> <br> shape: #ttnn.shape<64x10240> | tensor<[64,10240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x160>>> <br> shape: #ttnn.shape<1x64x5120> | tensor<[1,64,5120,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 9.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x2>>> <br> shape: #ttnn.shape<1x32x80x64> | tensor<[1,32,80,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x2560x8x8> | tensor<[1,2560,8,8,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 131008.76 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x8>>> <br> shape: #ttnn.shape<1x32x80x256> | tensor<[1,32,80,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x2560x16x16> | tensor<[1,2560,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 131009.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x8>>> <br> shape: #ttnn.shape<1x32x60x256> | tensor<[1,32,60,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x1920x16x16> | tensor<[1,1920,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 131008.86 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x32>>> <br> shape: #ttnn.shape<1x32x60x1024> | tensor<[1,32,60,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x1>>> <br> shape: #ttnn.shape<1x1920x32x32> | tensor<[1,1920,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 108864.27 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x32>>> <br> shape: #ttnn.shape<1x32x40x1024> | tensor<[1,32,40,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x1280x32x32> | tensor<[1,1280,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 131008.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x32>>> <br> shape: #ttnn.shape<1x32x30x1024> | tensor<[1,32,30,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x960x32x32> | tensor<[1,960,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 2.64 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x128>>> <br> shape: #ttnn.shape<1x32x30x4096> | tensor<[1,32,30,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x2>>> <br> shape: #ttnn.shape<1x960x64x64> | tensor<[1,960,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131008.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x128>>> <br> shape: #ttnn.shape<1x32x20x4096> | tensor<[1,32,20,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x2>>> <br> shape: #ttnn.shape<1x640x64x64> | tensor<[1,640,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 2.33 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x4096x1> | tensor<[1,4096,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1> | tensor<[1,1024,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x64x1> | tensor<[1,64,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1x1280> | tensor<[1,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x320x32x32> | tensor<[1,320,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x640x16x16> | tensor<[1,640,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.59 | 3.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.59 | 3.95 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 25.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x2560x8x8> | tensor<[1,2560,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 4.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x2560x16x16> | tensor<[1,2560,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.56 | 7.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x1920x16x16> | tensor<[1,1920,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.65 | 1.87 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x1>>> <br> shape: #ttnn.shape<1x1920x32x32> | tensor<[1,1920,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x1>>> <br> shape: #ttnn.shape<1x1280x32x32> | tensor<[1,1280,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x960x32x32> | tensor<[1,960,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1920x2>>> <br> shape: #ttnn.shape<1x960x64x64> | tensor<[1,960,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1280x2>>> <br> shape: #ttnn.shape<1x640x64x64> | tensor<[1,640,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x40>>> <br> shape: #ttnn.shape<1x4096x1280> | tensor<[1,4096,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x80>>> <br> shape: #ttnn.shape<1x1024x2560> | tensor<[1,1024,2560,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x160>>> <br> shape: #ttnn.shape<1x256x5120> | tensor<[1,256,5120,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x160>>> <br> shape: #ttnn.shape<1x64x5120> | tensor<[1,64,5120,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x128>>> <br> shape: #ttnn.shape<1x32x10x4096> | tensor<[1,32,10,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x32>>> <br> shape: #ttnn.shape<1x32x10x1024> | tensor<[1,32,10,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x32>>> <br> shape: #ttnn.shape<1x32x20x1024> | tensor<[1,32,20,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x8>>> <br> shape: #ttnn.shape<1x32x20x256> | tensor<[1,32,20,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x8>>> <br> shape: #ttnn.shape<1x32x40x256> | tensor<[1,32,40,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x8>>> <br> shape: #ttnn.shape<1x32x80x256> | tensor<[1,32,80,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x8>>> <br> shape: #ttnn.shape<1x32x60x256> | tensor<[1,32,60,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x32>>> <br> shape: #ttnn.shape<1x32x60x1024> | tensor<[1,32,60,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x128>>> <br> shape: #ttnn.shape<1x32x20x4096> | tensor<[1,32,20,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x25x768> | tensor<[1,25,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x25x1> | tensor<[1,25,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x25x768> | tensor<[1,25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<25x768> | tensor<[25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x12x25x25> | tensor<[1,12,25,25,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<25x3072> | tensor<[25,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<25x2> | tensor<[25,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<12x25x25> | tensor<[12,25,25,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 9.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<12x25x64> | tensor<[12,25,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 2.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x25x3072> | tensor<[1,25,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x25x3072> | tensor<[1,25,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<25x768> | tensor<[25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 5.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<25x3072> | tensor<[25,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 18.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<25x768> | tensor<[25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 10.99 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<25x2> | tensor<[25,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 12.49 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<1x12x25x64> | tensor<[1,12,25,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x25> | tensor<[1,12,64,25,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x25x768> | tensor<[1,25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<25x768> | tensor<[25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<25x3072> | tensor<[25,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<25x2> | tensor<[25,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x25x1> | tensor<[1,25,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x25x25> | tensor<[1,1,25,25,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x1x768> | tensor<[1,1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x25> | tensor<[1,25,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x25x1> | tensor<[1,25,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x25x1> | tensor<[1,25,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x25x768> | tensor<[1,25,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x25x25> | tensor<[1,1,25,25,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1x1445x192> | tensor<[1,1445,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x1>>> <br> shape: #ttnn.shape<1x1445x1> | tensor<[1,1445,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1x1445x192> | tensor<[1,1445,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1445x192> | tensor<[1445,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x24>>> <br> shape: #ttnn.shape<1445x768> | tensor<[1445,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x6>>> <br> shape: #ttnn.shape<100x192> | tensor<[100,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<100x92> | tensor<[100,92,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x4> | tensor<[100,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<136x46>>> <br> shape: #ttnn.shape<3x1445x1445> | tensor<[3,1445,1445,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 28.64 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<136x2>>> <br> shape: #ttnn.shape<3x1445x64> | tensor<[3,1445,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 10.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1x1445x192> | tensor<[1,1445,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x6>>> <br> shape: #ttnn.shape<1x1x1344x192> | tensor<[1,1,1344,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<192x2>>> <br> shape: #ttnn.shape<1x192x32x42> | tensor<[1,192,32,42,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x24>>> <br> shape: #ttnn.shape<1x1445x768> | tensor<[1,1445,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x24>>> <br> shape: #ttnn.shape<1x1445x768> | tensor<[1,1445,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1445x192> | tensor<[1445,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 9.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x24>>> <br> shape: #ttnn.shape<1445x768> | tensor<[1445,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 11.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1445x192> | tensor<[1445,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 11.46 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x6>>> <br> shape: #ttnn.shape<100x192> | tensor<[100,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 11.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<100x92> | tensor<[100,92,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 36.26 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x4> | tensor<[100,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 23.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<136x2>>> <br> shape: #ttnn.shape<1x3x1445x64> | tensor<[1,3,1445,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x46>>> <br> shape: #ttnn.shape<1x3x64x1445> | tensor<[1,3,64,1445,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1x1445x192> | tensor<[1,1445,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x6>>> <br> shape: #ttnn.shape<1445x192> | tensor<[1445,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<192> | tensor<[192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x24>>> <br> shape: #ttnn.shape<1445x768> | tensor<[1445,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x6>>> <br> shape: #ttnn.shape<100x192> | tensor<[100,192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<100x92> | tensor<[100,92,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<92> | tensor<[92,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<100x4> | tensor<[100,4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<4> | tensor<[4,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x6>>> <br> shape: #ttnn.shape<1x100x192> | tensor<[1,100,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x1>>> <br> shape: #ttnn.shape<1x1445x1> | tensor<[1,1445,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<1x1x192> | tensor<[1,1,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x100x4> | tensor<[1,100,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 0.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x6>>> <br> shape: #ttnn.shape<1x100x192> | tensor<[1,100,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<130x6>>> <br> shape: #ttnn.shape<1x4150x192> | tensor<[1,4150,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<46x1>>> <br> shape: #ttnn.shape<1x1445x1> | tensor<[1,1445,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.41 | 0.68 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.57 | 0.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 2.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 4080.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 4080.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 2.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 4080.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 2.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x2>>> <br> shape: #ttnn.shape<1x1x12544x64> | tensor<[1,1,12544,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.26 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x2>>> <br> shape: #ttnn.shape<1x1x3136x64> | tensor<[1,1,3136,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.58 | 3.89 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 124947431603782092052957863666352390144.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 240590267237069772995589077910742368256.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.57 | 2.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x8>>> <br> shape: #ttnn.shape<1x1x196x256> | tensor<[1,1,196,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 3.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x8>>> <br> shape: #ttnn.shape<1x1x196x256> | tensor<[1,1,196,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.32 | 1.27 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x8>>> <br> shape: #ttnn.shape<1x1x196x256> | tensor<[1,1,196,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 0.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x16>>> <br> shape: #ttnn.shape<1x1x49x512> | tensor<[1,1,49,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 120959747616427344434246442485511356416.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x16>>> <br> shape: #ttnn.shape<1x1x49x512> | tensor<[1,1,49,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 118301291624857512688438828364950667264.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x16>>> <br> shape: #ttnn.shape<1x1x49x512> | tensor<[1,1,49,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 1.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x512x1x1> | tensor<[1,512,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 6.22 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 4.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 4.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 4.20 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 4.20 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131008.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131008.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131008.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131008.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x12x8x8> | tensor<[1,12,8,8,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x12x8x1> | tensor<[1,12,8,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x8x768> | tensor<[1,8,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1> | tensor<[1,8,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x8x768> | tensor<[1,8,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x12x8x8> | tensor<[1,12,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.08 | 10.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x768x8> | tensor<[1,768,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x3> | tensor<[1,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<12x8x8> | tensor<[12,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 86.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<12x8x64> | tensor<[12,8,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 2.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x12x8x8> | tensor<[1,12,8,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<96x1>>> <br> shape: #ttnn.shape<1x3072x8> | tensor<[1,3072,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<96x1>>> <br> shape: #ttnn.shape<1x3072x8> | tensor<[1,3072,8,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 0.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x3> | tensor<[1,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.62 | 1.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x8> | tensor<[1,1,1,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x8x768> | tensor<[1,8,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x3> | tensor<[1,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3> | tensor<[3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1> | tensor<[1,8,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x8> | tensor<[1,1,1,8,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8> | tensor<[1,8,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.35 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x8x768> | tensor<[1,8,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x64>>> <br> shape: #ttnn.shape<1x8x256x2048> | tensor<[1,8,256,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x8x256x1> | tensor<[1,8,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<1x8x256x256> | tensor<[1,8,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x8x256x1> | tensor<[1,8,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x8x2048x256> | tensor<[1,8,2048,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x8x2048x1> | tensor<[1,8,2048,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1> | tensor<[1,2048,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<2048x256> | tensor<[2048,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x40>>> <br> shape: #ttnn.shape<2048x1280> | tensor<[2048,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x64>>> <br> shape: #ttnn.shape<1x8x256x2048> | tensor<[1,8,256,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x24>>> <br> shape: #ttnn.shape<256x768> | tensor<[256,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<2048x768> | tensor<[2048,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x9>>> <br> shape: #ttnn.shape<2048x262> | tensor<[2048,262,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.81 | 21.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x64>>> <br> shape: #ttnn.shape<8x256x2048> | tensor<[8,256,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 108.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x5>>> <br> shape: #ttnn.shape<8x256x160> | tensor<[8,256,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 0.51 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<8x256x256> | tensor<[8,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 196.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x5>>> <br> shape: #ttnn.shape<8x256x160> | tensor<[8,256,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 3.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<8x2048x256> | tensor<[8,2048,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 332.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x3>>> <br> shape: #ttnn.shape<8x2048x96> | tensor<[8,2048,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 1.07 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x64>>> <br> shape: #ttnn.shape<1x8x256x2048> | tensor<[1,8,256,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<1x8x256x256> | tensor<[1,8,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x8x2048x256> | tensor<[1,8,2048,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<2048x256> | tensor<[2048,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 3.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x40>>> <br> shape: #ttnn.shape<2048x1280> | tensor<[2048,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 0.90 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 4.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x24>>> <br> shape: #ttnn.shape<256x768> | tensor<[256,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 3.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<2048x768> | tensor<[2048,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 4.58 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x9>>> <br> shape: #ttnn.shape<2048x262> | tensor<[2048,262,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 19.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x1x1x2048> | tensor<[1,1,1,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<2048x256> | tensor<[2048,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x40>>> <br> shape: #ttnn.shape<2048x1280> | tensor<[2048,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x24>>> <br> shape: #ttnn.shape<256x768> | tensor<[256,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x24>>> <br> shape: #ttnn.shape<2048x768> | tensor<[2048,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1> | tensor<[1,2048,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x1x1x2048> | tensor<[1,1,1,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.52 | 23.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.7 | 9.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 131021.29 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 131016.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 131008.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131023.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 131024.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 131021.15 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131021.27 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x512x14x14> | tensor<[1,512,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 131023.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131017.95 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x2048x7x7> | tensor<[1,2048,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131030.95 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x2048x7x7> | tensor<[1,2048,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 41.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x2>>> <br> shape: #ttnn.shape<1x1x12544x64> | tensor<[1,1,12544,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 35.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x2>>> <br> shape: #ttnn.shape<1x1x3136x64> | tensor<[1,1,3136,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.56 | 85.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x2>>> <br> shape: #ttnn.shape<1x1x3136x64> | tensor<[1,1,3136,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x8>>> <br> shape: #ttnn.shape<1x1x3136x256> | tensor<[1,1,3136,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x2>>> <br> shape: #ttnn.shape<1x1x3136x64> | tensor<[1,1,3136,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x4>>> <br> shape: #ttnn.shape<1x1x3136x128> | tensor<[1,1,3136,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.23 | 27.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.42 | 15.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.43 | 22.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x128> | tensor<[1,1,784,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.33 | 27.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x8>>> <br> shape: #ttnn.shape<1x1x784x256> | tensor<[1,1,784,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 20.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x8>>> <br> shape: #ttnn.shape<1x1x196x256> | tensor<[1,1,196,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.16 | 20.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x1x196x1024> | tensor<[1,1,196,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.42 | 11.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x1x196x1024> | tensor<[1,1,196,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.33 | 13.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x8>>> <br> shape: #ttnn.shape<1x1x196x256> | tensor<[1,1,196,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 115642835633287680942631214244389978112.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x8>>> <br> shape: #ttnn.shape<1x1x196x256> | tensor<[1,1,196,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.44 | 11.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x16>>> <br> shape: #ttnn.shape<1x1x196x512> | tensor<[1,1,196,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 15.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x16>>> <br> shape: #ttnn.shape<1x1x49x512> | tensor<[1,1,49,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 71113697774492999200353677724998434816.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x64>>> <br> shape: #ttnn.shape<1x1x49x2048> | tensor<[1,1,49,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.14 | 8.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x64>>> <br> shape: #ttnn.shape<1x1x49x2048> | tensor<[1,1,49,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x16>>> <br> shape: #ttnn.shape<1x1x49x512> | tensor<[1,1,49,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 72442925770277915073257484785278779392.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x16>>> <br> shape: #ttnn.shape<1x1x49x512> | tensor<[1,1,49,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 142227395548985998400707355449996869632.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1x1> | tensor<[1,2048,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 7.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x512x14x14> | tensor<[1,512,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x2048x7x7> | tensor<[1,2048,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x512x14x14> | tensor<[1,512,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x2048x7x7> | tensor<[1,2048,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.52 | 45.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.52 | 45.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 27.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 27.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 34.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 34.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 17.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 17.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 24.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 24.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 23.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 23.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1024x1x1> | tensor<[1024,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x512x14x14> | tensor<[1,512,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 16.84 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 16.84 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 13.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 13.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x2048x7x7> | tensor<[1,2048,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<2048x1x1> | tensor<[2048,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<76x7>>> <br> shape: #ttnn.shape<1x12x201x201> | tensor<[1,12,201,201,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<76x1>>> <br> shape: #ttnn.shape<1x12x201x1> | tensor<[1,12,201,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1> | tensor<[1,8,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12> | tensor<[12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x193x768> | tensor<[1,193,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x201x1> | tensor<[1,201,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x201x768> | tensor<[1,201,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<201x768> | tensor<[201,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<76x7>>> <br> shape: #ttnn.shape<1x12x201x201> | tensor<[1,12,201,201,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.64 | 85.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x201x768> | tensor<[1,201,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<201x3072> | tensor<[201,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x98>>> <br> shape: #ttnn.shape<1x3129> | tensor<[1,3129,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<76x7>>> <br> shape: #ttnn.shape<12x201x201> | tensor<[12,201,201,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<76x2>>> <br> shape: #ttnn.shape<12x201x64> | tensor<[12,201,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 3.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x201x768> | tensor<[1,201,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<1x201> | tensor<[1,201,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x24>>> <br> shape: #ttnn.shape<1x1x192x768> | tensor<[1,1,192,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<288x1>>> <br> shape: #ttnn.shape<1x768x12x16> | tensor<[1,768,12,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<76x7>>> <br> shape: #ttnn.shape<1x12x201x201> | tensor<[1,12,201,201,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<1x201x3072> | tensor<[1,201,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<1x201x3072> | tensor<[1,201,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<201x768> | tensor<[201,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 10.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<201x3072> | tensor<[201,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 9.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<201x768> | tensor<[201,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 65.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 4.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 12.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x98>>> <br> shape: #ttnn.shape<1x3129> | tensor<[1,3129,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 37.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x8x768> | tensor<[1,8,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12> | tensor<[12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<1x1x1x201> | tensor<[1,1,1,201,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x201x768> | tensor<[1,201,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<201x768> | tensor<[201,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<201x3072> | tensor<[201,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1536> | tensor<[1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x98>>> <br> shape: #ttnn.shape<1x3129> | tensor<[1,3129,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x98>>> <br> shape: #ttnn.shape<3129> | tensor<[3129,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x201x1> | tensor<[1,201,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<1x192> | tensor<[1,192,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<1x1x1x201> | tensor<[1,1,1,201,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<192x1> | tensor<[192,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8> | tensor<[1,8,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x24>>> <br> shape: #ttnn.shape<1x144x768> | tensor<[1,144,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<12x16x2> | tensor<[12,16,2,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1x8> | tensor<[1,8,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<22x1>>> <br> shape: #ttnn.shape<1x1x676x32> | tensor<[1,1,676,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.58 | 1.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<26x1>>> <br> shape: #ttnn.shape<1x32x26x26> | tensor<[1,32,26,26,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.58 | 1.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x2>>> <br> shape: #ttnn.shape<1x1x576x64> | tensor<[1,1,576,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 76430609757632662691968905966119813120.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<48x1>>> <br> shape: #ttnn.shape<1x64x24x24> | tensor<[1,64,24,24,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 76430609757632662691968905966119813120.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 0.18 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.19 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10> | tensor<[10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<26x1>>> <br> shape: #ttnn.shape<1x32x26x26> | tensor<[1,32,26,26,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<48x1>>> <br> shape: #ttnn.shape<1x64x24x24> | tensor<[1,64,24,24,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<16x19x19> | tensor<[16,19,19,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<16x19x1> | tensor<[16,19,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x19> | tensor<[1,19,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x19x1024> | tensor<[1,19,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x19x1> | tensor<[1,19,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x19x1024> | tensor<[1,19,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<19x1024> | tensor<[19,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x16x19x19> | tensor<[1,16,19,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.38 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<19x4096> | tensor<[19,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<16x19x19> | tensor<[16,19,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 10.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<16x19x64> | tensor<[16,19,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.15 | 149.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<19x19> | tensor<[19,19,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8001>>> <br> shape: #ttnn.shape<19x256008> | tensor<[19,256008,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x19x4096> | tensor<[1,19,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x19x4096> | tensor<[1,19,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19x1> | tensor<[19,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x16x19x19> | tensor<[1,16,19,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<19x1024> | tensor<[19,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 9.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<19x4096> | tensor<[19,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 14.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<19x1024> | tensor<[19,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 388.77 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8001>>> <br> shape: #ttnn.shape<19x256008> | tensor<[19,256008,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x19x1024> | tensor<[1,19,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x19x1024> | tensor<[1,19,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<19x1024> | tensor<[19,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x19x1024> | tensor<[1,19,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<19x4096> | tensor<[19,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1x19> | tensor<[1,19,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x19x1> | tensor<[1,19,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x19x19> | tensor<[1,1,19,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x18> | tensor<[1,18,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.14 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x18> | tensor<[1,18,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x19x1> | tensor<[1,19,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8001>>> <br> shape: #ttnn.shape<19x256008> | tensor<[19,256008,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19x1> | tensor<[19,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19x19> | tensor<[19,19,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x19x19> | tensor<[1,1,19,19,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x19> | tensor<[1,19,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.7 | 1.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.86 | 0.74 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14> | tensor<[14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x14x56x56> | tensor<[1,14,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.93 | 0.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.92 | 0.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x2>>> <br> shape: #ttnn.shape<1x40x56x56> | tensor<[1,40,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.88 | 0.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<68> | tensor<[68,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<119x2>>> <br> shape: #ttnn.shape<1x68x56x56> | tensor<[1,68,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.91 | 0.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.93 | 0.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x28x28> | tensor<[1,16,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.98 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<28> | tensor<[28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x28x28x28> | tensor<[1,28,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.9 | 0.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<46> | tensor<[46,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<41x1>>> <br> shape: #ttnn.shape<1x46x28x28> | tensor<[1,46,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.93 | 0.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<78> | tensor<[78,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<69x1>>> <br> shape: #ttnn.shape<1x78x28x28> | tensor<[1,78,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 0.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<134> | tensor<[134,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<118x1>>> <br> shape: #ttnn.shape<1x134x28x28> | tensor<[1,134,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 0.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.95 | 0.43 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20> | tensor<[20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x20x28x28> | tensor<[1,20,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.97 | 0.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<34> | tensor<[34,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x34x28x28> | tensor<[1,34,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.95 | 0.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<58> | tensor<[58,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x58x28x28> | tensor<[1,58,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 0.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<98> | tensor<[98,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x98x28x28> | tensor<[1,98,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.92 | 0.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<168> | tensor<[168,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x168x28x28> | tensor<[1,168,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x320x28x28> | tensor<[1,320,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.9 | 0.76 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x40x14x14> | tensor<[1,40,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 0.21 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x68x14x14> | tensor<[1,68,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.92 | 0.46 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<116> | tensor<[116,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x116x14x14> | tensor<[1,116,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.87 | 0.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<196> | tensor<[196,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x196x14x14> | tensor<[1,196,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.9 | 0.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x11>>> <br> shape: #ttnn.shape<334> | tensor<[334,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x334x14x14> | tensor<[1,334,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.96 | 0.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x640x14x14> | tensor<[1,640,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.86 | 0.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.93 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x9>>> <br> shape: #ttnn.shape<272> | tensor<[272,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x1>>> <br> shape: #ttnn.shape<1x272x7x7> | tensor<[1,272,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.89 | 2.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<462> | tensor<[462,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<1x462x7x7> | tensor<[1,462,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.9 | 0.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x1024x7x7> | tensor<[1,1024,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<137x2>>> <br> shape: #ttnn.shape<1x78x56x56> | tensor<[1,78,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<179x2>>> <br> shape: #ttnn.shape<1x102x56x56> | tensor<[1,102,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<95x2>>> <br> shape: #ttnn.shape<1x54x56x56> | tensor<[1,54,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<249x2>>> <br> shape: #ttnn.shape<1x142x56x56> | tensor<[1,142,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<217x2>>> <br> shape: #ttnn.shape<1x124x56x56> | tensor<[1,124,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x144x28x28> | tensor<[1,144,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<151x1>>> <br> shape: #ttnn.shape<1x172x28x28> | tensor<[1,172,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<55x1>>> <br> shape: #ttnn.shape<1x62x28x28> | tensor<[1,62,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<191x1>>> <br> shape: #ttnn.shape<1x218x28x28> | tensor<[1,218,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<83x1>>> <br> shape: #ttnn.shape<1x94x28x28> | tensor<[1,94,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<107x1>>> <br> shape: #ttnn.shape<1x122x28x28> | tensor<[1,122,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<259x1>>> <br> shape: #ttnn.shape<1x296x28x28> | tensor<[1,296,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<230x1>>> <br> shape: #ttnn.shape<1x262x28x28> | tensor<[1,262,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<242x1>>> <br> shape: #ttnn.shape<1x276x28x28> | tensor<[1,276,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<272x1>>> <br> shape: #ttnn.shape<1x310x28x28> | tensor<[1,310,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<69x1>>> <br> shape: #ttnn.shape<1x78x28x28> | tensor<[1,78,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<322x1>>> <br> shape: #ttnn.shape<1x368x28x28> | tensor<[1,368,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<104x1>>> <br> shape: #ttnn.shape<1x118x28x28> | tensor<[1,118,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<133x1>>> <br> shape: #ttnn.shape<1x152x28x28> | tensor<[1,152,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<408x1>>> <br> shape: #ttnn.shape<1x466x28x28> | tensor<[1,466,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<287x1>>> <br> shape: #ttnn.shape<1x328x28x28> | tensor<[1,328,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<158x1>>> <br> shape: #ttnn.shape<1x360x14x14> | tensor<[1,360,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<188x1>>> <br> shape: #ttnn.shape<1x428x14x14> | tensor<[1,428,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<69x1>>> <br> shape: #ttnn.shape<1x156x14x14> | tensor<[1,156,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<238x1>>> <br> shape: #ttnn.shape<1x544x14x14> | tensor<[1,544,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<104x1>>> <br> shape: #ttnn.shape<1x236x14x14> | tensor<[1,236,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<133x1>>> <br> shape: #ttnn.shape<1x304x14x14> | tensor<[1,304,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<324x1>>> <br> shape: #ttnn.shape<1x740x14x14> | tensor<[1,740,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<287x1>>> <br> shape: #ttnn.shape<1x654x14x14> | tensor<[1,654,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<175x1>>> <br> shape: #ttnn.shape<1x800x7x7> | tensor<[1,800,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<235x1>>> <br> shape: #ttnn.shape<1x1072x7x7> | tensor<[1,1072,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<172x1>>> <br> shape: #ttnn.shape<1x782x7x7> | tensor<[1,782,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x1>>> <br> shape: #ttnn.shape<1x1x12544x32> | tensor<[1,1,12544,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x2>>> <br> shape: #ttnn.shape<1x1x12544x64> | tensor<[1,1,12544,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.45 | 11.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x14> | tensor<[1,1,3136,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 544693617285567320955614658560.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x24> | tensor<[1,1,3136,24,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.34 | 5.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x14> | tensor<[1,1,3136,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.42 | 1.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x2>>> <br> shape: #ttnn.shape<1x1x3136x40> | tensor<[1,1,3136,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 6.72 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x14> | tensor<[1,1,3136,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 83409056735503471024713893032591622144.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x24> | tensor<[1,1,3136,24,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 62141408802944817058252980068106108928.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x3>>> <br> shape: #ttnn.shape<1x1x3136x68> | tensor<[1,1,3136,68,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x4>>> <br> shape: #ttnn.shape<1x1x3136x128> | tensor<[1,1,3136,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x16> | tensor<[1,1,784,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.24 | 3.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x28> | tensor<[1,1,784,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.35 | 4.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x16> | tensor<[1,1,784,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 76430609757632662691968905966119813120.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x46> | tensor<[1,1,784,46,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.62 | 3.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x16> | tensor<[1,1,784,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.31 | 2.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x28> | tensor<[1,1,784,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 46522979852472055551633247109812060160.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x3>>> <br> shape: #ttnn.shape<1x1x784x78> | tensor<[1,1,784,78,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 5.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x16> | tensor<[1,1,784,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.51 | 1.58 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x28> | tensor<[1,1,784,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 2.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x46> | tensor<[1,1,784,46,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.31 | 2.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x5>>> <br> shape: #ttnn.shape<1x1x784x134> | tensor<[1,1,784,134,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 4.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x8>>> <br> shape: #ttnn.shape<1x1x784x256> | tensor<[1,1,784,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 2.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x20> | tensor<[1,1,784,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 1.84 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x34> | tensor<[1,1,784,34,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 2.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x20> | tensor<[1,1,784,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.38 | 0.93 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x58> | tensor<[1,1,784,58,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.34 | 1.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x20> | tensor<[1,1,784,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 1.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x34> | tensor<[1,1,784,34,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.48 | 1.18 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x4>>> <br> shape: #ttnn.shape<1x1x784x98> | tensor<[1,1,784,98,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.26 | 2.33 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x20> | tensor<[1,1,784,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 0.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x34> | tensor<[1,1,784,34,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 1.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x1x784x58> | tensor<[1,1,784,58,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.36 | 1.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x6>>> <br> shape: #ttnn.shape<1x1x784x168> | tensor<[1,1,784,168,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.36 | 3.27 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x10>>> <br> shape: #ttnn.shape<1x1x784x320> | tensor<[1,1,784,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 2.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x2>>> <br> shape: #ttnn.shape<1x1x196x40> | tensor<[1,1,196,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 1.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x3>>> <br> shape: #ttnn.shape<1x1x196x68> | tensor<[1,1,196,68,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 3.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x2>>> <br> shape: #ttnn.shape<1x1x196x40> | tensor<[1,1,196,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 1.45 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x4>>> <br> shape: #ttnn.shape<1x1x196x116> | tensor<[1,1,196,116,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 44196830859848452774051584754321457152.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x2>>> <br> shape: #ttnn.shape<1x1x196x40> | tensor<[1,1,196,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.36 | 2.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x3>>> <br> shape: #ttnn.shape<1x1x196x68> | tensor<[1,1,196,68,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.37 | 2.45 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<1x1x196x196> | tensor<[1,1,196,196,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 59815259810321214280671317712615505920.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x2>>> <br> shape: #ttnn.shape<1x1x196x40> | tensor<[1,1,196,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 68787548781869396422772015369507831808.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x3>>> <br> shape: #ttnn.shape<1x1x196x68> | tensor<[1,1,196,68,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 70116776777654312295675822429788176384.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x4>>> <br> shape: #ttnn.shape<1x1x196x116> | tensor<[1,1,196,116,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 2.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x11>>> <br> shape: #ttnn.shape<1x1x196x334> | tensor<[1,1,196,334,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 114978221635395223006179310714249805824.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x20>>> <br> shape: #ttnn.shape<1x1x196x640> | tensor<[1,1,196,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 1.82 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x5>>> <br> shape: #ttnn.shape<1x1x49x160> | tensor<[1,1,49,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 95704415696513942849074108340184809472.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x9>>> <br> shape: #ttnn.shape<1x1x49x272> | tensor<[1,1,49,272,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 113648993639610307133275503653969461248.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x5>>> <br> shape: #ttnn.shape<1x1x49x160> | tensor<[1,1,49,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 72442925770277915073257484785278779392.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x15>>> <br> shape: #ttnn.shape<1x1x49x462> | tensor<[1,1,49,462,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 106338239662793269832304564822427566080.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x32>>> <br> shape: #ttnn.shape<1x1x49x1024> | tensor<[1,1,49,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x14x56x56> | tensor<[1,14,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x2>>> <br> shape: #ttnn.shape<1x40x56x56> | tensor<[1,40,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<119x2>>> <br> shape: #ttnn.shape<1x68x56x56> | tensor<[1,68,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x28x28> | tensor<[1,16,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x28x28x28> | tensor<[1,28,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<41x1>>> <br> shape: #ttnn.shape<1x46x28x28> | tensor<[1,46,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<69x1>>> <br> shape: #ttnn.shape<1x78x28x28> | tensor<[1,78,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<118x1>>> <br> shape: #ttnn.shape<1x134x28x28> | tensor<[1,134,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x20x28x28> | tensor<[1,20,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x34x28x28> | tensor<[1,34,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x58x28x28> | tensor<[1,58,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x98x28x28> | tensor<[1,98,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x168x28x28> | tensor<[1,168,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x320x28x28> | tensor<[1,320,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x40x14x14> | tensor<[1,40,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x68x14x14> | tensor<[1,68,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x116x14x14> | tensor<[1,116,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x196x14x14> | tensor<[1,196,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x334x14x14> | tensor<[1,334,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x640x14x14> | tensor<[1,640,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x1>>> <br> shape: #ttnn.shape<1x272x7x7> | tensor<[1,272,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<1x462x7x7> | tensor<[1,462,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x1024x7x7> | tensor<[1,1024,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1x1> | tensor<[1,1024,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 11.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14> | tensor<[14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x14x56x56> | tensor<[1,14,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x2>>> <br> shape: #ttnn.shape<1x40x56x56> | tensor<[1,40,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<68> | tensor<[68,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<119x2>>> <br> shape: #ttnn.shape<1x68x56x56> | tensor<[1,68,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x28x28> | tensor<[1,16,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<28> | tensor<[28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x28x28x28> | tensor<[1,28,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<46> | tensor<[46,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<41x1>>> <br> shape: #ttnn.shape<1x46x28x28> | tensor<[1,46,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<78> | tensor<[78,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<69x1>>> <br> shape: #ttnn.shape<1x78x28x28> | tensor<[1,78,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<134> | tensor<[134,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<118x1>>> <br> shape: #ttnn.shape<1x134x28x28> | tensor<[1,134,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20> | tensor<[20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x20x28x28> | tensor<[1,20,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<34> | tensor<[34,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x34x28x28> | tensor<[1,34,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<58> | tensor<[58,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x58x28x28> | tensor<[1,58,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<98> | tensor<[98,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x98x28x28> | tensor<[1,98,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<168> | tensor<[168,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x168x28x28> | tensor<[1,168,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x320x28x28> | tensor<[1,320,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x40x14x14> | tensor<[1,40,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x68x14x14> | tensor<[1,68,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<116> | tensor<[116,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x116x14x14> | tensor<[1,116,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<196> | tensor<[196,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x196x14x14> | tensor<[1,196,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x11>>> <br> shape: #ttnn.shape<334> | tensor<[334,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x334x14x14> | tensor<[1,334,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x640x14x14> | tensor<[1,640,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x9>>> <br> shape: #ttnn.shape<272> | tensor<[272,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x1>>> <br> shape: #ttnn.shape<1x272x7x7> | tensor<[1,272,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<462> | tensor<[462,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<1x462x7x7> | tensor<[1,462,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x1024x7x7> | tensor<[1,1024,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14> | tensor<[14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<68> | tensor<[68,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<28> | tensor<[28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<46> | tensor<[46,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<78> | tensor<[78,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<134> | tensor<[134,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20> | tensor<[20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<34> | tensor<[34,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<58> | tensor<[58,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<98> | tensor<[98,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<168> | tensor<[168,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<116> | tensor<[116,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<196> | tensor<[196,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x11>>> <br> shape: #ttnn.shape<334> | tensor<[334,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x9>>> <br> shape: #ttnn.shape<272> | tensor<[272,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<462> | tensor<[462,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14> | tensor<[14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<68> | tensor<[68,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<28> | tensor<[28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<46> | tensor<[46,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<78> | tensor<[78,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<134> | tensor<[134,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20> | tensor<[20,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<34> | tensor<[34,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<58> | tensor<[58,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<98> | tensor<[98,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<168> | tensor<[168,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<116> | tensor<[116,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<196> | tensor<[196,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x11>>> <br> shape: #ttnn.shape<334> | tensor<[334,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x9>>> <br> shape: #ttnn.shape<272> | tensor<[272,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<462> | tensor<[462,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131009.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131009.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131016.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131016.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x2>>> <br> shape: #ttnn.shape<1x14x56x56> | tensor<[1,14,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 131009.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14x1x1> | tensor<[14,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 131009.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 7.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24x1x1> | tensor<[24,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 7.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x2>>> <br> shape: #ttnn.shape<1x40x56x56> | tensor<[1,40,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131009.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<40x1x1> | tensor<[40,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131009.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<119x2>>> <br> shape: #ttnn.shape<1x68x56x56> | tensor<[1,68,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 11.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<68x1x1> | tensor<[68,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 11.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x2>>> <br> shape: #ttnn.shape<1x128x56x56> | tensor<[1,128,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x28x28> | tensor<[1,16,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 3.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16x1x1> | tensor<[16,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 3.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x28x28x28> | tensor<[1,28,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 4.95 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<28x1x1> | tensor<[28,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 4.95 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<41x1>>> <br> shape: #ttnn.shape<1x46x28x28> | tensor<[1,46,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 4.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<46x1x1> | tensor<[46,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 4.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<69x1>>> <br> shape: #ttnn.shape<1x78x28x28> | tensor<[1,78,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 5.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<78x1x1> | tensor<[78,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 5.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<118x1>>> <br> shape: #ttnn.shape<1x134x28x28> | tensor<[1,134,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 5.80 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<134x1x1> | tensor<[134,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 5.80 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x256x28x28> | tensor<[1,256,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 2.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 2.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x20x28x28> | tensor<[1,20,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 2.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<20x1x1> | tensor<[20,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 2.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x34x28x28> | tensor<[1,34,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 2.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<34x1x1> | tensor<[34,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 2.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x58x28x28> | tensor<[1,58,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 2.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<58x1x1> | tensor<[58,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 2.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x98x28x28> | tensor<[1,98,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 2.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<98x1x1> | tensor<[98,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 2.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x168x28x28> | tensor<[1,168,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 4.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<168x1x1> | tensor<[168,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 4.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x320x28x28> | tensor<[1,320,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 2.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<320x1x1> | tensor<[320,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 2.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x40x14x14> | tensor<[1,40,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 1.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<40x1x1> | tensor<[40,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 1.37 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x68x14x14> | tensor<[1,68,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 3.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<68x1x1> | tensor<[68,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 3.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<51x1>>> <br> shape: #ttnn.shape<1x116x14x14> | tensor<[1,116,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131009.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<116x1x1> | tensor<[116,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131009.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<86x1>>> <br> shape: #ttnn.shape<1x196x14x14> | tensor<[1,196,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 3.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<196x1x1> | tensor<[196,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 3.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<147x1>>> <br> shape: #ttnn.shape<1x334x14x14> | tensor<[1,334,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 2.83 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<11x1>>> <br> shape: #ttnn.shape<334x1x1> | tensor<[334,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 2.83 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x640x14x14> | tensor<[1,640,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 2.57 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<20x1>>> <br> shape: #ttnn.shape<640x1x1> | tensor<[640,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 2.57 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131008.54 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<160x1x1> | tensor<[160,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131008.54 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x1>>> <br> shape: #ttnn.shape<1x272x7x7> | tensor<[1,272,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 5.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<9x1>>> <br> shape: #ttnn.shape<272x1x1> | tensor<[272,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 5.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<102x1>>> <br> shape: #ttnn.shape<1x462x7x7> | tensor<[1,462,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 0.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<462x1x1> | tensor<[462,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 0.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<224x1>>> <br> shape: #ttnn.shape<1x1024x7x7> | tensor<[1,1024,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 0.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1024x1x1> | tensor<[1024,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 0.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x16>>> <br> shape: #ttnn.shape<1x32x512x512> | tensor<[1,32,512,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.68 | 3.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.66 | 2.98 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.78 | 1.96 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131014.83 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.64 | 2.47 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.78 | 2.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.8 | 1.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.81 | 3.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.95 | 1.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131009.45 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.9 | 1.68 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 313697807005240146005298466226161319936.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x256x16x16> | tensor<[1,256,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x128x32x32> | tensor<[1,128,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.99 | 0.73 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<768x1>>> <br> shape: #ttnn.shape<1x768x32x32> | tensor<[1,768,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<768x2>>> <br> shape: #ttnn.shape<1x384x64x64> | tensor<[1,384,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8192x1>>> <br> shape: #ttnn.shape<1x1x262144x32> | tensor<[1,1,262144,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x2>>> <br> shape: #ttnn.shape<1x1x65536x64> | tensor<[1,1,65536,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x1>>> <br> shape: #ttnn.shape<1x1x65536x32> | tensor<[1,1,65536,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x2>>> <br> shape: #ttnn.shape<1x1x65536x64> | tensor<[1,1,65536,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x1x16384x128> | tensor<[1,1,16384,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x1x16384x64> | tensor<[1,1,16384,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x1x16384x128> | tensor<[1,1,16384,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x1x4096x256> | tensor<[1,1,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x4>>> <br> shape: #ttnn.shape<1x1x4096x128> | tensor<[1,1,4096,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x1x4096x256> | tensor<[1,1,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x16>>> <br> shape: #ttnn.shape<1x1x1024x512> | tensor<[1,1,1024,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1x1024x256> | tensor<[1,1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x16>>> <br> shape: #ttnn.shape<1x1x1024x512> | tensor<[1,1,1024,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x1x256x1024> | tensor<[1,1,256,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x1x256x512> | tensor<[1,1,256,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 4.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x1x256x1024> | tensor<[1,1,256,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.54 | 11.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x255> | tensor<[1,1,256,255,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x255x16x16> | tensor<[1,255,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 4.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1x1024x256> | tensor<[1,1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1x1024x255> | tensor<[1,1,1024,255,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<255x1>>> <br> shape: #ttnn.shape<1x255x32x32> | tensor<[1,255,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x4>>> <br> shape: #ttnn.shape<1x1x1024x128> | tensor<[1,1,1024,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x4>>> <br> shape: #ttnn.shape<1x1x4096x128> | tensor<[1,1,4096,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x1x4096x255> | tensor<[1,1,4096,255,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<510x2>>> <br> shape: #ttnn.shape<1x255x64x64> | tensor<[1,255,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x16>>> <br> shape: #ttnn.shape<1x32x512x512> | tensor<[1,32,512,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x256x16x16> | tensor<[1,256,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x128x32x32> | tensor<[1,128,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x16>>> <br> shape: #ttnn.shape<1x32x512x512> | tensor<[1,32,512,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x256x16x16> | tensor<[1,256,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x128x32x32> | tensor<[1,128,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x16>>> <br> shape: #ttnn.shape<1x32x512x512> | tensor<[1,32,512,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 17.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1024x1x1> | tensor<[1024,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 17.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131008.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131008.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x256x16x16> | tensor<[1,256,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 3.96 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 3.96 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x128x32x32> | tensor<[1,128,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 4080.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 4079.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 4080.23 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x1>>> <br> shape: #ttnn.shape<1x1x65536x32> | tensor<[1,1,65536,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x1x16384x64> | tensor<[1,1,16384,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x4>>> <br> shape: #ttnn.shape<1x1x4096x128> | tensor<[1,1,4096,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x4>>> <br> shape: #ttnn.shape<1x1x4096x128> | tensor<[1,1,4096,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1x1024x256> | tensor<[1,1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1x1024x256> | tensor<[1,1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.07 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x1x256x512> | tensor<[1,1,256,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.82 | 2.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x1x256x512> | tensor<[1,1,256,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1x1024x256> | tensor<[1,1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.33 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x4>>> <br> shape: #ttnn.shape<1x1x4096x128> | tensor<[1,1,4096,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x1x16384x64> | tensor<[1,1,16384,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x1>>> <br> shape: #ttnn.shape<1x1x65536x32> | tensor<[1,1,65536,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x1>>> <br> shape: #ttnn.shape<1x1x65536x1> | tensor<[1,1,65536,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x16> | tensor<[1,1,784,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.37 | 4.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x28x28> | tensor<[1,16,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.37 | 4.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x1x196x4> | tensor<[1,1,196,4,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 1.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x4x14x14> | tensor<[1,4,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 1.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x28x28> | tensor<[1,16,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x4x14x14> | tensor<[1,4,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x16x14x14> | tensor<[1,16,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.64 | 1.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x16>>> <br> shape: #ttnn.shape<1x1x256x512> | tensor<[1,1,256,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2048x1>>> <br> shape: #ttnn.shape<1x1x65536x1> | tensor<[1,1,65536,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x16x32x32> | tensor<[1,16,32,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x16x32x1> | tensor<[1,16,32,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x1> | tensor<[1,32,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x32x1536> | tensor<[1,32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x144>>> <br> shape: #ttnn.shape<32x4608> | tensor<[32,4608,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x16x32x32> | tensor<[1,16,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<32x1536> | tensor<[32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x32x1536> | tensor<[1,32,1536,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<32x6144> | tensor<[32,6144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<16x32x32> | tensor<[16,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x3>>> <br> shape: #ttnn.shape<16x32x96> | tensor<[16,32,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 9.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x32x32> | tensor<[1,1,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x144>>> <br> shape: #ttnn.shape<32x4608> | tensor<[32,4608,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 6.29 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<32x1536> | tensor<[32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 7.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<32x6144> | tensor<[32,6144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 12.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<32x1536> | tensor<[32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 52.71 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7840>>> <br> shape: #ttnn.shape<32x250880> | tensor<[32,250880,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x32x1536> | tensor<[1,32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1x32x1536> | tensor<[1,32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32> | tensor<[1,32,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x32> | tensor<[32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x144>>> <br> shape: #ttnn.shape<32x4608> | tensor<[32,4608,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x144>>> <br> shape: #ttnn.shape<4608> | tensor<[4608,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<32x1536> | tensor<[32,1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x48>>> <br> shape: #ttnn.shape<1536> | tensor<[1536,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<32x6144> | tensor<[32,6144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<6144> | tensor<[6144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x3>>> <br> shape: #ttnn.shape<1x32x16x1x96> | tensor<[1,32,16,1,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32> | tensor<[1,32,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x192>>> <br> shape: #ttnn.shape<1x32x6144> | tensor<[1,32,6144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x32x32> | tensor<[1,1,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x16x768> | tensor<[1,16,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1> | tensor<[1,16,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x16x768> | tensor<[1,16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<16x768> | tensor<[16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<1x12x16x16> | tensor<[1,12,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<16x3072> | tensor<[16,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<12x16x16> | tensor<[12,16,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 11.92 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x2>>> <br> shape: #ttnn.shape<12x16x64> | tensor<[12,16,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 4.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x16x3072> | tensor<[1,16,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x16x3072> | tensor<[1,16,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<16x768> | tensor<[16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 5.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<16x3072> | tensor<[16,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 17.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<16x768> | tensor<[16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 45.20 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x2>>> <br> shape: #ttnn.shape<1x12x16x64> | tensor<[1,12,16,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x16> | tensor<[1,12,64,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x16x768> | tensor<[1,16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<16x768> | tensor<[16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<16x3072> | tensor<[16,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1> | tensor<[1,16,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x16x16> | tensor<[1,1,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16> | tensor<[1,16,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x16x768> | tensor<[1,16,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x16x16> | tensor<[1,1,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x16x10x10> | tensor<[1,16,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x16x10x1> | tensor<[1,16,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x1> | tensor<[1,16,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x10> | tensor<[1,16,1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x1> | tensor<[1,16,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.18 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x16x10x10> | tensor<[1,16,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 42.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x16x10x10> | tensor<[1,16,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 949978046398464.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x10x1024> | tensor<[1,10,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x1> | tensor<[1,16,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.11 | 11.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x1> | tensor<[1,16,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 11.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x10> | tensor<[1,16,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x10> | tensor<[1,16,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 8.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<16x10x10> | tensor<[16,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x2>>> <br> shape: #ttnn.shape<16x10x64> | tensor<[16,10,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 9077567998918656.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16x1x1> | tensor<[16,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.36 | 60479873808213672217123221242755678208.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<16x1x64> | tensor<[16,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.29 | 1.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16x1x10> | tensor<[16,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 7.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<16x1x64> | tensor<[16,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 3.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<10x1024> | tensor<[10,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 1.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<10x4096> | tensor<[10,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 13.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<10x1024> | tensor<[10,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 144.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1024> | tensor<[1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 0.73 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x4096> | tensor<[1,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 61.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1024> | tensor<[1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 4384.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1004>>> <br> shape: #ttnn.shape<1x32128> | tensor<[1,32128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 47.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x10> | tensor<[1,1,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x10x1024> | tensor<[1,10,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x10x1024> | tensor<[1,10,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x10x4096> | tensor<[1,10,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x1x4096> | tensor<[1,1,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x10> | tensor<[1,1,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x1> | tensor<[1,1,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x16x1x10> | tensor<[1,16,1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x8x10x10> | tensor<[1,8,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x8x10x1> | tensor<[1,8,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x1> | tensor<[1,8,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x10> | tensor<[1,8,1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x1> | tensor<[1,8,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x8x10x10> | tensor<[1,8,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 16.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x8x10x10> | tensor<[1,8,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 19.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x10x512> | tensor<[1,10,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x1> | tensor<[1,8,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 5.47 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x1> | tensor<[1,8,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.1 | 8.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x512> | tensor<[1,1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x10> | tensor<[1,8,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x10> | tensor<[1,8,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 10.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<8x10x10> | tensor<[8,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 12.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<8x10x64> | tensor<[8,10,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 5.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<8x1x1> | tensor<[8,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 27097299230478631686393527718117376.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<8x1x64> | tensor<[8,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.33 | 2.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<8x1x10> | tensor<[8,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.16 | 10.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<8x1x64> | tensor<[8,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 4.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 2560.00 |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<10x512> | tensor<[10,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 0.74 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<10x2048> | tensor<[10,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 159.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<10x512> | tensor<[10,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 2672.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 0.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x2048> | tensor<[1,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 123.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 5120.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1004>>> <br> shape: #ttnn.shape<1x32128> | tensor<[1,32128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 76.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x10> | tensor<[1,1,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x10x512> | tensor<[1,10,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x10x512> | tensor<[1,10,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x512> | tensor<[1,1,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x512> | tensor<[1,1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x512> | tensor<[1,1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x10x2048> | tensor<[1,10,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x1x2048> | tensor<[1,1,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x10> | tensor<[1,1,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x1> | tensor<[1,1,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x8x1x10> | tensor<[1,8,1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x12x10x10> | tensor<[1,12,10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x12x10x1> | tensor<[1,12,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x1> | tensor<[1,12,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x10> | tensor<[1,12,1,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x1> | tensor<[1,12,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x12x10x10> | tensor<[1,12,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 30.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x12x10x10> | tensor<[1,12,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 32.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x1> | tensor<[1,12,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 22.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x1> | tensor<[1,12,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.07 | 17.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x1x768> | tensor<[1,1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x10> | tensor<[1,12,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x10> | tensor<[1,12,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 7.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<12x10x10> | tensor<[12,10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 73.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<12x10x64> | tensor<[12,10,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 6.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12x1x1> | tensor<[12,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 91607562907118140342535192576.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<12x1x64> | tensor<[12,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.59 | 1.51 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12x1x10> | tensor<[12,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 25587638918859630553398285910396633088.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<12x1x64> | tensor<[12,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 4.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 0.80 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<10x3072> | tensor<[10,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 69.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 936.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 0.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x3072> | tensor<[1,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 92.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 2880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1004>>> <br> shape: #ttnn.shape<1x32128> | tensor<[1,32128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 62.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x10> | tensor<[1,1,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x1x768> | tensor<[1,1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x1x768> | tensor<[1,1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x1x768> | tensor<[1,1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x10x3072> | tensor<[1,10,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x1x3072> | tensor<[1,1,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x10> | tensor<[1,1,1,10,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x1> | tensor<[1,1,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<10x10> | tensor<[10,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1x10> | tensor<[1,12,1,10,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x7>>> <br> shape: #ttnn.shape<1x64x224x224> | tensor<[1,64,224,224,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x4>>> <br> shape: #ttnn.shape<1x128x112x112> | tensor<[1,128,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.11 | 131008.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 131008.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 131008.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.09 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<896x1>>> <br> shape: #ttnn.shape<1x1024x28x28> | tensor<[1,1024,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<896x2>>> <br> shape: #ttnn.shape<1x512x56x56> | tensor<[1,512,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<896x4>>> <br> shape: #ttnn.shape<1x256x112x112> | tensor<[1,256,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<896x7>>> <br> shape: #ttnn.shape<1x128x224x224> | tensor<[1,128,224,224,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1568x2>>> <br> shape: #ttnn.shape<1x1x50176x64> | tensor<[1,1,50176,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1568x2>>> <br> shape: #ttnn.shape<1x1x50176x64> | tensor<[1,1,50176,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x4>>> <br> shape: #ttnn.shape<1x1x12544x128> | tensor<[1,1,12544,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.89 | 0.24 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x4>>> <br> shape: #ttnn.shape<1x1x12544x128> | tensor<[1,1,12544,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.88 | 0.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x8>>> <br> shape: #ttnn.shape<1x1x3136x256> | tensor<[1,1,3136,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 0.49 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x8>>> <br> shape: #ttnn.shape<1x1x3136x256> | tensor<[1,1,3136,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.33 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.11 | 0.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.11 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x1x196x1024> | tensor<[1,1,196,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 0.46 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x1x196x1024> | tensor<[1,1,196,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 17446117444677020831862467666179522560.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x16>>> <br> shape: #ttnn.shape<1x1x784x512> | tensor<[1,1,784,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x8>>> <br> shape: #ttnn.shape<1x1x3136x256> | tensor<[1,1,3136,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x4>>> <br> shape: #ttnn.shape<1x1x12544x128> | tensor<[1,1,12544,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.88 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1568x2>>> <br> shape: #ttnn.shape<1x1x50176x64> | tensor<[1,1,50176,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1568x1>>> <br> shape: #ttnn.shape<1x1x50176x1> | tensor<[1,1,50176,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<1x1x224x224> | tensor<[1,1,224,224,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x4>>> <br> shape: #ttnn.shape<1x128x112x112> | tensor<[1,128,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x7>>> <br> shape: #ttnn.shape<1x64x224x224> | tensor<[1,64,224,224,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x4>>> <br> shape: #ttnn.shape<1x128x112x112> | tensor<[1,128,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x4>>> <br> shape: #ttnn.shape<1x128x112x112> | tensor<[1,128,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.91 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1x1> | tensor<[128,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.91 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x2>>> <br> shape: #ttnn.shape<1x256x56x56> | tensor<[1,256,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 0.10 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 0.10 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x512x28x28> | tensor<[1,512,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<512x1x1> | tensor<[512,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1024x1x1> | tensor<[1024,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x10>>> <br> shape: #ttnn.shape<1x1x19200x300> | tensor<[1,1,19200,300,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x1>>> <br> shape: #ttnn.shape<1x1x19200x1> | tensor<[1,1,19200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x10>>> <br> shape: #ttnn.shape<1x2x4800x300> | tensor<[1,2,4800,300,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x1>>> <br> shape: #ttnn.shape<1x2x4800x1> | tensor<[1,2,4800,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<188x10>>> <br> shape: #ttnn.shape<1x5x1200x300> | tensor<[1,5,1200,300,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<188x1>>> <br> shape: #ttnn.shape<1x5x1200x1> | tensor<[1,5,1200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<75x10>>> <br> shape: #ttnn.shape<1x8x300x300> | tensor<[1,8,300,300,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<75x1>>> <br> shape: #ttnn.shape<1x8x300x1> | tensor<[1,8,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x1>>> <br> shape: #ttnn.shape<1x19200x1> | tensor<[1,19200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x19200x64> | tensor<[1,19200,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<19200x64> | tensor<[19200,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<1x300x64> | tensor<[1,300,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<300x64> | tensor<[300,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x19200x64> | tensor<[1,19200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x8>>> <br> shape: #ttnn.shape<19200x256> | tensor<[19200,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x4800x1> | tensor<[1,4800,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<1x4800x128> | tensor<[1,4800,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<4800x128> | tensor<[4800,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<1x300x128> | tensor<[1,300,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<300x128> | tensor<[300,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<1x4800x128> | tensor<[1,4800,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x16>>> <br> shape: #ttnn.shape<4800x512> | tensor<[4800,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x1>>> <br> shape: #ttnn.shape<1x1200x1> | tensor<[1,1200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1200x320> | tensor<[1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<1x300x320> | tensor<[1,300,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<300x320> | tensor<[300,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x40>>> <br> shape: #ttnn.shape<1200x1280> | tensor<[1200,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<300x512> | tensor<[300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x64>>> <br> shape: #ttnn.shape<300x2048> | tensor<[300,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30> | tensor<[30,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30x1> | tensor<[30,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x2>>> <br> shape: #ttnn.shape<1x32x30x40> | tensor<[1,32,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<60> | tensor<[60,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<60x1> | tensor<[60,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.07 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x32x60x80> | tensor<[1,32,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<120x1> | tensor<[120,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x5>>> <br> shape: #ttnn.shape<1x32x120x160> | tensor<[1,32,120,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<240x1> | tensor<[240,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<480x10>>> <br> shape: #ttnn.shape<1x64x240x320> | tensor<[1,64,240,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<480x1> | tensor<[480,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x20>>> <br> shape: #ttnn.shape<1x64x480x640> | tensor<[1,64,480,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x10>>> <br> shape: #ttnn.shape<1x19200x300> | tensor<[1,19200,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 274.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x19200x64> | tensor<[1,19200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.87 | 0.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x19200x64> | tensor<[1,19200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 2.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x10>>> <br> shape: #ttnn.shape<2x4800x300> | tensor<[2,4800,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x2>>> <br> shape: #ttnn.shape<2x4800x64> | tensor<[2,4800,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.51 | 10.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<1x4800x128> | tensor<[1,4800,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 3.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<188x10>>> <br> shape: #ttnn.shape<5x1200x300> | tensor<[5,1200,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<188x2>>> <br> shape: #ttnn.shape<5x1200x64> | tensor<[5,1200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.26 | 0.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 3.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<75x10>>> <br> shape: #ttnn.shape<8x300x300> | tensor<[8,300,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 193.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<75x2>>> <br> shape: #ttnn.shape<8x300x64> | tensor<[8,300,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 3.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 88.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x2>>> <br> shape: #ttnn.shape<1x128x30x40> | tensor<[1,128,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x3>>> <br> shape: #ttnn.shape<1x128x60x80> | tensor<[1,128,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<480x5>>> <br> shape: #ttnn.shape<1x128x120x160> | tensor<[1,128,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30> | tensor<[30,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30x1> | tensor<[30,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<60> | tensor<[60,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<60x1> | tensor<[60,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<120x1> | tensor<[120,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<240x1> | tensor<[240,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<480x1> | tensor<[480,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x1x19200x64> | tensor<[1,1,19200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<1x1x300x64> | tensor<[1,1,300,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 122.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x64x15x20> | tensor<[1,64,15,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 122.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x8>>> <br> shape: #ttnn.shape<1x1x19200x256> | tensor<[1,1,19200,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.32 | 20.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x5>>> <br> shape: #ttnn.shape<1x256x120x160> | tensor<[1,256,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.32 | 20.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<1x1x4800x128> | tensor<[1,1,4800,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x3>>> <br> shape: #ttnn.shape<1x128x60x80> | tensor<[1,128,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<1x1x300x128> | tensor<[1,1,300,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 51.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x1>>> <br> shape: #ttnn.shape<1x128x15x20> | tensor<[1,128,15,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 51.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x16>>> <br> shape: #ttnn.shape<1x1x4800x512> | tensor<[1,1,4800,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 9.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x3>>> <br> shape: #ttnn.shape<1x512x60x80> | tensor<[1,512,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 9.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1x1200x320> | tensor<[1,1,1200,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.86 | 87.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x2>>> <br> shape: #ttnn.shape<1x320x30x40> | tensor<[1,320,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.86 | 87.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<1x1x300x320> | tensor<[1,1,300,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x320x15x20> | tensor<[1,320,15,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x40>>> <br> shape: #ttnn.shape<1x1x1200x1280> | tensor<[1,1,1200,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1200x2>>> <br> shape: #ttnn.shape<1x1280x30x40> | tensor<[1,1280,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x1x300x512> | tensor<[1,1,300,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x1>>> <br> shape: #ttnn.shape<1x512x15x20> | tensor<[1,512,15,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x64>>> <br> shape: #ttnn.shape<1x1x300x2048> | tensor<[1,1,300,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 83076749736557242056487941267521536000.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x1>>> <br> shape: #ttnn.shape<1x2048x15x20> | tensor<[1,2048,15,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 83076749736557242056487941267521536000.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<1x1x300x64> | tensor<[1,1,300,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 13.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<1x64x15x20> | tensor<[1,64,15,20,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 13.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x2>>> <br> shape: #ttnn.shape<1x1x1200x64> | tensor<[1,1,1200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 5.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 5.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x2>>> <br> shape: #ttnn.shape<1x1x1200x64> | tensor<[1,1,1200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.33 | 22.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.33 | 22.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x1>>> <br> shape: #ttnn.shape<1x1x1200x32> | tensor<[1,1,1200,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 49181435844041887297440861230372749312.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x2>>> <br> shape: #ttnn.shape<1x32x30x40> | tensor<[1,32,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 49181435844041887297440861230372749312.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x1>>> <br> shape: #ttnn.shape<1x1x1200x2> | tensor<[1,1,1200,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 62806022800837274994704883598246281216.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x2>>> <br> shape: #ttnn.shape<1x2x30x40> | tensor<[1,2,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 62806022800837274994704883598246281216.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x2>>> <br> shape: #ttnn.shape<1x1x4800x64> | tensor<[1,1,4800,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 2.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 2.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x2>>> <br> shape: #ttnn.shape<1x1x4800x64> | tensor<[1,1,4800,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x1x4800x32> | tensor<[1,1,4800,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.64 | 8.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x32x60x80> | tensor<[1,32,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.64 | 8.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x1x4800x2> | tensor<[1,1,4800,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.84 | 3.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<1x2x60x80> | tensor<[1,2,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.84 | 3.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x1x19200x64> | tensor<[1,1,19200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x1>>> <br> shape: #ttnn.shape<1x1x19200x32> | tensor<[1,1,19200,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x5>>> <br> shape: #ttnn.shape<1x32x120x160> | tensor<[1,32,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x1>>> <br> shape: #ttnn.shape<1x1x19200x2> | tensor<[1,1,19200,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<1x2x120x160> | tensor<[1,2,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<9600x2>>> <br> shape: #ttnn.shape<1x1x307200x64> | tensor<[1,1,307200,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x20>>> <br> shape: #ttnn.shape<1x64x480x640> | tensor<[1,64,480,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<9600x1>>> <br> shape: #ttnn.shape<1x1x307200x1> | tensor<[1,1,307200,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x20>>> <br> shape: #ttnn.shape<1x1x480x640> | tensor<[1,1,480,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x10>>> <br> shape: #ttnn.shape<1x1x19200x300> | tensor<[1,1,19200,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<300x10>>> <br> shape: #ttnn.shape<1x2x4800x300> | tensor<[1,2,4800,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<188x10>>> <br> shape: #ttnn.shape<1x5x1200x300> | tensor<[1,5,1200,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<75x10>>> <br> shape: #ttnn.shape<1x8x300x300> | tensor<[1,8,300,300,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x8>>> <br> shape: #ttnn.shape<1x19200x256> | tensor<[1,19200,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x8>>> <br> shape: #ttnn.shape<1x19200x256> | tensor<[1,19200,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x16>>> <br> shape: #ttnn.shape<1x4800x512> | tensor<[1,4800,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x16>>> <br> shape: #ttnn.shape<1x4800x512> | tensor<[1,4800,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x40>>> <br> shape: #ttnn.shape<1x1200x1280> | tensor<[1,1200,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x40>>> <br> shape: #ttnn.shape<1x1200x1280> | tensor<[1,1200,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x64>>> <br> shape: #ttnn.shape<1x300x2048> | tensor<[1,300,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x64>>> <br> shape: #ttnn.shape<1x300x2048> | tensor<[1,300,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<19200x64> | tensor<[19200,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.07 | 8.47 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<300x64> | tensor<[300,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 2.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x8>>> <br> shape: #ttnn.shape<19200x256> | tensor<[19200,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 17.67 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<4800x128> | tensor<[4800,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 5.71 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<300x128> | tensor<[300,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 1.68 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x16>>> <br> shape: #ttnn.shape<4800x512> | tensor<[4800,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 18.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1200x320> | tensor<[1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 8.34 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<300x320> | tensor<[300,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 1.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x40>>> <br> shape: #ttnn.shape<1200x1280> | tensor<[1200,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 21.87 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<300x512> | tensor<[300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 4.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x64>>> <br> shape: #ttnn.shape<300x2048> | tensor<[300,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 28.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<1x19200x64> | tensor<[1,19200,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x2>>> <br> shape: #ttnn.shape<19200x64> | tensor<[19200,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<1x300x64> | tensor<[1,300,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<300x64> | tensor<[300,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x8>>> <br> shape: #ttnn.shape<19200x256> | tensor<[19200,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<4800x128> | tensor<[4800,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<1x300x128> | tensor<[1,300,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<300x128> | tensor<[300,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x16>>> <br> shape: #ttnn.shape<4800x512> | tensor<[4800,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1200x320> | tensor<[1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<1x300x320> | tensor<[1,300,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<300x320> | tensor<[300,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x40>>> <br> shape: #ttnn.shape<1200x1280> | tensor<[1200,1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<300x512> | tensor<[300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x64>>> <br> shape: #ttnn.shape<300x2048> | tensor<[300,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30> | tensor<[30,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x2>>> <br> shape: #ttnn.shape<1x32x30x40> | tensor<[1,32,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 6.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<60> | tensor<[60,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x32x60x80> | tensor<[1,32,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.31 | 1.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x5>>> <br> shape: #ttnn.shape<1x32x120x160> | tensor<[1,32,120,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x20>>> <br> shape: #ttnn.shape<1x1x480x640> | tensor<[1,1,480,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x2>>> <br> shape: #ttnn.shape<1x32x30x40> | tensor<[1,32,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x32x60x80> | tensor<[1,32,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x5>>> <br> shape: #ttnn.shape<1x32x120x160> | tensor<[1,32,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<960x20>>> <br> shape: #ttnn.shape<1x64x480x640> | tensor<[1,64,480,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x1>>> <br> shape: #ttnn.shape<1x19200x1> | tensor<[1,19200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x1>>> <br> shape: #ttnn.shape<1x4800x1> | tensor<[1,4800,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x1>>> <br> shape: #ttnn.shape<1x1200x1> | tensor<[1,1200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x30x40> | tensor<[1,1,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.66 | 0.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x30x40> | tensor<[1,1,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.31 | 0.76 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x3>>> <br> shape: #ttnn.shape<1x1x60x80> | tensor<[1,1,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 0.71 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x3>>> <br> shape: #ttnn.shape<1x1x60x80> | tensor<[1,1,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.27 | 0.82 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x5>>> <br> shape: #ttnn.shape<1x1x120x160> | tensor<[1,1,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x2>>> <br> shape: #ttnn.shape<1x2x30x40> | tensor<[1,2,30,40,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.67 | 0.48 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x3>>> <br> shape: #ttnn.shape<1x2x60x80> | tensor<[1,2,60,80,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.82 | 0.82 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<1x2x120x160> | tensor<[1,2,120,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x20>>> <br> shape: #ttnn.shape<1x1x480x640> | tensor<[1,1,480,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x2>>> <br> shape: #ttnn.shape<1x300x64> | tensor<[1,300,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<150x4>>> <br> shape: #ttnn.shape<1x4800x128> | tensor<[1,4800,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x4>>> <br> shape: #ttnn.shape<1x300x128> | tensor<[1,300,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<38x1>>> <br> shape: #ttnn.shape<1x1200x1> | tensor<[1,1200,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x10>>> <br> shape: #ttnn.shape<1x300x320> | tensor<[1,300,320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30> | tensor<[30,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<40> | tensor<[40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.32 | 19.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<30x1> | tensor<[30,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.27 | 14.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131011.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 131011.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x2>>> <br> shape: #ttnn.shape<1x32x30x40> | tensor<[1,32,30,40,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 5.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 5.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<60> | tensor<[60,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<80> | tensor<[80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.4 | 39.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<60x1> | tensor<[60,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.37 | 29.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131009.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131009.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<60x3>>> <br> shape: #ttnn.shape<1x32x60x80> | tensor<[1,32,60,80,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 11.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | 11.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<120> | tensor<[120,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.44 | 79.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<120x1> | tensor<[120,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.43 | 59.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<120x5>>> <br> shape: #ttnn.shape<1x32x120x160> | tensor<[1,32,120,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<240> | tensor<[240,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.46 | 159.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<240x1> | tensor<[240,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.45 | 119.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x15>>> <br> shape: #ttnn.shape<480> | tensor<[480,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.47 | 319.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<15x1>>> <br> shape: #ttnn.shape<480x1> | tensor<[480,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.47 | 239.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x197x1> | tensor<[1,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<197x3072> | tensor<[197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x7>>> <br> shape: #ttnn.shape<12x197x197> | tensor<[12,197,197,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 17.61 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x2>>> <br> shape: #ttnn.shape<12x197x64> | tensor<[12,197,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 3.71 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x1x196x768> | tensor<[1,1,196,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<336x1>>> <br> shape: #ttnn.shape<1x768x14x14> | tensor<[1,768,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<1x197x3072> | tensor<[1,197,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<1x197x3072> | tensor<[1,197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 4.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<197x3072> | tensor<[197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 9.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 15.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 6.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x2>>> <br> shape: #ttnn.shape<1x12x197x64> | tensor<[1,12,197,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x7>>> <br> shape: #ttnn.shape<1x12x64x197> | tensor<[1,12,64,197,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<197x3072> | tensor<[197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x197x1> | tensor<[1,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x1x16384x256> | tensor<[1,1,16384,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1x16384x1> | tensor<[1,1,16384,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x2x4096x256> | tensor<[1,2,4096,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<1x2x4096x1> | tensor<[1,2,4096,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x8>>> <br> shape: #ttnn.shape<1x5x1024x256> | tensor<[1,5,1024,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x1>>> <br> shape: #ttnn.shape<1x5x1024x1> | tensor<[1,5,1024,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<1x8x256x256> | tensor<[1,8,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x8x256x1> | tensor<[1,8,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x1> | tensor<[1,16384,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x32> | tensor<[1,16384,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<16384x32> | tensor<[16384,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x32> | tensor<[1,256,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x32> | tensor<[256,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x32> | tensor<[1,16384,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<16384x128> | tensor<[16384,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x4096x1> | tensor<[1,4096,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x4096x64> | tensor<[1,4096,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<4096x64> | tensor<[4096,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<1x256x64> | tensor<[1,256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<256x64> | tensor<[256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x4096x64> | tensor<[1,4096,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<4096x256> | tensor<[4096,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1> | tensor<[1,1024,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1x1024x160> | tensor<[1,1024,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1024x160> | tensor<[1024,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<1x256x160> | tensor<[1,256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<256x160> | tensor<[256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1x1024x160> | tensor<[1,1024,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x16384x256> | tensor<[1,16384,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1> | tensor<[128,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x4>>> <br> shape: #ttnn.shape<1x256x128x128> | tensor<[1,256,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x4096x256> | tensor<[1,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1024x256> | tensor<[1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x4>>> <br> shape: #ttnn.shape<1x256x128x128> | tensor<[1,256,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x16384x256> | tensor<[1,16384,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 172.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x32> | tensor<[1,16384,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x32> | tensor<[1,16384,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 2.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<2x4096x256> | tensor<[2,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 68.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x1>>> <br> shape: #ttnn.shape<2x4096x32> | tensor<[2,4096,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.53 | 0.77 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x4096x64> | tensor<[1,4096,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 1.80 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x8>>> <br> shape: #ttnn.shape<5x1024x256> | tensor<[5,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 102.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x1>>> <br> shape: #ttnn.shape<5x1024x32> | tensor<[5,1024,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 1.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1x1024x160> | tensor<[1,1024,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 4.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<8x256x256> | tensor<[8,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 63.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<8x256x32> | tensor<[8,256,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.07 | 1.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 6.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x4096x256> | tensor<[1,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 5.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x8>>> <br> shape: #ttnn.shape<1x1024x256> | tensor<[1,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 16.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 37.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4096x4>>> <br> shape: #ttnn.shape<1x1024x128x128> | tensor<[1,1024,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1> | tensor<[128,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1x16384x32> | tensor<[1,1,16384,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x4>>> <br> shape: #ttnn.shape<1x32x128x128> | tensor<[1,32,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x1x256x32> | tensor<[1,1,256,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 69.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x32x16x16> | tensor<[1,32,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 69.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x1x16384x128> | tensor<[1,1,16384,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 16.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 16.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x1x4096x64> | tensor<[1,1,4096,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x64x64x64> | tensor<[1,64,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<1x1x256x64> | tensor<[1,1,256,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 32.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x64x16x16> | tensor<[1,64,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 32.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x1x4096x256> | tensor<[1,1,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 12.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.18 | 12.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1x1x1024x160> | tensor<[1,1,1024,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x1>>> <br> shape: #ttnn.shape<1x160x32x32> | tensor<[1,160,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<1x1x256x160> | tensor<[1,1,256,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 16.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<80x1>>> <br> shape: #ttnn.shape<1x160x16x16> | tensor<[1,160,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 16.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1x1024x640> | tensor<[1,1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 29.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 29.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x1x256x256> | tensor<[1,1,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x256x16x16> | tensor<[1,256,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x1x256x1024> | tensor<[1,1,256,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 13.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 13.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x1x16384x256> | tensor<[1,1,16384,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x5>>> <br> shape: #ttnn.shape<1x1x16384x150> | tensor<[1,1,16384,150,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<600x4>>> <br> shape: #ttnn.shape<1x150x128x128> | tensor<[1,150,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x8>>> <br> shape: #ttnn.shape<1x1x16384x256> | tensor<[1,1,16384,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<256x8>>> <br> shape: #ttnn.shape<1x2x4096x256> | tensor<[1,2,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<160x8>>> <br> shape: #ttnn.shape<1x5x1024x256> | tensor<[1,5,1024,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x8>>> <br> shape: #ttnn.shape<1x8x256x256> | tensor<[1,8,256,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x16384x128> | tensor<[1,16384,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<1x16384x128> | tensor<[1,16384,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x4096x256> | tensor<[1,4096,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<1x4096x256> | tensor<[1,4096,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x256x1024> | tensor<[1,256,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<1x256x1024> | tensor<[1,256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<16384x32> | tensor<[16384,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 12.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x32> | tensor<[256,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.09 | 4.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<16384x128> | tensor<[16384,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 27.53 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<4096x64> | tensor<[4096,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 7.65 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<256x64> | tensor<[256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 3.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<4096x256> | tensor<[4096,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1024x160> | tensor<[1024,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 11.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<256x160> | tensor<[256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 2.72 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 26.29 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 24.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x32> | tensor<[1,16384,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<16384x32> | tensor<[16384,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x32> | tensor<[1,256,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x32> | tensor<[256,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x4>>> <br> shape: #ttnn.shape<16384x128> | tensor<[16384,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<1x4096x64> | tensor<[1,4096,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x2>>> <br> shape: #ttnn.shape<4096x64> | tensor<[4096,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<1x256x64> | tensor<[1,256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x2>>> <br> shape: #ttnn.shape<256x64> | tensor<[256,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x8>>> <br> shape: #ttnn.shape<4096x256> | tensor<[4096,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1x1024x160> | tensor<[1,1024,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x5>>> <br> shape: #ttnn.shape<1024x160> | tensor<[1024,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<1x256x160> | tensor<[1,256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x5>>> <br> shape: #ttnn.shape<256x160> | tensor<[256,160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x20>>> <br> shape: #ttnn.shape<640> | tensor<[640,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x4>>> <br> shape: #ttnn.shape<1x256x128x128> | tensor<[1,256,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x4>>> <br> shape: #ttnn.shape<1x256x128x128> | tensor<[1,256,128,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<512x1>>> <br> shape: #ttnn.shape<1x16384x1> | tensor<[1,16384,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x32> | tensor<[1,256,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<1x256x1> | tensor<[1,256,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 127.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<128x1> | tensor<[128,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 127.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1024x4>>> <br> shape: #ttnn.shape<1x256x128x128> | tensor<[1,256,128,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<8x1>>> <br> shape: #ttnn.shape<256x1x1> | tensor<[256,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x7> | tensor<[1,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x7x1> | tensor<[1,7,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x142>>> <br> shape: #ttnn.shape<1x7x4544> | tensor<[1,7,4544,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<1x71x7x64> | tensor<[1,71,7,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 18.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x7x64> | tensor<[1,1,7,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x71x7x7> | tensor<[1,71,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.4 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x142>>> <br> shape: #ttnn.shape<1x7x4544> | tensor<[1,7,4544,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x32x7> | tensor<[1,32,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<71x7x7> | tensor<[71,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 131024.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<71x7x64> | tensor<[71,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 131008.23 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x7x64> | tensor<[1,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<1x71x7x64> | tensor<[1,71,7,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x1x7x64> | tensor<[1,1,7,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x7x64> | tensor<[1,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<7x7> | tensor<[7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x7> | tensor<[1,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x568>>> <br> shape: #ttnn.shape<1x7x18176> | tensor<[1,7,18176,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x568>>> <br> shape: #ttnn.shape<1x7x18176> | tensor<[1,7,18176,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x146>>> <br> shape: #ttnn.shape<7x4672> | tensor<[7,4672,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 17.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x142>>> <br> shape: #ttnn.shape<7x4544> | tensor<[7,4544,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 4.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x568>>> <br> shape: #ttnn.shape<7x18176> | tensor<[7,18176,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 12.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x142>>> <br> shape: #ttnn.shape<7x4544> | tensor<[7,4544,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 13.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2032>>> <br> shape: #ttnn.shape<7x65024> | tensor<[7,65024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 78.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<1x71x7x64> | tensor<[1,71,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x1x64x7> | tensor<[1,1,64,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<7x7> | tensor<[7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x7x64> | tensor<[1,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x142>>> <br> shape: #ttnn.shape<1x7x4544> | tensor<[1,7,4544,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<1x71x7x64> | tensor<[1,71,7,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.24 | 18.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x71x7x32> | tensor<[1,71,7,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 17.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x32> | tensor<[1,1,7,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.45 | 11.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x2>>> <br> shape: #ttnn.shape<1x7x71x64> | tensor<[1,7,71,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x71x7x32> | tensor<[1,71,7,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.25 | 18.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<16x1>>> <br> shape: #ttnn.shape<1x71x7x32> | tensor<[1,71,7,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.16 | 11.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x32> | tensor<[1,1,7,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x7x7> | tensor<[1,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.48 | 6.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<56x4>>> <br> shape: #ttnn.shape<1x16x112x112> | tensor<[1,16,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<96> | tensor<[96,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<336x4>>> <br> shape: #ttnn.shape<1x96x112x112> | tensor<[1,96,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 5.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x2>>> <br> shape: #ttnn.shape<1x96x56x56> | tensor<[1,96,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.62 | 5.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<144> | tensor<[144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x2>>> <br> shape: #ttnn.shape<1x144x56x56> | tensor<[1,144,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.76 | 5.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | Inf |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x144x28x28> | tensor<[1,144,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.8 | 4.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x32x28x28> | tensor<[1,32,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<192> | tensor<[192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x192x28x28> | tensor<[1,192,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.76 | 3.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x32x28x28> | tensor<[1,32,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 51.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<84x1>>> <br> shape: #ttnn.shape<1x192x14x14> | tensor<[1,192,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.54 | 5.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x64x14x14> | tensor<[1,64,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x12>>> <br> shape: #ttnn.shape<384> | tensor<[384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x384x14x14> | tensor<[1,384,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.73 | 4.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x64x14x14> | tensor<[1,64,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x1>>> <br> shape: #ttnn.shape<1x96x14x14> | tensor<[1,96,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<576> | tensor<[576,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x1>>> <br> shape: #ttnn.shape<1x576x14x14> | tensor<[1,576,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.8 | 2.49 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x1>>> <br> shape: #ttnn.shape<1x96x14x14> | tensor<[1,96,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 30.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x576x7x7> | tensor<[1,576,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.3 | 5.84 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.30 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x30>>> <br> shape: #ttnn.shape<960> | tensor<[960,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x960x7x7> | tensor<[1,960,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.62 | 3.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 22.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x1>>> <br> shape: #ttnn.shape<1x320x7x7> | tensor<[1,320,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x1280x7x7> | tensor<[1,1280,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.94 | 6.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x1>>> <br> shape: #ttnn.shape<1x1x12544x32> | tensor<[1,1,12544,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 24.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x1>>> <br> shape: #ttnn.shape<1x1x12544x32> | tensor<[1,1,12544,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.32 | 45.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x1>>> <br> shape: #ttnn.shape<1x1x12544x16> | tensor<[1,1,12544,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.75 | 22.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<392x3>>> <br> shape: #ttnn.shape<1x1x12544x96> | tensor<[1,1,12544,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.15 | 99.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x3>>> <br> shape: #ttnn.shape<1x1x3136x96> | tensor<[1,1,3136,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.72 | 11.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x24> | tensor<[1,1,3136,24,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.28 | 26.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x5>>> <br> shape: #ttnn.shape<1x1x3136x144> | tensor<[1,1,3136,144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 227297987279220614266551007307938922496.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x5>>> <br> shape: #ttnn.shape<1x1x3136x144> | tensor<[1,1,3136,144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.17 | 35.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<98x1>>> <br> shape: #ttnn.shape<1x1x3136x24> | tensor<[1,1,3136,24,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 138239711561631250781995934269155835904.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x5>>> <br> shape: #ttnn.shape<1x1x784x144> | tensor<[1,1,784,144,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.29 | 37.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x32> | tensor<[1,1,784,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x6>>> <br> shape: #ttnn.shape<1x1x784x192> | tensor<[1,1,784,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 33.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x6>>> <br> shape: #ttnn.shape<1x1x784x192> | tensor<[1,1,784,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<25x1>>> <br> shape: #ttnn.shape<1x1x784x32> | tensor<[1,1,784,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x6>>> <br> shape: #ttnn.shape<1x1x196x192> | tensor<[1,1,196,192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 27.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x2>>> <br> shape: #ttnn.shape<1x1x196x64> | tensor<[1,1,196,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x12>>> <br> shape: #ttnn.shape<1x1x196x384> | tensor<[1,1,196,384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x12>>> <br> shape: #ttnn.shape<1x1x196x384> | tensor<[1,1,196,384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x2>>> <br> shape: #ttnn.shape<1x1x196x64> | tensor<[1,1,196,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x3>>> <br> shape: #ttnn.shape<1x1x196x96> | tensor<[1,1,196,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x18>>> <br> shape: #ttnn.shape<1x1x196x576> | tensor<[1,1,196,576,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 22.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x18>>> <br> shape: #ttnn.shape<1x1x196x576> | tensor<[1,1,196,576,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x3>>> <br> shape: #ttnn.shape<1x1x196x96> | tensor<[1,1,196,96,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x18>>> <br> shape: #ttnn.shape<1x1x49x576> | tensor<[1,1,49,576,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x5>>> <br> shape: #ttnn.shape<1x1x49x160> | tensor<[1,1,49,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x30>>> <br> shape: #ttnn.shape<1x1x49x960> | tensor<[1,1,49,960,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 15.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x30>>> <br> shape: #ttnn.shape<1x1x49x960> | tensor<[1,1,49,960,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 194067287384597717443955830800930308096.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x5>>> <br> shape: #ttnn.shape<1x1x49x160> | tensor<[1,1,49,160,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 5.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x10>>> <br> shape: #ttnn.shape<1x1x49x320> | tensor<[1,1,49,320,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x40>>> <br> shape: #ttnn.shape<1x1x49x1280> | tensor<[1,1,49,1280,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 14.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<336x4>>> <br> shape: #ttnn.shape<1x96x112x112> | tensor<[1,96,112,112,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x2>>> <br> shape: #ttnn.shape<1x96x56x56> | tensor<[1,96,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x2>>> <br> shape: #ttnn.shape<1x144x56x56> | tensor<[1,144,56,56,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x144x28x28> | tensor<[1,144,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x192x28x28> | tensor<[1,192,28,28,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<84x1>>> <br> shape: #ttnn.shape<1x192x14x14> | tensor<[1,192,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x384x14x14> | tensor<[1,384,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x1>>> <br> shape: #ttnn.shape<1x576x14x14> | tensor<[1,576,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x576x7x7> | tensor<[1,576,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x960x7x7> | tensor<[1,960,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x1280x7x7> | tensor<[1,1280,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1x1280x1x1> | tensor<[1,1280,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 7.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<56x4>>> <br> shape: #ttnn.shape<1x16x112x112> | tensor<[1,16,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<96> | tensor<[96,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<336x4>>> <br> shape: #ttnn.shape<1x96x112x112> | tensor<[1,96,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x2>>> <br> shape: #ttnn.shape<1x96x56x56> | tensor<[1,96,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<144> | tensor<[144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x2>>> <br> shape: #ttnn.shape<1x144x56x56> | tensor<[1,144,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x144x28x28> | tensor<[1,144,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x32x28x28> | tensor<[1,32,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<192> | tensor<[192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x192x28x28> | tensor<[1,192,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<84x1>>> <br> shape: #ttnn.shape<1x192x14x14> | tensor<[1,192,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x64x14x14> | tensor<[1,64,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x12>>> <br> shape: #ttnn.shape<384> | tensor<[384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x384x14x14> | tensor<[1,384,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x1>>> <br> shape: #ttnn.shape<1x96x14x14> | tensor<[1,96,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<576> | tensor<[576,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x1>>> <br> shape: #ttnn.shape<1x576x14x14> | tensor<[1,576,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x576x7x7> | tensor<[1,576,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x30>>> <br> shape: #ttnn.shape<960> | tensor<[960,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x960x7x7> | tensor<[1,960,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x1280x7x7> | tensor<[1,1280,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32> | tensor<[32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16> | tensor<[16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<96> | tensor<[96,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24> | tensor<[24,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<144> | tensor<[144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<192> | tensor<[192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x12>>> <br> shape: #ttnn.shape<384> | tensor<[384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<576> | tensor<[576,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x30>>> <br> shape: #ttnn.shape<960> | tensor<[960,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x10>>> <br> shape: #ttnn.shape<320> | tensor<[320,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x3>>> <br> shape: #ttnn.shape<96> | tensor<[96,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x5>>> <br> shape: #ttnn.shape<144> | tensor<[144,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x6>>> <br> shape: #ttnn.shape<192> | tensor<[192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x12>>> <br> shape: #ttnn.shape<384> | tensor<[384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x18>>> <br> shape: #ttnn.shape<576> | tensor<[576,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x30>>> <br> shape: #ttnn.shape<960> | tensor<[960,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<112x4>>> <br> shape: #ttnn.shape<1x32x112x112> | tensor<[1,32,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.63 | 21.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.63 | 21.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<56x4>>> <br> shape: #ttnn.shape<1x16x112x112> | tensor<[1,16,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.2 | 23.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<16x1x1> | tensor<[16,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.2 | 23.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<336x4>>> <br> shape: #ttnn.shape<1x96x112x112> | tensor<[1,96,112,112,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<96x1x1> | tensor<[96,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x2>>> <br> shape: #ttnn.shape<1x96x56x56> | tensor<[1,96,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 18.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<96x1x1> | tensor<[96,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 18.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.08 | 31.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<24x1x1> | tensor<[24,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.08 | 31.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x2>>> <br> shape: #ttnn.shape<1x144x56x56> | tensor<[1,144,56,56,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131026.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<144x1x1> | tensor<[144,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 131026.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x144x28x28> | tensor<[1,144,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<144x1x1> | tensor<[144,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x32x28x28> | tensor<[1,32,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 24.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<32x1x1> | tensor<[32,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 24.44 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x192x28x28> | tensor<[1,192,28,28,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<192x1x1> | tensor<[192,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<84x1>>> <br> shape: #ttnn.shape<1x192x14x14> | tensor<[1,192,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<192x1x1> | tensor<[192,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<28x1>>> <br> shape: #ttnn.shape<1x64x14x14> | tensor<[1,64,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<64x1x1> | tensor<[64,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<168x1>>> <br> shape: #ttnn.shape<1x384x14x14> | tensor<[1,384,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<12x1>>> <br> shape: #ttnn.shape<384x1x1> | tensor<[384,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<42x1>>> <br> shape: #ttnn.shape<1x96x14x14> | tensor<[1,96,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 23.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<96x1x1> | tensor<[96,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 23.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<252x1>>> <br> shape: #ttnn.shape<1x576x14x14> | tensor<[1,576,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<576x1x1> | tensor<[576,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<126x1>>> <br> shape: #ttnn.shape<1x576x7x7> | tensor<[1,576,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<576x1x1> | tensor<[576,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 22.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<160x1x1> | tensor<[160,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 22.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<210x1>>> <br> shape: #ttnn.shape<1x960x7x7> | tensor<[1,960,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 16.47 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<30x1>>> <br> shape: #ttnn.shape<960x1x1> | tensor<[960,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 16.47 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<70x1>>> <br> shape: #ttnn.shape<1x320x7x7> | tensor<[1,320,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 11.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<10x1>>> <br> shape: #ttnn.shape<320x1x1> | tensor<[320,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 11.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<280x1>>> <br> shape: #ttnn.shape<1x1280x7x7> | tensor<[1,1280,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1280x1x1> | tensor<[1280,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x12x128> | tensor<[1,12,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1> | tensor<[1,12,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x12x128> | tensor<[1,12,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<12x768> | tensor<[12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x12x12x12> | tensor<[1,12,12,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x12x768> | tensor<[1,12,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x12x768> | tensor<[1,12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<12x3072> | tensor<[12,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 1.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12x2> | tensor<[12,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<12x12x12> | tensor<[12,12,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 20.60 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x2>>> <br> shape: #ttnn.shape<12x12x64> | tensor<[12,12,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.13 | 6.95 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<12x768> | tensor<[12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 6.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<12x768> | tensor<[12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 9.52 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<12x3072> | tensor<[12,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 20.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<12x768> | tensor<[12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 8.99 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12x2> | tensor<[12,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.98 | 2.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x2>>> <br> shape: #ttnn.shape<1x12x12x64> | tensor<[1,12,12,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x12> | tensor<[1,12,64,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x12x128> | tensor<[1,12,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<12x768> | tensor<[12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x12x768> | tensor<[1,12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x12x768> | tensor<[1,12,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<12x3072> | tensor<[12,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12x2> | tensor<[12,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1> | tensor<[1,12,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x12x12> | tensor<[1,1,12,12,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.38 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x12x128> | tensor<[1,12,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12x1> | tensor<[1,12,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x12x12> | tensor<[1,1,12,12,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<1x12x9x9> | tensor<[1,12,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x9x768> | tensor<[1,9,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x9x768> | tensor<[1,9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 256.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<12x9x9> | tensor<[12,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 22.10 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<12x9x64> | tensor<[12,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 7.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 6.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 8.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 122.41 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 171.81 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 8.08 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 32.97 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<1x12x9x64> | tensor<[1,12,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x9> | tensor<[1,12,64,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x9x768> | tensor<[1,9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<30000> | tensor<[30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9> | tensor<[1,9,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.59 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<9x2048> | tensor<[9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x16x9x9> | tensor<[1,16,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x9x2048> | tensor<[1,9,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x9x2048> | tensor<[1,9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<9x8192> | tensor<[9,8192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<16x9x9> | tensor<[16,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 26.54 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x4>>> <br> shape: #ttnn.shape<16x9x128> | tensor<[16,9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 3.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<9x2048> | tensor<[9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 5.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<9x2048> | tensor<[9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 6.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<9x8192> | tensor<[9,8192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 12.46 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<9x2048> | tensor<[9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 164.66 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 22.29 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 36.63 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x4>>> <br> shape: #ttnn.shape<1x16x9x128> | tensor<[1,16,9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<64x1>>> <br> shape: #ttnn.shape<1x16x128x9> | tensor<[1,16,128,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<9x2048> | tensor<[9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x9x2048> | tensor<[1,9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<1x9x2048> | tensor<[1,9,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<9x8192> | tensor<[9,8192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<8192> | tensor<[8192,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<30000> | tensor<[30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.99 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<9x1024> | tensor<[9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<1x16x9x9> | tensor<[1,16,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x9x1024> | tensor<[1,9,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x9x1024> | tensor<[1,9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x1>>> <br> shape: #ttnn.shape<16x9x9> | tensor<[16,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 19.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x2>>> <br> shape: #ttnn.shape<16x9x64> | tensor<[16,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.16 | 5.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<9x1024> | tensor<[9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 6.89 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<9x1024> | tensor<[9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 6.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 8.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<9x1024> | tensor<[9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 55.87 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 19.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 36.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<5x2>>> <br> shape: #ttnn.shape<1x16x9x64> | tensor<[1,16,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<1x16x64x9> | tensor<[1,16,64,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<9x1024> | tensor<[9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x9x1024> | tensor<[1,9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<30000> | tensor<[30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x9x1024> | tensor<[1,9,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.99 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<1x64x9x9> | tensor<[1,64,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<9x16384> | tensor<[9,16384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x1>>> <br> shape: #ttnn.shape<64x9x9> | tensor<[64,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 19.80 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x2>>> <br> shape: #ttnn.shape<64x9x64> | tensor<[64,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 3.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 2.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 7.29 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<9x16384> | tensor<[9,16384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 87.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 809.19 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 17.10 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 28.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<18x2>>> <br> shape: #ttnn.shape<1x64x9x64> | tensor<[1,64,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<128x1>>> <br> shape: #ttnn.shape<1x64x64x9> | tensor<[1,64,64,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<9x16384> | tensor<[9,16384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<16384> | tensor<[16384,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x938>>> <br> shape: #ttnn.shape<30000> | tensor<[30000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x512>>> <br> shape: #ttnn.shape<1x9x16384> | tensor<[1,9,16384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.99 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.98 | 0.13 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x9x768> | tensor<[1,9,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<12x9x9> | tensor<[12,9,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 20.90 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<12x9x64> | tensor<[12,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 8.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 7.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 8.40 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 120.85 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 170.59 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 8.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -1.0 | 1.15 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<1x12x9x64> | tensor<[1,12,9,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x9> | tensor<[1,12,64,9,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x9x768> | tensor<[1,9,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x9x9> | tensor<[1,1,9,9,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x14x128> | tensor<[1,14,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x14x128> | tensor<[1,14,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<14x768> | tensor<[14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<1x12x14x14> | tensor<[1,12,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x14x768> | tensor<[1,14,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x14x768> | tensor<[1,14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<14x3072> | tensor<[14,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 8.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14x2> | tensor<[14,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x1>>> <br> shape: #ttnn.shape<12x14x14> | tensor<[12,14,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 24.86 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x2>>> <br> shape: #ttnn.shape<12x14x64> | tensor<[12,14,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.04 | 7.18 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<14x768> | tensor<[14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 7.05 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<14x768> | tensor<[14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 9.54 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<14x3072> | tensor<[14,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 133.64 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<14x768> | tensor<[14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 192.17 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14x2> | tensor<[14,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.23 | 11.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<6x2>>> <br> shape: #ttnn.shape<1x12x14x64> | tensor<[1,12,14,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x1>>> <br> shape: #ttnn.shape<1x12x64x14> | tensor<[1,12,64,14,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x14x128> | tensor<[1,14,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<14x768> | tensor<[14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x14x768> | tensor<[1,14,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<14x3072> | tensor<[14,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<14x2> | tensor<[14,2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2> | tensor<[2,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x14x14> | tensor<[1,1,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x14> | tensor<[1,14,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.39 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x14x128> | tensor<[1,14,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<1x14x3072> | tensor<[1,14,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x14x14> | tensor<[1,1,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<1x50x768> | tensor<[1,50,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x50x1> | tensor<[1,50,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<1x50x768> | tensor<[1,50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<50x768> | tensor<[50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x96>>> <br> shape: #ttnn.shape<50x3072> | tensor<[50,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x7x512> | tensor<[2,7,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<7> | tensor<[7,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x7x1> | tensor<[2,7,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x7x512> | tensor<[2,7,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x1x7x7> | tensor<[2,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<14x512> | tensor<[14,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<2x8x7x7> | tensor<[2,8,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<14x2048> | tensor<[14,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x2>>> <br> shape: #ttnn.shape<12x50x50> | tensor<[12,50,50,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 10.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x2>>> <br> shape: #ttnn.shape<12x50x64> | tensor<[12,50,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 4.55 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x1>>> <br> shape: #ttnn.shape<16x7x7> | tensor<[16,7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<16x7x64> | tensor<[16,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<1x50x768> | tensor<[1,50,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<1x1x49x768> | tensor<[1,1,49,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x512> | tensor<[2,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<7x7> | tensor<[7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<50x768> | tensor<[50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 3.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x96>>> <br> shape: #ttnn.shape<50x3072> | tensor<[50,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 8.99 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<50x768> | tensor<[50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 2.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<14x512> | tensor<[14,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 5.16 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<14x2048> | tensor<[14,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 246.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<14x512> | tensor<[14,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 307.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 7.28 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x512> | tensor<[2,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 6.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x1> | tensor<[2,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -1.0 | 0.57 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<19x2>>> <br> shape: #ttnn.shape<1x12x50x64> | tensor<[1,12,50,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<24x2>>> <br> shape: #ttnn.shape<1x12x64x50> | tensor<[1,12,64,50,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<4x2>>> <br> shape: #ttnn.shape<2x8x7x64> | tensor<[2,8,7,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<32x1>>> <br> shape: #ttnn.shape<2x8x64x7> | tensor<[2,8,64,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<1x50x768> | tensor<[1,50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<1x50x768> | tensor<[1,50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x24>>> <br> shape: #ttnn.shape<50x768> | tensor<[50,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x96>>> <br> shape: #ttnn.shape<50x3072> | tensor<[50,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x96>>> <br> shape: #ttnn.shape<1x50x3072> | tensor<[1,50,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x96>>> <br> shape: #ttnn.shape<1x50x3072> | tensor<[1,50,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x7x512> | tensor<[2,7,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x7x512> | tensor<[2,7,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<14x512> | tensor<[14,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<512> | tensor<[512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<14x2048> | tensor<[14,2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2x7x2048> | tensor<[2,7,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2x7x2048> | tensor<[2,7,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x1> | tensor<[2,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x50x1> | tensor<[1,50,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x7x1> | tensor<[2,7,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x1x7x7> | tensor<[2,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x96>>> <br> shape: #ttnn.shape<1x50x3072> | tensor<[1,50,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x64>>> <br> shape: #ttnn.shape<2x7x2048> | tensor<[2,7,2048,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x7> | tensor<[1,7,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.64 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<2x1>>> <br> shape: #ttnn.shape<1x50x1> | tensor<[1,50,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<2x7x512> | tensor<[2,7,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<7x7> | tensor<[7,7,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x1x7x7> | tensor<[2,1,7,7,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x6x15x15> | tensor<[1,6,15,15,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x6x15x1> | tensor<[1,6,15,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x1> | tensor<[1,6,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x15> | tensor<[1,6,1,15,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x1> | tensor<[1,6,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.27 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x15x1> | tensor<[1,15,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.13 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x6x15x15> | tensor<[1,6,15,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 25.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x6x15x15> | tensor<[1,6,15,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 25.38 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x15x512> | tensor<[1,15,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x1> | tensor<[1,6,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.14 | 25.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x1> | tensor<[1,6,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.12 | 25.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x1x512> | tensor<[1,1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x15> | tensor<[1,6,1,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x15> | tensor<[1,6,1,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.38 | 9.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<6x15x15> | tensor<[6,15,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 16.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<6x15x64> | tensor<[6,15,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 3.45 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6x1x1> | tensor<[6,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.44 | 1.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<6x1x64> | tensor<[6,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.21 | 1.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<6x1x15> | tensor<[6,1,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.27 | 10.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<6x1x64> | tensor<[6,1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.06 | 1.79 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x15x1> | tensor<[1,15,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x12>>> <br> shape: #ttnn.shape<15x384> | tensor<[15,384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 0.77 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<15x512> | tensor<[15,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 118.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<15x1024> | tensor<[15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 19.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<15x512> | tensor<[15,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 4352.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x12>>> <br> shape: #ttnn.shape<1x384> | tensor<[1,384,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.12 | 0.69 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 30.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1024> | tensor<[1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 15.75 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x512> | tensor<[1,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 928.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1004>>> <br> shape: #ttnn.shape<1x32128> | tensor<[1,32128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 82.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x15> | tensor<[1,1,1,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x15x512> | tensor<[1,15,512,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x16>>> <br> shape: #ttnn.shape<1x15x512> | tensor<[1,15,512,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x15x1> | tensor<[1,15,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1> | tensor<[1,1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x15> | tensor<[1,1,1,15,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x1x1> | tensor<[1,1,1,1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x15x1024> | tensor<[1,15,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1x1024> | tensor<[1,1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<15x15> | tensor<[15,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6x1x15> | tensor<[1,6,1,15,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<99x7>>> <br> shape: #ttnn.shape<1x16x197x197> | tensor<[1,16,197,197,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<99x1>>> <br> shape: #ttnn.shape<1x16x197x1> | tensor<[1,16,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x197x1> | tensor<[1,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<197x1024> | tensor<[197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27x1> | tensor<[27,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<14x1>>> <br> shape: #ttnn.shape<1x16x27x27> | tensor<[1,16,27,27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x196> | tensor<[196,196,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<99x7>>> <br> shape: #ttnn.shape<1x16x197x197> | tensor<[1,16,197,197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.55 | 952.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x128>>> <br> shape: #ttnn.shape<197x4096> | tensor<[197,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1024> | tensor<[1,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<99x7>>> <br> shape: #ttnn.shape<16x197x197> | tensor<[16,197,197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<99x2>>> <br> shape: #ttnn.shape<16x197x64> | tensor<[16,197,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 8.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<23x1>>> <br> shape: #ttnn.shape<732x16> | tensor<[732,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27x1> | tensor<[27,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x1x196x1024> | tensor<[1,1,196,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<448x1>>> <br> shape: #ttnn.shape<1x1024x14x14> | tensor<[1,1024,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<99x7>>> <br> shape: #ttnn.shape<1x16x197x197> | tensor<[1,16,197,197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x128>>> <br> shape: #ttnn.shape<1x197x4096> | tensor<[1,197,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x128>>> <br> shape: #ttnn.shape<1x197x4096> | tensor<[1,197,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1024> | tensor<[1,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<197x1024> | tensor<[197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 13.15 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x128>>> <br> shape: #ttnn.shape<197x4096> | tensor<[197,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 19.62 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<197x1024> | tensor<[197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 19.50 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.03 | 8.39 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<197x1024> | tensor<[197,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x196> | tensor<[196,196,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x128>>> <br> shape: #ttnn.shape<197x4096> | tensor<[197,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1201x1>>> <br> shape: #ttnn.shape<196x196x1> | tensor<[196,196,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1201x1>>> <br> shape: #ttnn.shape<196x196x1> | tensor<[196,196,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<1x197> | tensor<[1,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<197x1> | tensor<[197,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<23x1>>> <br> shape: #ttnn.shape<729x16> | tensor<[729,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.79 | 6.91 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3x16> | tensor<[3,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x197> | tensor<[196,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x196> | tensor<[196,196,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x32>>> <br> shape: #ttnn.shape<1x196x1024> | tensor<[1,196,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x14x14> | tensor<[2,14,14,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x197x1> | tensor<[1,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 25.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27x1> | tensor<[27,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 25.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1024> | tensor<[1,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x197> | tensor<[196,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<197x197> | tensor<[197,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<197x197> | tensor<[197,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x7>>> <br> shape: #ttnn.shape<1x12x197x197> | tensor<[1,12,197,197,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x1>>> <br> shape: #ttnn.shape<1x12x197x1> | tensor<[1,12,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x1>>> <br> shape: #ttnn.shape<1x197x1> | tensor<[1,197,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27x1> | tensor<[27,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<11x1>>> <br> shape: #ttnn.shape<1x12x27x27> | tensor<[1,12,27,27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x196> | tensor<[196,196,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x7>>> <br> shape: #ttnn.shape<1x12x197x197> | tensor<[1,12,197,197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<197x3072> | tensor<[197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x7>>> <br> shape: #ttnn.shape<12x197x197> | tensor<[12,197,197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x2>>> <br> shape: #ttnn.shape<12x197x64> | tensor<[12,197,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 17.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<23x1>>> <br> shape: #ttnn.shape<732x12> | tensor<[732,12,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27x1> | tensor<[27,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x1x196x768> | tensor<[1,1,196,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<336x1>>> <br> shape: #ttnn.shape<1x768x14x14> | tensor<[1,768,14,14,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<74x7>>> <br> shape: #ttnn.shape<1x12x197x197> | tensor<[1,12,197,197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<1x197x3072> | tensor<[1,197,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<1x197x3072> | tensor<[1,197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<1x768> | tensor<[1,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 102.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<197x3072> | tensor<[197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.01 | 30.15 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 16.98 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 9.32 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<197x768> | tensor<[197,768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x24>>> <br> shape: #ttnn.shape<768> | tensor<[768,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x196> | tensor<[196,196,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x197x768> | tensor<[1,197,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.03 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x96>>> <br> shape: #ttnn.shape<197x3072> | tensor<[197,3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<3072> | tensor<[3072,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1000> | tensor<[1000,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1201x1>>> <br> shape: #ttnn.shape<196x196x1> | tensor<[196,196,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1201x1>>> <br> shape: #ttnn.shape<196x196x1> | tensor<[196,196,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<23x1>>> <br> shape: #ttnn.shape<729x12> | tensor<[729,12,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3x12> | tensor<[3,12,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x24>>> <br> shape: #ttnn.shape<1x196x768> | tensor<[1,196,768,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<2x14x14> | tensor<[2,14,14,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<27> | tensor<[27,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x7>>> <br> shape: #ttnn.shape<197> | tensor<[197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<196x197> | tensor<[196,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<7x7>>> <br> shape: #ttnn.shape<197x197> | tensor<[197,197,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x16x5x5> | tensor<[1,16,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x16x5x1> | tensor<[1,16,5,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x5x5> | tensor<[1,1,5,5,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.53 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5x1> | tensor<[1,5,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x5x1024> | tensor<[1,5,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x5x16x32> | tensor<[1,5,16,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x16x5x5> | tensor<[1,16,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.53 | 338953138925153547590470800371487866880.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<5x4096> | tensor<[5,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x5x4096> | tensor<[1,5,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x5x4096> | tensor<[1,5,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<5x1024> | tensor<[5,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x5x1024> | tensor<[1,5,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.01 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1600>>> <br> shape: #ttnn.shape<5x51200> | tensor<[5,51200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<16x5x5> | tensor<[16,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.03 | 92.78 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<16x5x64> | tensor<[16,5,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.05 | 1.94 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x2>>> <br> shape: #ttnn.shape<1x5x16x64> | tensor<[1,5,16,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x6> | tensor<[1,6,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x16x5x5> | tensor<[1,16,5,5,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<5x5> | tensor<[5,5,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 168811955464684315858783496655603761152.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5> | tensor<[1,5,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5> | tensor<[1,5,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x5x5> | tensor<[1,1,5,5,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x96>>> <br> shape: #ttnn.shape<5x3072> | tensor<[5,3072,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.0 | 14.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<5x1024> | tensor<[5,1024,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 1.71 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<5x4096> | tensor<[5,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.01 | 5.25 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<5x1024> | tensor<[5,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 1.42 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1600>>> <br> shape: #ttnn.shape<5x51200> | tensor<[5,51200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.0 | 28.20 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<5x5> | tensor<[5,5,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1x5x1024> | tensor<[1,5,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.02 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x5x16x32> | tensor<[1,5,16,32,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 15.09 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<5x4096> | tensor<[5,4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<4096> | tensor<[4096,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x5x4096> | tensor<[1,5,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x5x4096> | tensor<[1,5,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x5x4096> | tensor<[1,5,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<5x1024> | tensor<[5,1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x32>>> <br> shape: #ttnn.shape<1024> | tensor<[1024,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1600>>> <br> shape: #ttnn.shape<5x51200> | tensor<[5,51200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1600>>> <br> shape: #ttnn.shape<51200> | tensor<[51200,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x5x16x16> | tensor<[1,5,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.02 | 14.56 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5x1> | tensor<[1,5,1,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1> | tensor<[1,1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x8>>> <br> shape: #ttnn.shape<1x5x4x256> | tensor<[1,5,4,256,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5x16> | tensor<[1,5,16,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x5x16x32> | tensor<[1,5,16,32,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x5x16x16> | tensor<[1,5,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 15.12 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<3x1>>> <br> shape: #ttnn.shape<1x5x16x16> | tensor<[1,5,16,16,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 13.88 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<40x1>>> <br> shape: #ttnn.shape<1x5x16x16x2> | tensor<[1,5,16,16,2,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<5> | tensor<[5,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5> | tensor<[1,5,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x128>>> <br> shape: #ttnn.shape<1x5x4096> | tensor<[1,5,4096,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.14 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x5> | tensor<[1,5,i32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x1x5x5> | tensor<[1,1,5,5,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x64> | tensor<[1,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x25>>> <br> shape: #ttnn.shape<1x784> | tensor<[1,784,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 1.0 | 0.00 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.04 | 1.33 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x64> | tensor<[1,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.1 | 0.36 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.08 | 0.11 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x3> | tensor<[1,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.76 | 0.06 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.48 | 0.04 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x64> | tensor<[1,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | 0.06 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.05 | 0.31 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x25>>> <br> shape: #ttnn.shape<1x784> | tensor<[1,784,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | yes | -0.02 | 0.22 |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<128> | tensor<[128,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x64> | tensor<[1,64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<64> | tensor<[64,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<12> | tensor<[12,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x3> | tensor<[1,3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<3> | tensor<[3,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x25>>> <br> shape: #ttnn.shape<1x784> | tensor<[1,784,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x25>>> <br> shape: #ttnn.shape<784> | tensor<[784,f32]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x2>>> <br> shape: #ttnn.shape<1x64> | tensor<[1,64,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, #dram, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,bf16]> | mapping_from: N/A, mapping_to: N/A, memory_config: N/A | no | nan | nan |
