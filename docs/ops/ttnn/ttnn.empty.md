# ttnn.empty

| Name | Input Shapes | Input Layouts | Attributes | Output Shapes | Output Layouts |
|------|--------------|---------------|------------|---------------|----------------|
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x1>>> <br> shape: #ttnn.shape<1x128x32x32> | tensor<[1,128,32,32,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 4096 + d1 * 32 + d2', 'd3'), memory_config: (128, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<256x1>>> <br> shape: #ttnn.shape<1x512x16x16> | tensor<[1,512,16,16,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8192 + d1 * 16 + d2', 'd3'), memory_config: (256, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<42x1>>> <br> shape: #ttnn.shape<1x96x14x14> | tensor<[1,96,14,14,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1344 + d1 * 14 + d2', 'd3'), memory_config: (42, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x1>>> <br> shape: #ttnn.shape<1x256x16x16> | tensor<[1,256,16,16,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 4096 + d1 * 16 + d2', 'd3'), memory_config: (128, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x10>>> <br> shape: #ttnn.shape<4096x320> | tensor<[4096,320,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (128, 10, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x96>>> <br> shape: #ttnn.shape<1x9x3072> | tensor<[1,9,3072,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 96, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<28x1>>> <br> shape: #ttnn.shape<1x32x28x28> | tensor<[1,32,28,28,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 896 + d1 * 28 + d2', 'd3'), memory_config: (28, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<112x1>>> <br> shape: #ttnn.shape<1x256x14x14> | tensor<[1,256,14,14,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3584 + d1 * 14 + d2', 'd3'), memory_config: (112, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x5>>> <br> shape: #ttnn.shape<1x160> | tensor<[1,160,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 5, 'tile<32x32, f32>', 'dram') |
| ttnn.empty |  |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<row_major> <br> shape: #ttnn.shape<32x32> | tensor<[32,32,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (32, 32, 'bf16', 'system') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<252x2>>> <br> shape: #ttnn.shape<1x144x56x56> | tensor<[1,144,56,56,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8064 + d1 * 56 + d2', 'd3'), memory_config: (252, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x18>>> <br> shape: #ttnn.shape<576> | tensor<[576,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 18, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x20>>> <br> shape: #ttnn.shape<1x1024x640> | tensor<[1,1024,640,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1024 + d1', 'd2'), memory_config: (32, 20, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<38x10>>> <br> shape: #ttnn.shape<1x1200x320> | tensor<[1,1200,320,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1200 + d1', 'd2'), memory_config: (38, 10, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x10>>> <br> shape: #ttnn.shape<4096x320> | tensor<[4096,320,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (128, 10, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<29x1>>> <br> shape: #ttnn.shape<920x1x1> | tensor<[920,1,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 + d1', 'd2'), memory_config: (29, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x32>>> <br> shape: #ttnn.shape<9x1024> | tensor<[9,1024,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 32, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x8>>> <br> shape: #ttnn.shape<1x64x256x256> | tensor<[1,64,256,256,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 16384 + d1 * 256 + d2', 'd3'), memory_config: (512, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x1>>> <br> shape: #ttnn.shape<1x300x1> | tensor<[1,300,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 300 + d1', 'd2'), memory_config: (10, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<11x1>>> <br> shape: #ttnn.shape<1x12x27x27> | tensor<[1,12,27,27,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 324 + d1 * 27 + d2', 'd3'), memory_config: (11, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x4>>> <br> shape: #ttnn.shape<1x32x32x128> | tensor<[1,32,32,128,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1024 + d1 * 32 + d2', 'd3'), memory_config: (32, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1280x2>>> <br> shape: #ttnn.shape<1x640x64x64> | tensor<[1,640,64,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 40960 + d1 * 64 + d2', 'd3'), memory_config: (1280, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<14x1>>> <br> shape: #ttnn.shape<1x16x27x27> | tensor<[1,16,27,27,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 432 + d1 * 27 + d2', 'd3'), memory_config: (14, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<23x1>>> <br> shape: #ttnn.shape<729x12> | tensor<[729,12,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (23, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<9x768> | tensor<[9,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x16>>> <br> shape: #ttnn.shape<1x300x512> | tensor<[1,300,512,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 300 + d1', 'd2'), memory_config: (10, 16, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x96>>> <br> shape: #ttnn.shape<14x3072> | tensor<[14,3072,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 96, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<256x4>>> <br> shape: #ttnn.shape<1x64x128x128> | tensor<[1,64,128,128,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8192 + d1 * 128 + d2', 'd3'), memory_config: (256, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<1x1x768> | tensor<[1,1,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 + d1', 'd2'), memory_config: (1, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<2x320>>> <br> shape: #ttnn.shape<64x10240> | tensor<[64,10240,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (2, 320, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x64>>> <br> shape: #ttnn.shape<1x9x2048> | tensor<[1,9,2048,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 64, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<256x8>>> <br> shape: #ttnn.shape<1x32x256x256> | tensor<[1,32,256,256,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8192 + d1 * 256 + d2', 'd3'), memory_config: (256, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<1x10x768> | tensor<[1,10,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 10 + d1', 'd2'), memory_config: (1, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x8001>>> <br> shape: #ttnn.shape<19x256008> | tensor<[19,256008,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 8001, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x1>>> <br> shape: #ttnn.shape<1x256x1x1> | tensor<[1,256,1,1,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 256 + d1 + d2', 'd3'), memory_config: (8, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<480x10>>> <br> shape: #ttnn.shape<1x64x240x320> | tensor<[1,64,240,320,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 15360 + d1 * 240 + d2', 'd3'), memory_config: (480, 10, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<23x1>>> <br> shape: #ttnn.shape<732x12> | tensor<[732,12,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (23, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<42x2>>> <br> shape: #ttnn.shape<1x24x56x56> | tensor<[1,24,56,56,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1344 + d1 * 56 + d2', 'd3'), memory_config: (42, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<60x2>>> <br> shape: #ttnn.shape<1x64x30x40> | tensor<[1,64,30,40,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1920 + d1 * 30 + d2', 'd3'), memory_config: (60, 2, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<1x9x768> | tensor<[1,9,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x96>>> <br> shape: #ttnn.shape<1x12x3072> | tensor<[1,12,3072,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 12 + d1', 'd2'), memory_config: (1, 96, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x1>>> <br> shape: #ttnn.shape<1x1x100x4> | tensor<[1,1,100,4,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 100 + d1 * 100 + d2', 'd3'), memory_config: (4, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<64x24>>> <br> shape: #ttnn.shape<1x2048x768> | tensor<[1,2048,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 2048 + d1', 'd2'), memory_config: (64, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x1>>> <br> shape: #ttnn.shape<1x1024x16x16> | tensor<[1,1024,16,16,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 16384 + d1 * 16 + d2', 'd3'), memory_config: (512, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<640x2>>> <br> shape: #ttnn.shape<1x320x64x64> | tensor<[1,320,64,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 20480 + d1 * 64 + d2', 'd3'), memory_config: (640, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x2>>> <br> shape: #ttnn.shape<1x256x64x64> | tensor<[1,256,64,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 16384 + d1 * 64 + d2', 'd3'), memory_config: (512, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (32, 20, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x40>>> <br> shape: #ttnn.shape<1280> | tensor<[1280,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 40, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x160>>> <br> shape: #ttnn.shape<1x256x5120> | tensor<[1,256,5120,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 256 + d1', 'd2'), memory_config: (8, 160, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<256x1>>> <br> shape: #ttnn.shape<1x256x32x32> | tensor<[1,256,32,32,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8192 + d1 * 32 + d2', 'd3'), memory_config: (256, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<320x1>>> <br> shape: #ttnn.shape<1x1280x8x8> | tensor<[1,1280,8,8,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 10240 + d1 * 8 + d2', 'd3'), memory_config: (320, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x40>>> <br> shape: #ttnn.shape<1x256x1280> | tensor<[1,256,1280,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 256 + d1', 'd2'), memory_config: (8, 40, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x6>>> <br> shape: #ttnn.shape<1x100x192> | tensor<[1,100,192,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 100 + d1', 'd2'), memory_config: (4, 6, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x10>>> <br> shape: #ttnn.shape<1x320> | tensor<[1,320,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 10, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<112x1>>> <br> shape: #ttnn.shape<1x128x28x28> | tensor<[1,128,28,28,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3584 + d1 * 28 + d2', 'd3'), memory_config: (112, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<14x768> | tensor<[14,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x96>>> <br> shape: #ttnn.shape<9x3072> | tensor<[9,3072,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 96, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<360x5>>> <br> shape: #ttnn.shape<1x128x90x160> | tensor<[1,128,90,160,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 11520 + d1 * 90 + d2', 'd3'), memory_config: (360, 5, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<35x1>>> <br> shape: #ttnn.shape<1x160x7x7> | tensor<[1,160,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1120 + d1 * 7 + d2', 'd3'), memory_config: (35, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<120x3>>> <br> shape: #ttnn.shape<1x64x60x80> | tensor<[1,64,60,80,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3840 + d1 * 60 + d2', 'd3'), memory_config: (120, 3, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x1>>> <br> shape: #ttnn.shape<1x4096x1> | tensor<[1,4096,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 4096 + d1', 'd2'), memory_config: (128, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x10>>> <br> shape: #ttnn.shape<300x320> | tensor<[300,320,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (10, 10, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x1>>> <br> shape: #ttnn.shape<1x16384x32> | tensor<[1,16384,32,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 16384 + d1', 'd2'), memory_config: (512, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x5>>> <br> shape: #ttnn.shape<1x1024x160> | tensor<[1,1024,160,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1024 + d1', 'd2'), memory_config: (32, 5, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x1>>> <br> shape: #ttnn.shape<1x512x32x32> | tensor<[1,512,32,32,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 16384 + d1 * 32 + d2', 'd3'), memory_config: (512, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x16>>> <br> shape: #ttnn.shape<1x32x512x512> | tensor<[1,32,512,512,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 16384 + d1 * 512 + d2', 'd3'), memory_config: (512, 16, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<112x1>>> <br> shape: #ttnn.shape<1x512x7x7> | tensor<[1,512,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3584 + d1 * 7 + d2', 'd3'), memory_config: (112, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x20>>> <br> shape: #ttnn.shape<1x640> | tensor<[1,640,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 20, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<168x2>>> <br> shape: #ttnn.shape<1x96x56x56> | tensor<[1,96,56,56,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 5376 + d1 * 56 + d2', 'd3'), memory_config: (168, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x2>>> <br> shape: #ttnn.shape<1x32x32x64> | tensor<[1,32,32,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1024 + d1 * 32 + d2', 'd3'), memory_config: (32, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x1>>> <br> shape: #ttnn.shape<100x4> | tensor<[100,4,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (4, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<256x2>>> <br> shape: #ttnn.shape<1x128x64x64> | tensor<[1,128,64,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8192 + d1 * 64 + d2', 'd3'), memory_config: (256, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x4>>> <br> shape: #ttnn.shape<1x9x128> | tensor<[1,9,128,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x24>>> <br> shape: #ttnn.shape<256x768> | tensor<[256,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<u32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x10> | tensor<[1,10,i32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, u32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<84x1>>> <br> shape: #ttnn.shape<1x192x14x14> | tensor<[1,192,14,14,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 2688 + d1 * 14 + d2', 'd3'), memory_config: (84, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<112x2>>> <br> shape: #ttnn.shape<1x64x56x56> | tensor<[1,64,56,56,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3584 + d1 * 56 + d2', 'd3'), memory_config: (112, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<7x24>>> <br> shape: #ttnn.shape<1x201x768> | tensor<[1,201,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 201 + d1', 'd2'), memory_config: (7, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x64>>> <br> shape: #ttnn.shape<9x2048> | tensor<[9,2048,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 64, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x8x1> | tensor<[1,8,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 8 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x5>>> <br> shape: #ttnn.shape<160> | tensor<[160,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 5, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<130x6>>> <br> shape: #ttnn.shape<1x4150x192> | tensor<[1,4150,192,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 4150 + d1', 'd2'), memory_config: (130, 6, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<46x6>>> <br> shape: #ttnn.shape<1445x192> | tensor<[1445,192,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (46, 6, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x8001>>> <br> shape: #ttnn.shape<19x256008> | tensor<[19,256008,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 8001, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<28x1>>> <br> shape: #ttnn.shape<1x64x14x14> | tensor<[1,64,14,14,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 896 + d1 * 14 + d2', 'd3'), memory_config: (28, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1> | tensor<[1,1024,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1024 + d1', 'd2'), memory_config: (32, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<5x24>>> <br> shape: #ttnn.shape<1x144x768> | tensor<[1,144,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 144 + d1', 'd2'), memory_config: (5, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x1>>> <br> shape: #ttnn.shape<1x128x1x1> | tensor<[1,128,1,1,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 128 + d1 + d2', 'd3'), memory_config: (4, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<224x4>>> <br> shape: #ttnn.shape<1x64x112x112> | tensor<[1,64,112,112,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 7168 + d1 * 112 + d2', 'd3'), memory_config: (224, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x256>>> <br> shape: #ttnn.shape<9x8192> | tensor<[9,8192,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 256, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<368x2>>> <br> shape: #ttnn.shape<1x512x23x40> | tensor<[1,512,23,40,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 11776 + d1 * 23 + d2', 'd3'), memory_config: (368, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<252x1>>> <br> shape: #ttnn.shape<1x576x14x14> | tensor<[1,576,14,14,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8064 + d1 * 14 + d2', 'd3'), memory_config: (252, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<12x768> | tensor<[12,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x30>>> <br> shape: #ttnn.shape<960> | tensor<[960,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 30, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x12>>> <br> shape: #ttnn.shape<384> | tensor<[384,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 12, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<14x2> | tensor<[14,2,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<46x6>>> <br> shape: #ttnn.shape<1x1445x192> | tensor<[1,1445,192,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1445 + d1', 'd2'), memory_config: (46, 6, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 40, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<210x1>>> <br> shape: #ttnn.shape<1x960x7x7> | tensor<[1,960,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 6720 + d1 * 7 + d2', 'd3'), memory_config: (210, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x40>>> <br> shape: #ttnn.shape<256x1280> | tensor<[256,1280,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 40, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x160>>> <br> shape: #ttnn.shape<1024x5120> | tensor<[1024,5120,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (32, 160, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x40>>> <br> shape: #ttnn.shape<9x1280> | tensor<[9,1280,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 40, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x4>>> <br> shape: #ttnn.shape<1x128x128x128> | tensor<[1,128,128,128,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 16384 + d1 * 128 + d2', 'd3'), memory_config: (512, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1440x3>>> <br> shape: #ttnn.shape<1x1024x45x80> | tensor<[1,1024,45,80,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 46080 + d1 * 45 + d2', 'd3'), memory_config: (1440, 3, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x10x1> | tensor<[1,10,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 10 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x16>>> <br> shape: #ttnn.shape<300x512> | tensor<[300,512,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (10, 16, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<640x1>>> <br> shape: #ttnn.shape<1x1280x16x16> | tensor<[1,1280,16,16,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 20480 + d1 * 16 + d2', 'd3'), memory_config: (640, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x96>>> <br> shape: #ttnn.shape<12x3072> | tensor<[12,3072,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 96, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<64x9>>> <br> shape: #ttnn.shape<2048x262> | tensor<[2048,262,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (64, 9, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x12x1> | tensor<[1,12,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 12 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x80>>> <br> shape: #ttnn.shape<1x1024x2560> | tensor<[1,1024,2560,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1024 + d1', 'd2'), memory_config: (32, 80, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<64x1>>> <br> shape: #ttnn.shape<1x2048x1> | tensor<[1,2048,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 2048 + d1', 'd2'), memory_config: (64, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<960x20>>> <br> shape: #ttnn.shape<1x64x480x640> | tensor<[1,64,480,640,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 30720 + d1 * 480 + d2', 'd3'), memory_config: (960, 20, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x3>>> <br> shape: #ttnn.shape<96> | tensor<[96,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 3, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x8>>> <br> shape: #ttnn.shape<256> | tensor<[256,bf16]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<29x8>>> <br> shape: #ttnn.shape<920x1x256> | tensor<[920,1,256,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 + d1', 'd2'), memory_config: (29, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<16x1>>> <br> shape: #ttnn.shape<1x512x1x1> | tensor<[1,512,1,1,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 512 + d1 + d2', 'd3'), memory_config: (16, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x48>>> <br> shape: #ttnn.shape<1x1536> | tensor<[1,1536,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 48, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<168x1>>> <br> shape: #ttnn.shape<1x384x14x14> | tensor<[1,384,14,14,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 5376 + d1 * 14 + d2', 'd3'), memory_config: (168, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x2> | tensor<[1,2,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<2x3>>> <br> shape: #ttnn.shape<1x1x60x80> | tensor<[1,1,60,80,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 60 + d1 * 60 + d2', 'd3'), memory_config: (2, 3, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<448x1>>> <br> shape: #ttnn.shape<1x2048x7x7> | tensor<[1,2048,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 14336 + d1 * 7 + d2', 'd3'), memory_config: (448, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x40>>> <br> shape: #ttnn.shape<1x4096x1280> | tensor<[1,4096,1280,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 4096 + d1', 'd2'), memory_config: (128, 40, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x32>>> <br> shape: #ttnn.shape<19x1024> | tensor<[19,1024,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 32, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<150x4>>> <br> shape: #ttnn.shape<4800x128> | tensor<[4800,128,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (150, 4, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<64x24>>> <br> shape: #ttnn.shape<2048x768> | tensor<[2048,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (64, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<46x24>>> <br> shape: #ttnn.shape<1445x768> | tensor<[1445,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (46, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<70x1>>> <br> shape: #ttnn.shape<1x320x7x7> | tensor<[1,320,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 2240 + d1 * 7 + d2', 'd3'), memory_config: (70, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<2x1>>> <br> shape: #ttnn.shape<1x64x1x1> | tensor<[1,64,1,1,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 64 + d1 + d2', 'd3'), memory_config: (2, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<600x2>>> <br> shape: #ttnn.shape<19200x64> | tensor<[19200,64,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (600, 2, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<240x3>>> <br> shape: #ttnn.shape<1x128x60x80> | tensor<[1,128,60,80,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 7680 + d1 * 60 + d2', 'd3'), memory_config: (240, 3, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<640x1>>> <br> shape: #ttnn.shape<1x640x32x32> | tensor<[1,640,32,32,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 20480 + d1 * 32 + d2', 'd3'), memory_config: (640, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x2>>> <br> shape: #ttnn.shape<1x1x30x40> | tensor<[1,1,30,40,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 30 + d1 * 30 + d2', 'd3'), memory_config: (1, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<2x24>>> <br> shape: #ttnn.shape<1x50x768> | tensor<[1,50,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 50 + d1', 'd2'), memory_config: (2, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<12x2> | tensor<[12,2,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<38x1>>> <br> shape: #ttnn.shape<1x1200x1> | tensor<[1,1200,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1200 + d1', 'd2'), memory_config: (38, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<38x10>>> <br> shape: #ttnn.shape<1200x320> | tensor<[1200,320,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (38, 10, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1> | tensor<[1,bf16]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x5>>> <br> shape: #ttnn.shape<1x1x120x160> | tensor<[1,1,120,160,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 120 + d1 * 120 + d2', 'd3'), memory_config: (4, 5, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x128>>> <br> shape: #ttnn.shape<1x9x4096> | tensor<[1,9,4096,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 128, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<240x5>>> <br> shape: #ttnn.shape<1x64x120x160> | tensor<[1,64,120,160,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 7680 + d1 * 120 + d2', 'd3'), memory_config: (240, 5, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<480x5>>> <br> shape: #ttnn.shape<1x128x120x160> | tensor<[1,128,120,160,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 15360 + d1 * 120 + d2', 'd3'), memory_config: (480, 5, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<10x768> | tensor<[10,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x128>>> <br> shape: #ttnn.shape<19x4096> | tensor<[19,4096,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 128, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<126x1>>> <br> shape: #ttnn.shape<1x144x28x28> | tensor<[1,144,28,28,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 4032 + d1 * 28 + d2', 'd3'), memory_config: (126, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<720x3>>> <br> shape: #ttnn.shape<1x512x45x80> | tensor<[1,512,45,80,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 23040 + d1 * 45 + d2', 'd3'), memory_config: (720, 3, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<768x2>>> <br> shape: #ttnn.shape<1x384x64x64> | tensor<[1,384,64,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 24576 + d1 * 64 + d2', 'd3'), memory_config: (768, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<1x8x768> | tensor<[1,8,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 8 + d1', 'd2'), memory_config: (1, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<64x40>>> <br> shape: #ttnn.shape<2048x1280> | tensor<[2048,1280,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (64, 40, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x32>>> <br> shape: #ttnn.shape<1x9x1024> | tensor<[1,9,1024,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 32, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x4>>> <br> shape: #ttnn.shape<1x14x128> | tensor<[1,14,128,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 14 + d1', 'd2'), memory_config: (1, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1920x2>>> <br> shape: #ttnn.shape<1x960x64x64> | tensor<[1,960,64,64,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 61440 + d1 * 64 + d2', 'd3'), memory_config: (1920, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x8>>> <br> shape: #ttnn.shape<1x256x256> | tensor<[1,256,256,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 256 + d1', 'd2'), memory_config: (8, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<720x10>>> <br> shape: #ttnn.shape<1x128x180x320> | tensor<[1,128,180,320,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 23040 + d1 * 180 + d2', 'd3'), memory_config: (720, 10, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x8>>> <br> shape: #ttnn.shape<256x256> | tensor<[256,256,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 8, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x80>>> <br> shape: #ttnn.shape<4096x2560> | tensor<[4096,2560,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (128, 80, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<960x1>>> <br> shape: #ttnn.shape<1x960x32x32> | tensor<[1,960,32,32,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 30720 + d1 * 32 + d2', 'd3'), memory_config: (960, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x32>>> <br> shape: #ttnn.shape<1x1000> | tensor<[1,1000,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 32, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x4>>> <br> shape: #ttnn.shape<9x128> | tensor<[9,128,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 4, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x320>>> <br> shape: #ttnn.shape<256x10240> | tensor<[256,10240,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 320, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<24x1>>> <br> shape: #ttnn.shape<1x768x8> | tensor<[1,768,8,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 768 + d1', 'd2'), memory_config: (24, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x256>>> <br> shape: #ttnn.shape<1x9x8192> | tensor<[1,9,8192,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 256, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<600x2>>> <br> shape: #ttnn.shape<1x19200x64> | tensor<[1,19200,64,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 19200 + d1', 'd2'), memory_config: (600, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x6>>> <br> shape: #ttnn.shape<192> | tensor<[192,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 6, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x344>>> <br> shape: #ttnn.shape<1x32x11008> | tensor<[1,32,11008,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 32 + d1', 'd2'), memory_config: (1, 344, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<7x32>>> <br> shape: #ttnn.shape<1x197x1024> | tensor<[1,197,1024,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 197 + d1', 'd2'), memory_config: (7, 32, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<512x1>>> <br> shape: #ttnn.shape<16384x32> | tensor<[16384,32,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (512, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x2>>> <br> shape: #ttnn.shape<300x64> | tensor<[300,64,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (10, 2, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x2>>> <br> shape: #ttnn.shape<1x64> | tensor<[1,64,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 2, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x64>>> <br> shape: #ttnn.shape<300x2048> | tensor<[300,2048,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (10, 64, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<74x7>>> <br> shape: #ttnn.shape<1x12x197x197> | tensor<[1,12,197,197,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 2364 + d1 * 197 + d2', 'd3'), memory_config: (74, 7, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<19x8>>> <br> shape: #ttnn.shape<6x100x1x256> | tensor<[6,100,1,256,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 100 + d1 + d2', 'd3'), memory_config: (19, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<19x8>>> <br> shape: #ttnn.shape<600x256> | tensor<[600,256,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (19, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<7x24>>> <br> shape: #ttnn.shape<1x193x768> | tensor<[1,193,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 193 + d1', 'd2'), memory_config: (7, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<56x4>>> <br> shape: #ttnn.shape<1x16x112x112> | tensor<[1,16,112,112,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1792 + d1 * 112 + d2', 'd3'), memory_config: (56, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x96>>> <br> shape: #ttnn.shape<10x3072> | tensor<[10,3072,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 96, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x64>>> <br> shape: #ttnn.shape<2048> | tensor<[2048,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 64, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1440x5>>> <br> shape: #ttnn.shape<1x512x90x160> | tensor<[1,512,90,160,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 46080 + d1 * 90 + d2', 'd3'), memory_config: (1440, 5, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<280x1>>> <br> shape: #ttnn.shape<1x1280x7x7> | tensor<[1,1280,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 8960 + d1 * 7 + d2', 'd3'), memory_config: (280, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x5>>> <br> shape: #ttnn.shape<144> | tensor<[144,f32]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 5, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x32x1> | tensor<[1,32,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 32 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<150x1>>> <br> shape: #ttnn.shape<1x4800x1> | tensor<[1,4800,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 4800 + d1', 'd2'), memory_config: (150, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x32x1x1> | tensor<[1,32,1,1,f32]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 32 + d1 + d2', 'd3'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<7x24>>> <br> shape: #ttnn.shape<201x768> | tensor<[201,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (7, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<64x8>>> <br> shape: #ttnn.shape<2048x256> | tensor<[2048,256,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (64, 8, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<7x32>>> <br> shape: #ttnn.shape<197x1024> | tensor<[197,1024,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (7, 32, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<7x24>>> <br> shape: #ttnn.shape<1x196x768> | tensor<[1,196,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 196 + d1', 'd2'), memory_config: (7, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x40>>> <br> shape: #ttnn.shape<1x1280> | tensor<[1,1280,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 40, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x12> | tensor<[1,12,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<168x1>>> <br> shape: #ttnn.shape<1x192x28x28> | tensor<[1,192,28,28,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 5376 + d1 * 28 + d2', 'd3'), memory_config: (168, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x128>>> <br> shape: #ttnn.shape<32x4096> | tensor<[32,4096,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 128, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<600x1>>> <br> shape: #ttnn.shape<1x19200x1> | tensor<[1,19200,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 19200 + d1', 'd2'), memory_config: (600, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<720x5>>> <br> shape: #ttnn.shape<1x256x90x160> | tensor<[1,256,90,160,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 23040 + d1 * 90 + d2', 'd3'), memory_config: (720, 5, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<29x8>>> <br> shape: #ttnn.shape<920x256> | tensor<[920,256,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (29, 8, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1280x1>>> <br> shape: #ttnn.shape<1x1280x32x32> | tensor<[1,1280,32,32,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 40960 + d1 * 32 + d2', 'd3'), memory_config: (1280, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x8>>> <br> shape: #ttnn.shape<100x1x256> | tensor<[100,1,256,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 + d1', 'd2'), memory_config: (4, 8, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x4>>> <br> shape: #ttnn.shape<1x128> | tensor<[1,128,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 4, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1000>>> <br> shape: #ttnn.shape<32x32000> | tensor<[32,32000,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1000, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<2x24>>> <br> shape: #ttnn.shape<50x768> | tensor<[50,768,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (2, 24, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x344>>> <br> shape: #ttnn.shape<32x11008> | tensor<[32,11008,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 344, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<3x12> | tensor<[3,12,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<126x1>>> <br> shape: #ttnn.shape<1x576x7x7> | tensor<[1,576,7,7,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 4032 + d1 * 7 + d2', 'd3'), memory_config: (126, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<128x10>>> <br> shape: #ttnn.shape<1x4096x320> | tensor<[1,4096,320,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 4096 + d1', 'd2'), memory_config: (128, 10, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<1x14x768> | tensor<[1,14,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 14 + d1', 'd2'), memory_config: (1, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x128>>> <br> shape: #ttnn.shape<9x4096> | tensor<[9,4096,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 128, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 14 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x4>>> <br> shape: #ttnn.shape<1x12x128> | tensor<[1,12,128,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 12 + d1', 'd2'), memory_config: (1, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x24>>> <br> shape: #ttnn.shape<1x12x768> | tensor<[1,12,768,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 12 + d1', 'd2'), memory_config: (1, 24, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x938>>> <br> shape: #ttnn.shape<9x30000> | tensor<[9,30000,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 938, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x10>>> <br> shape: #ttnn.shape<9x320> | tensor<[9,320,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 10, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x7813>>> <br> shape: #ttnn.shape<10x250002> | tensor<[10,250002,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 7813, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x20>>> <br> shape: #ttnn.shape<9x640> | tensor<[9,640,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 20, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x1>>> <br> shape: #ttnn.shape<256x32> | tensor<[256,32,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x3> | tensor<[1,3,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<120x2>>> <br> shape: #ttnn.shape<1x128x30x40> | tensor<[1,128,30,40,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3840 + d1 * 30 + d2', 'd3'), memory_config: (120, 2, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<32x32> | tensor<[32,32,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x19x1> | tensor<[1,19,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 19 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<150x16>>> <br> shape: #ttnn.shape<4800x512> | tensor<[4800,512,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (150, 16, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<46x1>>> <br> shape: #ttnn.shape<1x1445x1> | tensor<[1,1445,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 1445 + d1', 'd2'), memory_config: (46, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x1>>> <br> shape: #ttnn.shape<1x1024x1x1> | tensor<[1,1024,1,1,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 1024 + d1 + d2', 'd3'), memory_config: (32, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<600x8>>> <br> shape: #ttnn.shape<19200x256> | tensor<[19200,256,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (600, 8, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<8x32>>> <br> shape: #ttnn.shape<256x1024> | tensor<[256,1024,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (8, 32, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<4x8>>> <br> shape: #ttnn.shape<100x256> | tensor<[100,256,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (4, 8, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x25>>> <br> shape: #ttnn.shape<1x784> | tensor<[1,784,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (1, 25, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x14x1> | tensor<[1,14,1,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 14 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<150x4>>> <br> shape: #ttnn.shape<1x4800x128> | tensor<[1,4800,128,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 4800 + d1', 'd2'), memory_config: (150, 4, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1440x10>>> <br> shape: #ttnn.shape<1x256x180x320> | tensor<[1,256,180,320,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 46080 + d1 * 180 + d2', 'd3'), memory_config: (1440, 10, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<32x20>>> <br> shape: #ttnn.shape<1024x640> | tensor<[1024,640,bf16]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (32, 20, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<19> | tensor<[19,bf16]> | mapping_from: ('d0',), mapping_to: ('0', 'd0'), memory_config: (1, 1, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x128>>> <br> shape: #ttnn.shape<1x32x4096> | tensor<[1,32,4096,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 32 + d1', 'd2'), memory_config: (1, 128, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<99x7>>> <br> shape: #ttnn.shape<1x16x197x197> | tensor<[1,16,197,197,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 3152 + d1 * 197 + d2', 'd3'), memory_config: (99, 7, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x1>>> <br> shape: #ttnn.shape<1x9x1> | tensor<[1,9,1,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 9 + d1', 'd2'), memory_config: (1, 1, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x32>>> <br> shape: #ttnn.shape<1x19x1024> | tensor<[1,19,1024,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 19 + d1', 'd2'), memory_config: (1, 32, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<38x40>>> <br> shape: #ttnn.shape<1200x1280> | tensor<[1200,1280,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (38, 40, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<10x4>>> <br> shape: #ttnn.shape<300x128> | tensor<[300,128,f32]> | mapping_from: ('d0', 'd1'), mapping_to: ('d0', 'd1'), memory_config: (10, 4, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<f32> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x4>>> <br> shape: #ttnn.shape<1x32x128> | tensor<[1,32,128,f32]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 * 32 + d1', 'd2'), memory_config: (1, 4, 'tile<32x32, f32>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<1x6>>> <br> shape: #ttnn.shape<1x1x192> | tensor<[1,1,192,bf16]> | mapping_from: ('d0', 'd1', 'd2'), mapping_to: ('d0 + d1', 'd2'), memory_config: (1, 6, 'tile<32x32, bf16>', 'dram') |
| ttnn.empty | !tt.device<#device> |  | dtype: #tt.supportedDataTypes<bf16> <br> layout: #ttnn.layout<tile> <br> memory_config: #ttnn.memory_config<<interleaved>, <dram>, <<336x4>>> <br> shape: #ttnn.shape<1x96x112x112> | tensor<[1,96,112,112,bf16]> | mapping_from: ('d0', 'd1', 'd2', 'd3'), mapping_to: ('d0 * 10752 + d1 * 112 + d2', 'd3'), memory_config: (336, 4, 'tile<32x32, bf16>', 'dram') |
