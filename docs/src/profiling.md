# Profiling

## Introduction

tt-torch uses the [tt-metal Tracy fork](https://github.com/tenstorrent-metal/tracy) to collect profiling data. Tracy is a single process profiler, and uses a client-server model to trace both host calls and on-device operation performance. tt-torch implements a wrapper called `tt_profile.py` with custom orchestration logic to handle the spawning of the Tracy capture server and the client workload to be profiled, as well as report generation and data postprocessing functionality.

The output of `tt_profile.py` is a CSV report displaying a table of operations executed on device and rich timing, memory usage and configuration data associated with them.

An example of this output, for a simple addition test, is as follows:

|OP CODE                |OP TYPE      |GLOBAL CALL COUNT|DEVICE ID|ATTRIBUTES                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |MATH FIDELITY|CORE COUNT|PARALLELIZATION STRATEGY|HOST START TS|HOST END TS|HOST DURATION [ns]|DEVICE FW START CYCLE|DEVICE FW END CYCLE|OP TO OP LATENCY [ns]|OP TO OP LATENCY BR/NRISC START [ns]|DEVICE FW DURATION [ns]|DEVICE KERNEL DURATION [ns]|DEVICE KERNEL DURATION DM START [ns]|DEVICE KERNEL DURATION PER CORE MIN [ns]|DEVICE KERNEL DURATION PER CORE MAX [ns]|DEVICE KERNEL DURATION PER CORE AVG [ns]|DEVICE KERNEL FIRST TO LAST START [ns]|DEVICE BRISC KERNEL DURATION [ns]|DEVICE NCRISC KERNEL DURATION [ns]|DEVICE TRISC0 KERNEL DURATION [ns]|DEVICE TRISC1 KERNEL DURATION [ns]|DEVICE TRISC2 KERNEL DURATION [ns]|DEVICE ERISC KERNEL DURATION [ns]|DEVICE COMPUTE CB WAIT FRONT [ns]|DEVICE COMPUTE CB RESERVE BACK [ns]|DISPATCH TOTAL CQ CMD OP TIME [ns]|DISPATCH GO SEND WAIT TIME [ns]|INPUT_0_W|INPUT_0_Z|INPUT_0_Y|INPUT_0_X|INPUT_0_LAYOUT|INPUT_0_DATATYPE|INPUT_0_MEMORY        |INPUT_1_W|INPUT_1_Z|INPUT_1_Y|INPUT_1_X|INPUT_1_LAYOUT|INPUT_1_DATATYPE|INPUT_1_MEMORY        |OUTPUT_0_W|OUTPUT_0_Z|OUTPUT_0_Y|OUTPUT_0_X|OUTPUT_0_LAYOUT|OUTPUT_0_DATATYPE|OUTPUT_0_MEMORY       |METAL TRACE ID|METAL TRACE REPLAY SESSION ID|COMPUTE KERNEL SOURCE                                                                                 |COMPUTE KERNEL HASH                                   |DATA MOVEMENT KERNEL SOURCE                                                                                                                                                                                       |DATA MOVEMENT KERNEL HASH                                                                                |BRISC MAX KERNEL SIZE [B]|NCRISC MAX KERNEL SIZE [B]|TRISC 0 MAX KERNEL SIZE [B]|TRISC 1 MAX KERNEL SIZE [B]|TRISC 2 MAX KERNEL SIZE [B]|ERISC MAX KERNEL SIZE [B]|PM IDEAL [ns]|PM COMPUTE [ns]|PM BANDWIDTH [ns]|PM REQ I BW|PM REQ O BW|PM FPU UTIL (%)|NOC UTIL (%)|DRAM BW UTIL (%)|NPE CONG IMPACT (%)|LOC                                                                                     |CONST_EVAL_OP|PROGRAM_METADATA|
|-----------------------|-------------|-----------------|---------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------|----------|------------------------|-------------|-----------|------------------|---------------------|-------------------|---------------------|------------------------------------|-----------------------|---------------------------|------------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|--------------------------------------|---------------------------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|---------------------------------|---------------------------------|-----------------------------------|----------------------------------|-------------------------------|---------|---------|---------|---------|--------------|----------------|----------------------|---------|---------|---------|---------|--------------|----------------|----------------------|----------|----------|----------|----------|---------------|-----------------|----------------------|--------------|-----------------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|-------------------------|--------------------------|---------------------------|---------------------------|---------------------------|-------------------------|-------------|---------------|-----------------|-----------|-----------|---------------|------------|----------------|-------------------|----------------------------------------------------------------------------------------|-------------|----------------|
|BinaryNgDeviceOperation|tt_dnn_device|1024             |0        |{'binary_op_type': 'BinaryOpType::ADD'; 'compute_kernel_config': 'std::nullopt'; 'dtype': 'DataType::FLOAT32'; 'input_dtype': 'DataType::FLOAT32'; 'is_quant_op': 'false'; 'is_sfpu': 'true'; 'lhs_activations': 'SmallVector([])'; 'memory_config': 'MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED;buffer_type=BufferType::DRAM;shard_spec=std::nullopt;nd_shard_spec=std::nullopt;created_with_nd_shard_spec=0)'; 'post_activations': 'SmallVector([])'; 'rhs_activations': 'SmallVector([])'; 'scalar': 'std::nullopt'; 'subtile_broadcast_type': 'SubtileBroadcastType::NONE'; 'worker_grid': '{[(x=0;y=0) - (x=7;y=7)]}'}|HiFi4        |64        |                        |5281544411   |5281745609 |201198            |8692040843883        |8692040850400      |0                    |0                                   |6517                   |5889                       |5535                                |2702                                    |5805                                    |4272                                    |585                                   |5505                             |3619                              |4167                              |4451                              |588                               |                                 |                                 |                                   |                                  |                               |1        |1        |256      |256      |TILE          |FLOAT32         |DEV_1_DRAM_INTERLEAVED|1        |1        |256      |256      |TILE          |FLOAT32         |DEV_1_DRAM_INTERLEAVED|1         |1         |256       |256       |TILE           |FLOAT32          |DEV_1_DRAM_INTERLEAVED|              |                             |['ttnn/cpp/ttnn/operations/eltwise/binary_ng/device/kernels/compute/eltwise_binary_sfpu_no_bcast.cpp']|['eltwise_binary_sfpu_no_bcast/12581782860517479926/']|['ttnn/cpp/ttnn/operations/eltwise/binary_ng/device/kernels_ng/dataflow/writer_interleaved_no_bcast.cpp'; 'ttnn/cpp/ttnn/operations/eltwise/binary_ng/device/kernels_ng/dataflow/reader_interleaved_no_bcast.cpp']|['writer_interleaved_no_bcast/13543045522091367290/'; 'reader_interleaved_no_bcast/2421069877244112713/']|964                      |1716                      |2084                       |1204                       |1512                       |0                        |1            |1              |1                |[]         |[]         |0.017          |            |                |                   |loc(fused["/localdev/<USER>/test2/tt-torch/tests/torch/test_basic.py":60:0, "add"])|false        |                |


Note: Paths in this document are given relative to the repo root.

## Prerequisites

In the tt-torch building step ([Getting Started](https://docs.tenstorrent.com/tt-torch/getting_started.html#building-tt-torch)), it is required to configure your cmake build with the additional cmake directive `TT_RUNTIME_ENABLE_PERF_TRACE=ON` (i.e. run: `cmake -G Ninja -B build -DTT_RUNTIME_ENABLE_PERF_TRACE=ON`).


For a wheel install of tt-torch, some additional dependencies are needed on top of those required by tt-torch:
`pip install pyyaml click loguru pandas seaborn`


## Usage

The `tt_profile.py` tool is the recommended entrypoint for profiling workloads in tt-torch.

```
tt_profile.py [-h] [-o OUTPUT_PATH] [-p PORT] "test_command"
```
**Note: The `test_command` must be quoted!**


As a minimal example, the following command will run and tt_profile the MNIST test:
```
python tt_torch/tools/tt_profile.py "pytest -svv tests/models/mnist/test_mnist.py::test_mnist_train[single_device-full-eval]"
```

The report is created at `results/perf/device_ops_perf_trace.csv` by default, unless an output path is specified.

If tt-torch is installed using a wheel, the `tt_profile` command will be registered in the environment in which tt-torch is installed. Users can simply run `tt_profile "<pytest or other command>"` without providing a path to the profiler source file.

## Limitations

- Tracy is a single process profiler and will not work with multiprocessed workflows. This includes tests parameterized by `op_by_op_shlo` and `op_by_op_torch`, which break down a model into individual ops and run them serially in separate processes.
- To view traces, you can use `install/tt-metal/generated/profiler/.logs/tracy_profile_log_host.tracy`.
    - This is a `.tracy` file that can be consumed by the tt-metal Tracy GUI and produce visual profiling traces of host and device activity.
    - You must use the tt-metal Tracy GUI to view this file. Refer to the [GUI section](https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tools/tracy_profiler.html#gui) in the tt-metal profiling documentation. Other sections are not applicable to tt-torch profiling.

## Troubleshooting

- `tt-torch/install/tt-metal/tools/profiler/bin/capture-release -o tracy_profile_log_host.tracy -f -p 8086' timed out after X seconds`
    - Tracy uses a client-server model to communicate profiling data between the Tracy capture server and the client being profiled.
    - Communication between client and server is done on a given port (default: 8086) as specified with the `-p` option.
    - If there are multiple tracy clients/server processes active at once or previous processes are left dangling, or other processes on host occupying port 8086, there may be contention and unexpected behaviour including capture server timeouts.
    - This may be addressed by manually specifying an unused port with the -p option to `tt_profile.py`.
